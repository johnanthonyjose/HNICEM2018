<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml2/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
 <head>
  <title>IROS16</title>
  <link href="style.css" rel="stylesheet" type="text/css" media="screen" />


<script language="JavaScript">

function viewAbstract(number){
   var box = document.getElementById('Ab' + number);
   if (box.style.display == 'block'){
      box.style.display = 'none';
   }
   else if (box && box.style.display == 'none'){
      box.style.display = 'block';
   }
}
function openAllAbstracts(){
   var d = document.getElementsByTagName('div');
   var count = d.length;
   if (count == 0){return;}
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab' && d[i].style.display == 'none'){
         d[i].style.display = 'block';
      }
   }
}
function closeAllAbstracts(){
   var d = document.getElementsByTagName('div');
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab'){
         d[i].style.display = 'none';
      }
   }
}
</script>

</head>

<body leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">

<div class="c" id="TheTop">
</div>
<table border="0" cellspacing="0" cellpadding="1" width="85%" nowrap style="margin: auto">
<tr><td>
<h2>Technical Program for Wednesday October 12, 2016</h2>
</td></tr></table>

<p class="c"></p>
<div class="c">

                  <span style="color:gray ">To show or hide the keywords and abstract of a paper (if available), click on the paper title</span><br>
                  <a href="javascript:openAllAbstracts()" title="Click to open all abstracts">Open all abstracts</a>&nbsp;&nbsp;
                  <a href="javascript:closeAllAbstracts()" title="Click to close all abstracts">Close all abstracts</a>
               
</div>

<div class="c">
<table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wep1l"><b>WeP1L</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wep1l" title="Click to go to the Program at a Glance"><b>Plenary Talk 2. Tae Won Lim: Driving Together, Robot and Automobile</b></a></td>
               <td class="r">Plenary session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102941" title="Click to go to the Author Index">Oh, Jun Ho</a></td><td class="r">Korea Advanced Inst. of Sci. and Tech</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wep2r"><b>WeP2R</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wep2r" title="Click to go to the Program at a Glance"><b>Plenary Talk 3. Gill Pratt: A Billion Vehicles, Ten Trillion Miles - the
<br>Reliability Challenges of Autonomous Driving</b></a></td>
               <td class="r">Plenary session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102941" title="Click to go to the Author Index">Oh, Jun Ho</a></td><td class="r">Korea Advanced Inst. of Sci. and Tech</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weh1"><b>WeH1</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weh1" title="Click to go to the Program at a Glance"><b>Highlight 3: Motion and Path Planning</b></a></td>
               <td class="r">Highlight Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#118310" title="Click to go to the Author Index">Kyung, Ki-Uk</a></td><td class="r">ETRI</td></tr>

<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh1_01">10:00-10:05, Paper WeH1.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0884.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('884'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Probabilistic Approach to Liquid Level Detection in Cups Using an RGB-D Camera</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177123" title="Click to go to the Author Index">Do, Chau</a></td><td class="r">Albert-Ludwigs-Univ. Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#173321" title="Click to go to the Author Index">Schubert, Tobias</a></td><td class="r">AIS Univ. Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101785" title="Click to go to the Author Index">Burgard, Wolfram</a></td><td class="r">Univ. of Freiburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab884" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0884.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Domestic_Robots_and_Home_Automation" title="Click to go to the Keyword Index">Domestic Robots and Home Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> Robotic assistants have the potential to greatly improve our quality of life by supporting us in our daily activities. A service robot acting autonomously in an indoor environment is faced with very complex tasks. Consider the problem of pouring a liquid into a cup, the robot should first determine if the cup is empty or partially filled. RGB-D cameras provide noisy depth measurements which depend on the opaqueness and refraction index of the liquid. In this paper, we present a novel probabilistic approach for estimating the fill-level of a liquid in a cup using an RGB-D camera. Our approach does not make any assumptions about the properties of the liquid like its opaqueness or its refraction index. We develop a probabilistic model using features extracted from RGB and depth data. Our experiments demonstrate the robustness of our method and an improvement over the state of the art.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh1_02">10:05-10:10, Paper WeH1.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1099.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1099'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Multirobot Sequential Composition</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133915" title="Click to go to the Author Index">Wagner, Glenn</a></td><td class="r">Carnegie Mellon</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104011" title="Click to go to the Author Index">Choset, Howie</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166257" title="Click to go to the Author Index">Siravuru, Avinash</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1099" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1099.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Planning_and_Control" title="Click to go to the Keyword Index">Integrated Planning and Control</a></span><br>
                           <strong>Abstract:</strong> Conventional path planning algorithms compute a single path through the configuration space. There is no guarantee that a physical robot will be able to track the trajectory while avoiding collisions, particularly in the presence of environmental perturbations and errors in the process model. Sequential composition combines planning and control by computing a sequence of controllers to execute rather than a single trajectory, offering greater safety guarantees. In this paper, we apply sequential composition to multirobot systems in a scalable fashion using M*, an advanced multirobot path planning algorithm. Controllers will vary in size and geometry, and thus take different amounts of time to execute. To handle these differences, we introduce the time augmented joint prepares graph and the approximate time augmented joint prepares graph which simplifies implementation by discretizing time. We validate our approach in a mixed reality test framework.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh1_03">10:10-10:15, Paper WeH1.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1253.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1253'); return false" title="Click to show or hide the keywords and abstract">Watch This: Scalable Cost-Function Learning for Path Planning in Urban Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195800" title="Click to go to the Author Index">Wulfmeier, Markus</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150416" title="Click to go to the Author Index">Wang, Dominic Zeng</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106689" title="Click to go to the Author Index">Posner, Ingmar</a></td><td class="r">Oxford Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1253" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Intelligent_Transportation_Systems" title="Click to go to the Keyword Index">Intelligent Transportation Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> In this work, we present an approach to learn cost maps for driving in complex urban environments from a large number of demonstrations of human driving behaviour. The learned cost maps are constructed directly from raw sensor measurements, bypassing the effort of manually designing cost maps as well as features. When deploying the cost maps, the trajectories generated not only replicate human-like driving behaviour but are also demonstrably robust against systematic errors in putative robot configuration. To achieve this we deploy a Maximum Entropy based, non-linear IRL framework which uses Fully Convolutional Neural Networks (FCNs) to represent the cost model underlying expert driving behaviour. Using a deep, parametric approach enables us to scale efficiently to large datasets and complex behaviours while being run-time independent of dataset extent during deployment. We demonstrate scalability and performance on an ambitious dataset collected over the course of one year including more than 25k demonstration trajectories extracted from over 120km of driving and 13 different drivers. We evaluate against a carefully designed cost map and, in addition, demonstrate robustness to systematic errors by learning precise cost-maps even in the presence of system calibration perturbations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh1_04">10:15-10:20, Paper WeH1.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1259.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1259'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Predicting Actions to Act Predictably: Cooperative Partial Motion Planning with Maximum Entropy Models</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193501" title="Click to go to the Author Index">Pfeiffer, Mark</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150353" title="Click to go to the Author Index">Schwesinger, Ulrich</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172479" title="Click to go to the Author Index">Sommer, Hannes</a></td><td class="r">ETH Zürich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132521" title="Click to go to the Author Index">Galceran, Enric</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1259" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1259.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperating_Robots" title="Click to go to the Keyword Index">Cooperating Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a></span><br>
                           <strong>Abstract:</strong> This paper reports on a data-driven motion planning approach for interaction-aware, socially-compliant robot navigation among human agents. Autonomous mobile robots navigating in workspaces shared with human agents require motion planning techniques providing seamless integration and smooth navigation in such. Smooth integration in mixed scenarios calls for two abilities of the robot: predicting actions of others and acting predictably for them. The former requirement requests trainable models of agent behaviors in order to accurately forecast their actions in the future, taking into account their reaction on the robot’s decisions. A human-like navigation style of the robot facilitates other agents—most likely not aware of the underlying planning technique applied—to predict the robot motion vice versa, resulting in smoother joint navigation. The approach presented in this paper is based on a feature-based maximum entropy model and is able to guide a robot in an unstructured, real-world environment. The model is trained to predict joint behavior of heterogeneous groups of agents from onboard data of a mobile platform. We evaluate the benefit of interaction-aware motion planning in a realistic public setting with a total distance traveled of over 4 km. Interestingly the motion models learned from human-human interaction did not hold for robot-human interaction, due to the high attention and interest of pedestrians in testing basic braking functionality of the robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh1_05">10:20-10:25, Paper WeH1.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1492.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1492'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>An Information-Driven and Disturbance-Aware Planning Method for Long-Term Ocean Monitoring</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196810" title="Click to go to the Author Index">Ma, Kai-Chieh</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141677" title="Click to go to the Author Index">Liu, Lantao</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101856" title="Click to go to the Author Index">Sukhatme, Gaurav</a></td><td class="r">Univ. of Southern California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1492" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1492.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a>, <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> We propose an efficient path planning method for an autonomous underwater vehicle (AUV) used for the long-range and long-term ocean monitoring. We consider both the spatio-temporal variations of ocean phenomena and the disturbances caused by ocean currents, and design an approach integrating the information-theoretic and decision-theoretic planning frameworks. Specifically, the information-theoretic component employs a hierarchical structure and plans the most informative observation way-points for reducing the uncertainty of ocean phenomena modeling and prediction; whereas the decision-theoretic component plans local motions by taking into account the non-stationary ocean current disturbances. We validated the method through simulations with real ocean data.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weh2"><b>WeH2</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weh2" title="Click to go to the Program at a Glance"><b>Highlight 4: Bio-Related and Medical Robotics</b></a></td>
               <td class="r">Highlight Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#106263" title="Click to go to the Author Index">Yi, Byung-Ju</a></td><td class="r">Hanyang Univ</td></tr>

<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh2_01">10:00-10:05, Paper WeH2.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0163.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('163'); return false" title="Click to show or hide the keywords and abstract">Mroberto: A Modular Millirobot for Swarm-Behavior Studies</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195287" title="Click to go to the Author Index">Kim, Justin Yonghui</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195289" title="Click to go to the Author Index">Colaco, Tyler</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194723" title="Click to go to the Author Index">Kashino, Zendai</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104747" title="Click to go to the Author Index">Nejat, Goldie</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113747" title="Click to go to the Author Index">Benhabib, Beno</a></td><td class="r">Univ. of Toronto</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab163" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a></span><br>
                           <strong>Abstract:</strong> Millirobots have increasingly become popular over the past several years, especially for swarm-behavior studies, allowing researchers to run experiments with a large number of units in limited workspaces. However, as these robots have become smaller in size, their sensory capabilities and battery life have been reduced. A number of these have also been customized, with few off-the shelf components, exhibiting integral (i.e., non-modular) designs. In response to the above concerns, this paper presents a novel open-source millirobot with a modular design based on the use of easily sourced elements and off-the-shelf components. The proposed milli-robot-Toronto (mROBerTO), is a 16×16 mm^2 robot with a variety of sensors (including proximity, IMU, compass, ambient light, and camera). mROBerTO is capable of formation control using an IR emitter and detector add-on. It can also communicate via Bluetooth Smart, ANT+, or both concurrently. It is equipped with an ARM processor for handling complex tasks and has a flash memory of 256 KB with over-the-air programming capability.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh2_02">10:05-10:10, Paper WeH2.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0225.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('225'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Design of a Multilink-Articulated Wheeled Inspection Robot for Winding Pipelines: AIRo-II</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146708" title="Click to go to the Author Index">Kakogawa, Atsushi</a></td><td class="r">Ritsumeikan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101808" title="Click to go to the Author Index">Ma, Shugen</a></td><td class="r">Ritsumeikan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab225" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0225.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> This paper presents a multilink-articulated robot with omni and hemispherical wheels (AIRo-II) for inspecting and exploring winding pipes. To quickly adapt to winding pipes, holonomic rolling movement without moving forward and backward is more useful. However, this requires the replacement of driving actuators with rolling actuators at the expense of the driving force. In this paper, we investigate the possibility of high maneuverability of multilink-articulated robots in winding pipes by using less actuators and by designing spring joints. We further validate this by experimental verification.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh2_03">10:10-10:15, Paper WeH2.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1429.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1429'); return false" title="Click to show or hide the keywords and abstract">New Kinematic Multi-Section Model for Catheter Contact Force Estimation and Steering</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169486" title="Click to go to the Author Index">Back, Jungwhan</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192606" title="Click to go to the Author Index">Lindenroth, Lukas</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184537" title="Click to go to the Author Index">Karim, Rashed</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101975" title="Click to go to the Author Index">Althoefer, Kaspar</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178727" title="Click to go to the Author Index">Rhode, Kawal</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104575" title="Click to go to the Author Index">Liu, Hongbin</a></td><td class="r">Department of Informatics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1429" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a></span><br>
                           <strong>Abstract:</strong> Contact force play a significant role on success of the cardiac ablation. However it is still challenging to estimate contact force when catheter is under large bending and multiple contacts. This paper develops a new multi-section static model of tendon driven catheters for both real-time intrinsic force sensing and interaction control. The model allows the external force to be applied at arbitrary location on the catheter and can also cope with multiple contacts. In this study, we validated the model using a robotic platform, which steers a catheter consisting of 4 tendons with tension feedback. The experimental results show that the model can accurately predict the catheter shape with the effect of internal friction and large deflection. The position difference between measured and estimated was 2.5mm. Based on the catheter model, we developed an algorithm to estimate the contact force based on the catheter tip tracking and tension feedback. The validation results show that 3-dimensional contact forces can be estimated accurately using the proposed method. The magnitude of contact force error was 0.0117N with 400Hz update rate.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh2_04">10:15-10:20, Paper WeH2.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1457.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1457'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Cockroach-Inspired Winged Robot Reveals Principles of Ground-Based Dynamic Self-Righting</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157055" title="Click to go to the Author Index">Li, Chen</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132935" title="Click to go to the Author Index">Kessens, Chad C.</a></td><td class="r">United States Army Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196770" title="Click to go to the Author Index">Young, Austin</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101253" title="Click to go to the Author Index">Fearing, Ronald</a></td><td class="r">Univ. of California at Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108950" title="Click to go to the Author Index">Full, Robert</a></td><td class="r">Univ. of California at Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1457" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1457.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a></span><br>
                           <strong>Abstract:</strong> Animals and robots alike face challenges of flipping-over as they move in complex terrain. Small insects like cockroaches can rapidly right themselves when upside down, yet small fast-running legged robots are much less capable of ground-based self-righting. Inspired by the discoid cockroach that opens its wings to push against the ground to self-right, we designed actuated wings for robot self-righting based on recently-developed rounded shells for obstacle traversal [1]. We measured the self-righting performance of a robot using these actuated wings, and systematically studied the effects and trade-offs of wing opening magnitude, speed, symmetry, and wing geometry. Our study provided a proof-of-concept that robots can take advantage of an existing body structure (rounded shell) in novel ways (as actuated wings) to serve new locomotor functions, analogous to biological exaptations [2]. Our results demonstrated that the robot self-rights dynamically, with active wing pushing followed by passive falling, and benefits from increasing kinetic energy by pushing faster and longer. Our experiments also showed that opening both wings asymmetrically increases righting probability at low wing opening magnitudes.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weh2_05">10:20-10:25, Paper WeH2.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1703.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1703'); return false" title="Click to show or hide the keywords and abstract">Skeletal Structure with Artificial Perspiration for Cooling by Latent Heat for Musculoskeletal Humanoid Kengoro</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156135" title="Click to go to the Author Index">Kozuki, Toyotaka</a></td><td class="r">Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117940" title="Click to go to the Author Index">Hirose, Toshinori</a></td><td class="r">Panasonic Corp. / the Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156149" title="Click to go to the Author Index">Shirai, Takuma</a></td><td class="r">Tokyo Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182120" title="Click to go to the Author Index">Nakashima, Shinsuke</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151588" title="Click to go to the Author Index">Asano, Yuki</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135552" title="Click to go to the Author Index">Kakiuchi, Yohei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106350" title="Click to go to the Author Index">Okada, Kei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106348" title="Click to go to the Author Index">Inaba, Masayuki</a></td><td class="r">The Univ. of Tokyo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1703" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tendon_Wire_Mechanisms" title="Click to go to the Keyword Index">Tendon/Wire Mechanisms</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> In this paper we propose a novel method to utilize the skeletal structure not only for supporting force but can also cool by using latent heat. To enable robots using motors to exert great power, cooling the motor is known to be effective to prevent motors from burning out. Considering the fact that the spatial constraint is severe and that the surface of the skeletal structure is not used effectively in humanoid robots, we propose a skeletal structure with bi-layer porous that is fabricated with laser sintering using aluminum, that can not only function as skeletal frame but also help cool the motors by latent heat through artificial perspiration. First we show the detail of the fabrication process of the bi-layer porous structure that prevents water leakage, then we show the strength of the structure, evaluate the cooling effect of the system. In the end the proposed structure is applied to the skeletal frame in musculoskeletal humanoid Kengoro enabling the robot to perform powerful motions under low gear ratio configuration.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wet11"><b>WeT11</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wet11" title="Click to go to the Program at a Glance"><b>Advanced Automation/Sensor Fusion</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102761" title="Click to go to the Author Index">Maeda, Yusuke</a></td><td class="r">Yokohama National Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#111300" title="Click to go to the Author Index">Bachrach, Jonathan</a></td><td class="r">Uc Berkeley</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_01">10:30-10:31, Paper WeT11.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0053.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('53'); return false" title="Click to show or hide the keywords and abstract">A Novel Online Model-Based Wind Estimation Approach for Quadrotor Micro Air Vehicles Using Low Cost MEMS IMUs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195124" title="Click to go to the Author Index">Sikkel, Lodewijk Nicolaas Constantijn</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131959" title="Click to go to the Author Index">de Croon, Guido</a></td><td class="r">TU Delft / ESA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131961" title="Click to go to the Author Index">De Wagter, Christophe</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187837" title="Click to go to the Author Index">Chu, Qi Ping</a></td><td class="r">Delft Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab53" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> This work extends the drag-force enhanced quadrotor model by denoting the free stream air velocity as the difference between the ground speed and the wind speed. It is demonstrated that a relatively simple nonlinear observer is capable of estimating the local wind components, provided accelerometer and GPS-velocity measurements are available. We perform a wind tunnel experiment at various wind speeds using a quadrotor vehicle with a low-cost Inertial Measurement Unit (IMU) and a motion tracking system to provide accurate ground speed measurements. It is shown that the onboard Extended Kalman Filter (EKF) accurately estimates the wind components.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_02">10:31-10:32, Paper WeT11.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0195.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('195'); return false" title="Click to show or hide the keywords and abstract">Urban Scene Segmentation with Laser-Constrained CRFs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184144" title="Click to go to the Author Index">De Alvis, Charika</a></td><td class="r">Univ. of Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142888" title="Click to go to the Author Index">Ott, Lionel</a></td><td class="r">Univ. of Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101688" title="Click to go to the Author Index">Ramos, Fabio</a></td><td class="r">Univ. of Sydney</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab195" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> Robots typically possess sensors of different modalities, such as colour cameras, inertial measurement units, and 3D laser scanners. Often, solving a particular problem becomes easier when more than one modality is used. However, while there are undeniable benefits to combine sensors of different modalities the process tends to be complicated. Segmenting scenes observed by the robot into a discrete set of classes is a central requirement for autonomy as understanding the scene is the first step to reason about future situations. Scene segmentation is commonly performed using either image data or 3D point cloud data. In computer vision many successful methods for scene segmentation are based on conditional random fields (CRF) where the maximum a posteriori (MAP) solution to the segmentation can be obtained by inference. In this paper we devise a new CRF inference method for scene segmentation that incorporates global constraints, enforcing the sets of nodes are assigned the same class label. To do this efficiently, the CRF is formulated as a relaxed quadratic program whose MAP solution is found using a gradient-based optimisation approach. The proposed method is evaluated on images and 3D point cloud data gathered in urban environments where image data provides the appearance features needed by the CRF, while the 3D point cloud data provides global spatial constraints over sets of nodes. Comparisons with belief propagation, conventional quadratic programming relaxation, and higher order potential CRF show the benefits of the proposed method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_03">10:32-10:33, Paper WeT11.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0209.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('209'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Delta DLP 3D Printing with Large Size</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195500" title="Click to go to the Author Index">Wu, Chenming</a></td><td class="r">Tsinghua Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195501" title="Click to go to the Author Index">Yi, Ran</a></td><td class="r">Tsinghua Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129927" title="Click to go to the Author Index">Liu, Yong-Jin</a></td><td class="r">Tsinghua Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195509" title="Click to go to the Author Index">He, Ying</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124491" title="Click to go to the Author Index">Wang, Charlie C.L.</a></td><td class="r">Delft Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab209" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0209.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a></span><br>
                           <strong>Abstract:</strong> We present a delta DLP 3D printer with large size in this paper. Compared with traditional DLP 3D printers that use a low-cost off-the-shelf consumer projector and a single vertical carriage, the platform of our delta DLP 3D printer can also move horizontally in the plane. We show that this structure allows the printer to have a larger printing area than the projection area of a projector. Our system can print 3D models much larger than traditional DLP 3D printers. The major challenge to realize delta 3D printing with large size comes from how to partition an arbitrary planar polygonal shape (possibly with holes or multiple disjoint polygons) into a minimum number of rectangles with fixed size, which is NP-hard. We propose a simple yet efficient approximation algorithm to solve this problem. The time complexity of our algorithm is O(n^3log n), where n is the number of edges in the polygonal shape. A physical prototype system is built and several large 3D models with complex geometric structures have been printed as examples to demonstrate the effectiveness of our approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_04">10:33-10:34, Paper WeT11.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0211.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('211'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Pole-Based Localization for Autonomous Vehicles in Urban Scenarios</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195101" title="Click to go to the Author Index">Spangenberg, Robert</a></td><td class="r">Freie Univ. Berlin</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101824" title="Click to go to the Author Index">Goehring, Daniel</a></td><td class="r">Freie Univ. Berlin</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107636" title="Click to go to the Author Index">Rojas, Raul</a></td><td class="r">Freie Univ. Berlin</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab211" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0211.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Localization is a key capability for autonomous vehicles especially in urban scenarios. We propose the use of pole-like landmarks as primary features in these environments, as they are distinct, long-term stable and can be detected reliably with a stereo camera system. Furthermore, the resulting map representation is memory efficient, allowing for easy storage and on-line updates. The localization is performed in real-time by a stereo camera system as a main sensor, using vehicle odometry and an off-the-shelf GPS as secondary information sources. Localization is performed by a particle filter approach, coupled with an Kalman filter for robustness and sensor fusion. This leads to a lateral accuracy below 20 cm in various urban test areas. The system has been included in our autonomous test vehicle and successfully demonstrated the full loop from mapping to autonomous driving.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_05">10:34-10:35, Paper WeT11.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0380.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('380'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>From CAD Models to Toy Brick Sculptures: A 3D Block Printer</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102761" title="Click to go to the Author Index">Maeda, Yusuke</a></td><td class="r">Yokohama National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195740" title="Click to go to the Author Index">Nakano, Ojiro</a></td><td class="r">Yokohama National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130205" title="Click to go to the Author Index">Maekawa, Takashi</a></td><td class="r">Yokohama National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195739" title="Click to go to the Author Index">Maruo, Shoji</a></td><td class="r">Yokohama National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab380" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0380.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manipulation_and_Compliant_Assembly" title="Click to go to the Keyword Index">Manipulation and Compliant Assembly</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> This paper presents a robotic 3D printer: a robot system that can assemble toy block sculptures from their 3D CAD models. In this system, a 3D CAD model is automatically converted to a block model consisting of primitive toy blocks. Then an assembly plan of the block model is automatically generated, if feasible. According to the plan, an industrial robot assembles a block sculpture layer by layer from bottom to top. We demonstrate successful assembly of several block sculptures.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_06">10:35-10:36, Paper WeT11.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0444.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('444'); return false" title="Click to show or hide the keywords and abstract">Interlocking Structure Assembly with Voxels</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184071" title="Click to go to the Author Index">Zhang, Yinan</a></td><td class="r">Dartmouth Coll</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107151" title="Click to go to the Author Index">Balkcom, Devin</a></td><td class="r">Dartmouth Coll</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab444" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manipulation_and_Compliant_Assembly" title="Click to go to the Keyword Index">Manipulation and Compliant Assembly</a>, <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Construction" title="Click to go to the Keyword Index">Robotics in Construction</a>, <a href="IROS16_KeywordIndexMedia.html#Animation_and_Simulation" title="Click to go to the Keyword Index">Animation and Simulation</a></span><br>
                           <strong>Abstract:</strong> This paper explores the problem of building a structure of a desired shape, using re-usable interlocking blocks. Blocks are cubes; we make use of nine different types of cubes, each with different arrangements of male and female connectors on the six sides of the cube. The desired shape is specified by a set of voxels. We propose an algorithm that lays out cubes in a particular pattern to give the desired shape and gives a fairly simple assembly order.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_07">10:36-10:37, Paper WeT11.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0455.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('455'); return false" title="Click to show or hide the keywords and abstract">Real-Time Probabilistic Fusion of Sparse 3D LIDAR and Dense Stereo</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130517" title="Click to go to the Author Index">Maddern, Will</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105828" title="Click to go to the Author Index">Newman, Paul</a></td><td class="r">Oxford Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab455" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> Real-time 3D perception is critical for localisation, mapping, path planning and obstacle avoidance for mobile robots and autonomous vehicles. For outdoor operation in real-world environments, 3D perception is often provided by sparse 3D LIDAR scanners, which provide accurate but low-density depth maps, and dense stereo approaches, which require significant computational resources for accurate results. Here, taking advantage of the complementary error characteristics of LIDAR range sensing and dense stereo, we present a probabilistic method for fusing sparse 3D LIDAR data with stereo images to provide accurate dense depth maps and uncertainty estimates in real-time. We evaluate the method on data collected from a small urban autonomous vehicle and the KITTI dataset, providing accuracy results competitive with state-of-the-art stereo approaches and credible uncertainty estimates that do not misrepresent the true errors, and demonstrate real-time operation on a range of low-power GPU systems.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_08">10:37-10:38, Paper WeT11.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0537.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('537'); return false" title="Click to show or hide the keywords and abstract">A Nonparametric Belief Solution to the Bayes Tree</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168768" title="Click to go to the Author Index">Fourie, Dehann</a></td><td class="r">Massachusetts Inst. of Tech. and Woods Hole Oceanograph</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107631" title="Click to go to the Author Index">Leonard, John</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104298" title="Click to go to the Author Index">Kaess, Michael</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab537" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> We relax parametric inference to a non-parametric representation towards more general solutions on factor graphs. We use the Bayes tree factorization to maximally exploit structure in the joint posterior thereby minimizing computation. We use kernel density estimation to represent a wider class of constraint beliefs, which naturally encapsulates multi-hypothesis and non-Gaussian inference. A variety of new uncertainty models can now be directly applied in the factor graph, and have the solver recover a potentially multi-modal posterior. For example, data association for loop closure proposals can be incorporated at inference time without further modifications to the factor graph. Our implementation of the presented algorithm is written entirely in the Julia language, exploiting high performance parallel computing. We show a larger scale use case with the well known Victoria park mapping and localization data set inferring over uncertain loop closures.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_09">10:38-10:39, Paper WeT11.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0673.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('673'); return false" title="Click to show or hide the keywords and abstract">A Novel Contouring Error Estimation for Position-Loop Cross-Coupled Control of Biaxial Servo Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195199" title="Click to go to the Author Index">Shi, Ran</a></td><td class="r">School of Mechatronics Engineering and Automation, Harbin Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100484" title="Click to go to the Author Index">Lou, Yunjiang</a></td><td class="r">Harbin Inst. of Tech. Shenzhen Graduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196123" title="Click to go to the Author Index">Shao, Yongqi</a></td><td class="r">School of Mechatronics Engineering and Automation, Harbin Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108217" title="Click to go to the Author Index">Li, Jiangang</a></td><td class="r">Harbin Inst. of Tech. Shenzhen Graduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#121779" title="Click to go to the Author Index">Chen, Haoyao</a></td><td class="r">Harbin Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab673" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> How to achieve the required contouring tracking accuracy especially during high-speed and large-curvature contouring tasks, has always been an important problem in manufacturing applications. In this paper, a contouring error estimation method based on natural local approximation is used, and then the position-loop cross-coupled controller is proposed to reduce the estimated contouring error. The effectiveness and superiority of the natural local approximation method using on the position-loop cross-coupled control scheme are demonstrated through experiments on a biaxial linear motor drive servo system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_10">10:39-10:40, Paper WeT11.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0750.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('750'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Event-Driven Ball Detection and Gaze Fixation in Clutter</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130518" title="Click to go to the Author Index">Glover, Arren</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115929" title="Click to go to the Author Index">Bartolozzi, Chiara</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab750" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0750.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Neurorobotics" title="Click to go to the Keyword Index">Neurorobotics</a></span><br>
                           <strong>Abstract:</strong> The fast temporal-dynamics and intrinsic motion segmentation of event-based cameras are beneficial for robotic tasks that require low-latency visual tracking and control, for example a robot catching a ball. When the event-driven iCub humanoid robot grasps an object its head and torso move, inducing camera motion, and tracked objects become no longer trivially segmented amongst the mass of background clutter. Current event-based tracking algorithms have mostly considered stationary cameras that have clean event-streams with minimal clutter. This paper introduces novel methods to extend the Hough-based circle detection algorithm using optical flow information that is readily extracted from the spatio-temporal event space. Results indicate the proposed directed-Hough algorithm is more robust to other moving objects and the background event-clutter. Finally, we demonstrate successful on-line robot control and gaze following on the iCub robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_11">10:40-10:41, Paper WeT11.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0794.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('794'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Need-Based Coordination for Decentralized High-Level Robot Control</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164268" title="Click to go to the Author Index">Wong, Kai Weng</a></td><td class="r">Cornell Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103643" title="Click to go to the Author Index">Kress-Gazit, Hadas</a></td><td class="r">Cornell Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab794" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0794.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Formal_Methods_in_Robotics_and_Automation" title="Click to go to the Keyword Index">Formal Methods in Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a></span><br>
                           <strong>Abstract:</strong> We consider multiple robots operating in a shared workspace, each given a high-level task specification in the form of Linear Temporal Logic (LTL) formulas. The robots have no a priori knowledge about the tasks of the other robots and might run into conflicts during task execution. In this work, we develop algorithms that allow the robots to autonomously resolve conflicts and complete their tasks with correctness guarantees, when possible. <p>In our approach, the robots autonomously detect conflicts and trigger coordination within the subgroup of robots in conflict. The need-based coordination initiates the execution of a global robot controller on each robot in the subgroup until the robots all reach their current goals. The subgroup of robots then return to their local controllers and continue their execution. Our approach captures both the advantage of decentralized robot control and that of centralized robot control. The transition between centralized and decentralized robot control is seamless with guarantees provided.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_12">10:41-10:42, Paper WeT11.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0888.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('888'); return false" title="Click to show or hide the keywords and abstract">Automatic Configuration of ROS Applications for Near-Optimal Performance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196256" title="Click to go to the Author Index">Cano, José</a></td><td class="r">The Univ. of Edinburgh</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180203" title="Click to go to the Author Index">Bordallo, Alejandro</a></td><td class="r">The Univ. of Edinburgh</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195845" title="Click to go to the Author Index">Nagarajan, Vijay</a></td><td class="r">Univ. of Edinburgh</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114132" title="Click to go to the Author Index">Ramamoorthy, Subramanian</a></td><td class="r">The Univ. of Edinburgh</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103221" title="Click to go to the Author Index">Vijayakumar, Sethu</a></td><td class="r">Univ. of Edinburgh</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab888" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Performance_Evaluation_and_Benchmarking" title="Click to go to the Keyword Index">Performance Evaluation and Benchmarking</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a></span><br>
                           <strong>Abstract:</strong> The performance of a ROS application is a function of the individual performance of its constituent nodes. Since ROS nodes are typically configurable (parameterised), the specific parameter values adopted will determine the level of performance generated. In addition, ROS applications may be distributed across multiple computation devices, thus providing different options for node allocation. We address two configuration problems that the typical ROS user is confronted with: i) Determining parameter values and node allocations for maximising performance; ii) Determining node allocations for minimising hardware resources that can guarantee the desired performance. We formalise these problems with a mathematical model, a constrained form of a multiple-choice multiple knapsack problem. We propose a greedy algorithm for optimising each problem, using linear regression for predicting the performance of an individual ROS node over a continuum set of parameter combinations. We evaluate the algorithms through simulation and we validate them in a real ROS scenario, showing that the expected performance levels only deviate from the real measurements by an average of 2.5%.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_13">10:42-10:43, Paper WeT11.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1052.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1052'); return false" title="Click to show or hide the keywords and abstract">Enabling Intelligent Energy Management for Robots Using Publicly Available Maps</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196227" title="Click to go to the Author Index">Bartlett, Oliver</a></td><td class="r">Oxford Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160176" title="Click to go to the Author Index">Gurau, Corina</a></td><td class="r">Oxford Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179175" title="Click to go to the Author Index">Marchegiani, Letizia</a></td><td class="r">Oxford Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106689" title="Click to go to the Author Index">Posner, Ingmar</a></td><td class="r">Oxford Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1052" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Performance_Evaluation_and_Benchmarking" title="Click to go to the Keyword Index">Performance Evaluation and Benchmarking</a></span><br>
                           <strong>Abstract:</strong> Energy consumption represents one of the most basic constraints for mobile robot autonomy. We propose a new framework to predict energy consumption using information extracted from publicly available maps. This method avoids having to model internal robot configurations, which are often unavailable, while still providing invaluable predictions for both explored and unexplored trajectories. Our approach uses a heteroscedastic Gaussian Process to model the power consumption, which explicitly accounts for variance due to exogenous latent factors such as traffic and weather conditions. We evaluate our framework on 30km of data collected from a city centre environment with a mobile robot travelling on pedestrian walkways. Results across five different test routes show an average difference between predicted and measured power consumption of 3.3%, leading to an average error of 6.6% on predictions of energy consumption. The distinct advantage of our model is our ability to predict measurement variance. The variance predictions improved by 84.3% over a benchmark.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_14">10:43-10:44, Paper WeT11.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1149.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1149'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>JITPCB</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111300" title="Click to go to the Author Index">Bachrach, Jonathan</a></td><td class="r">Uc Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155271" title="Click to go to the Author Index">Haldane, Duncan</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196513" title="Click to go to the Author Index">Biancolin, David</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196551" title="Click to go to the Author Index">Lin, Richard</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148034" title="Click to go to the Author Index">Buchan, Austin D</a></td><td class="r">UC Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1149" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1149.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Architectures__Protocols_And_Middle_Ware" title="Click to go to the Keyword Index">Architectures, Protocols And Middle-Ware</a>, <a href="IROS16_KeywordIndexMedia.html#Programming_Environments" title="Click to go to the Keyword Index">Programming Environments</a>, <a href="IROS16_KeywordIndexMedia.html#Cellular_and_Modular_Robots" title="Click to go to the Keyword Index">Cellular and Modular Robots</a></span><br>
                           <strong>Abstract:</strong> Commercialization of desktop milling machines has made rapid Printed Circuit Board (PCB) fabrication accessible. Unfortunately, PCB design for embedded and robotic systems is still a tedious and time consuming activity. In this paper, we present a technique, Just In Time Printed Circuit Board (JITPCB) for designing PCB systems at speeds commensurate with the capability of desktop PCB milling machines. We propose designing boards by writing software circuit generators that wire together and lay out circuit components in a hierarchical and reusable fashion. We have developed a declarative design mechanism allowing users to specify desired input and output peripherals and well as application code. Given this input, our system produces a complete working circuit board design, along with necessary initialization and networking code. Our system is an open framework that allows users to create a set of highly reusable parametric hardware/software modules. We demonstrate our approach by showing some common robotics applications designed with JITPCB to show its utility and generality.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_15">10:44-10:45, Paper WeT11.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1223.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1223'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Duo-VIO: Fast, Light-Weight, Stereo Inertial Odometry</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196532" title="Click to go to the Author Index">de Palezieux, Nicolas</a></td><td class="r">ETH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171324" title="Click to go to the Author Index">Naegeli, Tobias</a></td><td class="r">ETH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170316" title="Click to go to the Author Index">Hilliges, Otmar</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1223" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1223.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> We present a Visual Inertial Odometry system that enables the autonomous flight of Micro Aerial Vehicles in GPS denied and unstructured environments. The system relies on commercially available and affordable hardware both for sensing and computation. The algorithm runs in real time on an ARM based embedded micro-computer on-board an MAV. In experiments, we demonstrate the performance of the system both indoors and outdoors, in hand held an in-flight scenarios. The achieved accuracy of the experiments is competitive with other research which uses custom designed hardware and desktop-grade processors.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_16">10:45-10:46, Paper WeT11.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1279.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1279'); return false" title="Click to show or hide the keywords and abstract">Context-Based Detection of Pedestrian Crossing Intention for Autonomous Driving in Urban Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196369" title="Click to go to the Author Index">Schneemann, Friederike</a></td><td class="r">Audi Electronics Venture GmbH, Gaimersheim</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196370" title="Click to go to the Author Index">Heinemann, Patrick</a></td><td class="r">Audi Electronics Venture GmbH, Gaimersheim</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1279" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Behaviour_Based_Systems" title="Click to go to the Keyword Index">Behaviour-Based Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a></span><br>
                           <strong>Abstract:</strong> This paper focuses on the detection of pedestrian crossing intention to improve the situation awareness for autonomous driving in urban environments. A new definition of pedestrian crossing intention is discussed, which allows self-driving vehicles to identify pedestrians, whose intended actions are relevant for the own behavior planning, at an early stage. We propose a context-based feature descriptor in combination with a SVM classifier for detecting this. The descriptor captures the movement of a pedestrian relative to the road and the spatial layout of other scene elements in a generic manner. The performance of the feature descriptor is evaluated in relation to various SVM setups. Feasibility of the approach is demonstrated with data captured on-board of a vehicle in real inner-city traffic. The evaluation of the classification results confirms, that context-based data is a promising indicator for pedestrian crossing intention and that the proposed feature descriptor is capable of representing this. It is further shown that a lack of information about the pedestrian’s posture and head movement results in a delayed detection of the pedestrians changing their crossing intention when compared to a human observer.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_17">10:46-10:47, Paper WeT11.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1433.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1433'); return false" title="Click to show or hide the keywords and abstract">Real-Time Contamination Modeling for Robotic Health Care Support</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196717" title="Click to go to the Author Index">Kraft, Kory</a></td><td class="r">Oregon State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196722" title="Click to go to the Author Index">Chu, Tiffany</a></td><td class="r">California State Univ. Stanislaus</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196724" title="Click to go to the Author Index">Hansen, Patrick</a></td><td class="r">Univ. of Notre Dame</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104078" title="Click to go to the Author Index">Smart, William</a></td><td class="r">Oregon State Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1433" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a></span><br>
                           <strong>Abstract:</strong> Real-time contamination monitoring in health care facilities would allow medical teams to take appropriate actions to carefully enter, avoid, or decontaminate contaminated areas, reducing infection risk for themselves and their patients. In this paper, we demonstrate and evaluate the first end-to-end, real-time contamination tracking system for robotic health care support. The system models contamination of the environment and people, directs decontamination efforts of a simulated scrubber robot, and alerts users when nearing contaminated areas. We outline our transmission model design choices, as based on Ebola virus disease, and evaluate the system against the spread of a physical substance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_18">10:47-10:48, Paper WeT11.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1645.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1645'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A CRF That Combines Touch and Vision for Haptic Mapping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184961" title="Click to go to the Author Index">Shenoi, Ashwin A</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122308" title="Click to go to the Author Index">Bhattacharjee, Tapomayukh</a></td><td class="r">Georgia-Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111654" title="Click to go to the Author Index">Kemp, Charlie</a></td><td class="r">Georgia Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1645" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1645.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Robots could benefit from maps that represent haptic properties of their surroundings. By touching locations with tactile sensors, robots can infer haptic properties of their surroundings, but touching all locations would be prohibitive. We present an algorithm that uses touch and vision to efficiently produce a dense haptic map. Our approach assumes that surfaces near a robot that are visually similar are more likely to have similar haptic properties. Given an image and sparse haptic labels, our algorithm uses a dense conditional random field (CRF) to produce a haptic map with labels for all image pixels. In an evaluation using images with idealized haptic labels, our algorithm substantially outperformed a previous algorithm. It also enabled a real robot to label leaves and trunks after reaching into artificial foliage. In addition, we show that our algorithm can use a convolutional neural network (CNN) for material recognition from Bell et al.[1] that we modified and fine-tuned. This CNN provides estimated probabilities for haptic labels using vision alone, which enables the algorithm to infer haptic labels before the robot makes contact with anything. In our evaluation, using this CNN further improved performance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_19">10:48-10:49, Paper WeT11.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1647.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1647'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Strategy-Based Robotic Item Picking from Shelves</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142676" title="Click to go to the Author Index">Zhu, Haifei</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191448" title="Click to go to the Author Index">Kok, Yuan Yik</a></td><td class="r">NANYANG Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115839" title="Click to go to the Author Index">Causo, Albert</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191364" title="Click to go to the Author Index">Chee, Keai Jiang</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140716" title="Click to go to the Author Index">Zou, Yuhua</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191415" title="Click to go to the Author Index">Al-Jufry, Sayyed Omar Kamal</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135573" title="Click to go to the Author Index">Liang, Conghui</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100042" title="Click to go to the Author Index">Chen, I-Ming</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101722" title="Click to go to the Author Index">Cheah, C. C.</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100138" title="Click to go to the Author Index">Low, K. H.</a></td><td class="r">Nanyang Tech. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1647" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1647.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a></span><br>
                           <strong>Abstract:</strong> Automating item picking in the e-commerce warehouse is pressing but challenging, due to a massive variety of items, tight environmental constraints and item location uncertainty. In this paper, we present an effective and efficient strategy-based planning approach to implement the robotic picking from shelves for e-commerce. Making full advantage of a gripper with multiple securing methods, differentiated strategies are modeled as picking primitives with different securing methods. A strategy generator is proposed to produce feasible potential pickings as quickly and as successfully as possible. A strategy evaluator considering reachability, collision, object-bias preference and the securing performance is also presented for ranking the picking strategies. Experiments were conducted to validate that the robotic picker is able to plan a picking strategy within 2 ms and pick daily items from the shelves with an average success rate of 68%.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_20">10:49-10:50, Paper WeT11.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0491.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('491'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Real Time Rotation Estimation for Dense Depth Senors in Piece-Wise Planar Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189093" title="Click to go to the Author Index">Zhou, Yi</a></td><td class="r">Australian National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123271" title="Click to go to the Author Index">Kneip, Laurent</a></td><td class="r">ANU</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143237" title="Click to go to the Author Index">Li, Hongdong</a></td><td class="r">Australian National Univ. and NICTA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab491" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0491.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> Low-drift rotation estimation is a crucial part of any accurate odometry system. In this paper, we focus on the problem of 3D rotation estimation with dense depth sensors in environments that consist of piece-wise planar structures such as corridors and office rooms. An efficient mean-shift paradigm is developed to extract and track planar modes in the surface normal vector distribution on the unit sphere. Robust and piece-wise drift-free behavior are achieved by registering bundles of planar modes from the reference frame and the current frame using a L_1-norm optimization scheme. We furthermore add a memory scheme to the regular birth and death of modes, which further compensates accumulated rotational drift when previously discovered modes are revisited. We discuss the robustness issue and evaluate our algorithm on both custom synthetic as well as real publicly available datasets. Our experimental results demonstrate high robustness and effectiveness of the proposed algorithm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_21">10:50-10:51, Paper WeT11.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0770.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('770'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Pose Estimation of Texture-Less Cylindrical Objects in Bin Picking Using Sensor Fusion</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192936" title="Click to go to the Author Index">Roy, Mayank</a></td><td class="r">Indian Inst. of Tech. Delhi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169021" title="Click to go to the Author Index">Abraham Boby, Riby</a></td><td class="r">IIT Delhi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192569" title="Click to go to the Author Index">Chaudhary, Shraddha</a></td><td class="r">Indian Inst. of Tech. Delhi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172205" title="Click to go to the Author Index">Chaudhury, Santanu</a></td><td class="r">IIT Delhi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107031" title="Click to go to the Author Index">Dutta Roy, Sumantra</a></td><td class="r">Indian Inst. of Tech. Delhi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102675" title="Click to go to the Author Index">Saha, Subir Kumar</a></td><td class="r">Indain Inst. of Tech. Delhi</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab770" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0770.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a>, <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a></span><br>
                           <strong>Abstract:</strong> We propose an approach for emptying of bin using a combination of Image and Range sensor. Offering a complete solution: calibration, segmentation and pose estimation, along with approachability analysis for the estimated pose. The work is novel in the sense that the objects to be picked are featureless and uniformly black in colour, hence existing approaches are not directly applicable. A key point involves optimal utilization of range data acquired from the laser scanner for 3-D segmentation using localized geometric information. This information guides segmentation of the image for better object pose estimation, used for pick-and-drop. We analytically assure the approachability of the object to avoid collision of the manipulator with the bin. Disturbance of objects caused during pick up has been modelled, which allows pickup of multiple pellets based on information from a single range scan. This eliminates the necessity of repeated scanning and data conditioning. The proposed method offers high object detection rate and pose estimation accuracy. The innovative techniques aimed at reducing the average pickup time makes it suitable for robust industrial operation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_22">10:51-10:52, Paper WeT11.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0977.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('977'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Dynamic Arrival Rate Estimation for Campus Mobility on Demand Network Graphs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192912" title="Click to go to the Author Index">Miller, Justin</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192923" title="Click to go to the Author Index">Hasfura, Andres</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#139022" title="Click to go to the Author Index">Liu, Shih-Yuan</a></td><td class="r">U.C. Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104610" title="Click to go to the Author Index">How, Jonathan Patrick</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab977" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0977.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> Mobility On Demand (MOD) systems are revolutionizing transportation in urban settings by improving vehicle utilization and reducing parking congestion. A key factor in the success of an MOD system is the ability to measure and respond to real-time customer arrival data. Real time traffic arrival rate data is traditionally difficult to obtain due to the need to install fixed sensors throughout the MOD network. This paper presents a framework for measuring pedestrian traffic arrival rates using sensors onboard the vehicles that make up the MOD fleet. A novel distributed fusion algorithm is presented which combines onboard LIDAR and camera sensor measurements to detect trajectories of pedestrians with a 90% detection hit rate with 1.5 false positives per minute. A novel moving observer method is introduced to estimate pedestrian arrival rates from pedestrian trajectories collected from mobile sensors. The moving observer method is evaluated in both simulation and hardware and is shown to achieve arrival rate estimates comparable to those that would be obtained with multiple stationary sensors.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_23">10:52-10:53, Paper WeT11.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1152.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1152'); return false" title="Click to show or hide the keywords and abstract">Intuitive Instruction of Industrial Robots: Semantic Process Descriptions for Small Lot Production</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142250" title="Click to go to the Author Index">Perzylo, Alexander Clifford</a></td><td class="r">Fortiss GmbH - An-Inst. Tech. Univ. Muenchen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165403" title="Click to go to the Author Index">Somani, Nikhil</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158929" title="Click to go to the Author Index">Profanter, Stefan</a></td><td class="r">Fortiss GmbH - An-Inst. Tech. Univ. Muenchen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178361" title="Click to go to the Author Index">Kessler, Ingmar</a></td><td class="r">Fortiss GmbH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114560" title="Click to go to the Author Index">Rickert, Markus</a></td><td class="r">Fortiss GmbH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105608" title="Click to go to the Author Index">Knoll, Alois</a></td><td class="r">Tech. Univ. Muenchen TUM</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1152" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a></span><br>
                           <strong>Abstract:</strong> In this paper, we introduce a novel robot programming paradigm. It focuses on reducing the required expertise in robotics to a level that allows shop floor workers to use robots in their application domain without the need of extensive training.<p>Our approach is user-centric and can interpret underspecified robot tasks, enabling communication on an abstract level. Such high-level task descriptions make the system amenable for users that are experts in a particular domain, but have limited knowledge about robotics and are thus not able to specify low-level details and instructions. Semantic models for all involved entities, i.e., processes, workpieces, and workcells, enable automatic reasoning about underspecified tasks and missing pieces of information.<p>We showcase and evaluate this methodology on two industrial use cases from the domains of assembly and woodworking, comparing it to state-of-the-art solutions provided by robot manufacturers.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_24">10:53-10:54, Paper WeT11.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1460.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1460'); return false" title="Click to show or hide the keywords and abstract">EureCar Turbo: A Self-Driving Car That Can Handle Adverse Weather Conditions</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166186" title="Click to go to the Author Index">Lee, Unghui</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184980" title="Click to go to the Author Index">Jung, Jiwon</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147515" title="Click to go to the Author Index">Shin, Seunghak</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149679" title="Click to go to the Author Index">Jeong, Yongseop</a></td><td class="r">Korea Advanced Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172770" title="Click to go to the Author Index">Park, Kibaek</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104593" title="Click to go to the Author Index">Shim, David Hyunchul</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101760" title="Click to go to the Author Index">Kweon, In So</a></td><td class="r">KAIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1460" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a></span><br>
                           <strong>Abstract:</strong> Autonomous driving technology has made significant advances in recent years. In order for self-driving cars to become practical, they are required to operate safely and reliably even under adverse driving conditions. However, most current autonomous driving cars have only been shown to be operational under amiable weather conditions, i.e., on sunny days on dry roads. In order to enable autonomous cars to handle adverse driving conditions such as rain and wet roads, the algorithm must be able to detect roads within a tolerable margin of error using sensors such as cameras and laser scanners. In this paper, we propose a sensor fusion algorithms that is able to operate under a variety of weather conditions, including rain. Our algorithm was validated when a strong shower occurred during the 2014 Hyundai Motor Company’s Autonomous Car Competition. In this paper, we present the competition results that were collected on the same course on both sunny and rainy days. Based on the comparison, we propose the future directions to improve the autonomous driving capability under adverse environmental conditions.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet11_25">10:54-10:55, Paper WeT11.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1527.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1527'); return false" title="Click to show or hide the keywords and abstract">UAV Based Target Finding and Tracking in GPS-Denied and Cluttered Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184991" title="Click to go to the Author Index">Vanegas, Fernando</a></td><td class="r">Queensland Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151717" title="Click to go to the Author Index">Gonzalez, Felipe</a></td><td class="r">Queensland Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158705" title="Click to go to the Author Index">Campbell, Duncan</a></td><td class="r">Queensland Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192893" title="Click to go to the Author Index">Eich, Markus</a></td><td class="r">Queensland Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1527" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> In this paper we describe and flight test a novel system architecture for low cost muti-rotor unmanned aerial vehicles (UAVs) for searching, tracking and following a ground target. The UAV uses only on-board sensors for localisation within a GPS-denied space with obstacles. This mission is formulated as a Partially Observable Markov Decision Process (POMDP) and uses a modular framework that runs on the Robotic Operating System (ROS). This system computes a policy for executing actions instead of way-points to navigate and avoid obstacles. Results indicate that the system is robust to overcome uncertainties in localisation of both, the aircraft and the target and avoids collisions with the obstacles.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wet12"><b>WeT12</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wet12" title="Click to go to the Program at a Glance"><b>Bio-Related and Medical Robotics</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100096" title="Click to go to the Author Index">Fu, Li-Chen</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#103299" title="Click to go to the Author Index">Kamegawa, Tetsushi</a></td><td class="r">Okayama Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_01">10:30-10:31, Paper WeT12.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0182.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('182'); return false" title="Click to show or hide the keywords and abstract">A Progressive Multidimensional Particle Swarm Optimizer for Magnetic Core Placement in Dipole Field Navigation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155802" title="Click to go to the Author Index">Latulippe, Maxime</a></td><td class="r">Pol. Montréal</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106516" title="Click to go to the Author Index">Martel, Sylvain</a></td><td class="r">Pol. Montreal</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab182" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a></span><br>
                           <strong>Abstract:</strong> This paper tackles the inverse problem of finding optimal configurations of magnetic gradient sources in Dipole Field Navigation (DFN), a magnetic navigation method proposed recently for the direct targeting of drugs. In DFN, a limited number of these gradient sources, called the cores, must be positioned properly around a patient in a Magnetic Resonance Imaging scanner to induce the required directional forces on the navigated therapeutic carriers. To overcome some limitations of the previous approach for solving this problem, here we propose a novel and conceptually simple multidimensional variant of the well-known Particle Swarm Optimization (PSO) algorithm. This variant, called Progressive Multidimensional PSO (PMD-PSO), enables a tradeoff between the quality and the complexity of the solutions by progressively increasing the number of dimensions in the search space. We apply this algorithm to the core placement problem using an improved fitness function for the evaluation of a core configuration given a vascular path towards a target. Experiments on simulated vasculatures show that, while the approach can effectively solve this inverse problem, PMD-PSO exhibits better performances for DFN compared with two other multidimensional PSO variants.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_02">10:31-10:32, Paper WeT12.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0183.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('183'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A New Robotic Ultrasound System for Tracking a Catheter with an Active Piezoelectric Element</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178545" title="Click to go to the Author Index">Ma, Qianli</a></td><td class="r">The Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178111" title="Click to go to the Author Index">Davis, Joshua</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160796" title="Click to go to the Author Index">Cheng, Alexis</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191749" title="Click to go to the Author Index">Kim, Younsu</a></td><td class="r">The Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102737" title="Click to go to the Author Index">Chirikjian, Gregory</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124994" title="Click to go to the Author Index">Boctor, Emad</a></td><td class="r">Johns Hopkins Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab183" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0183.VI.mpg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a></span><br>
                           <strong>Abstract:</strong> Robotic-assisted catheter insertion is becoming increasingly popular due to its potential applications including cardiac catheterization. Typically, catheters are tracked during insertion procedures to verify the location of the tip relative to anatomy or features of interest. To this end, many catheter tracking systems have been proposed in the literature. Current approaches such as visual servoing are computationally intensive and sometimes require harmful ionizing radiation (X-rays) for tip localization. Conversely, other approaches use 3D ultrasound probes which can be prohibitively expensive. As a result, we propose an ultrasound-enabled robotic catheter tracking system that uses a 2D ultrasound probe and an active piezoelectric element to track the tip of a catheter. This approach has the potential to guide catheters from initial insertion, in a vein of the groin, to final placement at a target area inside of the heart. During the tracking process, no information from the ultrasound image is necessary; however, this information can be used to help clinicians guide the catheter or to perform diagnostic procedures. In this paper, we outline this procedure by first discussing the individual components of the system and then by describing our methodology for tracking the catheter tip. Next, we simulate the system in ROS to test its effectiveness, and finally we experimentally verify that a robotic arm equipped with a 2D ultrasound probe can track a catheter in a multi-vein phantom. Furthermore, the data collected during tracking can be used to virtually reconstruct the 3D structure of veins while tracking.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_03">10:32-10:33, Paper WeT12.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0276.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('276'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Influence of Wing Morphological and Inertial Parameters on Flapping Flight Performance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164271" title="Click to go to the Author Index">Chen, YuFeng</a></td><td class="r">Microrobotics Lab. School of Applied Sciences and Enginee</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#127787" title="Click to go to the Author Index">Ma, Kevin</a></td><td class="r">Harvard Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102429" title="Click to go to the Author Index">Wood, Robert</a></td><td class="r">Harvard Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab276" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0276.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> Here we experimentally quantify the effects of wing morphological and inertial parameters on flapping flight performance. Through running at-scale, passive pitching experiments with different wing designs, we compare the relative importance of wing inertia, wing shape, and wing-actuation pairing. We find wing inertia strongly influences the coupling between stroke and pitch dynamics, which directly impacts lift production and efficiency. Flapping resonance frequency is reduced as wing aspect ratio or area moment increases. Further, wing leading edge design strongly influences chordwise center of pressure, which further impacts pitching dynamics. Based on our experimental results we propose a new wing design and measure 37% increase in mean lift relative to a previous work.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_04">10:33-10:34, Paper WeT12.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0430.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('430'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Partitioned Camera-OCT Based 6 DOF Visual Servoing for Automatic Repetitive Optical Biopsies</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168180" title="Click to go to the Author Index">Ourak, Mouloud</a></td><td class="r">FEMTO-ST Inst. Univ. De Franche Comté/CNRS/ENSMM/UTBM</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117023" title="Click to go to the Author Index">Tamadazte, Brahim</a></td><td class="r">Cnrs, Ufc/ensmm/utbm</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103294" title="Click to go to the Author Index">Andreff, Nicolas</a></td><td class="r">Univ. De Franche Comté</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab430" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0430.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> This paper addresses the design of a partitioned vision-guided scheme for repetitive optical biopsies. More precisely, our approach use two image modalities to perform 6 degrees of freedom (DOF) positioning task. The development aims to partition the control on 3~DOF controlled by the B-scan images acquired with an optical coherence tomography (OCT) system and remaining 3~DOF controlled by the white light images provided by a CCD camera. Moreover, for the control and instead of conventional visual features (e.g., points, lines, moments, etc.) extracted using image processing algorithms combined with visual tracking approaches, our visual servoing method uses the multi-resolution wavelet transform coefficients. The developed method was experimentally validated using a mathbf{3underline{PP}SR} parallel kinematic structure equipped with a Telesto-II OCT benchtop. The validation task consisted of an automatic spatial repositioning of the robotic structure to precisely retrieve the position of an initial optical biopsy. Several tests are achieved, which clearly demonstrate reliability of the proposed controller.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_05">10:34-10:35, Paper WeT12.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0431.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('431'); return false" title="Click to show or hide the keywords and abstract">Virtual Fixture Assistance for Needle Passing and Knot Tying</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160600" title="Click to go to the Author Index">Chen, Zihan</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147346" title="Click to go to the Author Index">Malpani, Anand</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170008" title="Click to go to the Author Index">Chalasani, Preetham</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123751" title="Click to go to the Author Index">Deguet, Anton</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167580" title="Click to go to the Author Index">Vedula, S. Swaroop</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106071" title="Click to go to the Author Index">Kazanzides, Peter</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105851" title="Click to go to the Author Index">Taylor, Russell H.</a></td><td class="r">The Johns Hopkins Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab431" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a></span><br>
                           <strong>Abstract:</strong> Suturing is a challenging and highly dexterous task in Minimally Invasive Surgery, even with the assistance of robotic surgical systems. In this work, we propose a simple yet versatile impedance virtual fixture framework, which can be applied on the master manipulator in a tele-operated robotic surgical system. With this framework, we further develop two types of virtual fixtures that assist with the needle passing and knot tying sub-tasks in suturing. The paper also presents the results of a 14-participant user study for both needle passing and knot tying sub-tasks, showing that virtual fixture assistance for novice users increases the needle passing exit point accuracy, reduces the number of adverse events (suture slip) in knot tying, and simultaneously decreases the task completion time and overall operator workload.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_06">10:35-10:36, Paper WeT12.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0527.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('527'); return false" title="Click to show or hide the keywords and abstract">Cleavage-Stage Embryo Rotation Tracking and Automated Micropipette Control: Towards Automated Single Cell Manipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195779" title="Click to go to the Author Index">Wong, Christopher Yee</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103657" title="Click to go to the Author Index">Mills, James K.</a></td><td class="r">Univ. of Toronto</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab527" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Biological_Applications_of_Micro_Robots" title="Click to go to the Keyword Index">Biological Applications of Micro Robots</a></span><br>
                           <strong>Abstract:</strong> Micromanipulation of individual biological cells, such as embryos during preimplantation genetic diagnosis (PGD), is a delicate and time-consuming task. Two major procedures in PGD include the rotation of the embryo to gain a more favorable position for zona breaching, and the extraction of a blastomere after an opening has been made in the zona pellucida. Rotation tracking of cleavage-stage embryos has not been reported given their lack of distinctive features. In this manuscript, a geometric model for partially determining the three dimensional (3-D) angular position of 2-cell embryos using two dimensional (2-D) microscopic brightfield images was derived and verified using a computer generated model. This model was then applied using computer vision algorithms on a rotating cleavage-stage mouse embryo, demonstrating partial 3-D rotation tracking. Furthermore, embryo micromanipulation tasks are typically performed manually using micropipettes. Technological advances have made automation of these tasks possible. This manuscript also presents computer vision algorithms for the segmentation and calibration of micropipettes. The calibration procedure allowed automated position control of the micropipettes without the need for real-time vision feedback using micropipette recognition algorithms, and effective position control was verified using semi-automated blastomere extraction experiments. This manuscript presents preliminary work towards the automation of cell manipulation procedures.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_07">10:36-10:37, Paper WeT12.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0611.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('611'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Automatic Palpation for Quantitative Ultrasound Elastography by Visual Servoing and Force Control</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191413" title="Click to go to the Author Index">Patlan Rosales, Pedro Alfonso</a></td><td class="r">INRIA Rennes - Bretagne Atlantique, Univ. De Rennes I</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104061" title="Click to go to the Author Index">Krupa, Alexandre</a></td><td class="r">INRIA Rennes - Bretagne Atlantique</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab611" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0611.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a></span><br>
                           <strong>Abstract:</strong> The precise location of tumors is an important step in surgical planning that can be obtained from mechanical properties of soft tissues. In this paper we propose a robotic-assisted palpation system that automatically moves an ultrasound probe to optimize the elastography process and improve the resulting elastogram. The main contribution of this work is the use of the elastography modality directly as input of the robot controller. Force measures are also considered in the probe control in order to automatically induce soft tissue deformation needed for real-time elastography imaging process. Moreover, an automatic exploration process is implemented to orient the probe to reach different views of a soft tissue target of interest. This allows to improve the elastogram quality of the element of interest by fusing the information observed from different positions.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_08">10:37-10:38, Paper WeT12.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0821.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('821'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>4-DoF Spherical Parallel Wrist with Embedded Grasping Capability for Minimally Invasive Surgery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196215" title="Click to go to the Author Index">Haouas, Wissem</a></td><td class="r">Femto-St</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108861" title="Click to go to the Author Index">Dahmouche, Redwan</a></td><td class="r">Univ. De Franche Comté</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123108" title="Click to go to the Author Index">Le Fort-Piat, Nadine</a></td><td class="r">FEMTO-ST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109843" title="Click to go to the Author Index">Laurent, Guillaume J.</a></td><td class="r">FEMTO-ST Inst. - CNRS - ENSMM - Univ. Defranche-Comté</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab821" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0821.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a></span><br>
                           <strong>Abstract:</strong> This paper presents preliminary results of a new robotic wrist for minimally invasive surgery. This wrist is a high-dexterity miniature robot, able to provide simultaneously the grasping/cutting (1-DoF) and rotations capabilities with 3-DoF. The grasping function is insured by the folding of the top platform of a parallel structure. The grasping capability of the wrist is part of the mechanical structure itself and can be fully controlled by external actuators. In order to validate this original approach, an experimental prototype has been fabricated using 3D printing technology at a larger scale. The inverse kinematic model has been developed and the workspace analysis was accomplished to assess the capabilities of the realized system. Finally, experimental tests have been also carried out for validating the proposed structure.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_09">10:38-10:39, Paper WeT12.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0866.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('866'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Development of Instantaneously Puncture System for CT Fluoroscopy-Guided Interventional Radiology</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195365" title="Click to go to the Author Index">Heya, Akira</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103299" title="Click to go to the Author Index">Kamegawa, Tetsushi</a></td><td class="r">Okayama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100906" title="Click to go to the Author Index">Matsuno, Takayuki</a></td><td class="r">Okayama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177896" title="Click to go to the Author Index">Hiraki, Takao</a></td><td class="r">Okayama Univ. Medical School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116829" title="Click to go to the Author Index">Gofuku, Akio</a></td><td class="r">Okayama Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab866" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0866.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a></span><br>
                           <strong>Abstract:</strong> There is minimally invasive method called Interventional Radiology (IR) that uses diagnostic imaging equipment such as Computed Tomography (CT). IR is applied to lung cancer treatment, liver cancer treatment, biopsy, and so on. However, doctors are exposed by X-ray in order to perform a procedure in the vicinity of the CT gantry. To solve this problem, we have developed a robot called &quot;Zerobot&quot; which has six DOF and controlled remotely. We previously conducted animal experiment using a rabbit to evaluate Zerobot. As a result, percutaneous puncture was impossible without epidermis cutting. Therefore, we developed new function called instantaneously puncture that can achieve high speed and short stroke puncture like a human operator. In this paper, overview of Zerobot is described first. Then, measurement of puncture speed of a human operator is described. Furthermore, design and system structure of instantaneously puncture system is described. Finally, we present the result of animal experiment using instantaneously puncture system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_10">10:39-10:40, Paper WeT12.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0989.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('989'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Online Prediction of Needle Shape Deformation in Moving Soft Tissues from Visual Feedback</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182744" title="Click to go to the Author Index">Chevrie, Jason</a></td><td class="r">IRISA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104061" title="Click to go to the Author Index">Krupa, Alexandre</a></td><td class="r">INRIA Rennes - Bretagne Atlantique</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154230" title="Click to go to the Author Index">Babel, Marie</a></td><td class="r">IRISA UMR CNRS 6074 - INRIA - INSA Rennes</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab989" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0989.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_tissue_Modeling" title="Click to go to the Keyword Index">Soft-tissue Modeling</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a></span><br>
                           <strong>Abstract:</strong> With the increasing number of clinical interventions using needle shaped tools, robotic control of needle insertion procedures has been an active research field for many years. In this work we propose a 3D model of a flexible needle that takes into account tissue deformations in order to predict the needle shape and trajectory when it is inserted using a robotic arm. To account for tissue displacements, we designed a method based on visual feedback that updates the interaction model between the needle and the tissue using an Unscented Kalman filter. Results obtained from several needle insertions in a soft tissue phantom showed that the method gives good performance in terms of needle trajectory prediction. This model was also considered in a closed-loop control approach to allow automatic reaching of a target.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_11">10:40-10:41, Paper WeT12.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1155.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1155'); return false" title="Click to show or hide the keywords and abstract">Kinetostatic Design of Asymmetric Notch Joints for Surgical Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191012" title="Click to go to the Author Index">Eastwood, Kyle</a></td><td class="r">The Hospital for Sick Children</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132913" title="Click to go to the Author Index">Azimian, Hamidreza</a></td><td class="r">Hospital for Sick Children</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195299" title="Click to go to the Author Index">Carrillo, Brian</a></td><td class="r">The Hospital for Sick Children</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109669" title="Click to go to the Author Index">Looi, Thomas</a></td><td class="r">Hospital for Sick Children</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195298" title="Click to go to the Author Index">Naguib, Hani E.</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157335" title="Click to go to the Author Index">Drake, James</a></td><td class="r">Hospital for Sick Children, Univ. of Toronto</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1155" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Joint_Mechanism_Design" title="Click to go to the Keyword Index">Joint/Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> We present a kinetostatic model for a needle-sized notched tube continuum joint design, and examine the impact that the design parameters have on both stiffness and joint kinematics. The joint is fabricated by removing a series of asymmetric notches from a metal tube. By fixing a cable to the distal end of the tube, and routing this tendon through the tube’s lumen, the joint can be actuated in bending. This simple cutting pattern allows for impressive performance compared to other mechanisms of similar size. However, selecting the cutting geometry using kinematics alone results in many redundant solutions. Since the notches significantly affect the overall structure’s stiffness, and limit the maximum forces that it can transmit, a stiffness model can be used to constrain the design-space. Further, because the notch geometry represents a non-prismatic beam configuration, modelling the force-deflection behavior is nontrivial. We have approached this problem using a variation of Castigliano’s 2nd Theorem, experimentally validated its performance with several test specimens, and analyzed the behavior of the model over a design space specific to neurosurgical applications. The outcomes of this study aim to aid in the design of joints given task-specific constraints, particularly within the field of surgical robotics.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_12">10:41-10:42, Paper WeT12.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1189.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1189'); return false" title="Click to show or hide the keywords and abstract">A Magnetic Soft Endoscopic Capsule for Non-Surgical Overweight and Obese Treatments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170656" title="Click to go to the Author Index">Do, Thanhnho</a></td><td class="r">Ntu</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201774" title="Click to go to the Author Index">Phan, Phuoc Thien</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195990" title="Click to go to the Author Index">Khek Yu Ho, Khek</a></td><td class="r">Yu Ho</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100127" title="Click to go to the Author Index">Phee, Louis</a></td><td class="r">Nanyang Tech. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1189" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a></span><br>
                           <strong>Abstract:</strong> Obesity is de&#64257;ned as an unhealthy excess of body fat, which increases the risks of medical illness and premature mortality. There are multiple health risks linked to obesity such as heart disease and stroke, high blood pressure, diabetes, cancers, gallbladder disease and gallstones, osteoarthritis, gout, and breathing problems like sleep apnea, and asthma. Intragastric balloons (IGBs) have become an ef&#64257;cient and less invasive method for obesity treatment. However, the use of traditional IGBs requires complex insertion tools and &#64258;exible endoscopes to place and remove the balloon inside patient’s stomach. This causes abdominal discomfort, nausea, vomiting, and gastric mucous damage. To overcome these limitations, we designed a novel magnetic soft capsule robot for obesity treatment with magnetically actuated in&#64258;atable IGB. The balloon is made from a thin, &#64258;exible, biocompatible material, and is in&#64258;ated to a desired volume using biocompatible effervescent chemicals. Instead of using complex de&#64258;ation mechanism, a biodegradable material is developed to automatically de&#64258;ate the balloon after a predetermined period of treatment. In addition, multiple capsules can be simultaneously swallowed. As the source of actuation is provided via external magnetic &#64257;elds, the magnetic soft capsule size can be signi&#64257;cantly reduced with no limitations on the power consumption. A prototype soft magnetic capsule is developed. Experiments are carried out to demonstrate the effectiveness of the proposed approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_13">10:42-10:43, Paper WeT12.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1206.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1206'); return false" title="Click to show or hide the keywords and abstract">A Novel Global and Local Saliency Coding Method for Polyp Recognition in WCE Videos</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168158" title="Click to go to the Author Index">Yuan, Yixuan</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100160" title="Click to go to the Author Index">Meng, Max Q.-H.</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1206" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> Wireless Capsule Endoscopy (WCE) allows physicians to examine the entire digestive system without any surgical operation. Although it provides a noninvasive imaging approach to access the gastrointestinal (GI) tract, the biggest drawback of this technology is the large number of images need to be diagnosed. In this paper, a global and local saliency coding (GLSAC) method is proposed to detect polyps from WCE images. We first extract the Scale Invariant Feature Transform (SIFT) features from image patches and apply K-means method on these features to obtain visual words. Since saliency is a fundamental characteristic of feature coding with maxpooling, a novel coding strategy: the global and local saliency coding (GLSAC) is proposed. The calculation of the global saliency coding and local saliency coding is obtained by the exponential function of feature differences to the nearest visual code and all visual words. Specifically, the local saliency strategy considers coding bases based on the distribution of the distances between the features and visual words adaptively. Furthermore, we presents a concentric circle-based spatial-rotation-invariant pooling strategy to obtain the final image features from the patch features. Experiment results achieve promising 91.13% accuracy and 92.51% sensitivity, validating the effectiveness of the proposed method. Moreover, the comparison results show that our strategy outperforms the state-of-the-art methods on the polyp recognition task.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_14">10:43-10:44, Paper WeT12.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1275.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1275'); return false" title="Click to show or hide the keywords and abstract">Toward On-Line Parameter Estimation of Concentric Tube Robots Using a Mechanics-Based Kinematic Model</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170657" title="Click to go to the Author Index">Jang, Cheongjae</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169131" title="Click to go to the Author Index">Ha, Junhyoung</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101790" title="Click to go to the Author Index">Dupont, Pierre</a></td><td class="r">Children's Hospital Boston, Harvard Medical School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106557" title="Click to go to the Author Index">Park, Frank</a></td><td class="r">Seoul National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1275" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a></span><br>
                           <strong>Abstract:</strong> Although existing mechanics-based models of concentric tube robots have been experimentally demonstrated to approximate the actual kinematics, determining accurate estimates of model parameters remains difficult due to the complex relationship between the parameters and available measurements. Further, because the mechanics-based models neglect some phenomena like friction, nonlinear elasticity, and cross section deformation, it is also not clear if model error is due to model simplification or to parameter estimation errors. The parameters of the superelastic materials used in these robots can be slowly time-varying, necessitating periodic re-estimation. This paper proposes a method for estimating the mechanics-based model parameters using an extended Kalman filter as a step toward on-line parameter estimation. Our methodology is validated through both simulation and experiments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_15">10:44-10:45, Paper WeT12.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1341.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1341'); return false" title="Click to show or hide the keywords and abstract">Active Control with Force Sensor and Shoulder Circumduction Implemented on Exoskeleton Robot NTUH-II</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183388" title="Click to go to the Author Index">Li, Hao-Ying</a></td><td class="r">Department of Electrical Engineering, National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195334" title="Click to go to the Author Index">Chien, Li Yu</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183392" title="Click to go to the Author Index">Hong, Heng-Yi</a></td><td class="r">Department of Electrical Engineering, National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195327" title="Click to go to the Author Index">Pan, Shang-Heh</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195419" title="Click to go to the Author Index">Chiao, Chi-Lun</a></td><td class="r">Department of Physical Therapy, National Taiwan Univ. (NTU)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195333" title="Click to go to the Author Index">Chen, Hung-Wen</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100096" title="Click to go to the Author Index">Fu, Li-Chen</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133517" title="Click to go to the Author Index">Lai, Jin-Shin</a></td><td class="r">National Taiwan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1341" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a></span><br>
                           <strong>Abstract:</strong> Many neurological or orthopedic disorders may cause motor impairments of shoulder. Patients require intensive training in order to recover from those impairments. However, the intensive training will lead to growing demand for strenuous work. Robot-aided therapy is able to alleviate the therapist’s laborious burden and to provide more information about patient’s condition during the therapy. Generally, the requirement of active therapy arises during the later stage of recovery. To realize the active therapy, useful active control of the robot and effective recovery assessment for the active robot-aided therapy are essential. In this paper, a new active control method and an active therapy protocol with assessment indexes are designed. In this pilot research, several experiments on healthy subjects are designed to verify the proposed method with its active control performance and the effectiveness of the assessment indexes.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_16">10:45-10:46, Paper WeT12.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1396.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1396'); return false" title="Click to show or hide the keywords and abstract">Resonance Principle for the Design of Flapping Wing Micro Air Vehicles</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160774" title="Click to go to the Author Index">Zhang, Jian</a></td><td class="r">Purdue Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106391" title="Click to go to the Author Index">Deng, Xinyan</a></td><td class="r">Purdue Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1396" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a></span><br>
                           <strong>Abstract:</strong> Achieving resonance in flapping wings has been recognized as one of the most important principles to enhance power efficiency, lift generation, and flight control performance of high-frequency flapping wing micro air vehicles (MAVs). Most of work on the development of such vehicles have attempted to achieve wing flapping resonance. However, the theoretical understanding of its effects on the response and energetics of flapping motion has lagged behind, leading to sub-optimal design decisions and misinterpretations of experimental results. In this work, we systematically model the dynamics of flapping wing as a forced nonlinear resonant system. Using linear approximation approach, we derived analytic solution for steady-state flapping amplitude, energetics, and characteristic frequencies including natural frequency, damped natural frequency, and peak frequency. Our results showed that both aerodynamic lift and power efficiency are maximized by driving the wing at natural frequency, instead of other frequencies. Interestingly, the flapping velocity is maximized at natural frequency as well, which can lead to an easy experimental approach to identify natural frequency and validate the resonance design. Our models and analysis were validated with both simulations and experiments on ten different wings mounted a direct-motor-drive flapping wing MAV. The result can serve as a systematic design principle and guidance in the interpretations of empirical results.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_17">10:46-10:47, Paper WeT12.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1496.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1496'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Human Mimetic Foot Structure with Multi-DOFs and Multi-Sensors for Musculoskeletal Humanoid Kengoro</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151588" title="Click to go to the Author Index">Asano, Yuki</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182120" title="Click to go to the Author Index">Nakashima, Shinsuke</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156135" title="Click to go to the Author Index">Kozuki, Toyotaka</a></td><td class="r">Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#176945" title="Click to go to the Author Index">Ookubo, Soichi</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202369" title="Click to go to the Author Index">Yanokura, Iori</a></td><td class="r">Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135552" title="Click to go to the Author Index">Kakiuchi, Yohei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106350" title="Click to go to the Author Index">Okada, Kei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106348" title="Click to go to the Author Index">Inaba, Masayuki</a></td><td class="r">The Univ. of Tokyo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1496" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1496.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Tendon_Wire_Mechanisms" title="Click to go to the Keyword Index">Tendon/Wire Mechanisms</a></span><br>
                           <strong>Abstract:</strong> We propose a human mimetic foot structure for musculoskeletal humanoids. We designed the foot structure by inspiring from human foot abilities of the multi-bone connected structure for flexibility and the distributed force sensor system. The foot has multi-DOFs structure including toe DOF that is composed of fingers. The distributed force sensing system is composed of 12 an-axis force sensors. In order to demonstrate those effectiveness, we implement the foot into musculoskeletal humanoid Kengoro and conduct several experiments. As a result, we confirmed effectiveness of the foot from tiptoe motion and balancing behavior by utilizing the foot characteristics.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_18">10:47-10:48, Paper WeT12.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1508.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1508'); return false" title="Click to show or hide the keywords and abstract">Cat-Inspired Mechanical Design of Self-Adaptive Toes for a Legged Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170153" title="Click to go to the Author Index">Liu, Huaxin</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100171" title="Click to go to the Author Index">Huang, Qiang</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111008" title="Click to go to the Author Index">Zhang, Weimin</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#139013" title="Click to go to the Author Index">Chen, Xuechao</a></td><td class="r">Beijing Insititute of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116950" title="Click to go to the Author Index">Yu, Zhangguo</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172861" title="Click to go to the Author Index">Meng, Libo</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202529" title="Click to go to the Author Index">Bao, Lei</a></td><td class="r">Beijing Insititute of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100164" title="Click to go to the Author Index">Ming, Aiguo</a></td><td class="r">The Univ. of Electro-Communications</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110578" title="Click to go to the Author Index">Huang, Yan</a></td><td class="r">Peking Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101936" title="Click to go to the Author Index">Hashimoto, Kenji</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102287" title="Click to go to the Author Index">Takanishi, Atsuo</a></td><td class="r">Waseda Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1508" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a></span><br>
                           <strong>Abstract:</strong> Cats have protractible claws to fold their tips to keep them sharp. They protract claws while hunting and pawing on slippery surfaces. Protracted claws by tendons and muscles of toes can help cats anchoring themselves steady while their locomotion trends to slip and releasing the hold while they retract claws intentionally. This research proposes a kind of modularized self-adaptive toe mechanism inspired by cat claws to improve the extremities’ contact performance for legged robot. The mechanism is constructed with four-bar linkage actuated by contact reaction force and retracted by applied spring tension. A feasible mechanical design based on several essential parameters is introduced and an integrated Sole-Toe prototype is built for experimental evaluation. Mechanical self-adaption and actual contact performance on specific surface have been evaluated respectively on a biped walking platform and a bench-top mechanical testing.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_19">10:48-10:49, Paper WeT12.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1536.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1536'); return false" title="Click to show or hide the keywords and abstract">Intention Recognition for Gaze Controlled Robotic Minimally Invasive Laser Ablation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169597" title="Click to go to the Author Index">Gras, Gauthier</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117925" title="Click to go to the Author Index">Yang, Guang-Zhong</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1536" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Eye tracking technology has shown promising results for allowing hands-free control of robotically-mounted cameras and tools. However existing systems present only limited capabilities in allowing the full range of camera motions in a safe, intuitive manner. This paper introduces a framework for the recognition of surgeon intention, allowing activation and control of the camera through natural gaze behaviour. The system is resistant to noise such as blinking, while allowing the surgeon to look away safely at any time. Furthermore, this paper presents a novel approach to control the translation of the camera along its optical axis using a combination of eye tracking and stereo reconstruction. Combining eye tracking and stereo reconstruction allows the system to determine which point in 3D space the user is fixating, enabling a translation of the camera to achieve the optimal viewing distance. In addition, the eye tracking information is used to perform automatic laser targeting for laser ablation. The desired target point of the laser, mounted on a separate robotic arm, is determined with the eye tracking thus removing the need to manually adjust the laser's target point before starting each new ablation. The calibration methodology used to obtain millimetre precision for the laser targeting without the aid of visual servoing is described. Finally, a user study validating the system is presented, showing clear improvement with median task times under half of those of a manually controlled robotic system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_20">10:49-10:50, Paper WeT12.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1555.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1555'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Locomotion and Gait Analysis of Multi-Limb Soft Robots Driven by Smart Actuators</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162997" title="Click to go to the Author Index">Mao, Shixin</a></td><td class="r">Univ. of Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162954" title="Click to go to the Author Index">Dong, Erbao</a></td><td class="r">Univ. of Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162947" title="Click to go to the Author Index">Jin, Hu</a></td><td class="r">Univ. of Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150603" title="Click to go to the Author Index">Xu, Min</a></td><td class="r">Univ. of Science & Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100138" title="Click to go to the Author Index">Low, K. H.</a></td><td class="r">Nanyang Tech. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1555" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1555.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Smart_Actuators" title="Click to go to the Keyword Index">Smart Actuators</a></span><br>
                           <strong>Abstract:</strong> Soft animals provide various inspiration for developing soft machines in bionics, robotics research as well as potential applications. This paper presents an integrated development of locomotive soft robot platforms: starfish-inspired robots with multi-limb bodies actuated by shape memory alloys (SMAs). The designs of these robots were based on the biological specifications of the locomotion and water-vascular systems of regenerating starfish. Multi-limb robot prototypes were fabricated with soft materials and 3D printing technology, satisfying modest movement requirements with SMA spring actuators. Experimental testing of multi-limb robots were conducted in accordance with biological locomotion principles. The robots vividly displayed typical starfish motion models. The locomotion of live starfish with different limb numbers suggests that, a correlation exists between movement and geometrical characteristics (e.g., body size) and such a correlation was also observed in the robot prototypes.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_21">10:50-10:51, Paper WeT12.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0334.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('334'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Design and Characterization of a Novel Mechanism of Multiple Joint Stiffness(MMJS)</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191479" title="Click to go to the Author Index">Medina Hernandez, José</a></td><td class="r">Univ. Carlos III De Madrid</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191480" title="Click to go to the Author Index">Lozano Vallés, Pedro Francisco</a></td><td class="r">Univ. Carlos III De Madrid</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104014" title="Click to go to the Author Index">Jardon Huete, Alberto</a></td><td class="r">Univ. CARLOS III DE MADRID</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105670" title="Click to go to the Author Index">Balaguer, Carlos</a></td><td class="r">Univ. Carlos III De Madrid</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab334" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0334.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a></span><br>
                           <strong>Abstract:</strong> This article presents the design, implementation and test of a joint mechanical device created to improve the safety and performance of robots interacting physically with the human beings. The mechanism consists of a series of linear springs, preloaded and arranged in such a way to take advantage of the benefits of series elastic actuators and to limit the maximum applicable torque. This is a passive mechanism because it does not have a second actuator system on the same joint. However, it involves a joint system of variable stiffness given the three distinct performance phases it has, each one having a different stiffness value, elastic torque-dependent occurring in the joint.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_22">10:51-10:52, Paper WeT12.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0626.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('626'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Low-Cost Tele-Presence Wheelchair System</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192031" title="Click to go to the Author Index">Shen, Jiajun</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192045" title="Click to go to the Author Index">Xu, Bin</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192049" title="Click to go to the Author Index">Pei, Mingtao</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192053" title="Click to go to the Author Index">Jia, Yunde</a></td><td class="r">Beijing Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab626" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0626.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Telerobotics" title="Click to go to the Keyword Index">Telerobotics</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> This paper presents the architecture and implementation of a tele-presence wheelchair system based on tele-presence robot, intelligent wheelchair, and touch screen technologies. The tele-presence wheelchair system consists of a commercial electric wheelchair, an add-on tele-presence interaction module, and a touchable live video image based user interface (called TIUI). The tele-presence interaction module is used to provide video-chatting for an elderly or disabled person with the family members or caregivers, and also captures the live video of an environment for tele-operation and semi-autonomous navigation. The user interface developed in our lab allows an operator to access the system anywhere and directly touch the live video image of the wheelchair to push it as if he/she did it in the presence. This paper also discusses the evaluation of the user experience.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_23">10:52-10:53, Paper WeT12.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1136.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1136'); return false" title="Click to show or hide the keywords and abstract">Stiffness-Based Modelling of a Hydraulically-Actuated Soft Robotics Manipulator</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192606" title="Click to go to the Author Index">Lindenroth, Lukas</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169486" title="Click to go to the Author Index">Back, Jungwhan</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192615" title="Click to go to the Author Index">Schoisengeier, Adrian</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105797" title="Click to go to the Author Index">Noh, Yohan</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142097" title="Click to go to the Author Index">Wurdemann, Helge Arne</a></td><td class="r">Univ. Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101975" title="Click to go to the Author Index">Althoefer, Kaspar</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104575" title="Click to go to the Author Index">Liu, Hongbin</a></td><td class="r">Department of Informatics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1136" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a>, <a href="IROS16_KeywordIndexMedia.html#Hydraulic_Pneumatic_Actuators" title="Click to go to the Keyword Index">Hydraulic/Pneumatic Actuators</a></span><br>
                           <strong>Abstract:</strong> This work investigates the applicability of stiffness-based modelling in soft robotics manipulation. The methodology is introduced and applied to model a soft robotics manipulator as single 3d Timoshenko beam element. The model is then utilized to solve the forward kinematics problem for the manipulator. The algorithm is validated comparing the simulated deflection with the deflection of the physical manipulator for two defined pressure sequences. It is shown that the model behaves in a highly similar fashion in comparison to the manipulator. For both trajectories the maximum position error is close to 6 mm while the error in orientation not more than 18 degrees. The methodology as described in this work reveals great applicability to the field of soft robots being limited only by the stiffness matrix assembly for the given system. Implementations of inverse kinematics and the effects of external force applications are effectively integrable in the described theory.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_24">10:53-10:54, Paper WeT12.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1495.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1495'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Convolutional Neural Network for Robotic Arm Guidance Using Semg Based Frequency-Features</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190425" title="Click to go to the Author Index">Côté Allard, Ulysse</a></td><td class="r">Univ. Laval</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196637" title="Click to go to the Author Index">Nougarou, François</a></td><td class="r">Laval Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196627" title="Click to go to the Author Index">Fall, Cheikh Latyr</a></td><td class="r">Univ. Laval</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110648" title="Click to go to the Author Index">Giguere, Philippe</a></td><td class="r">Univ. Laval</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105379" title="Click to go to the Author Index">Gosselin, Clement</a></td><td class="r">Univ. Laval</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190427" title="Click to go to the Author Index">Laviolette, François</a></td><td class="r">Univ. Laval</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190426" title="Click to go to the Author Index">Gosselin, Benoit</a></td><td class="r">Univ. Laval</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1495" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1495.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a></span><br>
                           <strong>Abstract:</strong> Recently, robotics has been seen as a key solution to improve the quality of life of amputees. In order to create smarter robotic prosthetic devices to be used in an everyday context, one must be able to interface them seamlessly with the end-user in an inexpensive, yet reliable way. In this paper, we are looking at guiding a robotic device by detecting gestures through measurement of the electrical activity of muscles captured by surface electromyography (sEMG). Reliable sEMG-based gesture classifiers for end-users are challenging to design, as they must be extremely robust to signal drift, muscle fatigue and small electrode displacement without the need for constant recalibration. In spite of extensive research, sophisticated sEMG classifiers for prostheses guidance are not yet widely used, as systems often fail to solve these issues simultaneously. We propose to address these problems by employing Convolutional Neural Networks. Specifically as a first step, we demonstrate their viability to the problem of gesture recognition for a low-cost, low-sampling rate (200 Hz) consumer-grade, 8-channel, dry electrodes sEMG device called Myo Armband (Thalmic Labs) on able-bodied subjects. To this effect, we assessed the robustness of this machine learning oriented approach by classifying a combination of 7 hand/wrist gestures with an accuracy of ~97.9% in real-time, over a period of 6 consecutive days with no recalibration. In addition, we used the classifier (in conjunction with orientation data) to guide a 6DoF robotic arm, using the armband with the same speed and precision as with a joystick. We also show that the classifier is able to generalize to different users by testing it on 18 participants.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet12_25">10:54-10:55, Paper WeT12.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1503.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1503'); return false" title="Click to show or hide the keywords and abstract">Hands-On Reconfigurable Robotic Arm for Surgical Instruments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169470" title="Click to go to the Author Index">Wisanuvej, Piyamate</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157759" title="Click to go to the Author Index">Leibrandt, Konrad</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#112909" title="Click to go to the Author Index">Liu, Jindong</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117925" title="Click to go to the Author Index">Yang, Guang-Zhong</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1503" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> The use of conventional surgical tool holders often requires manual positioning and adjustment due to a lack of weight compensation. In this paper, we introduce a robotic arm with hands-on control. The robot incorporates a force sensor at the end effector which realises tool weight compensation as well as hands-on manipulation. On the operating table, the required workspace can be limited due to a number of instruments required. There are situations where the surgical tool is at the desired location but the pose of the holding arm is not ideal due to space constraints or obstacles. Although the arm is a non-redundant robot because of the limited degrees of freedom, the pseudo-null-space inverse kinematics can be used to constrain a particular joint of the robot to a specific angle while the other joints compensate in order to minimise the tool movement. This allows the operator to adjust the arm configuration conveniently together with weight compensation. Experimental results demonstrated that our robotic arm can maintain the tool position during reconfiguration much more stably than a conventional one.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weai1"><b>WeAI1</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weai1" title="Click to go to the Program at a Glance"><b>Interactive Session: Advanced Automation/Sensor Fusion</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102761" title="Click to go to the Author Index">Maeda, Yusuke</a></td><td class="r">Yokohama National Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#111300" title="Click to go to the Author Index">Bachrach, Jonathan</a></td><td class="r">Uc Berkeley</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weai2"><b>WeAI2</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weai2" title="Click to go to the Program at a Glance"><b>Interactive Session: Bio-Related and Medical Robotics</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100096" title="Click to go to the Author Index">Fu, Li-Chen</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#103299" title="Click to go to the Author Index">Kamegawa, Tetsushi</a></td><td class="r">Okayama Univ</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat1"><b>WeAT1</b></a></td>
               <td class="r">#101</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat1" title="Click to go to the Program at a Glance"><b>Robot Calibration and Modeling</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102379" title="Click to go to the Author Index">Christensen, Henrik Iskov</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#128031" title="Click to go to the Author Index">Stoyanov, Danail</a></td><td class="r">Univ. Coll. London</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat1_01">11:00-11:15, Paper WeAT1.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0165.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('165'); return false" title="Click to show or hide the keywords and abstract">Performances of Observability Indices for Industrial Robot Calibration</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130443" title="Click to go to the Author Index">Joubair, Ahmed</a></td><td class="r">École De Tech. Supérieure</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#163762" title="Click to go to the Author Index">Tahan, Souheil-Antoine</a></td><td class="r">École De Tech. Supérieure (ÉTS)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102877" title="Click to go to the Author Index">Bonev, Ilian</a></td><td class="r">École De Tech. Supérieure</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab165" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a></span><br>
                           <strong>Abstract:</strong> This work presents a comparison of the five observability indices used for robot calibration. The comparison is realized in order to determine the most appropriate observability index, which allows for the best parameter identification of a calibrated robot, and therefore leading to the best improvement of the robot accuracy. In this study, the accuracy analysis is based on the robot end-effector errors, which are expressed in term of Euclidean errors. The parameter identification process is based on minimizing the residual of the position errors. The actual values of these positions are usually measured by an external measurement device and have measurement noise. The position residuals are calculated in all the calibration configurations, which are selected by using observability indices. An optimal set of configurations is the one reducing the impact of the measurement noise on the parameter identification efficacy. Our study is carried out for the calibra-tion of four robots: two degrees of freedom (DOF) and 6-DOF serial robots, and 2-DOF and 3-DOF planar parallel robots. The comparison of the observability indices was achieved through a Monte Carlo simulation, using 100 different cases for each of the four robots considered. The position measure-ment noise was assumed to be within a range of ± 200µm. In-vestigations led to conclude that there is a specific index that may be considered the best observability index for robot cali-bration. Finally, an experimental study has been applied to a LR Mate 200ic FANUC robot and confirms the simulated re-sults.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat1_02">11:15-11:30, Paper WeAT1.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1284.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1284'); return false" title="Click to show or hide the keywords and abstract">Hand-Eye Calibration for Robotic Assisted Minimally Invasive Surgery without a Calibration Object</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192655" title="Click to go to the Author Index">Pachtrachai, Krittin</a></td><td class="r">Univ. Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196584" title="Click to go to the Author Index">Allan, Max</a></td><td class="r">UCL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170824" title="Click to go to the Author Index">Pawar, Vijay</a></td><td class="r">Univ. Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123425" title="Click to go to the Author Index">Hailes, Stephen</a></td><td class="r">Univ. Coll. London , Dept. of Computer Science , Gower S</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128031" title="Click to go to the Author Index">Stoyanov, Danail</a></td><td class="r">Univ. Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1284" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> In a robot mounted camera arrangement, hand-eye calibration estimates the rigid relationship between the robot and camera coordinate frames. Most hand-eye calibration techniques use a calibration object to estimate the relative transformation of the camera in several views of the calibration object and link these to the forward kinematics of the robot to compute the hand-eye transformation. Such approaches achieve good accuracy for general use but for applications such as robotic assisted minimally invasive surgery, acquiring a calibration sequence multiple times during a procedure is not practical. In this paper, we present a new approach to tackle the problem by using the robotic surgical instruments as the calibration object with well known geometry from CAD models used for manufacturing. Our approach removes requirement of custom sterile calibration object to be used in the operating room and it simplifies the process of acquiring calibration data when the laparoscope is constrained to move around a remote centre of motion. This is the first demonstration of the feasibility to perform hand-eye calibration using components of the robotic system itself and we show promising validation results on synthetic data as well as data acquired with the da Vinci Research Kit.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat1_03">11:30-11:45, Paper WeAT1.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1626.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1626'); return false" title="Click to show or hide the keywords and abstract">Stereo Vision-Based Localization for Hexapod Walking Robots Operating in Rough Terrains</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179990" title="Click to go to the Author Index">Fischer, Thomas</a></td><td class="r">UBA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179977" title="Click to go to the Author Index">Pire, Taihú</a></td><td class="r">Facultad De Ciencias Exactas Y Naturales, Univ. De Buenos</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191847" title="Click to go to the Author Index">Cizek, Petr</a></td><td class="r">Czech Tech. Univ. in Prague, Faculty of Electrical Engi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169795" title="Click to go to the Author Index">De Cristóforis, Pablo</a></td><td class="r">Facultad De Ciencias Exactas Y Naturales, Univ. De Buenos</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130305" title="Click to go to the Author Index">Faigl, Jan</a></td><td class="r">Czech Tech. Univ. in Prague</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1626" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> This paper concerns the self-localization problem of a hexapod walking robot operating in rough terrains. Given that legged robots exhibit higher terrain passability than wheeled or tracked platforms when operating in harsh environments, they constitute a challenge for the localization techniques because the camera motion between consecutive frames can be arbitrary due to the motion gait and terrain irregularities. In this paper, we present and evaluate an inertially assisted Stereo Parallel Tracking and Mapping (S-PTAM) method deployed on a hexapod crawling robot in a rough terrain. The considered deployment scenario is motivated by autonomous navigation in an unknown environment in an open loop fashion. The reported results and comparison with an existing RGB-D SLAM technique show the feasibility of the proposed approach and its suitability for navigation of crawlers in harsh environments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat1_04">11:45-12:00, Paper WeAT1.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1663.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1663'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Active Planning Based Extrinsic Calibration of Exteroceptive Sensors in Unkown Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189452" title="Click to go to the Author Index">Murali, Varun</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103595" title="Click to go to the Author Index">Nieto-Granda, Carlos</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169806" title="Click to go to the Author Index">Choudhary, Siddharth</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102379" title="Click to go to the Author Index">Christensen, Henrik Iskov</a></td><td class="r">Georgia Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1663" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1663.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a></span><br>
                           <strong>Abstract:</strong> Existing Simultaneous Localization and Mapping systems require an extensive manual pre-calibration process. Non-manual calibration procedures use manipulators to create known patterns in order to estimate the unknown calibration. Calibration is often time consuming and involves humans performing repetitive tasks such as aligning a known calibration target at different poses with respect to the sensor. We propose an algorithm that plans a trajectory which actively reduces the uncertainty of the robot’s calibration given a rough initial calibration estimate. Calibration is performed autonomously in a previously unknown environment by maintaining the belief over landmarks, poses and the calibration parameters. We present experimental results to demonstrate the approach’s ability to autonomously calibrate the exteroceptive sensor in simulated and real environments. We believe that this greatly reduces the amount of effort needed to perform calibration every time the robot is reconfigured for autonomous tasks and mitigates the possibility of human error added into the calibration.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat2"><b>WeAT2</b></a></td>
               <td class="r">#102</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat2" title="Click to go to the Program at a Glance"><b>Omnidirectional Vision</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#168557" title="Click to go to the Author Index">Miraldo, Pedro</a></td><td class="r">Inst. Superior Técnico, Univ. of Lisbon</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#196618" title="Click to go to the Author Index">Benseddik, Houssem-Eddine</a></td><td class="r">IBISC Labiratory Evry Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat2_01">11:00-11:15, Paper WeAT2.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0003.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('3'); return false" title="Click to show or hide the keywords and abstract">Towards an Omnidirectional Catadioptric RGB-D Camera</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195214" title="Click to go to the Author Index">Iglesias, José</a></td><td class="r">Inst. Superior Técnico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168557" title="Click to go to the Author Index">Miraldo, Pedro</a></td><td class="r">Inst. Superior Técnico, Univ. of Lisbon</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122994" title="Click to go to the Author Index">Ventura, Rodrigo</a></td><td class="r">Inst. Superior Técnico</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab3" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Omnidirectional_Vision" title="Click to go to the Keyword Index">Omnidirectional Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a></span><br>
                           <strong>Abstract:</strong> In this paper we address the 3D reconstruction of points, on a non-central catadioptric system, composed by a mirror, a projector, and a perspective camera. The goal of the paper is to propose a framework to build an omnidirectional depth camera, towards an omnidirectional RGB-D camera system. The main contributions are: an efficient technique to project 3D points from the world to an image of a general non-central catadioptric camera; the definition of the template pattern (for both the projector and camera's images); and the matching between the projection of these features to the world and its respective images. The 3D depth is directly recovered using the template matching approach. In conclusion, we apply some filtering techniques to improve the results. To evaluate the proposed framework, we test the method using synthetic data, under different levels and types of noises, proving that the framework is robust to noise and, thus, can be put into practice.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat2_02">11:15-11:30, Paper WeAT2.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1240.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1240'); return false" title="Click to show or hide the keywords and abstract">Camera Rotation Estimation Using 3D Mesh Surfaces Representation of Spherical Images</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196618" title="Click to go to the Author Index">Benseddik, Houssem-Eddine</a></td><td class="r">IBISC Labiratory Evry Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105844" title="Click to go to the Author Index">Hadj-Abdelkader, Hicham</a></td><td class="r">IBISC</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128885" title="Click to go to the Author Index">Bouchafa, Samia</a></td><td class="r">Univ. Paris XI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201265" title="Click to go to the Author Index">Cherki, Brahim</a></td><td class="r">Tlemcen Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1240" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Omnidirectional_Vision" title="Click to go to the Keyword Index">Omnidirectional Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> This paper presents a novel rotation estimation approach based on 3D mesh representation of spherical images. Indeed, unit sphere is becoming a natural space for projecting images captured from the central cameras (conventional and nonconventional cameras, as omnidirectional camera) and obtaining the spherical images. The proposed method relies on representing the spherical images into a 3D space based on image intensities. Spherical harmonic coefficients are then calculated for the 3D mesh surfaces and used to estimate an initial rotation between the underlying spherical images in spectral domain. The optimal rotation is then refined through the ICP algorithm. Experimental results, using synthetic and real image dataset, demonstrate the effectiveness of the proposed approach for rotation estimation, as well as its robustness against real conditions and images occlusion. A comparison between the proposed method and competitive ones, is performed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat2_03">11:30-11:45, Paper WeAT2.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1447.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1447'); return false" title="Click to show or hide the keywords and abstract">Spatial Layout and Surface Reconstruction from Omnidirectional Images</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128778" title="Click to go to the Author Index">Posada, Luis Felipe</a></td><td class="r">Univ. EAFIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202550" title="Click to go to the Author Index">Velasquez-Lopez, Alejandro</a></td><td class="r">Univ. EAFIT</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1447" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Omnidirectional_Vision" title="Click to go to the Keyword Index">Omnidirectional Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> This paper presents a spatial layout recovery approach from single omnidirectional images. Vertical structures in the scene are extracted via classification from heterogeneous features computed at the superpixel level. Vertical surfaces are further classified according to their main orientation by fusing oriented line features, floor-wall boundary features and histogram of oriented gradients (HOG) with a Random Forest classifier. Oriented line features are used to build an orientation map that considers the main vanishing points. The floor-wall boundary feature attempts to reconstruct the scene shape as if it were observed from a bird’s-eye view. Finally, the HOG descriptors are aggregated per superpixel and summarize the gradient distribution at homogeneous appearance regions. Compared to existing methods in the literature which rely only on corners or lines, our method gains statistical support from multiple cues aggregated per superpixel which provide more robustness against noise, occlusion, and clutter.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat2_04">11:45-12:00, Paper WeAT2.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1488.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1488'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>GUMS: A Generalized Unified Model for Stereo Omnidirectional Vision (Demonstrated Via a Folded Catadioptric System)</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137693" title="Click to go to the Author Index">Jaramillo, Carlos</a></td><td class="r">The City Coll. of New York</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156565" title="Click to go to the Author Index">Valenti, Roberto G.</a></td><td class="r">The City Coll. City Univ. of New York</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100041" title="Click to go to the Author Index">Xiao, Jizhong</a></td><td class="r">The City Coll. of New York</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1488" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1488.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Omnidirectional_Vision" title="Click to go to the Keyword Index">Omnidirectional Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a></span><br>
                           <strong>Abstract:</strong> This paper introduces GUMS, a complete projection model for omnidirectional stereo vision systems. GUMS is based on the existing generalized unified model (GUM), which we extend in order to satisfy a tight relationship among a pair of omnidirectional views for fixed baseline sensors. We exemplify the proposed model’s calibration via a single-camera coaxial omnistereo system in a joint bundle-adjusted fashion. We compare our coupled method against the naive approach where the calibration of intrinsic parameters is first performed individually for each omnidirectional view using existing monoc- ular implementations, to then solve for the extrinsic parameters as an additional step that has no effect on the intrinsic model solutions initially computed. We validate GUMS and its calibration effectiveness using both real and synthetic systems against ground-truth data. Our calibration method proves successful for correcting the unavoidable misalignment present in vertically-configured catadioptric rigs. We also generate 3D point clouds employing the calibrated GUMS systems in order to demonstrate the qualitative outcome of our contribution.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat3"><b>WeAT3</b></a></td>
               <td class="r">#103</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat3" title="Click to go to the Program at a Glance"><b>Manipulation</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102257" title="Click to go to the Author Index">Harada, Kensuke</a></td><td class="r">Osaka Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#195462" title="Click to go to the Author Index">Sadigh, Dorsa</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat3_01">11:00-11:15, Paper WeAT3.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0001.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Learning Task-Specific Models for Dexterous, In-Hand Manipulation with Simple, Adaptive Robot Hands</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#136999" title="Click to go to the Author Index">Liarokapis, Minas</a></td><td class="r">Yale Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103607" title="Click to go to the Author Index">Dollar, Aaron</a></td><td class="r">Yale Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0001.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Dexterous_Manipulation" title="Click to go to the Keyword Index">Dexterous Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a hybrid methodology based on a combination of analytical, numerical and machine learning methods for performing dexterous, in-hand manipulation with simple, adaptive robot hands. A constrained optimization scheme utilizes analytical models that describe the kinematics of adaptive hands and classic conventions for modelling quasistatically the manipulation problem, providing intuition about the problem mechanics. A machine learning (ML) scheme is used in order to split the problem space, deriving task-specific models that account for difficult to model, dynamic phenomena (e.g., slipping). In this respect, the ML scheme: 1) employs the simulation module in order to explore the feasible manipulation paths for a specific hand-object system, 2) feeds the feasible paths to an experimental setup that collects manipulation data in an automated fashion, 3) uses clustering techniques in order to group together similar manipulation trajectories, 4) trains a set of task-specific manipulation models and 5) uses classification techniques in order to trigger a task-specific model based on the user provided task specifications. The efficacy of the proposed methodology is experimentally validated using various adaptive robot hands in 2D and 3D in-hand manipulation tasks.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat3_02">11:15-11:30, Paper WeAT3.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1112.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1112'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Position-Force Combination Control with Passive Flexibility for Versatile In-Hand Manipulation Based on Posture Interpolation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182454" title="Click to go to the Author Index">Or, Keung</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191034" title="Click to go to the Author Index">Tomura, Mami</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108304" title="Click to go to the Author Index">Schmitz, Alexander</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184706" title="Click to go to the Author Index">Funabashi, Satoshi</a></td><td class="r">Waseda Univ. Sugano Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100151" title="Click to go to the Author Index">Sugano, Shigeki</a></td><td class="r">Waseda Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1112" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1112.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Dexterous_Manipulation" title="Click to go to the Keyword Index">Dexterous Manipulation</a></span><br>
                           <strong>Abstract:</strong> In-hand manipulation is often needed to accomplish a practical task after grasping an object. In-hand manipulation of variously sized and shaped objects in multi-fingered hands without dropping the object is challenging. In this paper we suggest a combined strategy of force control and passive adaptation through soft fingertips with simple interpolation control to achieve in-hand manipulation between various postures and with various objects. While passive compliance can be achieved in numerous ways, this paper uses soft skin, as it does not require complex mechanisms and was easy to integrate in the robot hand (Allegro hand). Softness has proven to significantly ease object grasping, and the current paper shows the importance of softness also for in-hand manipulation. In particular, the simple interpolation strategy between various postures is successful when combined with soft fingertips, with or without force control, but fails with hard fingertips. Objects of varying size, shape and hardness were reliably manipulated. While the soft fingertips enabled good results in our experiments, a sufficiently precise definition of the postures and object size was required. When combining the interpolation control with a force control strategy, bigger errors in defining the posture and object size are possible, without deforming or dropping the object, and the resultant force is lower. As a result, we achieved robust in-hand manipulation between various postures and with objects of different size, shape and hardness.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat3_03">11:30-11:45, Paper WeAT3.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1438.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1438'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>An Empirical Comparison among the Effect of Different Supports in Sequential Robotic Manipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180200" title="Click to go to the Author Index">Cao, Chao</a></td><td class="r">The Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109858" title="Click to go to the Author Index">Wan, Weiwei</a></td><td class="r">National Inst. of AIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131357" title="Click to go to the Author Index">Pan, Jia</a></td><td class="r">The City Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102257" title="Click to go to the Author Index">Harada, Kensuke</a></td><td class="r">Osaka Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1438" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1438.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manipulation_and_Compliant_Assembly" title="Click to go to the Keyword Index">Manipulation and Compliant Assembly</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> Pick-and-place regrasp extends the manipulation capability of a robot by using a sequence of regrasps to accomplish tasks that are not possible using a single grasp due to constraints such as kinematics or collisions between the robot and the environment. Previous work on pick-and-place only leveraged static passive devices for intermediate placements, and thus is limited in the flexibility and robustness to reorient an object.<p>In this paper, we extend the reorientation capability of a pick-and-place regrasp by adding an actively actuated gripper fixed in the working cell, and using it as the intermediate location for regrasping. In particular, our method automatically computes the stable placements of an object being hold in the gripper support, finds a rich set of force-closure grasps, performs k-means based grasp clustering, generates a graph of regrasp actions, and searches for the optimal regrasp sequence. To compare the regrasping performance with typical passive supports, we evaluate the success rate while performing tasks on various models. Experiments on reorientation tasks validate the benefit of using an actively actuated gripper for regrasp placement.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat3_04">11:45-12:00, Paper WeAT3.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1684.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1684'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Data-Driven Statistical Modeling of a Cube Regrasp</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149887" title="Click to go to the Author Index">Paolini, Robert</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107845" title="Click to go to the Author Index">Mason, Matthew T.</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1684" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1684.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Dexterous_Manipulation" title="Click to go to the Keyword Index">Dexterous Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a></span><br>
                           <strong>Abstract:</strong> Regrasping is the process of adjusting the position and orientation of an object in one's hand. The study of robotic regrasping has generally been limited to use of theoretical analytical models and cases with little uncertainty. Analytical models and simulations have so far proven unable to capture the complexity of the real world. Empirical statistical models are more promising, but collecting good data is difficult. In this paper, we collect data from 3300 robot regrasps, and use this data to learn two probability functions: 1) The probability that the object is still in the robot's hand after a regrasp action; and 2) The probability distribution of the object pose after the regrasp given that the object is still grasped. Both of these functions are learned using kernel density estimation with a similarity metric over object pose. We show that our data-driven models achieve comparable accuracy to a geometric model and an off-the-shelf simulator in classification and prediction tasks, while also enabling us to predict probability distributions.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat4"><b>WeAT4</b></a></td>
               <td class="r">#104</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat4" title="Click to go to the Program at a Glance"><b>Cell Manipulation</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102299" title="Click to go to the Author Index">Sun, Dong</a></td><td class="r">City Univ. of Hong Kong</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#100115" title="Click to go to the Author Index">Arai, Tatsuo</a></td><td class="r">Osaka Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat4_01">11:00-11:15, Paper WeAT4.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0170.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('170'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Automated In-Vivo Transportation of Biological Cells with a Disturbance Compensation Controller</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191797" title="Click to go to the Author Index">Li, Xiao Jian</a></td><td class="r">Univ. of Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178749" title="Click to go to the Author Index">Liu, Chi Chi</a></td><td class="r">City Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#144342" title="Click to go to the Author Index">Chen, Shuxun</a></td><td class="r">City Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168604" title="Click to go to the Author Index">Wang, Yong</a></td><td class="r">Univ. of Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113528" title="Click to go to the Author Index">Cheng, Shuk Han</a></td><td class="r">City Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102299" title="Click to go to the Author Index">Sun, Dong</a></td><td class="r">City Univ. of Hong Kong</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab170" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0170.VI.mpg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a></span><br>
                           <strong>Abstract:</strong> As rapid development of precision medicine, in vivo manipulation of micro/nano-scaled particles have attracted increasing attention in recent years. To accommodate complex in-vivo environment, robot-aided automated manipulation technology is highly demanded in trapping and controlling micro/nano-particles stably and effectively. This paper presents an in-vivo cell manipulation system, where a disturbance compensation controller is utilized to minimize the effect of fluid (e.g., blood flow) on the cell. The controller has exhibited advantages in adjusting cell tracking trajectory online, minimizing the steady-state error, and eliminating overshoot. Simulation and experimental results verify the performance of the controller.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat4_02">11:15-11:30, Paper WeAT4.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1434.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1434'); return false" title="Click to show or hide the keywords and abstract">Localizing a Needle Tip Using 2D Microscope Images and Detecting Vertical Approach of a Needle Based on Focus Measures for Intracellular Microneedle Insertion</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156185" title="Click to go to the Author Index">Park, Seongsik</a></td><td class="r">POSTECH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100095" title="Click to go to the Author Index">Chung, Wan Kyun</a></td><td class="r">POSTECH</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1434" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biological_Applications_of_Micro_Robots" title="Click to go to the Keyword Index">Biological Applications of Micro Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> Microneedle insertion is useful for elucidating the processes in living cells and their organelles. However, mechanical puncture by the needle causes traumatic damage to the cell. As a less invasive process, we have developed intracellular needle insertion using femtosecond laser cell ablation. To quickly and precisely position the spot ablated by the laser, we accurately located the needle tip in a 2D image plane. When the needle approaches the cell surface, the only accessible information is the microscope image; the vertical approach of the needle is unknown and must be detected. To this end, we propose an image process that integrates needle recognition, needle-tip localization, image focus measure, and vertical approach detection. The proposed image process was tested in 15 experimental sessions at various locations. The needle tip was reasonably and consistently positioned in the image, and the vertical approach was detected within the safe and plausible ranges.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat4_03">11:30-11:45, Paper WeAT4.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1507.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1507'); return false" title="Click to show or hide the keywords and abstract">Accurate Releasing of Biological Cells Using Two Release Methods Generated by High Speed Motion of an End Effector</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184847" title="Click to go to the Author Index">Kim, Eunhye</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133641" title="Click to go to the Author Index">Kojima, Masaru</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107423" title="Click to go to the Author Index">Kamiyama, Kazuto</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165924" title="Click to go to the Author Index">Horade, Mitsuhiro</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105114" title="Click to go to the Author Index">Mae, Yasushi</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100115" title="Click to go to the Author Index">Arai, Tatsuo</a></td><td class="r">Osaka Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1507" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biological_Applications_of_Micro_Robots" title="Click to go to the Keyword Index">Biological Applications of Micro Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> The reliable manipulation of micro-objects has been a still difficult work in scientific and technical field due to scale effects. This paper presents two types of release methods, using local stream and inertia force generated by 3D high speed motion of an end effector, for releasing and accurate positioning of biological cells. Two-fingered microhand driven by DC motors for both end effectors and PZT actuators for right end effector is employed. A parallel mechanism controlled by three PZT actuators generates 3D high speed motions to release cells adhered to one of the end effector. The local stream and inertia force created by high speed motion of the right end effector detach the cells adhered to the left end effector and right end effector, respectively. To generate the necessary external forces for separation of the attached cells, the vibration having high frequency and suitable amplitude is applied. For accurate positioning of the object, circular motions are proposed. To verify the advantage of the proposed motion, we compare five motions, three 1D motions and two circular motions. Experiments were conducted employing 16µm NIH3T3 cells. From these analyses of experiments, we conclude that the proposed motions can detach micro objects (100%) with high position accuracy (3±0.7µm) on desired position after release.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat4_04">11:45-12:00, Paper WeAT4.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1633.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1633'); return false" title="Click to show or hide the keywords and abstract">Self-Assembly of Toroidal Magnetic Microstructures towards in Vitro Cell Structures</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123774" title="Click to go to the Author Index">Takeuchi, Masaru</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192991" title="Click to go to the Author Index">Hattori, Mamoru</a></td><td class="r">Meijo Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113358" title="Click to go to the Author Index">Ichikawa, Akihiko</a></td><td class="r">Meijo Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111272" title="Click to go to the Author Index">Ohara, Kenichi</a></td><td class="r">Meijo Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103491" title="Click to go to the Author Index">Nakajima, Masahiro</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101162" title="Click to go to the Author Index">Fukuda, Toshio</a></td><td class="r">Meijo Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101240" title="Click to go to the Author Index">Hasegawa, Yasuhisa</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146031" title="Click to go to the Author Index">Huang, Qiang</a></td><td class="r">Intelligent Robotics Inst. Beijing Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1633" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biological_Applications_of_Micro_Robots" title="Click to go to the Keyword Index">Biological Applications of Micro Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a new method to assemble microstructures with biological cells towards in vitro 3D cellular structures. The proposed assembly method uses self-assembly process of magnetized toroidal microstructures. Biocompatible toroidal hydrogel microstructures are prepared by electrodeposition method, and ferrite particles are put on the fabricated structures using poly-L-lysine (PLL). The microstructures are magnetized by the magnetic field at 3 T, and assembled by the magnetic self-assembly process. Biological cells were encapsulated in the microstructures and cultured to achieve high density of cells inside structures. The magnetized microstructures were assembled automatically. The magnetic force generated from the ferrite embedded microstructures was estimated and compared to the fluid resistance applied to the microstructures. The proposed method can be applied to achieve 3D in vitro cell structures with vascular networks for tissue engineering applications.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat5"><b>WeAT5</b></a></td>
               <td class="r">#105</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat5" title="Click to go to the Program at a Glance"><b>Search and Rescue Robots</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#124488" title="Click to go to the Author Index">Wang, Dangxiao</a></td><td class="r">Beihang Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#100118" title="Click to go to the Author Index">Tadokoro, Satoshi</a></td><td class="r">Tohoku Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat5_01">11:00-11:15, Paper WeAT5.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0664.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('664'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>WALS-Robot: A Compact and Transformable Wheel-Arm-Leg-Sucker Hybrid Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191798" title="Click to go to the Author Index">Zhang, Dandan</a></td><td class="r">Beihang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124488" title="Click to go to the Author Index">Wang, Dangxiao</a></td><td class="r">Beihang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab664" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0664.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Search_and_Rescue_Robots" title="Click to go to the Keyword Index">Search and Rescue Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Mobile_Manipulation" title="Click to go to the Keyword Index">Mobile Manipulation</a></span><br>
                           <strong>Abstract:</strong> Based on the integrated design concept of using the robot’s mechanical arm for both locomotion and manipulation, we proposed a compact and transformable robot, i.e. the WALS-Robot, which utilizes combination and switch among four components: wheels, arms, legs and suckers. The WALS-Robot could transform among five locomotion modes to fulfill locomotion requirements in indoor unstructured environments, and have dexterous manipulation, and low power consumption. To reduce the redundancy of mechanical structure and the moving payload for the robot, the mobile platform and the mechanical arm could work as a unity, i.e. the mechanical arm can switch into a leg of the robot to reduce payload during moving modes. Experimental results validated key performance of the robot, including locomotion accuracy and efficiency, compact volume and low power consumption. The integrated design concept illustrated the adaptability in diverse unstructured indoor environments, enlarging the manipulation workspace, and enhancing the energy efficiency.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat5_02">11:15-11:30, Paper WeAT5.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0784.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('784'); return false" title="Click to show or hide the keywords and abstract">The Design and Experiments of a Small Wheel-Legged Mobile Robot System with Two Robotic Arms</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196130" title="Click to go to the Author Index">Chang, Qingkai</a></td><td class="r">Harbin Inst. of Tech. Shenzhen Graduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196152" title="Click to go to the Author Index">Liu, Xiaolong</a></td><td class="r">Harbin Inst. of Tech. Shenzhen Graduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114039" title="Click to go to the Author Index">Xu, Wenfu</a></td><td class="r">Harbin Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196150" title="Click to go to the Author Index">Yan, Lei</a></td><td class="r">Harbin Inst. of Tech. Shenzhen Graduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188978" title="Click to go to the Author Index">Yang, Bingsong</a></td><td class="r">Harbin Inst. of Tecnology</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab784" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Search_and_Rescue_Robots" title="Click to go to the Keyword Index">Search and Rescue Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a></span><br>
                           <strong>Abstract:</strong> In this paper, we developed a small wheel-legged mobile robot system, which could walk on different road environments using wheels or legs. It is composed of mechanical, sensor and control subsystems. The mechanical subsystem includes a wheel-legged mobile platform, a rigid robotic arm and a flexible arm. The mobile platform provides a variety of movement ways to meet the requirement of different mobility. The rigid arm (denoted by arm-a) is a serial manipulator with 4-DOFs. It can be used to grasp and manipulate payloads. The flexible arm (denoted by arm-b) is a manipulator with continuous curve, and a camera is mounted on arm-b. So it can be used to provide visual inspection and measurement information. The sensor subsystem is composed of ultrasonic sensors mounted on the platform and a WIFI camera mounted on arm-b. It provides measurement information and visual inspection for remote control. The control subsystem includes an embedded controller and a PC computer. The former is developed based on an ARM microprocessor, on which the real-time operation system—RT-Thread system runs. The mission decomposition and trajectory planning algorithms are programed in C language and run in the PC. At last, typical experiments are performed. Experiment results verified the robot’s mobility, operation capability and remote-control function.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat5_03">11:30-11:45, Paper WeAT5.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0826.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('826'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Multi-Target Rendezvous Search</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133857" title="Click to go to the Author Index">Meghjani, Malika</a></td><td class="r">McGill Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166102" title="Click to go to the Author Index">Manjanna, Sandeep</a></td><td class="r">McGill Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102604" title="Click to go to the Author Index">Dudek, Gregory</a></td><td class="r">McGill Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab826" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0826.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Search_and_Rescue_Robots" title="Click to go to the Keyword Index">Search and Rescue Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a></span><br>
                           <strong>Abstract:</strong> In this paper, we examine multi-target search, where one or more targets must be found by a moving robot. Given the target’s initial probability distribution or the expected search region, we present an analysis of three search strategies - Global maxima search, Local maxima search, and Spiral search. We aim at minimizing the mean-time-to-find and maximizing the total probability of finding the target. This leads to two types of illustrative performance metrics: minimum time capture and guaranteed capture. We validate the search strategies with respect to these two performance metrics. In addition, we study the effect of different target distributions on the performance of the search strategies. We also consider the practical realization of the proposed algorithms for multi-target search. The search strategies are analytically evaluated, through simulations and illustrative deployments, in open-water with an Autonomous Surface Vehicle (ASV) and drifting sensor targets.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat5_04">11:45-12:00, Paper WeAT5.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1416.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1416'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Development of a Spherical Tether-Handling Device with a Coupled Differential Mechanism for Tethered Teleoperated Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196591" title="Click to go to the Author Index">Ichimura, Tomoya</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102290" title="Click to go to the Author Index">Tadakuma, Kenjiro</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196599" title="Click to go to the Author Index">Takane, Eri</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110833" title="Click to go to the Author Index">Konyo, Masashi</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100118" title="Click to go to the Author Index">Tadokoro, Satoshi</a></td><td class="r">Tohoku Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1416" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1416.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Search_and_Rescue_Robots" title="Click to go to the Keyword Index">Search and Rescue Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> Tethered robots often experience entangling of their cables with obstacles in uncertain disaster environments. This paper proposes a spherical tether handling device that unfastens a robot's tether during surveys by releasing the tether and carrying it aside. By using a differential mechanism, the device drives shells and rollers that hold the tether. On flat surfaces, the device moves forward by driving the shells. When the device climbs over steps, the rollers are driven by the differential mechanism to pull the tether automatically. After prototyping the device, we confirm the surmountability of the proposed device against steps. The results show that the device can climb a height 90.9% of its diameter. We also demonstrate a scenario to handle the tether and untangle multiple tangles in an environment with several obstacles.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat6"><b>WeAT6</b></a></td>
               <td class="r">#106</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat6" title="Click to go to the Program at a Glance"><b>Industrial Robot</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#166803" title="Click to go to the Author Index">MacCurdy, Robert</a></td><td class="r">MIT</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#140616" title="Click to go to the Author Index">Yuan, Peijiang</a></td><td class="r">Beihang Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat6_01">11:00-11:15, Paper WeAT6.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0268.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('268'); return false" title="Click to show or hide the keywords and abstract"> Object Detection and Motion Planning for Automated Welding of Tubular Joints</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164751" title="Click to go to the Author Index">Ahmed, Mariam</a></td><td class="r">National Univ. of Singapore</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187902" title="Click to go to the Author Index">Tan, Yan Zhi</a></td><td class="r">National Univ. of Singapore</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107947" title="Click to go to the Author Index">Lee, Gim Hee</a></td><td class="r">National Univ. of Singapore</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100139" title="Click to go to the Author Index">Chew, Chee Meng</a></td><td class="r">National Univ. of Singapore</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#125394" title="Click to go to the Author Index">Pang, Chee Khiang</a></td><td class="r">National Univ. of Singapore</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab268" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a></span><br>
                           <strong>Abstract:</strong> Automatic welding of tubular TKY joints is an important and challenging task for the marine and offshore industry. In this paper, a framework for tubular joint detection and motion planning is proposed. The pose of the real tubular joint is detected using RGB-D sensors, which is used to obtain a real-to-virtual mapping for positioning the workpiece in a virtual environment. For motion planning, a Bi-directional Transition-based Rapidly exploring Random Tree (BiTRRT) algorithm is used to generate trajectories for reaching the desired goals. The complete framework is verified with experiments, and the results show that the robot welding torch is able to transit without collision to desired goals which are close to the tubular joint.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat6_02">11:15-11:30, Paper WeAT6.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0635.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('635'); return false" title="Click to show or hide the keywords and abstract">Perpendicularity Adjustment End Effector for Aeronautical Drilling Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168488" title="Click to go to the Author Index">Chen, Dongdong</a></td><td class="r">Beihang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140616" title="Click to go to the Author Index">Yuan, Peijiang</a></td><td class="r">Beihang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130202" title="Click to go to the Author Index">Wang, Tianmiao</a></td><td class="r">Beijing Univ. of Aeronautics and Astronautics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159441" title="Click to go to the Author Index">Shi, Zhenyun</a></td><td class="r">Beihang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168522" title="Click to go to the Author Index">Liu, Yuanwei</a></td><td class="r">Beihang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183126" title="Click to go to the Author Index">Lin, Minqing</a></td><td class="r">Beihang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab635" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Planning_and_Control" title="Click to go to the Keyword Index">Integrated Planning and Control</a></span><br>
                           <strong>Abstract:</strong> The quality of holes has important influence on the mechanical strength, assembly quality and life of aircraft, and inferior quality holes may even cause airplane crash and casualties. The perpendicular accuracy of holes during drilling is crucial one of all the factors influencing the quality of holes. In order to improve the perpendicular accuracy during drilling, this paper presented an attitude adjustment mechanism and attitude adjustment algorithm for the end effector. For the mechanism, it adjusts the drill bit attitude by using double eccentric discs and a spherical pair. After the surface normal vector at drilling point is obtained, double eccentric discs will rotate define angels calculated by using attitude adjustment algorithm based on the shortest time principle to achieve the coincidence of the surface normal vector and the drill bit axis vector if the angle between the normal vector and drill bit axis vector is greater than 0.5 degree. To demonstrate the method mentioned above, simulation and experiment are carried out on the aeronautical drilling robot. The results show that the attitude adjustment mechanism and attitude adjustment algorithm can increase the perpendicular accuracy of holes during drilling and satisfy the demand in automatic aircraft assembly.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat6_03">11:30-11:45, Paper WeAT6.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0768.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('768'); return false" title="Click to show or hide the keywords and abstract">Vibration Control of Multilink Flexible Robotic Arm with Impulse Spectrum</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171236" title="Click to go to the Author Index">Zhang, Wenxi</a></td><td class="r">Shanghai Jiao Tong Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab768" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a></span><br>
                           <strong>Abstract:</strong> In this paper, a new method with impulse spectrum is presented as a more general way for vibration control of the robotic arm of flexible multiple links. An impulse spectrum is directly responsible for basic processions. The multiple ODE of the arm is analyzed as an LTI system fit for superposition due to its dynamically relative constant. The study shows that the impulse spectrum proposed to suppress vibration of the multiple links driven by a joint is dependent on the spectral functions of individual subsystem modes. An oscillatory matrix built with spectral functions of higher orders is derived for multi-degree optional design of the multilink, multi-mode spectrum robust against multiple parameters perturbation. Nonlinear programming is discussed to shorten a band spectrum. The band spectra are proposed, presented for wider robustness against variation of frequencies in the vicinity of a centered frequency, and for band robustness over grouped frequencies. Finally simulations are conducted to validate the theoretical work, and the satisfactory results are achieved.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat6_04">11:45-12:00, Paper WeAT6.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1567.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1567'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Printable Programmable Viscoelastic Materials for Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166803" title="Click to go to the Author Index">MacCurdy, Robert</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196842" title="Click to go to the Author Index">Lipton, Jeffrey</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137750" title="Click to go to the Author Index">Li, Shuguang</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101388" title="Click to go to the Author Index">Rus, Daniela</a></td><td class="r">MIT</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1567" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1567.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> Impact protection and vibration isolation are an important component of the mobile robot designer's toolkit; however, current damping materials are available only in bulk or molded form, requiring manual fabrication steps and restricting material property control. In this paper we demonstrate a new method for 3D printing viscoelastic materials with specified material properties. This method allows arbitrary net-shape material geometries to be rapidly fabricated and enables continuously varying material properties throughout the finished part. This new ability allows robot designers to tailor the properties of viscoelastic damping materials in order to reduce impact forces and isolate vibrations. We present a case study for using this material to create jumping robots with programmed levels of bouncing.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat7"><b>WeAT7</b></a></td>
               <td class="r">#107</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat7" title="Click to go to the Program at a Glance"><b>Robot Learning</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#111403" title="Click to go to the Author Index">Nagai, Takayuki</a></td><td class="r">Univ. of Electro-Communications</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#107736" title="Click to go to the Author Index">Howard, Thomas</a></td><td class="r">Univ. of Rochester</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat7_01">11:00-11:15, Paper WeAT7.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1220.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1220'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Online Joint Learning of Object Concepts and Language Model Using Multimodal Hierarchical Dirichlet Process</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195844" title="Click to go to the Author Index">Aoki, Tatsuya</a></td><td class="r">The Univ. of Electro-Communications</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195842" title="Click to go to the Author Index">Nishihara, Joe</a></td><td class="r">The Univ. of Electro-Communications</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111407" title="Click to go to the Author Index">Nakamura, Tomoaki</a></td><td class="r">The Univ. of Electro-Communications</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111403" title="Click to go to the Author Index">Nagai, Takayuki</a></td><td class="r">Univ. of Electro-Communications</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1220" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1220.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a></span><br>
                           <strong>Abstract:</strong> One of the biggest challenges in intelligent robotics is to build robots that can learn to use language. To this end, we think that the practical long-term on-line concept/word learning algorithm for robots is a key issue to be addressed. In this paper, we develop an unsupervised on-line learning algorithm that uses Bayesian nonparametrics for categorizing multimodal sensory signals such as audio, visual, and haptic information for robots. The robot uses its physical body to grasp and observe an object from various viewpoints as well as listen to the sound during the observation. The most important property of the proposed framework is to learn multimodal concepts and the language model simultaneously. This mutual learning framework of concepts and language significantly improves both speech recognition and multimodal categorization performances. We conducted a long-term experiment where a human subject interacted with a real robot over 100 hours using 499 objects. Some interesting results of the experiment are discussed in this paper.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat7_02">11:15-11:30, Paper WeAT7.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1467.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1467'); return false" title="Click to show or hide the keywords and abstract">Non-Parametric Contextual Stochastic Search</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#173616" title="Click to go to the Author Index">Abdolmaleki, Abbas</a></td><td class="r">Campus Univ. De Santiago</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106277" title="Click to go to the Author Index">Lau, Nuno</a></td><td class="r">Aveiro Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106288" title="Click to go to the Author Index">Reis, Luís Paulo</a></td><td class="r">Univ. of Minho</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113579" title="Click to go to the Author Index">Neumann, Gerhard</a></td><td class="r">TU Darmstadt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1467" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Motor_Skill_Learning" title="Click to go to the Keyword Index">Motor Skill Learning</a></span><br>
                           <strong>Abstract:</strong> Stochastic search algorithms are black-box optimizer of an objective function. They have recently gained a lot of attention in operations research, machine learning and policy search of robot motor skills due to their ease of use and their generality. Yet, many stochastic search algorithms require relearning if the task or objective function changes slightly to adapt the solution to the new situation or the new context. In this paper, we consider the contextual stochastic search setup. Here, we want to find multiple good parameter vectors for multiple related tasks, where each task is described by a continuous context vector. Hence, the objective function might change slightly for each parameter vector evaluation of a task or context. Contextual algorithms have been investigated in the field of policy search, however, the search distribution typically uses a parametric model that is linear in the some hand-defined context features. Finding good context features is a challenging task, and hence, non-parametric methods are often preferred over their parametric counter-parts. In this paper, we propose a non-parametric contextual stochastic search algorithm that can learn a non-parametric search distribution for multiple tasks simultaneously. In difference to existing methods, our method can also learn a context dependent covariance matrix that guides the exploration of the search process. We illustrate its performance on several non-linear contextual tasks.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat7_03">11:30-11:45, Paper WeAT7.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1594.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1594'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Model for Verifiable Grounding and Execution of Complex Natural Language Instructions</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#173640" title="Click to go to the Author Index">Boteanu, Adrian</a></td><td class="r">Cornell Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107736" title="Click to go to the Author Index">Howard, Thomas</a></td><td class="r">Univ. of Rochester</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196806" title="Click to go to the Author Index">Arkin, Jacob</a></td><td class="r">Univ. of Rochester</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103643" title="Click to go to the Author Index">Kress-Gazit, Hadas</a></td><td class="r">Cornell Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1594" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1594.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Personal_Robots" title="Click to go to the Keyword Index">Personal Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Reactive_and_Sensor_Based_Planning" title="Click to go to the Keyword Index">Reactive and Sensor-Based Planning</a></span><br>
                           <strong>Abstract:</strong> Current methods of grounding natural language instructions do not include reactive or temporal components, making these methods unsuitable for instructions describing tasks as sets of conditional instructions. We introduce the Verifiable Distributed Correspondence Graph (V-DCG) model, which enables the validation of natural language instructions by using Linear Temporal Logic (LTL) specifications together with physical world groundings. We demonstrate the V-DCG model on a physical robot and provide examples of the output our system produces for natural language instructions.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat7_04">11:45-12:00, Paper WeAT7.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1616.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1616'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Functional Object-Oriented Network for Manipulation Learning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192313" title="Click to go to the Author Index">Paulius, David A.</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158962" title="Click to go to the Author Index">Huang, Yongqiang</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192343" title="Click to go to the Author Index">Milton, Roger</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192259" title="Click to go to the Author Index">Buchanan, William</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192238" title="Click to go to the Author Index">Sam, Jeanine</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105834" title="Click to go to the Author Index">Sun, Yu</a></td><td class="r">Univ. of South Florida</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1616" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1616.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> This paper presents a novel structured knowledge representation called the functional object-oriented network (FOON) to model the connectivity of the functional-related objects and their motions in manipulation tasks. The graphical model FOON is learned by observing object state change and human manipulations with the objects. Using a well-trained FOON, robots can decipher a task goal, seek the correct objects at the desired states on which to operate, and generate a sequence of proper manipulation motions. The paper describes FOON's structure and an approach to form a universal FOON with extracted knowledge from online instructional videos. A graph retrieval approach is presented to generate manipulation motion sequences from the FOON to achieve a desired goal, demonstrating the flexibility of FOON in creating a novel and adaptive means of solving a problem using knowledge gathered from multiple sources. The results are demonstrated in a simulated environment to illustrate the motion sequences generated from the FOON to carry out the desired tasks.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat8"><b>WeAT8</b></a></td>
               <td class="r">#108</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat8" title="Click to go to the Program at a Glance"><b>Physical Human-Robot Interaction</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100071" title="Click to go to the Author Index">Tomizuka, Masayoshi</a></td><td class="r">Univ. of California</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#150752" title="Click to go to the Author Index">Ajoudani, Arash</a></td><td class="r">Advanced Robotics Department</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat8_01">11:00-11:15, Paper WeAT8.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0369.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('369'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Towards Multi-Modal Intention Interfaces for Human-Robot Co-Manipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156776" title="Click to go to the Author Index">Peternel, Luka</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105401" title="Click to go to the Author Index">Tsagarakis, Nikos</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150752" title="Click to go to the Author Index">Ajoudani, Arash</a></td><td class="r">Advanced Robotics Department</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab369" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0369.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperative_Manipulators" title="Click to go to the Keyword Index">Cooperative Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a></span><br>
                           <strong>Abstract:</strong> This paper presents a novel approach for human-robot cooperation in tasks with dynamic uncertainties. The essential element of the proposed method is a multi-modal interface that provides the robot with the feedback about the human motor behaviour in real-time. The human muscle activity measurements and the arm force manipulability properties encode the information about the motion and impedance, and the intended configuration of the task frame, respectively. Through this human-in-the-loop framework, the developed hybrid controller of the robot can adapt its actions to provide the desired motion and impedance regulation in different phases of the cooperative task. We experimentally evaluate the proposed approach in a two-person sawing task that requires an appropriate complementary behaviour from the two agents.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat8_02">11:15-11:30, Paper WeAT8.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0446.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('446'); return false" title="Click to show or hide the keywords and abstract">Implementation of Haptic Communication in Comanipulative Tasks: A Statistical State Machine Model</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190324" title="Click to go to the Author Index">Lucas, Roche</a></td><td class="r">Univ. Pierre Et Marie Curie</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105836" title="Click to go to the Author Index">Saint-Bauzel, Ludovic</a></td><td class="r">Univ. Pierre Et Marie Curie-Paris6</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab446" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a></span><br>
                           <strong>Abstract:</strong> This paper presents an experimental evaluation of physical human-human interaction in lightweight condition using a one degree of freedom robotized setup. It explores possible origins of Physical Human-Human communication, more precisely, the hypothesis of a time based communication. To explore if the communication is correlated to time a statistical state machine model based on physical Human-Human interaction is proposed. The model is tested with 14 subjects and presents results that are close to human-human performances.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat8_03">11:30-11:45, Paper WeAT8.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0481.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('481'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Human Guidance Programming on a 6-DoF Robot with Collision Avoidance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195814" title="Click to go to the Author Index">Lin, Hsien-Chung</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195830" title="Click to go to the Author Index">Fan, Yongxiang</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194727" title="Click to go to the Author Index">Tang, Te</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100071" title="Click to go to the Author Index">Tomizuka, Masayoshi</a></td><td class="r">Univ. of California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab481" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0481.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a></span><br>
                           <strong>Abstract:</strong> In the application of physical human-robot interaction (pHRI), the collaboration between human and robot can significantly improve the production efficiency through combination of the human's flexible intelligence and the robot's consistent performance. In this application, however, it is an important concern to ensure the safety of the human and the robot. In the human guidance programming scenario, the operator plans a collision-free path for the robot end-effector, but the robot body might collide with an obstacle while being guided by the operator. In this paper, a novel on-line velocity based collision avoidance algorithm is developed to solve the problem in this particular scenario. The proposed algorithm gives an explicit solution to deal with both collision avoidance and human guidance command at the same time, which provides the operator a better and safer lead through programming experience. The real-time experiment is performed on FANUC LR Mate 200 iD/7L in three different obstacle scenarios.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat8_04">11:45-12:00, Paper WeAT8.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1050.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1050'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Sensorimotor Reinforcement Learning Framework for Physical Human-Robot Interaction</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#173904" title="Click to go to the Author Index">Ghadirzadeh, Ali</a></td><td class="r">Computer Vision and Active Perception (CVAP) Lab, CSC KTH Royal</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191936" title="Click to go to the Author Index">Bütepage, Judith</a></td><td class="r">KTH Royal Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170470" title="Click to go to the Author Index">Maki, Atsuto</a></td><td class="r">KTH Royal Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101716" title="Click to go to the Author Index">Kragic, Danica</a></td><td class="r">KTH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106818" title="Click to go to the Author Index">Björkman, Mårten</a></td><td class="r">KTH</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1050" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1050.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a></span><br>
                           <strong>Abstract:</strong> Modeling of physical human-robot collaborations is generally a challenging problem due to the unpredictive nature of human behavior. To address this issue, we present a data-efficient reinforcement learning framework which enables a robot to learn how to collaborate with a human partner. The robot learns the task from its own sensorimotor experiences in an unsupervised manner. The uncertainty in the interaction is modeled using Gaussian processes (GP) to implement a forward model and an action-value function. Optimal action selection given the uncertain GP model is ensured by Bayesian optimization. We apply the framework to a scenario in which a human and a PR2 robot jointly control the ball position on a plank based on vision and force/torque data. Our experimental results show the suitability of the proposed method in terms of fast and data-efficient model learning, optimal action selection under uncertainty and equal role sharing between the partners.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat9"><b>WeAT9</b></a></td>
               <td class="r">#204~205</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat9" title="Click to go to the Program at a Glance"><b>Force Control 1</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#119052" title="Click to go to the Author Index">Yu, Ningbo</a></td><td class="r">NanKai Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#107817" title="Click to go to the Author Index">Righetti, Ludovic</a></td><td class="r">Max-Planck Inst. for Intelligent Systems</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat9_01">11:00-11:15, Paper WeAT9.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0482.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('482'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Robotic Manipulation of Deformable Objects by Tangent Space Mapping and Non-Rigid Registration</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194727" title="Click to go to the Author Index">Tang, Te</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171352" title="Click to go to the Author Index">Liu, Changliu</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135706" title="Click to go to the Author Index">Chen, Wenjie</a></td><td class="r">FANUC Corp</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100071" title="Click to go to the Author Index">Tomizuka, Masayoshi</a></td><td class="r">Univ. of California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab482" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0482.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a></span><br>
                           <strong>Abstract:</strong> Recent works of non-rigid registration have shown promising applications on tasks of deformable manipulation. Those approaches use thin plate spline-robust point matching (TPS-RPM) algorithm to regress a transformation function, which could generate a corresponding manipulation trajectory given a new pose/shape of the object. However, this method regards the object as a bunch of discrete and independent points. Structural information, such as shape and length, is lost during the transformation. This limitation makes the object’s final shape to differ from training to test, and can sometimes cause damage to the object because of excessive stretching. To deal with these problems, this paper introduces a tangent space mapping (TSM) algorithm, which maps the deformable object in the tangent space instead of the Cartesian space to maintain structural information. The new algorithm is shown to be robust to the changes in the object’s pose/shape, and the object’s final shape is similar to that of training. It is also guaranteed not to overstretch the object during manipulation. A series of rope manipulation tests are performed to validate the effectiveness of the proposed algorithm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat9_02">11:15-11:30, Paper WeAT9.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0747.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('747'); return false" title="Click to show or hide the keywords and abstract">Coordinated Compliance Control of Dual-Arm Robot for Payload Manipulation: Master-Slave and Shared Force Control</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196150" title="Click to go to the Author Index">Yan, Lei</a></td><td class="r">Harbin Inst. of Tech. Shenzhen Graduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169193" title="Click to go to the Author Index">Mu, Zonggao</a></td><td class="r">Harbin Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114039" title="Click to go to the Author Index">Xu, Wenfu</a></td><td class="r">Harbin Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188978" title="Click to go to the Author Index">Yang, Bingsong</a></td><td class="r">Harbin Inst. of Tecnology</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab747" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperative_Manipulators" title="Click to go to the Keyword Index">Cooperative Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> With the rapid development of robotics, dual-arm robots have been more and more widely used. Compared with the traditional single manipulator, it is very challenging for a dual-arm robot in modelling, planning and control. In this paper, we propose two compliance control methods for dual arm coordination to meet different requirements of fine manipulation tasks, such as payload carrying, assembly and repairing. The first method is called master-slave force control strategy, and the second is shared force control strategy. For the former, the desired trajectory and operational force of master arm are given in advance. Then that of salve arm are calculated from the closed-chain constraint equation. On the contrary, the two arms can be controlled in shared mode, that is to say, the desired trajectory and operational force of the end-effector of dual arms are decomposed from the closed-chain constraint equation directly. The coordinated kinematic and dynamic equations of dual-arm robot system are established by considering the closed-chain constraint relationship. According to the force balance equation of the objective payload, the common force is decomposed into the desired end-effector force of each manipulator. Finally, the control algorithms are verified by simulation and experiment.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat9_03">11:30-11:45, Paper WeAT9.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1359.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1359'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Structured Contact Force Optimization for Kino-Dynamic Motion Generation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149791" title="Click to go to the Author Index">Herzog, Alexander</a></td><td class="r">Max-Planck-Inst. for Intelligent Systems, Tuebingen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102004" title="Click to go to the Author Index">Schaal, Stefan</a></td><td class="r">MPI Intelligent Systems & Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107817" title="Click to go to the Author Index">Righetti, Ludovic</a></td><td class="r">Max-Planck Inst. for Intelligent Systems</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1359" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1359.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> Optimal control approaches in combination with trajectory optimization have recently proven to be a promising control strategy for legged robots. Computationally efficient and robust algorithms were derived using simplified models of the contact interaction between robot and environment such as the linear inverted pendulum model (LIPM). However, as humanoid robots enter more complex environments, less restrictive models become increasingly important. As we leave the regime of linear models, we need to build dedicated solvers that can compute interaction forces together with consistent kinematic plans for the whole-body. In this paper, we address the problem of planning robot motion and interaction forces for legged robots given predefined contact surfaces. The motion generation process is decomposed into two alternating parts computing force and motion plans in coherence. We focus on the properties of the momentum computation leading to sparse optimal control formulations to be exploited by a dedicated solver. In our experiments, we demonstrate that our motion generation algorithm computes consistent contact forces and joint trajectories for our humanoid robot. We also demonstrate the favorable time complexity due to our formulation and composition of the momentum equations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat9_04">11:45-12:00, Paper WeAT9.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1606.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1606'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Deformation Control of a Multijoint Manipulator Based on Maxwell and Voigt Models</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108266" title="Click to go to the Author Index">Senoo, Taku</a></td><td class="r">Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196834" title="Click to go to the Author Index">Jinnai, Gaku</a></td><td class="r">Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148187" title="Click to go to the Author Index">Murakami, Kenichi</a></td><td class="r">Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101392" title="Click to go to the Author Index">Ishikawa, Masatoshi</a></td><td class="r">Univ. of Tokyo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1606" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1606.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Dexterous_Manipulation" title="Click to go to the Keyword Index">Dexterous Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> In this study, a deformation control with spatial decoupling properties is designed and implemented. This control strategy treats the shift in position and posture attributable to an external force as the deformation of the robot. The deformation dynamics are constructed from the Maxwell and Voigt models, which describe plastic and elastic deformation, respectively. Next, a control method is proposed to passively achieve different deformation characteristics in each direction. Two physical simulations with a robotic arm are executed to validate the proposed control law.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weat10"><b>WeAT10</b></a></td>
               <td class="r">#206~208</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weat10" title="Click to go to the Program at a Glance"><b>Animation and Simulation</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#172580" title="Click to go to the Author Index">Magnanimo, Vito</a></td><td class="r">Kuka Roboter GmbH</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#101638" title="Click to go to the Author Index">Corke, Peter</a></td><td class="r">QUT</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat10_01">11:00-11:15, Paper WeAT10.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0478.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('478'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Inverse Real-Time Finite Element Simulation for Robotic Control of Flexible Needle Insertion in Deformable Tissues</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183480" title="Click to go to the Author Index">Adagolodjo, Yinoussa</a></td><td class="r">Univ. of Strasbourg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195847" title="Click to go to the Author Index">Goffin, Laurent</a></td><td class="r">Unistra, ICube</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105409" title="Click to go to the Author Index">de Mathelin, Michel</a></td><td class="r">Univ. of Strasbourg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170047" title="Click to go to the Author Index">Courtecuisse, Hadrien</a></td><td class="r">AVR, CNRS Strasbourg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab478" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0478.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Animation_and_Simulation" title="Click to go to the Keyword Index">Animation and Simulation</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_tissue_Modeling" title="Click to go to the Keyword Index">Soft-tissue Modeling</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a></span><br>
                           <strong>Abstract:</strong> This paper introduces a new method for automatic robotic needle steering in deformable tissues. The main contribution relies on the use of an inverse Finite Element (FE) simulation to control an articulated robot interacting with deformable structures. In this work we consider a flexible needle, embedded in the end effector of a 6 arm Mitsubishi RV1A robot, and its insertion into a silicone phantom. Given a trajectory on the rest configuration of the silicone phantom, our method provides in real-time the displacements of the articulated robot which guarantee the permanence of the needle within the predefined path, taking into account any undergoing deformation on both the needle and the trajectory itself. A forward simulation combines i) a kinematic model of the robot, ii) FE models of the needle and phantom gel iii) an interaction model allowing the simulation of friction and puncture force. A Newton-type method is then used to provide the displacement of the robot to minimize the distance between the needle's tip and the desired trajectory. We validate our approach with a simulation in which a virtual robot can successfully perform the insertion while both the needle and the trajectory undergo significant deformations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat10_02">11:15-11:30, Paper WeAT10.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0725.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('725'); return false" title="Click to show or hide the keywords and abstract">Integrating Realistic Simulation Engines within the MORSE Framework</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141869" title="Click to go to the Author Index">Degroote, Arnaud</a></td><td class="r">ISAE</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190040" title="Click to go to the Author Index">Koch, Pierrick</a></td><td class="r">LAAS-CNRS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101697" title="Click to go to the Author Index">Lacroix, Simon</a></td><td class="r">LAAS/CNRS</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab725" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Animation_and_Simulation" title="Click to go to the Keyword Index">Animation and Simulation</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Architectures__Protocols_And_Middle_Ware" title="Click to go to the Keyword Index">Architectures, Protocols And Middle-Ware</a></span><br>
                           <strong>Abstract:</strong> The complexity of robotics is due to the tight interactions between hardware, complex softwares, and environments. While real world experience is the only way to assess the efficiency and robustness of a robotics system, simulations help to pave the way to actual experiments. But an overall robotics system requires simulations at a level of realism which no holistic simulator can provide, given the wide spectrum of disciplines and physical processes involved. This paper presents a way to integrate various simulators, in a distributed, scalable and repeatable way, to benefit from their different advantages and get the best fitted and accurate simulation for a given robotics system. It depicts how the MORSE open-source robotics simulator is adapted to comply with the High Level Architecture standard, thus allowing the reuse of numerous dedicated realistic simulators. Two examples of the integration of simulators are provided.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat10_03">11:30-11:45, Paper WeAT10.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0976.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('976'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Simulation-Based Design of Dynamic Controllers for Humanoid Balancing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188961" title="Click to go to the Author Index">Tan, Jie</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191091" title="Click to go to the Author Index">Xie, Zhaoming</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151779" title="Click to go to the Author Index">Boots, Byron</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132937" title="Click to go to the Author Index">Liu, Karen</a></td><td class="r">Georgia Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab976" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0976.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Animation_and_Simulation" title="Click to go to the Keyword Index">Animation and Simulation</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> Model-based trajectory optimization often fails to find a reference trajectory for under-actuated bipedal robots performing highly-dynamic, contact-rich tasks in the real world due to inaccurate physical models. In this paper, we propose a complete system that automatically designs a reference trajectory that succeeds on tasks in the real world with a very small number of real world experiments. We adopt existing system identification techniques and show that, with appropriate model parameterization and control optimization, an iterative system identification framework can be effective for designing reference trajectories. We focus on a set of tasks that leverage the momentum transfer strategy to rapidly change the whole-body from an initial configuration to a target configuration by generating large accelerations at the center of mass and switching contacts.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weat10_04">11:45-12:00, Paper WeAT10.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1485.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1485'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>High-Fidelity Simulation for Evaluating Robotic Vision Performance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196766" title="Click to go to the Author Index">Skinner, John Robert</a></td><td class="r">Queensland Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196783" title="Click to go to the Author Index">Garg, Sourav</a></td><td class="r">Queensland Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101779" title="Click to go to the Author Index">Sünderhauf, Niko</a></td><td class="r">Queensland Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101638" title="Click to go to the Author Index">Corke, Peter</a></td><td class="r">QUT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104502" title="Click to go to the Author Index">Upcroft, Ben</a></td><td class="r">Queensland Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106848" title="Click to go to the Author Index">Milford, Michael J</a></td><td class="r">Queensland Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1485" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1485.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Animation_and_Simulation" title="Click to go to the Keyword Index">Animation and Simulation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> Robotic vision, unlike computer vision, typically involves processing a stream of images from a camera with time varying pose operating in an environment with time varying lighting conditions and moving objects. Repeating robotic vision experiments under identical conditions is often impossible, making it difficult to compare different algorithms. For machine learning applications a critical bottleneck is the limited amount of real world image data that can be captured and labelled for both training and testing purposes. In this paper we investigate the use of a photo-realistic simulation tool to address these challenges, in three specific domains: robust place recognition, visual SLAM and object recognition. For the first two problems we generate generate images from a complex 3D environment with systematically varying camera paths, camera viewpoints and lighting conditions. For the first time we are able to systematically characterize the performance of these algorithms as paths and lighting conditions change. In particular, we are able to systematically generate varying camera viewpoint datasets that would be difficult or impossible to generate in the real world. We also compare algorithm results for a camera in a real environment and a simulated camera in a simulation model of that real environment. Finally, for the object recognition domain, we generate labelled image data and characterise the viewpoint dependency of a current convolution neural network in performing object recognition. Together these results provide a multi-domain demonstration of the beneficial properties of using simulation to characterize and analyse a wide range of robotic vision algorithms.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wef1t12"><b>WeF1T12</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wef1t12" title="Click to go to the Program at a Glance"><b>RSJ Special Tutorial for Young Researchers</b></a></td>
               <td class="r">Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#106955" title="Click to go to the Author Index">Shibata, Tomohiro</a></td><td class="r">Kyushu Inst. of Tech</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wef1t11"><b>WeF1T11</b></a></td>
               <td class="r">#301</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wef1t11" title="Click to go to the Program at a Glance"><b>Industry Forum</b></a></td>
               <td class="r">Forum</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102438" title="Click to go to the Author Index">Choi, Hyouk Ryeol</a></td><td class="r">Sungkyunkwan Univ</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="welunch1"><b>WeLunch1</b></a></td>
               <td class="r">#203</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#welunch1" title="Click to go to the Program at a Glance"><b>SICE Luncheon Seminar</b></a></td>
               <td class="r">Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101826" title="Click to go to the Author Index">Nakauchi, Yasushi</a></td><td class="r">Univ. of Tsukuba</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wek1"><b>WeK1</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wek1" title="Click to go to the Program at a Glance"><b>Keynote Talk 3. I-Ming Chen: Human-Robot-Environment Interaction for
<br>Advanced Manufacturing Skill Learning and Automation</b></a></td>
               <td class="r">Keynote session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100103" title="Click to go to the Author Index">Wang, Zhidong</a></td><td class="r">Chiba Inst. of Tech</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wek2"><b>WeK2</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wek2" title="Click to go to the Program at a Glance"><b>Keynote Talk 4. Jungyun Choi: Robots That Could Change Our Lives–
<br>Challenges and Opportunities</b></a></td>
               <td class="r">Keynote session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100181" title="Click to go to the Author Index">Oh, Paul Y.</a></td><td class="r">Univ. of Nevada, Las Vegas (UNLV)</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wet21"><b>WeT21</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wet21" title="Click to go to the Program at a Glance"><b>AI-Based Robot Systems</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#107437" title="Click to go to the Author Index">Lima, Pedro U.</a></td><td class="r">Inst. Superior Técnico - Inst. for Systems and Robotics</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#115196" title="Click to go to the Author Index">Piater, Justus</a></td><td class="r">Univ. of Innsbruck</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_01">14:05-14:06, Paper WeT21.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0025.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('25'); return false" title="Click to show or hide the keywords and abstract">Efficient Object Search for Mobile Robots in Dynamic Environments: Semantic Map As an Input for the Decision Maker</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#136419" title="Click to go to the Author Index">Veiga, Tiago</a></td><td class="r">Inst. Superior Técnico - Inst. for Systems and Robotics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168557" title="Click to go to the Author Index">Miraldo, Pedro</a></td><td class="r">Inst. Superior Técnico, Univ. of Lisbon</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122994" title="Click to go to the Author Index">Ventura, Rodrigo</a></td><td class="r">Inst. Superior Técnico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107437" title="Click to go to the Author Index">Lima, Pedro U.</a></td><td class="r">Inst. Superior Técnico - Inst. for Systems and Robotics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab25" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#AI_Reasoning_Methods" title="Click to go to the Keyword Index">AI Reasoning Methods</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a></span><br>
                           <strong>Abstract:</strong> In this work we study the efficient search of objects in domestic environments, using probabilistic logic to represent uncertainty about object location and partially observable Markov Decision Processes (POMDP) for the decision-making process regarding the movements to be carried out by the robot to improve its belief about the object locations. We propose the use of a semantic map that stores information about the knowledge in the system and updates it, by an inference process, with sensor information received from the object recognition module. However, semantic maps are not capable of actively search for more information in the environment. For that reason a decision-making module, based on a POMDP framework, is integrated in the system. Several experiments were made in a realistic apartment test bed using every day objects and a mobile robot, showing that this hybrid solution makes the search process more efficient.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_02">14:06-14:07, Paper WeT21.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0065.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('65'); return false" title="Click to show or hide the keywords and abstract">Task-Conversions for Integrating Human and Machine Perception in a Unified Task</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183483" title="Click to go to the Author Index">Lee, Hyungtae</a></td><td class="r">US Army Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184470" title="Click to go to the Author Index">Kwon, Heesung</a></td><td class="r">U.S. Army Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182748" title="Click to go to the Author Index">Robinson, Ryan</a></td><td class="r">Army Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192506" title="Click to go to the Author Index">Donavanik, Daniel</a></td><td class="r">Army Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182797" title="Click to go to the Author Index">Nothwang, William</a></td><td class="r">Army Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183505" title="Click to go to the Author Index">Marathe, Amar</a></td><td class="r">U.S. Army Res. Lab</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab65" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Different strategies for feature extraction and synthesis employed by humans and computers are complementary. Combining the two paradigms into an integrated object recognition system may considerably improve performance over either used in isolation.	Rapid Serial Visual Presentation (RSVP) is one technique that is useful for integrating human perception into a machine perception system. In this paper, we apply computer vision techniques to image data filtered through human RSVP combined with button-press. We introduce &quot;task conversions&quot; to integrate the two modalities, applying precise localization of computer vision with the detection capabilities of RSVP. We also introduce new training/test/validation partition scheme in order to avoid overfitting. We employ naive Bayesian fusion and a novel method, dynamic belief fusion (DBF), in a joint scheme as fusion approaches.	The experiment demonstrates that DBF consistently leverages the complementary approaches in order to improve recognition consistently.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_03">14:07-14:08, Paper WeT21.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0084.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('84'); return false" title="Click to show or hide the keywords and abstract">A Deep-Network Solution towards Model-Less Obstacle Avoidance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195229" title="Click to go to the Author Index">Tai, Lei</a></td><td class="r">City Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171600" title="Click to go to the Author Index">Li, Shaohua</a></td><td class="r">The Hong Kong Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#125556" title="Click to go to the Author Index">Liu, Ming</a></td><td class="r">City Univ. of Hong Kong</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab84" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_Control" title="Click to go to the Keyword Index">Learning Control</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a></span><br>
                           <strong>Abstract:</strong> Obstacle avoidance is the core problem for mobile robots. Its objective is to allow mobile robots to explore an unknown environment without colliding into other objects. It is the basis for various tasks, e.g. surveillance and rescue, etc. Previous approaches mainly focused on geometric models (such as constructing local cost-maps) which could be regarded as low-level intelligence without any cognitive process. Recently, deep learning has made great breakthroughs in computer vision, especially for recognition and cognitive tasks. It takes advantage of the hierarchical models inspired by human brain structures. However, it is a fact that deep learning, up till now, has seldom been used for controlling and decision making. <p>Inspired by the advantages of deep learning, we take indoor obstacle avoidance as example to show the effectiveness of a hierarchical structure that fuses a convolutional neural network (CNN) with a decision process. It is a highly compact network structure that takes raw depth images as input, and generates control commands as network output, by which a model-less obstacle avoidance behavior is achieved. We test our approach in real-world indoor environments. The new findings and results are reported at the end of the paper.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_04">14:08-14:09, Paper WeT21.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0159.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('159'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Detecting Object Affordances with Convolutional Neural Networks</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171078" title="Click to go to the Author Index">Nguyen, Anh</a></td><td class="r">Inst. Italiano Di Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147896" title="Click to go to the Author Index">Kanoulas, Dimitrios</a></td><td class="r">Inst. Italiano Di Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100179" title="Click to go to the Author Index">Caldwell, Darwin G.</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105401" title="Click to go to the Author Index">Tsagarakis, Nikos</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab159" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0159.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a></span><br>
                           <strong>Abstract:</strong> We present a novel and real-time method to detect object affordances from RGB-D images. Our method trains a deep Convolutional Neural Network (CNN) to learn deep features from the input data in an end-to-end manner. The CNN has an encoder-decoder architecture in order to obtain smooth label predictions. The input data are represented as multiple modalities to let the network learn the features more effectively. Our method sets a new benchmark on detecting object affordances, improving the accuracy by 20% in comparison with the state-of-the-art methods that use hand-designed geometric features. Furthermore, we apply our detection method on a full-size humanoid robot (WALK-MAN) to demonstrate that the robot is able to perform grasps after efficiently detecting the object affordances.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_05">14:09-14:10, Paper WeT21.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0289.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('289'); return false" title="Click to show or hide the keywords and abstract">Robust Sound Source Mapping Using Three-Layered Selective Audio Rays for Mobile Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168487" title="Click to go to the Author Index">Su, Daobilige</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128040" title="Click to go to the Author Index">Nakamura, Keisuke</a></td><td class="r">Honda Res. Inst. Japan Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107173" title="Click to go to the Author Index">Nakadai, Kazuhiro</a></td><td class="r">Honda Res. Inst. Japan Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106478" title="Click to go to the Author Index">Valls Miro, Jaime</a></td><td class="r">Univ. of Tech. Sydney</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab289" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Audition" title="Click to go to the Keyword Index">Robot Audition</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> This paper investigates sound source mapping in a real environment using a mobile robot. Our approach is based on audio ray tracing which integrates occupancy grids and sound source localization using a laser range finder and a microphone array. Since previous audio ray tracing approaches rely on all observed rays and grids, the observation error caused by sound reflection, sound occlusion, wall occlusion, sounds at misdetected grids, etc. degrades the mapping performance, which is a critical issue in real-world applications. Thus, we propose a three-layered selective audio ray tracing inspired by the multi-store model. The first layer conducts frame-based unreliable ray rejection (sensory rejection) considering sound reflection and wall occlusion. The second layer introduces triangulation using all audio rays to detect sounds at misdetected grids and reject audio rays related to the detected sounds every time after the detection (short-term rejection). After all, the third layer rejects rays using the whole history (long-term rejection) to disambiguate the sound occlusion. Experimental results under various situations are presented, which proves the effectiveness of our method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_06">14:10-14:11, Paper WeT21.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0357.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('357'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Characterization and Validation of a Novel Robotic System for Fluid-Mediated Programmable Stochastic Self-Assembly</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159628" title="Click to go to the Author Index">Haghighat, Bahar</a></td><td class="r">EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102253" title="Click to go to the Author Index">Martinoli, Alcherio</a></td><td class="r">EPFL</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab357" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0357.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Self_Organised_Robot_Systems" title="Click to go to the Keyword Index">Self-Organised Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Agent_Based_Systems" title="Click to go to the Keyword Index">Agent-Based Systems</a></span><br>
                           <strong>Abstract:</strong> Several self-assembly systems have been developed in recent years, where depending on the capabilities of the building blocks and the controlability of the environment, the assembly process is guided typically through either a fully centralized or a fully distributed control approach. In this work, we present a novel experimental system for studying the range of fully centralized to fully distributed control strategies. The system is built around the floating 3-cm-sized Lily robots, and comprises a water-filled tank with peripheral pumps, an overhead camera, an overhead projector, and a workstation capable of controlling the fluidic flow field, setting the ambient luminosity, communicating with the robots over radio, and visually tracking their trajectories. We carry out several experiments to characterize the system and validate its capabilities. First, a statistical analysis is conducted to show that the system is governed by reaction diffusion dynamics, and validate the applicability of the standard chemical kinetics modeling. Additionally, the natural tendency of the system for structure formation subject to different flow fields is investigated and corresponding implications on guiding the self-assembly process are discussed. Finally, two control approaches are studied: 1) a fully distributed control approach and 2) a distributed approach with additional central supervision exhibiting an improved performance. The formation time statistics are compared and a discussion on the generalization of the method is provided.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_07">14:11-14:12, Paper WeT21.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0358.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('358'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Reducing Adaptation Latency for Multi-Concept Visual Perception in Outdoor Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192056" title="Click to go to the Author Index">Wigness, Maggie</a></td><td class="r">U.S. Army Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102697" title="Click to go to the Author Index">Rogers III, John G.</a></td><td class="r">US Army Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#119729" title="Click to go to the Author Index">Navarro-Serment, Luis E.</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165684" title="Click to go to the Author Index">Suppe, Arne</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192099" title="Click to go to the Author Index">Draper, Bruce</a></td><td class="r">Colorado State Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab358" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0358.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> Multi-concept visual classification is emerging as a common environment perception technique, with applications in autonomous mobile robot navigation. Supervised visual classifiers are typically trained with large sets of images, hand annotated by humans with region boundary outlines followed by label assignment. This annotation is time consuming, and unfortunately, a change in environment requires new or additional labeling to adapt visual perception. The time is takes for a human to label new data is what we call adaptation latency. High adaptation latency is not simply undesirable but may be infeasible for scenarios with limited labeling time and resources. In this paper, we introduce a labeling framework to the environment perception domain that significantly reduces adaptation latency using unsupervised learning in exchange for a small amount of label noise. Using two real-world datasets we demonstrate the speed of our labeling framework, and its ability to collect environment labels that train high performing multi-concept classifiers. Finally, we demonstrate the relevance of this label collection process for visual perception as it applies to navigation in outdoor environments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_08">14:12-14:13, Paper WeT21.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0440.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('440'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Online Learning of Visibility and Appearance for Object Pose Estimation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179466" title="Click to go to the Author Index">Lee, Bhoram</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106613" title="Click to go to the Author Index">Lee, Daniel D.</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab440" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0440.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> This paper presents an online self-supervised approach to improve the quality and relevance of input point cloud to a 3D registration algorithm. The suggested method considers the visibility of the model points and learns discriminative appearance of the object under gradual changes. It selectively reduces the amount of information to process by excluding non-visible points of the model and removing outliers from data stream, which results in better alignment between the input data and the model. Thus, by providing a good initial pose, it speeds up the iterative procedure of EM-like optimization for pose estimation (i.e., ICP) to achieve better efficiency and robustness. We compiled a new object dataset of RGBD images under camera motion with ground truth poses of the camera and the objects. We have performed experiments on this dataset and obtained promising results.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_09">14:13-14:14, Paper WeT21.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0485.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('485'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Robotic Playing for Hierarchical Complex Skill Learning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172161" title="Click to go to the Author Index">Hangl, Simon</a></td><td class="r">Univ. of Innsbruck</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106000" title="Click to go to the Author Index">Ugur, Emre</a></td><td class="r">Bogazici Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171972" title="Click to go to the Author Index">Szedmak, Sandor</a></td><td class="r">Univ. of Innsbruck</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115196" title="Click to go to the Author Index">Piater, Justus</a></td><td class="r">Univ. of Innsbruck</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab485" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0485.VI.mpg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> In complex manipulation scenarios (e.g. tasks requiring complex interaction of two hands or in-hand manipulation), generalization is a hard problem. Current methods still either require a substantial amount of (supervised) training data and / or strong assumptions on both the environment and the task. In this paradigm, controllers solving these tasks tend to be complex. We propose a paradigm of maintaining simpler controllers solving the task in a small number of specific situations. In order to generalize to novel situations, the robot transforms the environment from novel situations into a situation where the solution of the task is already known. Our solution to this problem is to play with objects and use previously trained skills (basis skills). These skills can either be used for estimating or for changing the current state of the environment and are organized in skill hierarchies. The approach is evaluated in complex pick-and-place scenarios that involve complex manipulation. We further show that these skills can be learned by autonomous playing.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_10">14:14-14:15, Paper WeT21.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0657.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('657'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Mixed Initiative Controller for Simultaneous Intervention, a Model Predictive Control Formulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195570" title="Click to go to the Author Index">Shang, Chengsi</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113582" title="Click to go to the Author Index">Fang, Hao</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202851" title="Click to go to the Author Index">Cai, Tao</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202850" title="Click to go to the Author Index">Chen, Chen</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202852" title="Click to go to the Author Index">Chen, Wenjie</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201763" title="Click to go to the Author Index">Wu, Chu</a></td><td class="r">Beijing Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab657" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0657.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Semi_Autonomous_Robots" title="Click to go to the Keyword Index">Semi-Autonomous Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a></span><br>
                           <strong>Abstract:</strong> In this paper, we discussed the simultaneous intervention problem that arises from human-robot teams. The problem concerns with the case that one human operator has to intervene with several robots at almost the same time and it cannot be handled properly by existing methods. A model predictive control(MPC) based mixed initiative controller was proposed to solve this problem by embedding an intention model into the optimization problem. This method is in essence suitable for general MPC based mixed initiative controllers. The embedded intention model may cause the robot to deviate from its desired trajectory, for which conditions were developed to guarantee that the task completeness is not be affected. A comparison experiment was conducted and results showed that the proposed controller is more efficient and helpful in shortening the intervention time and allowing more robots to be successfully intervened in a simultaneous intervention scenario.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_11">14:15-14:16, Paper WeT21.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0688.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('688'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Active Boundary Component Models for Robotic Dressing Assistance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137244" title="Click to go to the Author Index">Twardon, Lukas</a></td><td class="r">Bielefeld Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103487" title="Click to go to the Author Index">Ritter, Helge Joachim</a></td><td class="r">Bielefeld Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab688" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0688.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> The dynamics of deformable objects, especially that of highly flexible articles of clothing, is difficult to model. This is due to their vast number of degrees of freedom in addition to the noisy and incomplete measurements robots have to cope with. Therefore, we suggest focusing on the structures and object parts which are relevant to the task at hand. The openings (e.g., at the waist, leg or sleeve ends) characterize garments surprisingly well, not only from a topological perspective, but also in terms of their inherent function, namely dressing. We model openings as closed, oriented chains of movable points which we refer to as Active Boundary Component Models (ABCMs). Compared with the hardly predictable motions of an overall piece of clothing, relatively strict assumptions regarding the dynamics of these contour models can be made. We express these assumptions through position-based constraints which drastically restrict the degrees of freedom. In the present paper, we show how ABCMs can be initialized exploiting geometric prior knowledge of garments, and how they can be tracked visually using 3D point cloud data. Additionally, we consider the task of sliding a rod through a pant leg as a first step toward robotic dressing assistance for physically handicapped persons.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_12">14:16-14:17, Paper WeT21.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0775.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('775'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Reverberant Sound Localization with a Robot Head Based on Direct-Path Relative Transfer Function</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146864" title="Click to go to the Author Index">Li, Xiaofei</a></td><td class="r">INRIA Grenoble Rhone-Alpes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155113" title="Click to go to the Author Index">Girin, Laurent</a></td><td class="r">Univ. Grenoble Alpes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192461" title="Click to go to the Author Index">Badeig, Fabien</a></td><td class="r">INRIA Grenoble Rhone-Alpes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123562" title="Click to go to the Author Index">Horaud, Radu</a></td><td class="r">INRIA Grenoble Rhone-Alpes</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab775" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0775.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Audition" title="Click to go to the Keyword Index">Robot Audition</a></span><br>
                           <strong>Abstract:</strong> This paper addresses the problem of sound-source localization (SSL) with a robot head, which remains a challenge in real-world environments. In particular we are interested in locating speech sources, as they are of high interest for human-robot interaction. The microphone-pair response corresponding to the direct-path sound propagation is a function of the source direction. In practice, this response is contaminated by noise and reverberations. The direct-path relative transfer function (DP-RTF) is defined as the ratio between the direct-path acoustic transfer function (ATF) of the two microphones, and it is an important feature for SSL. We propose a method to estimate the DP-RTF from noisy and reverberant signals in the short-time Fourier transform (STFT) domain. First, the convolutive transfer function (CTF) approximation is adopted to accurately represent the impulse response of the microphone array, and the first coefficient of the CTF is mainly composed of the direct-path ATF. At each frequency, the frame-wise speech auto- and cross-power spectral density (PSD) are obtained by spectral subtraction. Then a set of linear equations is constructed by the speech auto- and cross-PSD of multiple frames, in which the DP-RTF is an unknown variable, and is estimated by solving the equations. Finally, the estimated DP-RTFs are concatenated across frequencies and used as a feature vector for SSL. Experiments with a robot, placed in various reverberant environments, show that the proposed method outperforms two state-of-the-art methods.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_13">14:17-14:18, Paper WeT21.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0829.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('829'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Real-Time Pose Estimation and Obstacle Avoidance for Multi-Segment Continuum Manipulator in Dynamic Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190514" title="Click to go to the Author Index">Ataka, Ahmad</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165194" title="Click to go to the Author Index">Qi, Peng</a></td><td class="r">National Univ. of Singapore</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190439" title="Click to go to the Author Index">Shiva, Ali</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181142" title="Click to go to the Author Index">Shafti, Ali</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142097" title="Click to go to the Author Index">Wurdemann, Helge Arne</a></td><td class="r">Univ. Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104575" title="Click to go to the Author Index">Liu, Hongbin</a></td><td class="r">Department of Informatics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101975" title="Click to go to the Author Index">Althoefer, Kaspar</a></td><td class="r">King's Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab829" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0829.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Reactive_and_Sensor_Based_Planning" title="Click to go to the Keyword Index">Reactive and Sensor-Based Planning</a></span><br>
                           <strong>Abstract:</strong> In this paper, we present a novel pose estimation and obstacle avoidance approach for tendon-driven multi-segment continuum manipulators moving in dynamic environments. A novel multi-stage implementation of an Extended Kalman Filter is used to estimate the pose of every point along the manipulator's body using only the position information of each segment tip. Combined with a potential field, the overall algorithm will guide the manipulator tip to a desired target location and, at the same time, keep the manipulator body safe from collisions with obstacles. The results show that the approach works well in a real-time simulation environment that contains moving obstacles in the vicinity of the manipulator.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_14">14:18-14:19, Paper WeT21.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0862.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('862'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Action Recognition and Interpretation from Virtual Demonstrations</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159954" title="Click to go to the Author Index">Haidu, Andrei</a></td><td class="r">Univ. Bremen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103133" title="Click to go to the Author Index">Beetz, Michael</a></td><td class="r">Univ. of Bremen</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab862" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0862.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#AI_Reasoning_Methods" title="Click to go to the Keyword Index">AI Reasoning Methods</a>, <a href="IROS16_KeywordIndexMedia.html#Imitation_Learning" title="Click to go to the Keyword Index">Imitation Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a></span><br>
                           <strong>Abstract:</strong> To properly perform tasks based on abstract instructions, autonomous robots need refined reasoning skills in order to bridge the gap between the ambiguous descriptions and the comprehensive information needed to execute the implied actions. In this article, we present an automated knowledge acquisition system from human executed tasks in virtual environments, and extend the knowledge processing system KNOWROB to be capable to reason on the acquired data. We have set up two scenarios in a physics based simulator: creating a pancake, and garnishing a pizza dough. Users where asked to execute these tasks using the provided tools and ingredients. Using a data processing module we then collect the low-level data and the relevant abstract events from the performed episodes. The recorded data is then made available in a format that robots can understand, by using a symbolic layer to interconnect the two data types in a seamless way.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_15">14:19-14:20, Paper WeT21.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0874.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('874'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Towards a Hierarchy of Loco-Manipulation Affordances</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141340" title="Click to go to the Author Index">Kaiser, Peter</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132185" title="Click to go to the Author Index">Aksoy, Eren Erdal</a></td><td class="r">Karlsruhe Inst. for Tech. (KIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188389" title="Click to go to the Author Index">Grotz, Markus</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102922" title="Click to go to the Author Index">Asfour, Tamim</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab874" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0874.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#AI_Reasoning_Methods" title="Click to go to the Keyword Index">AI Reasoning Methods</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> We propose a formalism for the hierarchical representation of affordances. Starting with a perceived model of the environment consisting of geometric primitives like planes or cylinders, we define a hierarchical system for affordance extraction whose foundation are elementary power grasp affordances. Higher-level affordances, e.g. bimanual affordances, result from combining lower-level affordances with additional properties concerning the underlying geometric primitives of the scene. We model affordances as continuous certainty functions taking into account properties of the environmental elements and the perceiving robot's embodiment. The developed formalism is regarded as the basis for the description of whole-body affordances, i.e. affordances associated with whole-body actions. The proposed formalism was implemented and experimentally evaluated in multiple scenarios based on RGB-D camera data. The feasibility of the approach is demonstrated on a real robotic platform.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_16">14:20-14:21, Paper WeT21.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0970.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('970'); return false" title="Click to show or hide the keywords and abstract">Mobile Robots As Remote Sensors for Spatial Point Process Models</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169916" title="Click to go to the Author Index">Reverdy, Paul</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108300" title="Click to go to the Author Index">Koditschek, Daniel</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab970" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a>, <a href="IROS16_KeywordIndexMedia.html#Reactive_and_Sensor_Based_Planning" title="Click to go to the Keyword Index">Reactive and Sensor-Based Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Networks" title="Click to go to the Keyword Index">Sensor Networks</a></span><br>
                           <strong>Abstract:</strong> Spatial point process models are a commonly-used statistical tool for studying the distribution of objects of interest in a domain. We study the problem of deploying mobile robots as remote sensors to estimate the parameters of such a model, in particular the intensity parameter lambda which measures the mean density of points in a Poisson point process. This problem requires covering an appropriately large section of the domain while avoiding the objects, which we treat as obstacles. We develop a control law that covers an expanding section of the domain and an online criterion for determining when to stop sampling, i.e., when the covered area is large enough to achieve a desired level of estimation accuracy, and illustrate the resulting system with numerical simulations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_17">14:21-14:22, Paper WeT21.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1082.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1082'); return false" title="Click to show or hide the keywords and abstract">Contingency Planning for Automated Vehicles</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196454" title="Click to go to the Author Index">Salvado, João</a></td><td class="r">Inst. for Systems and Robotics (ISR/IST), LARSyS, Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196457" title="Click to go to the Author Index">Custódio, Luis</a></td><td class="r">Inst. for Systems and Robotics (ISR/IST), LARSyS, Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196456" title="Click to go to the Author Index">Hess, Daniel</a></td><td class="r">Deutsches Zentrum F{"u}r Luft Und Raumfahrt E.v. (DLR), Inst</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1082" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> Automated driving is a safety critical process, which requires complex decision making. In order to validate driving decisions, it is possible to maintain at all times a contingency maneuver, which transfers the vehicle to a safe standstill, if other decision making processes fail. In this paper we present a motion planner, which computes contingency maneuvers for an automated vehicle in a 0.1[s] time frame. A discrete set of motion primitives is assembled in a heuristic best-first search. In order to speed up the search, an obstacle sensitive heuristic is applied, which maintains properties of bounded sub-optimality and completeness. A run-time comparison with and without the obstacle sensitive heuristic is presented on two exemplary collision avoidance scenarios.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_18">14:22-14:23, Paper WeT21.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1156.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1156'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Collaborative Navigation for Flying and Walking Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146641" title="Click to go to the Author Index">Fankhauser, Péter</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133249" title="Click to go to the Author Index">Bloesch, Michael</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165855" title="Click to go to the Author Index">Krüsi, Philipp Andreas</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185810" title="Click to go to the Author Index">Diethelm, Remo</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192731" title="Click to go to the Author Index">Wermelinger, Martin</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190619" title="Click to go to the Author Index">Schneider, Thomas</a></td><td class="r">ETH Zürich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178436" title="Click to go to the Author Index">Dymczyk, Marcin Tomasz</a></td><td class="r">ETH Zurich, Autonomous Systems Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114045" title="Click to go to the Author Index">Hutter, Marco</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1156" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1156.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperating_Robots" title="Click to go to the Keyword Index">Cooperating Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Flying and walking robots can use their complementary features in terms of viewpoint and payload capability to the best in a heterogeneous team. To this end, we present our online collaborative navigation framework for unknown and challenging terrain. The method leverages the flying robot's onboard monocular camera to create both a map of visual features for simultaneous localization and mapping and a dense representation of the environment as an elevation map. This shared knowledge from the flying platform enables the walking robot to localize itself against the global map, and plan a global path to the goal by interpreting the elevation map in terms of traversability. While following the planned path, the absolute pose corrections are fused with the legged state estimation and the elevation map is continuously updated with distance measurements from an onboard laser range sensor. This allows the legged robot to safely navigate towards the goal while taking into account any changes in the environment. In this setup, our approach is independent of external localization, relative observations between the robots, and does not require an initial guess about the pose of the robots. The presented methods are fully integrated and we demonstrate their capabilities in an experiment with a hexacopter and a quadrupedal robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_19">14:23-14:24, Paper WeT21.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1212.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1212'); return false" title="Click to show or hide the keywords and abstract">A Perception System for Detecting Brake Levers in Outdoor Rail Yard Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#163853" title="Click to go to the Author Index">Li, Shuai</a></td><td class="r">RPI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192359" title="Click to go to the Author Index">Jain, Arpit</a></td><td class="r">GE Global Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192787" title="Click to go to the Author Index">Sharma, Pramod</a></td><td class="r">GE Global Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111640" title="Click to go to the Author Index">Sen, Shiraj</a></td><td class="r">General Electric</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1212" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> A rail yard is a dangerous environment for humans to work in, primarily because of the possibility of serious injuries associated with moving rail cars, locomotives, and uneven terrain. For robots to act autonomously in such environments, there exists a need for a perception system that can act reliably under uncertain conditions. This uncertainty arises from multiple factors---uncontrolled lighting, uneven terrain, variability in appearance of objects, dynamic environment, noisy sensors, and controllers. In this paper, we present a perception system for a mobile robot that leverages information from various sensing modalities to act reliably in a partially observable environment. We show how our system can detect brake levers on a rail car, by fusing information from multiple detectors. We validate our approach by performing tests in an actual rail yard over multiple days and nights.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_20">14:24-14:25, Paper WeT21.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1224.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1224'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Anticipation and Attention for Robust Object Recognition with RGBD-Data in an Industrial Application Scenario</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114463" title="Click to go to the Author Index">Vaskevicius, Narunas</a></td><td class="r">Jacobs Univ. Bremen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100515" title="Click to go to the Author Index">Pathak, Kaustubh</a></td><td class="r">Jacobs Univ. Bremen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105458" title="Click to go to the Author Index">Birk, Andreas</a></td><td class="r">Jacobs Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1224" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1224.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> An extension based on attention and anticipation of a robot vision pipeline for object recognition in RGBD images from low-cost sensors like MS Kinect or ASUS Xtion is presented. This work originated in research on an industrial application scenario, namely shipping-container unloading, but it is applicable to advanced manipulation tasks in unstructured environments in general where the perception must be very robust while being as fast as possible. For these scenarios, we build on our previous work that proved to be competitive in cluttered scenes in table-top scenarios and which forms the backbone of our RGBD object recognition. It is further enhanced by two main contributions. First, a simple but very effective form of anticipation as top-down expectations of the evolution of the scene due to the actions of the robot is used to speed up the processing. Second, attention is used as a mechanism for further speed-up by focusing processing only on certain regions of interest of the scene based also on an anticipation mechanism. The method is analyzed in experiments using real-world data from an industrial demonstration set-up.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_21">14:25-14:26, Paper WeT21.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1245.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1245'); return false" title="Click to show or hide the keywords and abstract">Active Vision for Dexterous Grasping of Novel Objects</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196262" title="Click to go to the Author Index">Arruda, Ermano Ardiles</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128648" title="Click to go to the Author Index">Wyatt, Jeremy</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142216" title="Click to go to the Author Index">Kopicki, Marek</a></td><td class="r">Univ. of Birmingham</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1245" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Grasping" title="Click to go to the Keyword Index">Grasping</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a></span><br>
                           <strong>Abstract:</strong> How should a robot direct active vision so as to ensure reliable grasping? We answer this question for the case of dexterous grasping of unfamiliar objects. By dexterous grasping we simply mean grasping by any hand with more than two fingers, such that the robot has some choice about where to place each finger. Such grasps typically fail in one of two ways, either unmodeled objects in the scene cause collisions or object reconstruction is insufficient to ensure that the grasp points provide a stable force closure. These problems can be solved more easily if active sensing is guided by the anticipated actions. Our approach has three stages. First, we take a single view and generate candidate grasps from the resulting partial object reconstruction. Second, we drive the active vision approach to maximise surface reconstruction quality around the planned contact points. During this phase, the anticipated grasp is continually refined. Third, we direct gaze to improve the safety of the planned reach to grasp trajectory. We show, on a dexterous manipulator with a camera on the wrist, that our approach (80.4% success rate) outperforms a randomised algorithm (64.3% success rate).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_22">14:26-14:27, Paper WeT21.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1291.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1291'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Autonomous Flipper Control with Safety Constraints</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195222" title="Click to go to the Author Index">Pecka, Martin</a></td><td class="r">Czech Tech. Univ. in Prague</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192220" title="Click to go to the Author Index">Salansky, Vojtech</a></td><td class="r">Faculty of Electrical Engineering, Czech Tech. Univ. In</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134222" title="Click to go to the Author Index">Zimmermann, Karel</a></td><td class="r">Czech Tech. Univ. Prague</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107657" title="Click to go to the Author Index">Svoboda, Tomas</a></td><td class="r">Faculty of Electrical Engineering</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1291" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1291.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a></span><br>
                           <strong>Abstract:</strong> Policy gradient methods require many real-world trials. Some of such trials may endanger the real system and cause its rapid wear. Therefore, a safe or at least gentle-to-wear exploration is a~desired property. We incorporate bounds on the probability of such unwanted trials into a~recent existing method called GPREPS. The resulting algorithm is evaluated on the task of autonomous flipper control for a real Search&Rescue rover platform.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_23">14:27-14:28, Paper WeT21.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1321.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1321'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Learning to Grasp Familiar Objects Using Object View Recognition and Template Matching</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#126160" title="Click to go to the Author Index">Shafii, Nima</a></td><td class="r">Univ. of Aveiro</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169824" title="Click to go to the Author Index">Mohades Kasaei, Seyed Hamidreza</a></td><td class="r">Univ. De Aveiro</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108694" title="Click to go to the Author Index">Seabra Lopes, Luís</a></td><td class="r">Univ. De Aveiro</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1321" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1321.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Grasping" title="Click to go to the Keyword Index">Grasping</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a></span><br>
                           <strong>Abstract:</strong> Robots are still not able to grasp all unforeseen objects. Finding a proper grasp configuration, i.e. the position and orientation of the arm relative to the object, is still challenging. One approach for grasping unforeseen objects is to recognize an appropriate grasp configuration from previous grasp demonstrations. The underlying assumption in this approach is that new objects that are similar to known ones (i.e. they are familiar) can be grasped in a similar way. However finding a grasp representation and a grasp similarity metric is still the main challenge in developing an approach for grasping familiar objects. In this paper, interactive object view learning and recognition capabilities are integrated in the process of learning and recognizing grasps. The object view recognition module uses an interactive incremental learning approach to recognize object view labels. The grasp pose learning approach uses local and global visual features of a demonstrated grasp to learn a grasp template associated with the recognized object view. A grasp distance measure based on Mahalanobis distance is used in a grasp template matching approach to recognize an appropriate grasp pose. The experimental results demonstrate the high reliability of the developed template matching approach in recognizing the grasp poses. Experimental results also show how the robot can incrementally improve its performance in grasping familiar objects.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_24">14:28-14:29, Paper WeT21.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1409.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1409'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Visual Programming for Mobile Robot Navigation Using High-Level Landmarks</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172244" title="Click to go to the Author Index">Lee, Joseph</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#126537" title="Click to go to the Author Index">Lu, Yan</a></td><td class="r">Honda Res. Inst. USA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113892" title="Click to go to the Author Index">Xu, Yiliang</a></td><td class="r">Apple Inc</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101712" title="Click to go to the Author Index">Song, Dezhen</a></td><td class="r">Texas A&M Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1409" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1409.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Programming_Environments" title="Click to go to the Keyword Index">Programming Environments</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a></span><br>
                           <strong>Abstract:</strong> We propose a visual programming system that allows users to specify navigation tasks for mobile robots using high-level landmarks in a virtual reality (VR) environment constructed from the output of visual simultaneous localization and mapping (vSLAM). The VR environment provides a Google Street View-like interface for users to familiarize themselves with the robot's working environment, specify high-level landmarks, and determine task-level motion commands related to each landmark. Our system builds a roadmap by using the pose graph from the vSLAM outputs. Based on the roadmap, the high-level landmarks, and task-level motion commands, our system generates an output path for the robot to accomplish the navigation task. We present data structures, architecture, interface, and algorithms for our system and show that, given n_s search-type motion commands, our system generates a path in O(n_s (n_rlog n_r + m_r)) time, where n_r and m_r are the number of roadmap nodes and edges, respectively. We have implemented our system and tested it on real world data.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet21_25">14:29-14:30, Paper WeT21.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1699.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1699'); return false" title="Click to show or hide the keywords and abstract">A Self-Stabilizing Algorithm for the Foraging Problem in Swarm Robotic Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183228" title="Click to go to the Author Index">Zhou, Guang</a></td><td class="r">Univ. of Texas at Dallas</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196851" title="Click to go to the Author Index">Farokh, Bastani</a></td><td class="r">Univ. of Texas at Dallas</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196854" title="Click to go to the Author Index">Zhu, Wei</a></td><td class="r">Univ. of Texas at Dallas</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196857" title="Click to go to the Author Index">I-Ling, Yen</a></td><td class="r">Univ. of Texas at Dallas</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1699" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Self_Organised_Robot_Systems" title="Click to go to the Keyword Index">Self-Organised Robot Systems</a></span><br>
                           <strong>Abstract:</strong> The foraging problem, which evolved from ants finding food and delivering them to the nest, is for a swarm of robots to transport objects from a source to a destination. To avoid collision of robots or congestions, object transportation is generally conducted in a pipelining manner. Existing solutions towards the foraging problem either have performance problems or cannot tolerate failures. We present a self-stabilizing solution for the swarm robotic system to form a pipeline structure to transport objects and achieve the foraging task. In this paper, we first define the stable state for the swarm, which includes two requirements: (1) the robots operate in non-overlapping regions, i.e., transport objects in a pipeline structure and (2) the transportation rate of the system is optimal. Then, we introduce our self-stabilizing algorithm for the foraging problem and prove its convergence and the correctness of its convergence properties. Due to the self-stabilization nature, our solution is decentralized and fault tolerant. The swarm can achieve the foraging task as long as there is at least one working robot. Due to the definition of the stable state, our swarm system, when converged, can achieve optimal performance. We conduct simulations to evaluate the effectiveness of our algorithm, and the experimental results show that from any state, our algorithm can converge very quickly to reach the stable state and provide optimal performance for object transportation.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wet22"><b>WeT22</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wet22" title="Click to go to the Program at a Glance"><b>Robotic Applications</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#110584" title="Click to go to the Author Index">Abderrahim, Mohamed</a></td><td class="r">Carlos III Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#100097" title="Click to go to the Author Index">Luo, Ren</a></td><td class="r">National Taiwan Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_01">14:05-14:06, Paper WeT22.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0015.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('15'); return false" title="Click to show or hide the keywords and abstract">Autonomous 6D-Docking and Manipulation with Non-Stationary-Base Using Self-Reconfigurable Modular Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159648" title="Click to go to the Author Index">Barrios, Luenin</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165455" title="Click to go to the Author Index">Collins, Thomas Joseph</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#126498" title="Click to go to the Author Index">Kovac, Robert</a></td><td class="r">Jet Propulsion Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106210" title="Click to go to the Author Index">Shen, Wei-Min</a></td><td class="r">USC Information Science Inst</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab15" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Cellular_and_Modular_Robots" title="Click to go to the Keyword Index">Cellular and Modular Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a></span><br>
                           <strong>Abstract:</strong> Aggregation of self-reconfigurable robotic modules can potentially offer many advantages for robotic locomotion and manipulation. The resulting system could be more reliable and fault-tolerant and provide the necessary flexibility for new tasks and environments. However, self-aggregation of modules is a challenging task, especially when the alignment of the docking parties in a 3D environment involves both position and orientation (6D), since the bases of docking may be non-stationary (e.g., floating in space, underwater, or moving along the ground), and the end-effectors may have accumulated uncertainties due to many dynamically-established connections between modules. This paper presents a new framework for docking in such a context and describes a solution for sensor-guided self-reconfiguration and manipulation with non-fixed bases. The main contributions of the paper include a realistic experiment setting for 6D docking where a modular manipulator is floating or rotating in space with a reaction wheel and searches and docks with a target module using vision. The movement of the docking parties is a combination of floating and manipulation, and the precision of the docking is guided by a sensor located at the tip of the docking interface. The docking itself is planned and executed by a real-time algorithm with a theoretical convergence boundary. This new framework has been tested in a high-fidelity physics-based simulator, as well as by real robotic modules based on SuperBot. Experimental results have shown an average success rate of more than 86.7 percent in a variety of different 6D-docking scenarios.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_02">14:06-14:07, Paper WeT22.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0035.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('35'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Rigid and Flexible Structures Combined Deployable Boom for Space Exploration</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#136930" title="Click to go to the Author Index">Zhang, Jun</a></td><td class="r">Southeast Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#112790" title="Click to go to the Author Index">Song, Aiguo</a></td><td class="r">Southeast Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202091" title="Click to go to the Author Index">Xu, Xiaonong</a></td><td class="r">Southeast Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179906" title="Click to go to the Author Index">Lu, Wei</a></td><td class="r">Nanjing Agricultural Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab35" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0035.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> This paper presents a deployable boom which combines a rigid telescopic frame and a flexible tape spring. The front end of the spring is fixed on the rear end of the innermost segment of the frame. The spring spreads and rolls up inside the frame to drive the segments to move one by one to realize the boom deployment and retraction. The driving forces needed to deploy and retract the frame are modeled and simulated. The feasibility of the frame driving by only one spring is also studied. A 1.6 kg prototype system with 2.1 m total deployment length is implemented. Experimental results show the maximum driving forces for deployment and retraction of the frame are about 9.1 N and 6.8 N respectively. The boom is able to deploy in 76 s with energy consumption of 315 J. The boom can resist at least 15 N force axially and 31.5 N&#8729;m bending moment when the forces are acted on its front end. Advantages of this kind of boom enable it to be applied for instruments deployment, walking and sampling assists, and robotic arms design in space exploration.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_03">14:07-14:08, Paper WeT22.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0110.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('110'); return false" title="Click to show or hide the keywords and abstract">A Self-Competitive Method for the Development of an Educational Robot for Children</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#118358" title="Click to go to the Author Index">Tanaka, Fumihide</a></td><td class="r">Univ. of Tsukuba</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146545" title="Click to go to the Author Index">Matsuzoe, Shizuko</a></td><td class="r">Univ. of Tsukuba</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab110" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Education_Robotics" title="Click to go to the Keyword Index">Education Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Companions_and_Social_Human_Robot_Interaction" title="Click to go to the Keyword Index">Robot Companions and Social Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> To accelerate the developmental process of robots interacting with humans in the real world, we propose the simultaneous introduction of two competing robots into the test field. One robot moves autonomously using a preprogrammed behavior set, while the other is remotely controlled by a human operator. The operator attempts to improve the robot by exploring new behavioral elements. Concurrently, the preprogrammed behavior set is tested by the first robot. The main concept is that by allowing the two robots compete against each other, we aim to accelerate the development process. By applying this methodology, we developed an educational robot for children. Herein we report the functioning of this methodology and how behavioral elements were explored and improved through field development.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_04">14:08-14:09, Paper WeT22.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0193.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('193'); return false" title="Click to show or hide the keywords and abstract">Co-Diagnosing Configuration Failures in Co-Robotic Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172313" title="Click to go to the Author Index">Taylor, Adam</a></td><td class="r">Univ. of Nebraska - Lincoln</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147791" title="Click to go to the Author Index">Elbaum, Sebastian</a></td><td class="r">Univ. of Nebraska - Lincoln</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106284" title="Click to go to the Author Index">Detweiler, Carrick</a></td><td class="r">Univ. of Nebraska-Lincoln</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab193" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Failure_Detection_and_Recovery" title="Click to go to the Keyword Index">Failure Detection and Recovery</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> Robotic systems often have complex configuration spaces that, when poorly set, can cause failures. In this work we take advantage of the close synergy between user and robot in co-robotic systems to better diagnose and overcome configuration failures. We leverage users' understanding of the system to mark failures they observe while the system is in operation. <p>A marked failure indicates that the robot either &quot;did not do something when it should have&quot; or &quot;did something when it should not have&quot;. The failure marking is coupled with an automated analysis approach that identifies code predicates involving configuration parameters that may be relevant to each failure type, ranks the parameters according to their potential to be associated with the failure, and suggests adjustments based on the run-time outcome of those predicates. <p>We present the approach, its implementation, and a preliminary study on a configurable unmanned air system. The results show how the approach can successfully help diagnose and adjust faulty configuration parameters in co-robotic systems.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_05">14:09-14:10, Paper WeT22.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0215.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('215'); return false" title="Click to show or hide the keywords and abstract">Electroencephalogram Signal Analysis As Basis for Effective Evaluation of Robotic Therapeutic Massage</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100097" title="Click to go to the Author Index">Luo, Ren</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191424" title="Click to go to the Author Index">Hsu, Chien-Wei</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155884" title="Click to go to the Author Index">Chen, ShenYu</a></td><td class="r">National Taiwan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab215" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> This paper proposes a robotics therapeutic massage evaluation system using electroencephalogram (EEG) signal analysis approach. An anthropomorphic dual arm robot is developed in this work for massage application. Compare to other massage systems, our dual arm robot can provides diversified massage techniques through the impedance control of both Cartesian space and joint space. In order to evaluate the effectiveness of robotic therapeutic massage, the experiments are conducted by recording EEG signals of subject before and after robotic massage. Independent Components Analysis (ICA) is used to filter out artifacts of EEG signals. After signal processing, the power of delta, alpha and beta rhythms are analyzed. The experimental results show an increase in delta power and a decrease in alpha power which represents the relaxation response of subjects. These results give the scientific proof of the effectiveness of robotic therapeutic massage.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_06">14:10-14:11, Paper WeT22.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0240.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('240'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Visual Servoing in Orchard Settings</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#186234" title="Click to go to the Author Index">Haeni, Nicolai</a></td><td class="r">Zurich Univ. of Applied Sciences</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101719" title="Click to go to the Author Index">Isler, Volkan</a></td><td class="r">Univ. of Minnesota</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab240" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0240.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Agriculture_and_Forestry" title="Click to go to the Keyword Index">Robotics in Agriculture and Forestry</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Reactive_and_Sensor_Based_Planning" title="Click to go to the Keyword Index">Reactive and Sensor-Based Planning</a></span><br>
                           <strong>Abstract:</strong> We present a general framework for accurate positioning of sensors and end effectors in farm settings using a camera mounted on a robotic manipulator. Our main contribution is a visual servoing approach based on a new and robust feature tracking algorithm. Results from field experiments performed at an apple orchard demonstrate that our approach converges to a given termination criterion even under environmental influences such as strong winds, varying illumination conditions and partial occlusion of the target object. Further, we show experimentally that the system converges to the desired view for a wide range of initial conditions. This approach opens possibilities for new applications such as automated fruit inspection, fruit picking or precise pesticide application.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_07">14:11-14:12, Paper WeT22.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0301.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('301'); return false" title="Click to show or hide the keywords and abstract">Optimal Non-Bernoulli Modeling Method for Experimental Hydraulic Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103572" title="Click to go to the Author Index">Sakai, Satoru</a></td><td class="r">Shinshu Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202545" title="Click to go to the Author Index">Nabana, Yusuke</a></td><td class="r">Shinshu Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab301" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a>, <a href="IROS16_KeywordIndexMedia.html#Hydraulic_Pneumatic_Actuators" title="Click to go to the Keyword Index">Hydraulic/Pneumatic Actuators</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> For hydraulic robots, modeling of the control flows is a key issue. The conventional modeling methods are based on the Bernoulli equation (i.e., the control flow is a functon of the form (sqrt{pressure}) which needs assumption of steady flow. In robotics applications, since the actual control flow is not a steady flow, this paper provides a new practical modeling method without the Berunoulli equation. In a word, the proposed modeling method is a systematic version of the industrial modeling in which table representations are accepted and the assumption of steady flow is not needed. First, based on the input-state equation of hydraulic robots, we propose a new matrix representation of control flows via off-line inputoutput calculations. Second, based on the projection theorem in the matrix space, the optimal table representation is uniquely determined to be implementable. Finally, in comparison with the conventional modeling method with the Bernoulli equation, the effectiveness of the proposed modeling method is confirmed experimentally. Note that the proposed modeling method is applicable to complex friction of electric robots.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_08">14:12-14:13, Paper WeT22.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0359.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('359'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Road Traversability Analysis Using Network Properties of Roadmaps</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191719" title="Click to go to the Author Index">Khan, Muhammad Mudassir</a></td><td class="r">Lahore Univ. of Management Sciences</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151057" title="Click to go to the Author Index">Ali, Haider</a></td><td class="r">German Aerospace Centre (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103429" title="Click to go to the Author Index">Berns, Karsten</a></td><td class="r">Univ. of Kaiserslautern</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103167" title="Click to go to the Author Index">Muhammad, Abubakr</a></td><td class="r">Lahore Univ. of Management Sciences (LUMS)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab359" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0359.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a>, <a href="IROS16_KeywordIndexMedia.html#Intelligent_Transportation_Systems" title="Click to go to the Keyword Index">Intelligent Transportation Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> Traversability analysis is an important aspect of autonomous navigation in robotics. In this paper, we relate the idea of traversability to safety and ease of road usage by defining a novel sensor-data driven metric called Road Traversability Index (RTI). The RTI translate the geometric interaction of vehicle with road into a distance modulated index that can be used as advice for a human driver or an autonomous agent intending to traverse a particular road segment using a specific vehicle. We present a framework in which 3D sensor data is converted into a road model, which in turn is converted into a roadmap based motion planning graph to represent the underlying configuration space. The RTI is defined as a function of the roadmap by axiomatically satisfying all required properties of road traversability. We have tested our algorithmic framework on simulated scenarios to explore safety; and real world data sets to discover aspects of traversability for vehicles of various types. Experimental results show that RTI is a practical tool that reveals information that may be hidden to human inspection or other methods of assessment that do not explicitly model a vehicle.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_09">14:13-14:14, Paper WeT22.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0360.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('360'); return false" title="Click to show or hide the keywords and abstract">A Rotary-Percussive Ultrasonic Drill for Planetary Rock Sampling</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195623" title="Click to go to the Author Index">Wang, Yinchao</a></td><td class="r">Harbin Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#121555" title="Click to go to the Author Index">Quan, Qiquan</a></td><td class="r">Harbin Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192104" title="Click to go to the Author Index">Yu, Hongying</a></td><td class="r">Harbin Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188599" title="Click to go to the Author Index">Tang, Dewei</a></td><td class="r">Harbin Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122676" title="Click to go to the Author Index">Deng, Zongquan</a></td><td class="r">Harbin Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab360" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Smart_Actuators" title="Click to go to the Keyword Index">Smart Actuators</a>, <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> Conventional ultrasonic drills can drill into rocks using high frequency axial vibration, which feature lower power and lower preload force, thus they could become a very attractive solution for future deep-space exploration. However, drill cuttings cannot be removed effectively with the increase of drilling depth by conventional ultrasonic drills that only driven by longitudinal vibration. To address this issue, a Rotary-Percussive Ultrasonic Drill (RPUD) is proposed, which employs one single PZT transducer to generate rotary-percussive motion for rock fracturing. RPUD is composed of a PZT transducer, a percussive unit, a rotary unit, and a drill tool. The percussive unit enlarges the longitudinal vibration of front part of PZT transducer, and provides a reciprocating percussion to the drill tool. The rotary unit transforms longitudinal vibration of rear part of PZT transducer into longitudinal-torsional vibration to drive the drill tool to rotate continuously. The rotary and percussive motions are independent of each other, and can be adjusted separately. To make the rotary and percussive motions move synchronously, finite element method is employed to tune the resonance frequencies of the rotary unit and percussive unit to be close by transient analysis. Experimental results show that RPUD can improve removal efficiency of the drill cuttings due to its rotary motion, compared with conventional ultrasonic drills.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_10">14:14-14:15, Paper WeT22.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0413.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('413'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Safeguarding a Mobile Manipulator Using Dynamic Safety Fields</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172580" title="Click to go to the Author Index">Magnanimo, Vito</a></td><td class="r">Kuka Roboter GmbH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195643" title="Click to go to the Author Index">Walther, Steffen</a></td><td class="r">Kuka Roboter GmbH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184285" title="Click to go to the Author Index">Tecchia, Luigi</a></td><td class="r">Second Univ. of Naples</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#10016" title="Click to go to the Author Index">Natale, Ciro</a></td><td class="r">Seconda Univ. Degli Studi Di Napoli</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124275" title="Click to go to the Author Index">Guhl, Tim</a></td><td class="r">KUKA Lab. GmbH</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab413" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0413.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a></span><br>
                           <strong>Abstract:</strong> This paper presents a novel approach for safeguarding a mobile manipulator. To overcome the shortcomings of state-of-the-art safeguarding techniques, we present a dynamic approach capable of covering different situations and adapting itself to the situation at hand. The proposed approach is based on the continuous dynamic update of a safety field using both exteroceptive and proprioceptive data. The proprioceptive data are the platform velocity vector and the manipulator position; the exteroceptive data refers to the environment in which the mobile manipulator is moving, namely distances to obstacles acquired by laser scanners. The effectiveness of the proposed approach has been validated in an industrial test case scenario in which the robot had to execute a fetch and carry task while safely coexisting with human workers. Experimental results proved that the use of dynamic protection fields allowed the robot to carry out its tasks with a significant reduction (about 50%) of the execution time.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_11">14:15-14:16, Paper WeT22.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0596.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('596'); return false" title="Click to show or hide the keywords and abstract">Modeling and Stochastic Optimization of Complete Coverage under Uncertainties in Multi-Robot Base Placements</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180776" title="Click to go to the Author Index">Hassan, Mahdi</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106490" title="Click to go to the Author Index">Liu, Dikai</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113516" title="Click to go to the Author Index">Paul, Gavin</a></td><td class="r">Univ. of Tech. Sydney</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab596" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a></span><br>
                           <strong>Abstract:</strong> Uncertainties in base placements of mobile, autonomous industrial robots can cause incomplete coverage in tasks such as grit-blasting and spray painting. Sensing and localization errors can cause such uncertainties in robot base placements. This paper addresses the problem of collaborative complete coverage under uncertainties through appropriate base placements of multiple mobile and autonomous industrial robots while aiming to optimize the performance of the robot team. A mathematical model for complete coverage under uncertainties is proposed and then solved using a stochastic multi-objective optimization algorithm. The approach aims to concurrently find an optimal number and sequence of base placements for each robot such that the robot team's objectives are optimized whilst uncertainties are accounted for. Several case studies based on a real-world application using a real-world object and a complex simulated object are provided to demonstrate the effectiveness of the approach for different conditions and scenarios, e.g. various levels of uncertainties, different numbers of robots, and robots with different capabilities.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_12">14:16-14:17, Paper WeT22.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0605.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('605'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Robot Body Design Including Degrees of Freedom and Link Parameters Maximizing Ball Throwing Performance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154282" title="Click to go to the Author Index">Miyazaki, Tetsuro</a></td><td class="r">Yokohama National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178105" title="Click to go to the Author Index">Sanada, Kazushi</a></td><td class="r">Yokohama National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab605" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0605.VI.mpg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> This paper proposes a particular case of a robot body design method which determines a degrees of freedom (DOFs) number and link parameters to maximize a target task performance. The DOFs number is an essential point to be considered in the robot body design problem. In this paper, the target task is to make a long throw, and multi DOFs ball throwing robot is designed. Design parameters are the robot body parameters and its motion pattern, and they are designed to maximize ball flying distance under long throw task conditions. To define the link lengths and the robot DOFs number as design parameters, it is assumed that intermediate links of the robot have identical actuators, and these link parameters are defined as functions of link lengths. These links are chained to construct the whole link system. Because of this assumption, the motion equation, which is utilized in the task conditions, is determined by the given robot DOFs number and link lengths. The proposed method was applied to the ball throwing robot model, and its body parameters and motion pattern were designed in the proposed calculation algorithm. As a result, 5 DOFs robot and its throwing motion were obtained, and the ball flying distance was maximized. The ball flying distance was changed along with the DOFs number, and the effectiveness of the proposed design method was demonstrated.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_13">14:17-14:18, Paper WeT22.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0743.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('743'); return false" title="Click to show or hide the keywords and abstract">Robotic Simulation of on Orbit Servicing Including Hard Impacts</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113658" title="Click to go to the Author Index">Lange, Friedrich</a></td><td class="r">German Aerospace Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196224" title="Click to go to the Author Index">Grunwald, Gerhard</a></td><td class="r">German Aerospace Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101628" title="Click to go to the Author Index">Albu-Schäffer, Alin</a></td><td class="r">DLR - German Aerospace Center</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab743" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> Industrial robots are often used for the simulation of satellites during on orbit servicing. In order to cover also the docking phase, both robots are equipped with force-torque sensors, and the measured forces and torques are taken to compute the desired motion of the position controlled robots. Since the system dynamics of robots and of free floating bodies obviously differ, for each robot we distinguish between the really executed and the assumed satellite motion. The difference between the two motions is used to adapt the measured forces in such a way that they correspond to the satellite's trajectory. In this way the docking procedure can be visualized by two robots which closely follow the satellites' trajectories. Stability of the robot control is not compromised even if the dynamics of the satellites and the robots are totally different. Simulation results verify the approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_14">14:18-14:19, Paper WeT22.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0764.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('764'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Robot Artist for Colorful Picture Painting with Visual Control System</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100097" title="Click to go to the Author Index">Luo, Ren</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191929" title="Click to go to the Author Index">Hong, Ming-Jyun</a></td><td class="r">National Taiwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196230" title="Click to go to the Author Index">Chung, Ping-Chang</a></td><td class="r">National Taiwan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab764" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0764.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Entertainment_Robotics" title="Click to go to the Keyword Index">Entertainment Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> This paper presents a robot capable of painting colorful pictures with a visual control system like human artists. It can use only five basic colors (cyan, magenta, yellow, white and black) to mix a variety of colors. After receiving a picture, the Robot Artist creates the artwork in two stages - the underpainting and the refinement. In the underpainting stage, it covers the canvas with a thin layer of acrylic paint, which can effectively set the basic tone of the painting. In the second stage, the robot uses the camera attached to its wrist to obtain the current artwork and refine it repeatedly. During the refinement, the methodology of non-photorealistic rendering (NPR) is also introduced to generate hand-painted strokes, which will be painted on the canvas to refine the artworks.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_15">14:19-14:20, Paper WeT22.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0832.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('832'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>CASPR: A Comprehensive Cable-Robot Analysis and Simulation Platform for the Research of Cable-Driven Parallel Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141072" title="Click to go to the Author Index">Lau, Darwin</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#161040" title="Click to go to the Author Index">Eden, Jonathan Paul</a></td><td class="r">The Univ. of Melbourne</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#161086" title="Click to go to the Author Index">Tan, Ying</a></td><td class="r">The Univ. of Melbourne</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107362" title="Click to go to the Author Index">Oetomo, Denny</a></td><td class="r">The Univ. of Melbourne</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab832" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0832.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tendon_Wire_Mechanisms" title="Click to go to the Keyword Index">Tendon/Wire Mechanisms</a>, <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Programming_Environments" title="Click to go to the Keyword Index">Programming Environments</a></span><br>
                           <strong>Abstract:</strong> The study of cable-driven parallel robots (CDPRs) has attracted much attention in recent years. However, to the best of the authors' knowledge, no single software platform exists for researchers to perform different types of analyses for CDPRs of arbitrary structure. In this paper, the Cable-robot Analysis and Simulation Platform for Research (CASPR) of CDPRs is introduced. Using this platform, arbitrary types and structures of CDPRs, such as single and multi-link CDPRs, can be studied for a wide range of analyses, including kinematics, dynamics, control and workspace analysis. CASPR achieves this using a general CDPR model representation and an abstracted software architecture. Moveover, CDPRs can be defined using Extensible Markup Language (XML) with out-of-the-box availability of an extensive range of robots and analysis tools. The open-source platform aims to provide both a communal environment for the researchers to use and add models and algorithms to. The example case studies demonstrate the potential to perform analysis on CDPRs, directly compare algorithms and conveniently add new models and analyses.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_16">14:20-14:21, Paper WeT22.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0867.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('867'); return false" title="Click to show or hide the keywords and abstract">Map-Optimized Probabilistic Traffic Rule Evaluation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182706" title="Click to go to the Author Index">Wellhausen, Lorenz</a></td><td class="r">ETH Zürich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#144621" title="Click to go to the Author Index">Jacob, Mithun</a></td><td class="r">Robert Bosch LLC</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab867" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Intelligent_Transportation_Systems" title="Click to go to the Keyword Index">Intelligent Transportation Systems</a></span><br>
                           <strong>Abstract:</strong> Current traffic rule handling in autonomous driving relies on non-scalable methods such as explicitly hard-coding sets of logical statements to evaluate rules. This is sufficient for early prototypes but is not scalable for larger systems designed to work in arbitrary locations. Such methods can also become problematic when traversing different geographical entities with changing traffic rules. Additionally, they do not adequately convey the uncertainty of the traffic rule evaluation stemming from uncertainty in sensor measurements.<p>We propose an exchangeable traffic rules module which takes a knowledge base of sentences in first-order logic as input. These sentences consist of a limited number of high-level queries which are independent of local jurisdiction (e.g. can I turn right?). The knowledge base is then compiled into a potentially large logic graph. However, only a relatively small subset of the knowledge base is relevant for specific road geometries (e.g. some of the rules applicable to an intersection is not relevant for a T-junction). Since detailed road maps are available for autonomous driving, this information can be used to resolve these subsets in the knowledge base which only require map knowledge. Therefore, map information can be used to convert a single, large logic graph into a set of smaller, map-optimized logic graphs pruned for specific road geometries. The optimized graphs are then converted into Bayesian networks to facilitate probabilistic inference.<p>Experiments were conducted using a traffic and scenario simulation framework. The results demonstrate a significant improvement in performance when using map-optimized logic graphs over a traditional first-order logic knowledge base.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_17">14:21-14:22, Paper WeT22.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0880.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('880'); return false" title="Click to show or hide the keywords and abstract">A Symbolic Geometric Formulation of Branched Articulated Multibody Systems Based on Graphs and Lie Groups</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113394" title="Click to go to the Author Index">Escalera, Juan Antonio</a></td><td class="r">Univ. Carlos III De Madrid</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143489" title="Click to go to the Author Index">Abu-Dakka, Fares J.</a></td><td class="r">Carlos III Univ. of Madrid</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110584" title="Click to go to the Author Index">Abderrahim, Mohamed</a></td><td class="r">Carlos III Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab880" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> In this article we present a symbolic closed-form matrix formulation to obtain the dynamic equations of branched articulated multibody systems (AMS)s. The proposed approach uses geometric mechanics based on Screw Theory and Lie groups. Both Lagrange's and Newton-Euler's equation of motion are derived. Furthermore, the structure of the proposed set of geometric equations holds the intrinsic robot parameters explicitly arranged like symbolic matrices. The formulation is valid for any branched AMS without closed kinematic chains and whose joints have one degree of freedom (DoF) (revolute and/or prismatic). All these properties allow the use of these equations in different algorithms such as identification, simulation and control of branched AMSs like hands or humanoids. Finally, the proposed equations have been validated and verified with the multi-body simulation software package MSC/ADAMS by computing the inverse dynamics of a two arm torso of 16 DoF.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_18">14:22-14:23, Paper WeT22.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0943.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('943'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>The CableRobot Simulator - Large Scale Motion Platform Based on Cable Robot Technology</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167662" title="Click to go to the Author Index">Miermeister, Philipp</a></td><td class="r">Fraunhofer IPA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131403" title="Click to go to the Author Index">Masone, Carlo</a></td><td class="r">Max Planck Inst. for Biological Cybernetics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100616" title="Click to go to the Author Index">Pott, Andreas</a></td><td class="r">Fraunhofer-Gesellschaft</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115597" title="Click to go to the Author Index">Buelthoff, Heinrich H.</a></td><td class="r">Max Planck Inst. for Biol. Cybernetics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131226" title="Click to go to the Author Index">Tesch, Joachim</a></td><td class="r">Max Planck Inst. for Biological Cybernetics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab943" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0943.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Entertainment_Robotics" title="Click to go to the Keyword Index">Entertainment Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Centered_Robotics" title="Click to go to the Keyword Index">Human Centered Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a></span><br>
                           <strong>Abstract:</strong> This paper introduces the CableRobot simulator, which was developed at the Max Planck Institute for Biological Cybernetics in cooperation with the Fraunhofer Institute for Manufacturing Engineering and Automation IPA. The simulator is a completely novel approach to the design of motion simulation platforms in so far as it uses cables and winches for actuation instead of rigid links known from hexapod simulators. This approach allows to reduce the actuated mass, scale up the workspace significantly, and provides great flexibility to switch between system configurations in which the robot can be operated. The simulator will be used for studies in the field of human perception research and virtual reality applications. The paper dicusses some of the issues arising from the usage of cables and provides a system overview regarding kinematics and system dynamics as well as giving a brief introduction into possible application use cases.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_19">14:23-14:24, Paper WeT22.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1035.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1035'); return false" title="Click to show or hide the keywords and abstract">On the Gyroscopic Force in Mechanical Manipulators and Its Artificial Shaping for Taskspace Movement Coordination</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195538" title="Click to go to the Author Index">Wei, Nan</a></td><td class="r">Univ. of Waterloo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100980" title="Click to go to the Author Index">Jeon, Soo</a></td><td class="r">Univ. of Waterloo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1035" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> In this paper, we try to draw attention to a particular type of force that has been somehow overlooked in the control of mechanical manipulators: gyroscopic force. At first, we broaden our understanding of gyroscopic effect intrinsic in mechanical systems by reformulating the Euler-Lagrange (EL) equation in terms of a gyroscopic part and the non-gyroscopic ones (or Rayleigh type). Then, we propose the use of artificial gyroscopic force to assist existing control laws. As a force that does not do any work, the gyroscopic force can be effectively used in combination with many existing control laws for mechanical systems without affecting their salient features such as the stability or the convergence to a target point. As a specific example, we look into the potential energy shaping parameterized by taskspace variables (also known as the Jacobian transpose method) as a base control law, and combine it with an artificial gyroscopic forcing term. We propose one specific way to design the gyroscopic force as a term quadratic in velocity that operates in reference to a desired velocity field shape (also parameterized in taskspace). The resulting control strategy enables us to shape the intermediate path profiles and thus realizes a taskspace control law that is free from any inverse transformations. We demonstrate the effectiveness of this method using simulation results with a three-link planar manipulator.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_20">14:24-14:25, Paper WeT22.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1191.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1191'); return false" title="Click to show or hide the keywords and abstract">Gravity-Assist: A Series Elastic Body Weight Support System with Inertia Compensation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185180" title="Click to go to the Author Index">Munawar, Hammad</a></td><td class="r">Sabanci Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110950" title="Click to go to the Author Index">Patoglu, Volkan</a></td><td class="r">Sabanci Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1191" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a></span><br>
                           <strong>Abstract:</strong> We present Gravity-Assist, a series elastic active body weight support and inertia compensation system for use in robot assisted gait rehabilitation. The device consists of a single degree of freedom series elastic actuator that connects to the trunk of a patient. The series elastic system is novel in that, it can provide the desired level of dynamic unloading such that the patient experiences only a percentage of his/her weight and inertia. Inertia compensation is important, since the inertial forces can cause significant deviations from the desired unloading force, specially at low support forces and fast walking speeds. Furthermore, this feature enables the inertia of the harness and force sensing unit attached to the patient to be compensated for, making sure that the device does not interfere with the natural gait cycle. We present a functional prototype of the device, its characterization and experimental verification of the approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_21">14:25-14:26, Paper WeT22.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1300.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1300'); return false" title="Click to show or hide the keywords and abstract">Communicating Intent on the Road through Human-Inspired Control Schemes</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180408" title="Click to go to the Author Index">Driggs-Campbell, Katherine Rose</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#112939" title="Click to go to the Author Index">Bajcsy, Ruzena</a></td><td class="r">Univ. of California, Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1300" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Intelligent_Transportation_Systems" title="Click to go to the Keyword Index">Intelligent Transportation Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Centered_Robotics" title="Click to go to the Keyword Index">Human Centered Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Given the current capabilities of autonomous vehicles, one can easily imagine autonomy released on the road in the near future. However, it can be assumed that the transition will not be instantaneous, meaning they will have to be capable of driving well in a mixed environment, with both humans and other autonomous vehicles on the road. This leaves a number of concerns for autonomous vehicles in terms of dealing with human uncertainty and understanding of cooperation on the road. This work demonstrates the need for focusing on communication and collaboration between autonomy and human drivers. After analyzing how drivers perform cooperative maneuvers (e.g. lane changing), key cues were identified for conveying intent through nonverbal communication. It was found that human observers can predict lane changes with over two seconds in prior to the lane departure, without use of a turning signal. Building on this concept, an autonomous control scheme is proposed that aims to capture these subtle motions before executing a lane change. To compare the proposed human-inspired methods, three possible control schemes for autonomous vehicles are implemented for a validation study on human subjects to provide feedback on their experience. By properly conveying intent through nuanced trajectory planning, we show that drivers can predict the autonomous vehicle's actions with 40% increase in prediction time when compared to traditional control methods, both as a passenger and while observing the autonomous vehicle.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_22">14:26-14:27, Paper WeT22.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1355.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1355'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Cyclic Hydraulic Actuation for Soft Robotic Devices</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164300" title="Click to go to the Author Index">Katzschmann, Robert</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196432" title="Click to go to the Author Index">de Maille, Austin</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196266" title="Click to go to the Author Index">Dorhout, David</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101388" title="Click to go to the Author Index">Rus, Daniela</a></td><td class="r">MIT</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1355" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1355.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Hydraulic_Pneumatic_Actuators" title="Click to go to the Keyword Index">Hydraulic/Pneumatic Actuators</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#New_Actuators" title="Click to go to the Keyword Index">New Actuators</a></span><br>
                           <strong>Abstract:</strong> Undulating structures are one of the most diverse and successful forms of locomotion in nature, both on ground and in water. This paper presents a comparative study for actuation by undulation in water. We focus on actuating a 1DOF systems with several mechanisms. A hydraulic pump attached to a soft body allows for water movement between two inner cavities, ultimately leading to a flexing actuation in a side-to-side manner. The effectiveness of six different, self-contained designs based on centrifugal pump, flexible impeller pump, external gear pump and rotating valves are compared. These hydraulic actuation systems combined with soft test bodies were then measured at a lower and higher oscillation frequency. The deflection characteristics of the soft body, the acoustic noise of the pump and the overall efficiency of the system are recorded. A brushless, centrifugal pump combined with a novel rotating valve performed at both test frequencies as the most efficient pump, producing sufficiently large cyclic body deflections along with the least acoustic noise among all pumps tested. An external gear pump design produced the largest body deflection, but consumes an order of magnitude more power and produced high noise levels. Further refinement remains on determining the suitable oscillation frequencies and inner cavity designs for optimal efficiency and movement.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_23">14:27-14:28, Paper WeT22.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1620.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1620'); return false" title="Click to show or hide the keywords and abstract">Internal Localization Algorithm Based on Relative Positions for Cubic-Lattice Modular-Robotic Ensembles</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168316" title="Click to go to the Author Index">Holobut, Pawel</a></td><td class="r">Inst. of Fundamental Tech. Res. Pol. Acad</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196153" title="Click to go to the Author Index">Chodkiewicz, Pawel</a></td><td class="r">Faculty of Automotive and Construction Machinery Engineering, Wa</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196871" title="Click to go to the Author Index">Macios, Anna</a></td><td class="r">-</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168210" title="Click to go to the Author Index">Lengiewicz, Jakub</a></td><td class="r">Inst. of Fundamental Tech. Res. Pol. Acad</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1620" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Cellular_and_Modular_Robots" title="Click to go to the Keyword Index">Cellular and Modular Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Self_Organised_Robot_Systems" title="Click to go to the Keyword Index">Self-Organised Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> Module localization is an important aspect of the operation of self-reconfigurable robots. The knowledge of spatial positions of modules, or at least of the overall shape which the modules form, is the usual prerequisite for reconfiguration planning. We present a general, decentralized algorithm for determining the positions of modules placed on a cubic grid from local sensor information. The connection topology of the robot is arbitrary. We assume that a module can sense the presence of its immediate neighbors on the grid and determine their positions in its own local coordinate system, but cannot sense the orientations of the coordinate systems of its neighbors. Since orientation cannot be directly communicated between modules, the modules can only exchange information about the relative positions of their neighbors. The algorithm aggregates this information over the entire network of modules and narrows down the set of valid positions for each module as far as possible. If there exists a unique locally-consistent assignment of coordinates to all modules then it is found.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_24">14:28-14:29, Paper WeT22.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1673.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1673'); return false" title="Click to show or hide the keywords and abstract">On Robust Classification of Hemodynamic Signals for BCIs Via Multiple Kernel nu-SVM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196801" title="Click to go to the Author Index">Abibullaev, Berdakh</a></td><td class="r">Nazarbayev Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128924" title="Click to go to the Author Index">An, Jinung</a></td><td class="r">DGIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1673" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Brain_Machine_Interfaces" title="Click to go to the Keyword Index">Brain Machine Interfaces</a></span><br>
                           <strong>Abstract:</strong> Near-Infrared spectroscopy (NIRS) is an emerging non-invasive brain computer interface (BCI) modality that measures changes in haemoglobin concentrations in the cortical tissue. To date most NIRS studies have used standard multiple subject/session dependent classifiers for neural signal decoding. Such approach is preferable to avoid large degree of variabilities in the acquired data that affects classifier generalization. This study presents a classification algorithm that maintains a good performance under the presence of variability in the NIRS data. It is based on nu- support vector machines and its extensions to a multiple kernel learning framework. Empirical evaluations have shown that through the proposed method one can improve the overall BCI decoding accuracy, and its robustness against the variability in neural data.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wet22_25">14:29-14:30, Paper WeT22.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1733.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1733'); return false" title="Click to show or hide the keywords and abstract">Cellular Space Robot and Its Interactive Model Identification for Spacecraft Takeover Control</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196897" title="Click to go to the Author Index">Chang, Haitao</a></td><td class="r">Northwestern Pol. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102722" title="Click to go to the Author Index">Huang, Panfeng</a></td><td class="r">Northwestern Pol. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184347" title="Click to go to the Author Index">Lu, Zhenyu</a></td><td class="r">Northwest Pol. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178598" title="Click to go to the Author Index">Meng, Zhongjie</a></td><td class="r">Northwestern Pol. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184975" title="Click to go to the Author Index">Liu, Zhengxiong</a></td><td class="r">Northwest Pol. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135120" title="Click to go to the Author Index">Zhang, Yizhai</a></td><td class="r">Northwestern Pol. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1733" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a></span><br>
                           <strong>Abstract:</strong> Facing the new challenges of the spacecraft developing, the concept of cellular space robot (CSR) for both spacecraft system construction and on-orbit operation is presented in this paper. The system description and design principles are introduced to ensure the &#64258;exibility of the system. And dynamics model for takeover control is developed. After that, the regression models for the parameter identi&#64257;cation are deduced based on the dynamics model. An interaction model identi&#64257;cation algorithm is presented to solve the parameter identi&#64257;cation problem for the distributed cells. Besides, the interactive model identi&#64257;cation is validated by simulations. The simulations show that the interactive model identi&#64257;cation method can achieve the consensus and convergence.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webi1"><b>WeBI1</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webi1" title="Click to go to the Program at a Glance"><b>Interactive Session: AI-Based Robot Systems</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#107437" title="Click to go to the Author Index">Lima, Pedro U.</a></td><td class="r">Inst. Superior Técnico - Inst. for Systems and Robotics</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#115196" title="Click to go to the Author Index">Piater, Justus</a></td><td class="r">Univ. of Innsbruck</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webi2"><b>WeBI2</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webi2" title="Click to go to the Program at a Glance"><b>Interactive Session: Robotic Applications</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#110584" title="Click to go to the Author Index">Abderrahim, Mohamed</a></td><td class="r">Carlos III Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#100097" title="Click to go to the Author Index">Luo, Ren</a></td><td class="r">National Taiwan Univ</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt1"><b>WeBT1</b></a></td>
               <td class="r">#101</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt1" title="Click to go to the Program at a Glance"><b>Field Robots 1</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#103723" title="Click to go to the Author Index">Lenain, Roland</a></td><td class="r">Irstea</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#105341" title="Click to go to the Author Index">Auat Cheein, Fernando</a></td><td class="r">Univ. Tecnica Federico Santa Maria</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt1_01">14:35-14:50, Paper WeBT1.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0046.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('46'); return false" title="Click to show or hide the keywords and abstract">Automatic Driving Control by Robotic Driver Considering the Lack of a Driving Force at Changing Gears</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154476" title="Click to go to the Author Index">Mizutani, Naoto</a></td><td class="r">Mie Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190873" title="Click to go to the Author Index">Ishida, Yuya</a></td><td class="r">Mie Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102395" title="Click to go to the Author Index">Matsui, HIrokazu</a></td><td class="r">Mie Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103137" title="Click to go to the Author Index">Yano, Ken'ichi</a></td><td class="r">Mie Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178920" title="Click to go to the Author Index">Takahashi, Toshimichi</a></td><td class="r">MEIDENSHA Corp</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab46" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> Vehicle performance tests are conducted to evaluate factors of vehicle performance such as fuel consumption and durability. Robotic drivers are often used in these tests to ensure that performance evaluate is reproducible, and various types of vehicles have been tested. Manual transmission (MT) vehicles are widely used and represent about 50% of vehicles in the world. When the driver selects the gear ratio in MT, speed control performance is degraded during changing the gear. Because a torque transmission between the engine and wheels is cut during this sequence, the driver must drive the vehicle while considering the influence of changing the gear. Therefore, control performance in MTs depends on driver's technique. If robotic drivers are used with MT, there is a possibility that performance will be significantly degraded because the robot cannot adjust to change the gear while driving. In this paper, we realized the driving while considering shift changes by the robotic driver. First, we modeled the lack of a driving force using the dynamic characteristics of the vehicle and the deceleration during changing the gear. We then derived a target vehicle speed waveform using the lack of a driving force model. Finally, we performed vehicle tests using a robotic driver. We confirmed the effectiveness of the proposed system from the results of actual vehicle tests.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt1_02">14:50-15:05, Paper WeBT1.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0598.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('598'); return false" title="Click to show or hide the keywords and abstract">High Precision Marker Based Localization and Movement on the Ceiling Employing an Aerial Robot with Top Mounted Omni Wheel Drive System</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183294" title="Click to go to the Author Index">Ladig, Robert</a></td><td class="r">Ritsumeikan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#161409" title="Click to go to the Author Index">Shimonomura, Kazuhiro</a></td><td class="r">Ritsumeikan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab598" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Construction" title="Click to go to the Keyword Index">Robotics in Construction</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> While aerial vehicles have become more and more popular in the hobbyist sector as a platform for photography and cinematography, currently there is barely any utilization of aerial vehicles in an industrial environment. In this work, we describe our efforts to develop an aerial robotics platform with the ability to traverse a ceiling with high stability and precision using a top mounted omni wheel drive system and an AR marker system that has been extended to incorporate the use of dual camera sensor fusion. The proposed system is specifically designed and planned to accustom a real world industrial assignment, namely the setting of painted ink-marker used as an orientation for drilling-, measuring- or maintenance-tasks on the ceiling in an infrastructure inspection work environment. We show with test flights the feasibility of this approach and ability of the developed platform to do high precision localization and positioning relative to an AR-marker in order to solve an ink-marker placement task.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt1_03">15:05-15:20, Paper WeBT1.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0760.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('760'); return false" title="Click to show or hide the keywords and abstract">High Speed Path Tracking Application in Harsh Conditions : Predictive Speed Control to Restrict the Lateral Deviation to Some Threshold</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159331" title="Click to go to the Author Index">Braconnier, Jean-Baptiste</a></td><td class="r">Irstea</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103723" title="Click to go to the Author Index">Lenain, Roland</a></td><td class="r">Irstea</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103548" title="Click to go to the Author Index">Thuilot, Benoit</a></td><td class="r">Clermont-Ferrand Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150306" title="Click to go to the Author Index">Rousseau, Vincent</a></td><td class="r">IRSTEA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab760" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> One of the most important points in path tracking applications, is the capability of the robot to track the desired path as accurately as possible. Results presented in the literature in on-road contexts are convincing, but the case of off-road mobile robots introduces other issues, like bad grip conditions or non-flat ground. These issues can lead to a lack of accuracy of the tracking, even more when we consider high speed. The quality of the tracking depends on the modelling and the control laws used, but it depends also on the path to follow and on the soil conditions. If some small errors may be acceptable, it is sometimes mandatory to have a limited error, in particular when avoiding an obstacle or when moving in a narrow pathway. The aim of the algorithm proposed in this paper is to determine the maximum velocity of the robot during the tracking, for the lateral error to stay below a desired limit. In order to achieve this, a predictive approach taking into account for the evolution of a dynamic model, control laws and actuators properties is proposed. It permits to predict the forthcoming tracking error and consequently to estimate the maximum velocity that the robot can reach in accordance with the maximum deviation allowed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt1_04">15:20-15:35, Paper WeBT1.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1176.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1176'); return false" title="Click to show or hide the keywords and abstract">Probabilistic Approaches for Self-Tuning Path Tracking Controllers Using Prior Knowledge of the Terrain</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196119" title="Click to go to the Author Index">Prado, Romo</a></td><td class="r">Univ. Tecnica Federico Santa Maria</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105341" title="Click to go to the Author Index">Auat Cheein, Fernando</a></td><td class="r">Univ. Tecnica Federico Santa Maria</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107884" title="Click to go to the Author Index">Torres-Torriti, Miguel</a></td><td class="r">Pontificia Univ. Catolica De Chile</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1176" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> Nowadays, agricultural and mining industry applications require saving energy in mobile robotic tasks. This critical issue encouraged us to enhance the performance of path tracking controllers during manoeuvring over slippery and rough terrains. In this scenario, we propose probabilistic approaches under machine learning schemes in order to optimally self-tune the controller. The approaches are real time implemented and tested in a mining machinery skid steer loader Cat R 262C under gravel and muddy terrains (and their transitions). Finally, experimental results presented in this work show that the performance of the controller enhances up to 20% (average) without compromising saturations in the actuators.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt1_05">15:35-15:50, Paper WeBT1.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1734.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1734'); return false" title="Click to show or hide the keywords and abstract">Stochastic Modeling and Control for Tracking the Periodic Movement of Marine Animals Via AUVs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196873" title="Click to go to the Author Index">Smith, Kevin D.</a></td><td class="r">Harvey Mudd Coll</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196033" title="Click to go to the Author Index">Hsiung, Shih-Chieh</a></td><td class="r">Harvey Mudd Coll</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171513" title="Click to go to the Author Index">White, Connor</a></td><td class="r">California State Univ. Long Beach</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151007" title="Click to go to the Author Index">Lowe, Christopher G.</a></td><td class="r">California State Univ. Long Beach</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107898" title="Click to go to the Author Index">Clark, Christopher M.</a></td><td class="r">Harvey Mudd Coll</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1734" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a></span><br>
                           <strong>Abstract:</strong> This paper presents a graph-based model of periodic migrations of tagged fish populations and two multi-AUV stochastic controllers developed to track these fish from the model. The model presented in this paper characterizes patterns in the historical movement of tagged fish and is used to develop stochastic tracking by a model based control and a feedback control. These two controllers permit swarms of AUVs to track the transition probabilities of the tagged population between vertices of the model. To validate these controllers, a periodic model is developed for a simulated population based on three months of geolocation data from a kelp bass (<i>Paralabrax clathratus</i>), and AUV teams utilizing both controllers are simulated in tracking this population. Results show the viability of stochastic controls for multi-AUV tracking of populations whose behavior is well-approximated by the graph-based model. Preliminary trials with physical AUV systems indicate the plausibility of hardware implementation.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt2"><b>WeBT2</b></a></td>
               <td class="r">#102</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt2" title="Click to go to the Program at a Glance"><b>Sensor Fusion</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#191510" title="Click to go to the Author Index">Abramov, Alexey</a></td><td class="r">Continental Teves AG</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#191517" title="Click to go to the Author Index">Loy, Claudia</a></td><td class="r">Continental Teves AG</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt2_01">14:35-14:50, Paper WeBT2.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0122.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('122'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Multi-Lane Perception Using Feature Fusion Based on GraphSLAM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191510" title="Click to go to the Author Index">Abramov, Alexey</a></td><td class="r">Continental Teves AG</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191514" title="Click to go to the Author Index">Bayer, Christopher</a></td><td class="r">Continental Teves AG</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191515" title="Click to go to the Author Index">Heller, Claudio</a></td><td class="r">Continental Teves AG</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191517" title="Click to go to the Author Index">Loy, Claudia</a></td><td class="r">Continental Teves AG</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab122" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0122.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a></span><br>
                           <strong>Abstract:</strong> An extensive, precise and robust recognition and modeling of the environment is a key factor for next generations of Advanced Driver Assistance Systems and development of autonomous vehicles. In this paper, a real-time approach for the perception of multiple lanes on highways is proposed. Lane markings detected by camera systems and observations of other traffic participants provide the input data for the algorithm. The information is accumulated and fused using GraphSLAM and the result constitutes the basis for a multilane clothoid model. To allow incorporation of additional information sources, input data is processed in a generic format. Evaluation of the method is performed by comparing real data, collected with an experimental vehicle on highways, to a ground truth map. The results show that ego and adjacent lanes are robustly detected with high quality up to a distance of 120 m. In comparison to serial lane detection, an increase in the detection range of the ego lane and a continuous perception of neighboring lanes is achieved. The method can potentially be utilized for the longitudinal and lateral control of self-driving vehicles.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt2_02">14:50-15:05, Paper WeBT2.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0148.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('148'); return false" title="Click to show or hide the keywords and abstract">Pose Fusion with Chain Pose Graphs for Automated Driving</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195362" title="Click to go to the Author Index">Merfels, Christian</a></td><td class="r">Univ. of Bonn</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101642" title="Click to go to the Author Index">Stachniss, Cyrill</a></td><td class="r">Univ. of Bonn</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab148" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a></span><br>
                           <strong>Abstract:</strong> Automated driving relies on fast, recent, accurate, and highly available pose estimates. A single localization system, however, can commonly ensure this only to some extent. In this paper, we propose a multi-sensor fusion approach that resolves this by combining multiple localization systems in a plug and play manner. We formulate our approach as a sliding window pose graph and enforce a particular graph structure which enables efficient optimization and a novel form of marginalization. Our pose fusion approach scales from a filtering-based to a batch solution by increasing the size of the sliding window. We evaluate our approach on simulated data as well as on real data gathered with a prototype vehicle and demonstrate that our solution runs comfortably at 20 Hz, provides timely estimates, is accurate, and yields a high availability.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt2_03">15:05-15:20, Paper WeBT2.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0461.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('461'); return false" title="Click to show or hide the keywords and abstract">Generalized Information Filtering for MAV Parameter Estimation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168414" title="Click to go to the Author Index">Burri, Michael</a></td><td class="r">ETH Zuerich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133249" title="Click to go to the Author Index">Bloesch, Michael</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159060" title="Click to go to the Author Index">Schindler, Dominik</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187957" title="Click to go to the Author Index">Gilitschenski, Igor</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159722" title="Click to go to the Author Index">Taylor, Zachary Jeremy</a></td><td class="r">Univ. of Sydney, Australian Centre for Field Robotics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab461" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> In this paper we present a new estimation algorithm that allows to combine information from any number of process and measurement models. This adds more flexibility to the design of the estimator and in our case avoids the need for state augmentation. We achieve this by adapting the maximum likelihood formulation of the Kalman Filter, and thereby represent all measurement models as residuals. Posing the problem in this form allows for the straightforward integration of any number of (nonlinear) constraints between two subsequent states. % In other words we show how to derive a very general recursive formulation that can handle any number of driving processes and measurements. To solve the optimization we present a closed form recursive set of equations that directly marginalizes out information that is not required, this leads to an efficient and generic implementation. The new algorithm is applied to parameter estimation on MAVs which have two dynamic models, the MAV dynamic model and the IMU-driven model. We show the benefits and limitations of the new filtering approach on a simplified simulation example and on a real MAV system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt2_04">15:20-15:35, Paper WeBT2.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0542.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('542'); return false" title="Click to show or hide the keywords and abstract">Constrained Sampling of 2.5D Probabilistic Maps for Augmented Inference</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#136672" title="Click to go to the Author Index">Shi, Lei</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106478" title="Click to go to the Author Index">Valls Miro, Jaime</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179004" title="Click to go to the Author Index">Zhang, Teng</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103428" title="Click to go to the Author Index">Vidal-Calleja, Teresa A.</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179565" title="Click to go to the Author Index">Sun, Liye</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106485" title="Click to go to the Author Index">Dissanayake, Gamini</a></td><td class="r">Univ. of Tech. Sydney</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab542" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> This work exploits modeling spatial correlation in 2.5D data using Gaussian Processes (GPs), and produces constrained sampling realizations on these models to improve certainty in the predictions by means of integrating additional sparse information. Data organized in 2.5D such as elevation and thickness maps has been extensively studied in the fields of robotics and geostatistics. These maps are typically represented as a probabilistic 2D grid that stores an estimated value (height or thickness) for each cell. With the increasing popularity and deployment of robotic devices for infrastructure inspection, 2.5D data becomes a common interpretation of the condition of the target being inspected. Modeling the spatial dependencies and making inferences on new grid locations is a common task that has been addressed using GPs, but inference results on locations which are weakly correlated with the training data are generally not sufficiently informative and distinctly uncertain. The predictive capability of the proposed framework, which is applicable to any 2.5D data, is demonstrated with field inspection data from pipelines. Specifically, sparse and complementary measurements from alternative sensing modalities have been incorporated into the model to predict in more detail local thickness conditions where GP training data is limited. The output of this work aims to probabilistically present variations of the target in the case that both accuracy and reasonable diversity are of significant interest.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt2_05">15:35-15:50, Paper WeBT2.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1320.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1320'); return false" title="Click to show or hide the keywords and abstract">Iterative Closest Labeled Point for Tactile Object Shape Recognition</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165900" title="Click to go to the Author Index">Luo, Shan</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172628" title="Click to go to the Author Index">Mou, Wenxuan</a></td><td class="r">Queen Mary Univ. of London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101975" title="Click to go to the Author Index">Althoefer, Kaspar</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104575" title="Click to go to the Author Index">Liu, Hongbin</a></td><td class="r">Department of Informatics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1320" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> Tactile data and kinesthetic cues are two important sensing sources in robot object recognition and are complementary to each other. In this paper, we propose a novel algorithm named Iterative Closest Labeled Point (iCLAP) to recognize objects using both tactile and kinesthetic information. The iCLAP first assigns different local tactile features with distinct label numbers. The label numbers of the tactile features together with their associated 3D positions form a 4D point cloud of the object. In this manner, the two sensing modalities are merged to form a synthesized perception of the touched object. To recognize an object, the partial 4D point cloud obtained from a number of touches iteratively matches with all the reference cloud models to identify the best fit. An extensive evaluation study with 20 real objects shows that our proposed iCLAP approach outperforms those using either of the separate sensing modalities, with a high recognition rate improvement of up to 18%.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt3"><b>WeBT3</b></a></td>
               <td class="r">#103</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt3" title="Click to go to the Program at a Glance"><b>Trajectory Generation 1</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#115600" title="Click to go to the Author Index">Wörgötter, Florentin</a></td><td class="r">Univ. of Göttingen</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#143237" title="Click to go to the Author Index">Li, Hongdong</a></td><td class="r">Australian National Univ. and NICTA</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt3_01">14:35-14:50, Paper WeBT3.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0152.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('152'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Optimal Trajectory Generation for Generalization of Discrete Movements with Boundary Conditions</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191445" title="Click to go to the Author Index">Herzog, Sebastian</a></td><td class="r">Department of Computational Neuroscience, Univ. of Goetting</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115600" title="Click to go to the Author Index">Wörgötter, Florentin</a></td><td class="r">Univ. of Göttingen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140153" title="Click to go to the Author Index">Kulvicius, Tomas</a></td><td class="r">The Maersk Mc-Kinney Moller Inst. Univ. of Southern De</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab152" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0152.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a></span><br>
                           <strong>Abstract:</strong> Trajectory generation methods play an important role in robotics since they are essential for the execution of actions. In this paper we present a novel trajectory generation method for generalization of accurate movements with boundary conditions. Our approach originates from optimal control theory and is based on a second order dynamic system. We evaluate our method and compare it to state-of-the-art movement generation methods in both simulations and a real robot experiment. We show that the new method is very compact in its representation and can reproduce demonstrated trajectories with zero error. Moreover, it has most of the properties of the state-of-the-art trajectory generation methods such as robustness to perturbations and generalization to new boundary position and velocity conditions. We believe that, due to these features, our method has great potential for various robotic applications, especially, where high accuracy is required, for example, in industrial and medical robotics.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt3_02">14:50-15:05, Paper WeBT3.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0432.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('432'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Planning Longest Pitch Trajectories for Compliant Serial Manipulators</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166925" title="Click to go to the Author Index">Kolyubin, Sergey</a></td><td class="r">NTNU</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109377" title="Click to go to the Author Index">Shiriaev, Anton</a></td><td class="r">Norwegian Univ. of Science and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab432" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0432.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a></span><br>
                           <strong>Abstract:</strong> The work addresses the problem of model-based planning an optimal pitch trajectory realizable on compliant serial manipulators. The proposed solution presented as a generic framework for finding the longest possible pitch given angle, velocity, and torque constraints. Within this framework an infinite-dimensional task is decomposed into a finite number of original numerical routines. Their efficient implementations allowed computing both an optimal release configuration and a release velocity as well as temporal nominal control torque profiles consistent with dynamic constraints. Besides that, it returned optimal stiffness coefficients of compliant robot joints, which appeared to be	critical for realization of the optimal pitch. Computational complexity of the nonlinear optimization task was reduced applying a novel motion parametrization method. The proposed approach was successfully exemplified on the dynamical model of the KUKA LWR4+ and confirmed through a series of experiments performed on the robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt3_03">15:05-15:20, Paper WeBT3.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0466.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('466'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Warping the Workspace Geometry with Electric Potentials for Motion Optimization of Manipulation Tasks</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137310" title="Click to go to the Author Index">Mainprice, Jim</a></td><td class="r">Max Planck Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115278" title="Click to go to the Author Index">Ratliff, Nathan</a></td><td class="r">Lula Robotics Inc</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102004" title="Click to go to the Author Index">Schaal, Stefan</a></td><td class="r">MPI Intelligent Systems & Univ. of Southern California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab466" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0466.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> In this paper we present motion optimization algorithms for computing manipulation motions in presence of obstacles. Our approach builds a geometric representation of the workspace by constructing Riemannian metrics using electric potentials emanating from the workspace obstacles. Velocity of the robot's body is measured with respect to this metric instead of traditional Cartesian velocity. Empirical results demonstrate that Riemannian metrics are better handled by optimizerrs that leverage objective and constraint functions' second order information. This information encodes how the Riemannian geometry of the modeled workspace pulls back into the configuration space. We also show that despite the additional computational burden of computing the electric-potential based metric, it results in faster overall convergence than reasoning on Euclidean geometry alone. Evaluation is made efficient by cashing the electric potential in voxel grids and using Tri-cubic spline interpolation to assess the potentials gradient.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt3_04">15:20-15:35, Paper WeBT3.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0625.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('625'); return false" title="Click to show or hide the keywords and abstract">Multi-Robot Path Planning for Budgeted Active Perception with Self-Organising Maps</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185051" title="Click to go to the Author Index">Best, Graeme</a></td><td class="r">The Univ. of Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130305" title="Click to go to the Author Index">Faigl, Jan</a></td><td class="r">Czech Tech. Univ. in Prague</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104600" title="Click to go to the Author Index">Fitch, Robert</a></td><td class="r">The Univ. of Sydney</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab625" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a></span><br>
                           <strong>Abstract:</strong> We propose a self-organising map (SOM) algorithm as a solution to a new multi-goal path planning problem for active perception and data collection tasks. We optimise paths for a multi-robot team that aims to maximally observe a set of nodes in the environment. The selected nodes are observed by visiting associated viewpoint regions defined by a sensor model. The key problem characteristics are that the viewpoint regions are overlapping polygonal continuous regions, each node has an observation reward, and the robots are constrained by travel budgets. The SOM algorithm jointly selects and allocates nodes to the robots and finds favourable sequences of sensing locations. The algorithm has polynomial-bounded runtime independent of the number of robots. We demonstrate feasibility for the active perception task of observing a set of 3D objects. The viewpoint regions consider sensing ranges and self-occlusions, and the rewards are measured as discriminability in the ensemble of shape functions feature space. Simulations were performed using a 3D point cloud dataset from a real robot in a large outdoor environment. Our results show the proposed methods enable multi-robot planning for budgeted active perception tasks with continuous sets of candidate viewpoints and long planning horizons.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt3_05">15:35-15:50, Paper WeBT3.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1706.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1706'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Non-Iterative, Fast SE(3) Path Smoothing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196480" title="Click to go to the Author Index">Ng, Yonhon</a></td><td class="r">Australian National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196889" title="Click to go to the Author Index">Jiang, Bomin</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140651" title="Click to go to the Author Index">Yu, Changbin (Brad)</a></td><td class="r">The Australian National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143237" title="Click to go to the Author Index">Li, Hongdong</a></td><td class="r">Australian National Univ. and NICTA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1706" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1706.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a></span><br>
                           <strong>Abstract:</strong> In this paper, we present a fast, non-iterative approach to smooth a noisy input on the Special Euclidean Group, SE(3) manifold. The translational part can be smoothed by a simple Gaussian convolution. We then proposed a novel approach to rotation smoothing. Unlike existing rotation smoothing methods using either iterative optimization methods or stochastic filtering methods, our method allows direct computation of the smoothing result and allows parallelization of the computation. Furthermore, we have done a comparative study on Jia and Evans's method published in 2014, and shown that our method can better smooth an input rotation sequence, with shorter computational time. The smoothed camera path is then used for video stabilisation, which shows fluid and smooth camera motion.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt4"><b>WeBT4</b></a></td>
               <td class="r">#104</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt4" title="Click to go to the Program at a Glance"><b>Rehabilitation Robotics</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#106386" title="Click to go to the Author Index">Yoon, Jungwon</a></td><td class="r">Gyeongsang National Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#156191" title="Click to go to the Author Index">Lee, Jongwoo</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt4_01">14:35-14:50, Paper WeBT4.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0243.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('243'); return false" title="Click to show or hide the keywords and abstract">Online Estimation of Rollator User Condition Using Spatiotemporal Gait Parameters</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154530" title="Click to go to the Author Index">Ballesteros, Joaquin</a></td><td class="r">Univ. of Malaga</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103810" title="Click to go to the Author Index">Urdiales, Cristina</a></td><td class="r">Univ. De Málaga</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124133" title="Click to go to the Author Index">Antonio B., Martinez</a></td><td class="r">Tech. Univ. of Cataluña</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183603" title="Click to go to the Author Index">Tirado, Marina</a></td><td class="r">UGC Rehabilitación, Hospital Regional De Málaga</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab243" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a></span><br>
                           <strong>Abstract:</strong> The assistance to people during rehabilitation has to be adapted to their needs. Too little help can lead to frustration and stress in the user; an excess of help may lead to low participation and loss of residual skills. Robotic rollators may adapt assistance. The main challenge to cope with this issue is to estimate how much help is needed on the fly, because it depends not only on the person condition, but also on the specific situation that they are negotiating. Clinical scales provide a global condition based estimation, but no local estimator based on punctual needs. Condition also changes in time, so clinical scales need to be recalculated again and again. In this paper we propose a novel approach to estimate users’ condition in a continuous way via a robotic rollator. Our work focuses on predicting the value of the well known Tinetti Mobility test from spatiotemporal gait parameters obtained from our platform while users walk. This prediction provides continuous insight on the condition of the user and could be used to modify the amount of help provided. The proposed method has been validated with 19 volunteers at a local hospital that use a rollator for rehabilitation. All volunteers presented some physical or mental disabilities. Our results successfully show a high correlation of spatiotemporal gait parameters with Tinetti Mobility test gait (R2 = 0.7) and Tinetti Mobility test balance (R2 = 0.6).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt4_02">14:50-15:05, Paper WeBT4.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1125.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1125'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Design and Functional Evaluation of an Epidermal Strain Sensing System for Hand Tracking</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195803" title="Click to go to the Author Index">Michaud, Hadrien Olivier</a></td><td class="r">EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195975" title="Click to go to the Author Index">Dejace, Laurent</a></td><td class="r">EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196271" title="Click to go to the Author Index">De Mulatier, Séverine Claire Marie</a></td><td class="r">EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#176759" title="Click to go to the Author Index">Lacour, Stéphanie P.</a></td><td class="r">EPFL</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1125" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1125.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Grasping" title="Click to go to the Keyword Index">Grasping</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a></span><br>
                           <strong>Abstract:</strong> This study demonstrates soft, epidermal resistive strain gauges capable of tracking finger joint angle during dexterous manipulation tasks. Intrinsically stretchable, biphasic, gallium-based metal films embedded in an elastomeric substrate allow for extremely thin (<50 &#956;m) and skin-conforming wearable sensors with outstanding robustness. The sensors sustain repeated cycling to 50% strain and are insensitive to normal pressure up to 100 kPa. Following a calibration phase, we recorded flexions of a human finger using the soft sensors and compared their joint angle estimation to that of a commercial marker-based visual motion tracking system. The accuracy of our system (defined as the mean angular deviation between our sensors’ output and the reference system) was below 9° over a set of 11 different grasping and motion tasks. We demonstrate the scalability and wearability of our technology with a three-finger sensing system used to track the fine movements of a pianist hand. Our soft technology is a promising candidate for implementation of truly wearable proprioceptive sensing systems.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt4_03">15:05-15:20, Paper WeBT4.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1272.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1272'); return false" title="Click to show or hide the keywords and abstract">A Robotic Human Body Model with Joint Limits for Simulation of Upper Limb Prosthesis Users</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185761" title="Click to go to the Author Index">Menychtas, Dimitrios</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#112915" title="Click to go to the Author Index">Carey, Stephanie</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100175" title="Click to go to the Author Index">Dubey, Rajiv</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#121730" title="Click to go to the Author Index">Lura, Derek</a></td><td class="r">Univ. of South Florida</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1272" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a>, <a href="IROS16_KeywordIndexMedia.html#Motor_Skill_Learning" title="Click to go to the Keyword Index">Motor Skill Learning</a></span><br>
                           <strong>Abstract:</strong> The human upper body has many degrees of freedom (DoFs) making it highly redundant and allowing for great flexibility during daily tasks. Because of this redundancy, each joint rarely uses its full range of motion (ROM) during activities of daily living (ADL). However, when DoFs are lost due to an amputation, a greater ROM of the intact joints is used. This decreases the number of achievable postures. This paper describes, a kinematic robotic human body model (RHBM) that is used to simulate the upper body movements of able-bodied and transradial prosthesis users. The motions of a total of 22 subjects from these two groups were evaluated during five ADLs. The RHBM uses a weighted-least-norm (WLN) solution to bias each joint resulting in a human-like posture. The weights are dynamically updated to prevent the joints from moving beyond the individual’s joint limits. These limits were determined by the recorded data of each participant. Applying the individualized joint limits, resulted in postures that were always physically possible for each person and more accurate than the static WLN solution. In the case of prosthesis users, the static WLN solution tended to predict joint angles that were outside of the physical joint limits. The inclusion of joint limit avoidance helped predict more human-like postures.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt4_04">15:20-15:35, Paper WeBT4.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1388.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1388'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Haptic Based Gait Rehabilitation System for Stroke Patients</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#152768" title="Click to go to the Author Index">Afzal, Muhammad Raheel</a></td><td class="r">Gyeongsang National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#161103" title="Click to go to the Author Index">Pyo, Sanghun</a></td><td class="r">Gyeongsang National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184929" title="Click to go to the Author Index">Oh, Min-Kyun</a></td><td class="r">Gyeongsang National Univ. Hospital</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192819" title="Click to go to the Author Index">Park, Young Sook</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195066" title="Click to go to the Author Index">Lee, Beom-Chan</a></td><td class="r">Univ. of Houston</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106386" title="Click to go to the Author Index">Yoon, Jungwon</a></td><td class="r">Gyeongsang National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1388" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1388.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a></span><br>
                           <strong>Abstract:</strong> Among most existing gait rehabilitation robots, it is difficult to find adequate devices for gait rehabilitation of chronic stroke patients who can already stand and move but still need to rehabilitate the affected lower limb through simple, compact, and easy-to use devices. This paper presents a novel haptic based gait rehabilitation system (HGRS) which has the potential to provide over-ground gait training regimens for post-stroke ambulatory subjects. It consists of a portable cane for kinesthetic sensing and a wearable vibrotactor array for tactile biofeedback. Contact of user with the handle provides light grip force, it serves the purpose of balance assurance and increased muscle activity through light touch concept and vibrotactors contribute in enhancing the gait modification through afferent signal of vibration. Walking trials conducted with stroke patients indicate increased muscle activation and balance, and improved temporal symmetry with use of HGRS. HGRS is capable of assisting physical therapists in training individuals with stroke suffering from gait abnormalities. In addition, it is easy to use and low-cost which makes it reachable to a vast domain of subjects suffering from gait abnormalities.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt4_05">15:35-15:50, Paper WeBT4.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1657.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1657'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Upslope Walking with Transfemoral Prosthesis Using Optimization Based Spline Generation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180261" title="Click to go to the Author Index">Paredes, Victor</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196669" title="Click to go to the Author Index">Hong, Woolim</a></td><td class="r">TEXAS A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196685" title="Click to go to the Author Index">Patrick, Shawanee</a></td><td class="r">Texas A&M</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196856" title="Click to go to the Author Index">Hur, Pilwon</a></td><td class="r">Texas A&M Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1657" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1657.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> Powered transfemoral prostheses are robotic systems that aim to restore the mobility of transfemoral amputees by mimicking the functionalities of healthy human legs. The advantage of using a powered prosthetic device is the enhanced performance on various terrains. One of the most frequent terrain found during daily locomotion (other than flat ground) is the surface with slope. In this work, we introduce a framework to generate upslope walking gaits automatically utilizing an online algorithmic formulation. This approach is inspired from analyzing human gait characteristics during upslope walking. In particularly, it is found that the ankle and knee trajectories of upslope walking share a similar pattern with flat ground walking during the middle section (from 20% to 80%) of one step. This observation motivates us to propose an approach of blending the first portion of nominal flat ground gaits with a set of cubic splines to achieve upslope gaits. Importantly, parameters of these cubic splines are solved using an online optimization, which gives the users ability to traverse in different terrains without using any intention detection algorithm. For the last portion of a step, an impedance controller with low gains is considered upon the contact of prosthetic legs to the ground, which allows the users to step onto unknown terrains. The proposed framework is validated on a custom transfemoral prosthesis AMPRO II with showing automatic motion switches between flat ground and upslope walking.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt5"><b>WeBT5</b></a></td>
               <td class="r">#105</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt5" title="Click to go to the Program at a Glance"><b>Motion and Path Planning 1</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#137719" title="Click to go to the Author Index">Scholz, Jonathan</a></td><td class="r">Google Deepmind</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#115221" title="Click to go to the Author Index">Waslander, Steven Lake</a></td><td class="r">Univ. of Waterloo</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt5_01">14:35-14:50, Paper WeBT5.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0244.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('244'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Motion Planning for Persistent Traveling Solar-Powered Unmanned Ground Vehicles</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179375" title="Click to go to the Author Index">Kaplan, Adam</a></td><td class="r">Iowa State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179371" title="Click to go to the Author Index">Kingry, Nathaniel</a></td><td class="r">Iowa State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191715" title="Click to go to the Author Index">Van Den Top, Justin</a></td><td class="r">Iowa State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191714" title="Click to go to the Author Index">Patel, Kishan</a></td><td class="r">Iowa State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179370" title="Click to go to the Author Index">Dai, Ran</a></td><td class="r">Iowa State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196101" title="Click to go to the Author Index">Grymin, David</a></td><td class="r">Air Force Res. Lab</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab244" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0244.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a></span><br>
                           <strong>Abstract:</strong> This paper examines a mission planning problem for a solar-powered unmanned ground vehicle (UGV) which requires the vehicle to visit a series of objective points in minimal time subject to a strict net-energy change constraint. Though related to the Traveling Salesperson Problem, the mission planning problem discussed herein imposes further complexity through additional coupled mixed-variable sets and the strict energy constraint. A scalar field representing the solar radiation of the mission environment is first characterized from a visual-spectrum image. A cascaded particle swarm optimization algorithm, coupled with the integer linear programming technique, is used to generate a time-optimized motion plan and power schedules for the UGV, which guides it to visit the assigned objective points with optimized sequence and paths, and then return to its starting location and orientation while guaranteeing compliance with the net energy gain constraint.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt5_02">14:50-15:05, Paper WeBT5.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0924.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('924'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Local Multiresolution Trajectory Optimization for Micro Aerial Vehicles Employing Continuous Curvature Transitions</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132616" title="Click to go to the Author Index">Nieuwenhuisen, Matthias</a></td><td class="r">Univ. of Bonn</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107752" title="Click to go to the Author Index">Behnke, Sven</a></td><td class="r">Univ. of Bonn</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab924" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0924.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> Complex indoor and outdoor missions for autonomous micro aerial vehicles (MAV) require fast generation of collision-free paths in 3D space. Often not all obstacles in an environment are known prior to the mission execution. Consequently, the ability for replanning during a flight is key for success. Our approach locally optimizes trajectories of grid-based path planning. It preserves obstacle-freeness of the path and ensures smoothness with continuous curvature transition segments.<p>Fast optimization and frequent reoptimization is made possible by means of local multiresolution time discretization. With our extensions, high dimensional flight trajectories incorporating velocities and accelerations can be planned with a time discretization of 100,Hz within the prediction horizon of the underlying controller.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt5_03">15:05-15:20, Paper WeBT5.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0984.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('984'); return false" title="Click to show or hide the keywords and abstract">Batting Flying Objects to the Target in 2D</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192250" title="Click to go to the Author Index">Gardner, Matthew</a></td><td class="r">Iowa State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101853" title="Click to go to the Author Index">Jia, Yan-Bin</a></td><td class="r">Iowa State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150054" title="Click to go to the Author Index">Lin, Huan</a></td><td class="r">Iowa State Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab984" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> This paper presents a planning algorithm for a 2-DOF robotic arm to bat a flying 2D object to a targeted location. Impact dynamics are combined with trajectory kinematics and manipulator dynamics to compute the evolving set of states (poses and velocities) of the arm able to achieve the task as the object is flying. Planning is conducted under the arm’s dynamic and kinematic constraints. At the time of hit, the robot executes an action to minimize its total energy. Simulation and Experiments have been conducted using a Whole Arm Manipulator (WAM) from Barrett Technology, Inc.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt5_04">15:20-15:35, Paper WeBT5.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1395.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1395'); return false" title="Click to show or hide the keywords and abstract">The Constriction Decomposition Method for Coverage Path Planning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196720" title="Click to go to the Author Index">Brown, Stanley</a></td><td class="r">Univ. of Waterloo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115221" title="Click to go to the Author Index">Waslander, Steven Lake</a></td><td class="r">Univ. of Waterloo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1395" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a></span><br>
                           <strong>Abstract:</strong> The task of coverage path planning in 2D indoor and outdoor environments is classified as a NP-hard problem, and has been an active research topic for over 30 years. We derive a novel, exact cellular decomposition method called the Constriction Decomposition Method (CDM) and apply it to complex indoor environments. The CDM rapidly identifies constriction points in the environment and decomposes the environment into easily traversable cells by exploiting the geometric information contained in the environment's straight skeleton. Several heuristic path planning methods that find paths that completely cover each cell are explored. We apply our method on a complex indoor office-like environment and compare our results to existing methods.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt5_05">15:35-15:50, Paper WeBT5.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1523.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1523'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Path Planning Algorithm for Single-Ended Continuous Planar Robotic Ribbon Folding</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196820" title="Click to go to the Author Index">Nagabandi, Anusha</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137918" title="Click to go to the Author Index">Wang, Liyu</a></td><td class="r">Univ. of California at Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101253" title="Click to go to the Author Index">Fearing, Ronald</a></td><td class="r">Univ. of California at Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1523" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1523.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> Ribbon folding is a new approach to structure formation that forms higher dimensional structures using a lower dimensional primitive, namely a ribbon. In this paper, we present a novel algorithm to address path planning for ribbon folding of multi-link planar structures. We first represent the desired structure with a graph-based representation of edges and nodes. We then use graph theory to claim that for any object which is represented by a connected graph, there exists a continuous path which visits all of its edges. Finally, we develop a path planning algorithm that takes into account the physical constraints of the folding machine. The input is the desired planar structure, and the output is the optimal sequence of ribbon folds for creating that structure using the minimum number of folds. The results of this algorithm are successfully used to fold various planar structures.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt6"><b>WeBT6</b></a></td>
               <td class="r">#106</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt6" title="Click to go to the Program at a Glance"><b>Mapping</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101688" title="Click to go to the Author Index">Ramos, Fabio</a></td><td class="r">Univ. of Sydney</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#100055" title="Click to go to the Author Index">Liu, Yunhui</a></td><td class="r">Chinese Univ. of Hong Kong</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt6_01">14:35-14:50, Paper WeBT6.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0187.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('187'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Large-Scale 3D Scene Reconstruction with Hilbert Maps</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141133" title="Click to go to the Author Index">Guizilini, Vitor</a></td><td class="r">Univ. of Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101688" title="Click to go to the Author Index">Ramos, Fabio</a></td><td class="r">Univ. of Sydney</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab187" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0187.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a></span><br>
                           <strong>Abstract:</strong> 3D scene reconstruction involves the volumetric modeling of space, and it is a fundamental step in a wide variety of robotic applications, including grasping, obstacle avoidance, path planning, mapping and many others. Nowadays, sensors are able to quickly collect vast amounts of data, and the challenge has become one of storing and processing all this information in a timely manner, especially if real-time performance is required. Recently, a novel technique for the stochastic learning of discriminative models through continuous occupancy maps was proposed: Hilbert Maps, that is able to represent the input space at an arbitrary resolution while capturing statistical relationships between measurements. The original framework was proposed for 2D environments, and here we extend it to higher-dimensional spaces, addressing some of the challenges brought by the curse of dimensionality. Namely, we propose a method for the automatic selection of feature coordinate locations, and introduce the concept of localized automatic relevance determination (LARD) to the Hilbert Maps framework, in which different dimensions in the projected Hilbert space operate within independent length-scale values. The proposed technique was tested against other state-of-the-art 3D scene reconstruction tools in three different datasets: a simulated indoors environment, RIEGL laser scans and dense LSD-SLAM pointclouds. The results testify to the proposed framework's ability to model complex structures and correctly interpolate over unobserved areas of the input space while achieving real-time training and querying performances.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt6_02">14:50-15:05, Paper WeBT6.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0204.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('204'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Pose Graph Optimization with Hierarchical Conditionally Independent Graph Partitioning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184383" title="Click to go to the Author Index">Tang, Hengbo</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100055" title="Click to go to the Author Index">Liu, Yunhui</a></td><td class="r">Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159543" title="Click to go to the Author Index">Li, Luyang</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab204" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0204.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a hierarchical pose graph optimization algorithm, which hierarchically divides a large pose graph into subgraphs and solves the optimization problem for each subgraph independently. Applying a modified graph partitioning algorithm, normalized cut, the original graph could be partitioned into subgraphs, which are conditionally independent on a set of key nodes. A modified normalized cut algorithm is applied to automatically partition a pose graph into several subgraphs, which are independent on each other when conditioned on a small number of keynodes. Preserving keynodes only, a simplified upper level graph is generated by a pose graph sparsification algorithm. Given the optimization results of all keynodes, which are obtained by solving the upper level graph, each subgraph in the lower level can be solved efficiently without concerning other subgraphs. The scale of each optimization is limited during graph partitioning. Therefore, the efficiency of the optimization is improved. Experiments with both public standard datasets and a dataset collected by an autonomous guided vehicle (AGV) system are conducted to test our algorithm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt6_03">15:05-15:20, Paper WeBT6.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0988.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('988'); return false" title="Click to show or hide the keywords and abstract">Robust Map Generation for Fixed-Wing UAVs with Low-Cost Highly-Oblique Monocular Cameras</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191712" title="Click to go to the Author Index">Hinzmann, Timo</a></td><td class="r">Swiss Federal Inst. of Tech. / ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190619" title="Click to go to the Author Index">Schneider, Thomas</a></td><td class="r">ETH Zürich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178436" title="Click to go to the Author Index">Dymczyk, Marcin Tomasz</a></td><td class="r">ETH Zurich, Autonomous Systems Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179324" title="Click to go to the Author Index">Melzer, Amir</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165203" title="Click to go to the Author Index">Mantel, Thomas</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187957" title="Click to go to the Author Index">Gilitschenski, Igor</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab988" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> Accurate and robust real-time map generation onboard of a fixed-wing UAV is essential for obstacle avoidance, path planning, and critical maneuvers such as autonomous take-off and landing. Due to the computational constraints, the required robustness and reliability, it remains a challenge to deploy a fixed-wing UAV with an online-capable, accurate and robust map generation framework. While photogrammetric approaches have underlying assumptions on the structure and the view of the camera, generic simultaneous localization and mapping (SLAM) approaches are computationally demanding. This paper presents a framework that uses the autopilot's state estimate as a prior for sliding window bundle adjustment and map generation. Our approach outputs an accurate geo-referenced dense point-cloud which was validated in simulation on a synthetic dataset and on two real-world scenarios based on ground control points.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt6_04">15:20-15:35, Paper WeBT6.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1161.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1161'); return false" title="Click to show or hide the keywords and abstract">Long-Term Place Recognition Using Multi-Level Words of Spatial Densities</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148047" title="Click to go to the Author Index">Maffei, Renan</a></td><td class="r">Univ. Federal Do Rio Grande Do Sul</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148251" title="Click to go to the Author Index">Jorge, Vitor</a></td><td class="r">Univ. Federal Do Rio Grande Do Sul</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180668" title="Click to go to the Author Index">Fortes Rey, Vitor</a></td><td class="r">UFRGS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165993" title="Click to go to the Author Index">Kolberg, Mariana</a></td><td class="r">UFRGS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117913" title="Click to go to the Author Index">Prestes, Edson</a></td><td class="r">UFRGS</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1161" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Proper place recognition on an environment that can change over time is fundamental for long-term SLAM. In such scenarios the observations obtained in the same region can drastically differ due to changes caused by semi-static objects, such as doors, furniture, etc. In this work, we extend a strategy that represents environment regions using words, based on spatial density information extracted from laser readings. This time, in order to deal with changes in the environment, our method not only builds words representing the real observations made by the robot, but also alternative multi-level words to account for possible changes in a place's observations generated by non-static objects. Place recognition is made by searching matches of sequences of N consecutive words (both real or alternatives). Experiments performed in real and simulated scenarios are shown, and demonstrate the advantages associated to the use of multi-level words.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt6_05">15:35-15:50, Paper WeBT6.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1241.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1241'); return false" title="Click to show or hide the keywords and abstract">Decoupled, Consistent Node Removal and Edge Sparsification for Graph-Based SLAM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191701" title="Click to go to the Author Index">Eckenhoff, Kevin</a></td><td class="r">Univ. of Delaware</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#136946" title="Click to go to the Author Index">Paull, Liam</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114431" title="Click to go to the Author Index">Huang, Guoquan</a></td><td class="r">Univ. of Delaware</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1241" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Networks" title="Click to go to the Keyword Index">Sensor Networks</a></span><br>
                           <strong>Abstract:</strong> Graph-based SLAM approaches have had success recently despite suffering from ever-increasing computational costs due to the need of optimizing over the entire robot trajectory. To address this issue, in this paper, we advocate the decoupling of marginalization (node removal) and sparsification (edge reduction) to allow for short-term retention of dense factors induced by marginalization while enabling us to spread the computation of these two operations over time. In particular, we analytically show that during marginalization, the correct choice of linearization points in constructing dense marginal factors is to use the relative (local), instead of global, state estimates in the Markov blanket of the marginalized node, which has lacked a general consensus in the literature. Furthermore, during sparsification, we determine an online sparse topology through sparsity-regularized convex optimization, which guides us to construct consistent sparse factors to best approximate the original dense factors across the Markov blanket. The proposed approach is tested extensively on both 2D and 3D public datasets and shown to perform competitively to the state-of-the-art algorithms.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt7"><b>WeBT7</b></a></td>
               <td class="r">#107</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt7" title="Click to go to the Program at a Glance"><b>(Special Session) Robotics Software Engineering</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#107803" title="Click to go to the Author Index">MacDonald, Bruce</a></td><td class="r">Univ. of Auckland</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#104078" title="Click to go to the Author Index">Smart, William</a></td><td class="r">Oregon State Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt7_01">14:35-14:50, Paper WeBT7.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0102.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('102'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>RAFCON: A Graphical Tool for Engineering Complex, Robotic Tasks</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195196" title="Click to go to the Author Index">Brunner, Sebastian Georg</a></td><td class="r">German Aerospace Center, Robotics and Mechatronics Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179040" title="Click to go to the Author Index">Steinmetz, Franz</a></td><td class="r">German Aerospace Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137730" title="Click to go to the Author Index">Belder, Rico</a></td><td class="r">German Aerospace Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#152543" title="Click to go to the Author Index">Dömel, Andreas</a></td><td class="r">German Aerospace Center (DLR)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab102" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0102.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Architectures__Protocols_And_Middle_Ware" title="Click to go to the Keyword Index">Architectures, Protocols And Middle-Ware</a></span><br>
                           <strong>Abstract:</strong> Robotic tasks are becoming increasingly complex, and with this also the robotic systems. This requires new tools to manage this complexity and to orchestrate the systems to fulfill demanding autonomous tasks. For this purpose, we developed a new graphical tool targeting at the creation and execution of robotic tasks, called RAFCON. These tasks are described in hierarchical state machines supporting concurrency. A formal notation of this concept is given. The tool provides many debugging mechanisms and a GUI with a graphical editor, allowing for intuitive visual programming and fast prototyping. The application of RAFCON for an autonomous mobile robot in the SpaceBotCamp competition has already proved to be successful.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt7_02">14:50-15:05, Paper WeBT7.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0150.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('150'); return false" title="Click to show or hide the keywords and abstract">Autonomous Fault Detection for Performance Bugs in Component-Based Robotic Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146176" title="Click to go to the Author Index">Wienke, Johannes</a></td><td class="r">Bielefeld Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108953" title="Click to go to the Author Index">Wrede, Sebastian</a></td><td class="r">Bielefeld Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab150" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Failure_Detection_and_Recovery" title="Click to go to the Keyword Index">Failure Detection and Recovery</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Performance_Evaluation_and_Benchmarking" title="Click to go to the Keyword Index">Performance Evaluation and Benchmarking</a></span><br>
                           <strong>Abstract:</strong> We present a novel fault detection method for application in component-based robotic systems. In contrast to existing work, our method specifically addresses faults in the software system of the robot using a data-driven methodology which exploits the inter-process communication of the system. This enables an application of the approach without expert knowledge or availability of complex software models. We specifically focus on performance bugs, which slowly degrade the performance of the system and are thereby harder to detect but also most valuable for automatic recovery. Using a data set recorded on a RoboCup@Home platform we demonstrate the performance and applicability of our method and analyze the types of faults that can be detected by the method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt7_03">15:05-15:20, Paper WeBT7.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0882.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('882'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Towards Automated System and Experiment Reproduction in Robotics</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151571" title="Click to go to the Author Index">Lier, Florian Hans Michael</a></td><td class="r">Cognitive Interaction Tech. - Center of Excellence</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104948" title="Click to go to the Author Index">Hanheide, Marc</a></td><td class="r">Univ. of Lincoln</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111056" title="Click to go to the Author Index">Natale, Lorenzo</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132992" title="Click to go to the Author Index">Schulz, Simon</a></td><td class="r">Bielefeld Univ. - Cognitive Interaction Tech. - Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142188" title="Click to go to the Author Index">Weisz, Jonathan</a></td><td class="r">Columbia Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110312" title="Click to go to the Author Index">Wachsmuth, Sven</a></td><td class="r">Bielefeld Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108953" title="Click to go to the Author Index">Wrede, Sebastian</a></td><td class="r">Bielefeld Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab882" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0882.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Performance_Evaluation_and_Benchmarking" title="Click to go to the Keyword Index">Performance Evaluation and Benchmarking</a>, <a href="IROS16_KeywordIndexMedia.html#Programming_Environments" title="Click to go to the Keyword Index">Programming Environments</a></span><br>
                           <strong>Abstract:</strong> Even though research on autonomous robots and human-robot interaction accomplished great progress in recent years, and reusable soft- and hardware components are available, many of the reported findings are only hardly reproducible by fellow scientists. Usually, reproducibility is impeded because required information, such as the specification of software versions and their configuration, required data sets, and experiment protocols are not mentioned or referenced in most publications. In order to address these issues, we recently introduced an integrated tool chain and its underlying development process to facilitate reproducibility in robotics. In this contribution we instantiate the complete tool chain in a unique user study in order to assess its applicability and usability. To this end, we chose three different robotic systems from independent institutions and modeled them in our tool chain, including three exemplary experiments. Subsequently, we asked twelve researchers to reproduce one of the formerly unknown systems and the associated experiment. We show that all twelve scientists were able to replicate a formerly unknown robotics experiment using our tool chain.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt7_04">15:20-15:35, Paper WeBT7.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1083.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1083'); return false" title="Click to show or hide the keywords and abstract">Measurement-Based Real-Time Analysis of Robotic Software Architectures</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184052" title="Click to go to the Author Index">Gobillot, Nicolas</a></td><td class="r">ONERA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196145" title="Click to go to the Author Index">Guet, Fabrice</a></td><td class="r">ONERA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150099" title="Click to go to the Author Index">Doose, David</a></td><td class="r">Onera - the French Aerospace Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105440" title="Click to go to the Author Index">Grand, Christophe</a></td><td class="r">ONERA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109029" title="Click to go to the Author Index">Lesire, Charles</a></td><td class="r">ONERA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182925" title="Click to go to the Author Index">Santinelli, Luca</a></td><td class="r">ONERA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1083" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a></span><br>
                           <strong>Abstract:</strong> Providing guarantees on the system behavior is mandatory in order to let the robots enter our every-day life. Among these guarantees, proving the fulfillment of real-time constraints on the software is a key issue, as their violation could result into unexpected and unsafe behaviors. In this paper, we present a methodology to guarantee real-time constraints on component-based software architectures of robots. This methodology relies on the MAUVE language to model the component architecture, and on a set of analysis tools that first estimate the worst case execution time of elementary functions from actual component traces, and then check the real-time constraints of each component. We illustrate this process on the architecture developed for the autonomous navigation of a partially known area by a mobile robot.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt8"><b>WeBT8</b></a></td>
               <td class="r">#108</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt8" title="Click to go to the Program at a Glance"><b>Robot Companions and Social Human-Robot Interaction</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#191788" title="Click to go to the Author Index">O'Sullivan, Carol</a></td><td class="r">The Walt Disney Company</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#104030" title="Click to go to the Author Index">Minato, Takashi</a></td><td class="r">ATR</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt8_01">14:35-14:50, Paper WeBT8.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0164.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('164'); return false" title="Click to show or hide the keywords and abstract">Maintaining Efficient Collaboration with Trust-Seeking Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102607" title="Click to go to the Author Index">Xu, Anqi</a></td><td class="r">McGill Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102604" title="Click to go to the Author Index">Dudek, Gregory</a></td><td class="r">McGill Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab164" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a></span><br>
                           <strong>Abstract:</strong> In this work, we grant robot agents the capacity to sense and react to their human supervisor’s changing trust state, as a means to maintain the efficiency of their collaboration. We propose the novel formulation of Trust-Aware Conservative Control (TACtiC), in which the agent alters its behaviors momentarily whenever the human loses trust. This trust-seeking robot framework builds upon an online trust inference engine and also incorporates an interactive behavior adaptation technique. We present end-to-end instantiations of trust-seeking robots for distinct task domains of aerial terrain coverage and interactive autonomous driving. Empirical assessments comprise a large-scale controlled interaction study and its extension into field evaluations with an autonomous car. These assessments substantiate the efficiency gains that trust-seeking agents bring to asymmetric human-robot teams.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt8_02">14:50-15:05, Paper WeBT8.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0558.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('558'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>HI Robot: Human Intention-Aware Robot Planning for Safe and Efficient Navigation in Crowds</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159532" title="Click to go to the Author Index">Park, Chonhyon</a></td><td class="r">Univ. of North Carolina at Chapel Hill</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191751" title="Click to go to the Author Index">Ondrej, Jan</a></td><td class="r">Disney Res</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191752" title="Click to go to the Author Index">Gilbert, Max</a></td><td class="r">Disney Res</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192552" title="Click to go to the Author Index">Freeman, Kyle</a></td><td class="r">Disney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191788" title="Click to go to the Author Index">O'Sullivan, Carol</a></td><td class="r">The Walt Disney Company</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab558" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0558.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> We present an algorithmic framework for the early classification of human intentions, and use it to accurately predict future human motions when planning the path of a robot in an environment that is shared with humans. During an off-line learning phase, a classifier that can recognize when a human intends to interact with the robot is trained. At runtime, this trained classifier allows us to recognize humans who intend to interact with, or obstruct, the robot in some way. We validate our approach using both recorded and simulated data in an environment in which some humans intentionally obstruct the robot. Our classifier identifies these potential blockers, thus allowing the robot to safely and efficiently navigate the environment by minimizing the chances of being blocked.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt8_03">15:05-15:20, Paper WeBT8.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0609.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('609'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Motion Generation in Android Robots During Laughing Speech</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109330" title="Click to go to the Author Index">Ishi, Carlos Toshinori</a></td><td class="r">ATR</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196617" title="Click to go to the Author Index">Funayama, Tomo</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104030" title="Click to go to the Author Index">Minato, Takashi</a></td><td class="r">ATR</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101596" title="Click to go to the Author Index">Ishiguro, Hiroshi</a></td><td class="r">Osaka Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab609" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0609.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a>, <a href="IROS16_KeywordIndexMedia.html#Voice__Speech_Synthesis_and_Recognition" title="Click to go to the Keyword Index">Voice, Speech Synthesis and Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> We are dealing with the problem of generating natural human-like motions during speech in android robots, which have human-like appearances. So far, automatic generation methods have been proposed for lip and head motions of tele-presence robots, based on the speech signal of the tele-operator. In the present study, we aim on extending the speech-driven motion generation methods for laughing speech, since laughter often occurs in natural dialogue interactions and may cause miscommunication if there is mismatch between audio and visual modalities. Based on analysis results of human behaviors during laughing speech, we proposed a motion generation method given the speech signal and the laughing speech intervals. Subjective experiments were conducted using our android robot by generating five different motion types, considering several modalities. Evaluation results show the effectiveness of controlling different parts of the face, head and upper body (eyelid narrowing, lip corner/cheek raising, eye blinking, head motion and upper body motion control).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt8_04">15:20-15:35, Paper WeBT8.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0947.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('947'); return false" title="Click to show or hide the keywords and abstract">Autonomous Mapping between Motions and Labels</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140038" title="Click to go to the Author Index">Tay, Junyun</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100042" title="Click to go to the Author Index">Chen, I-Ming</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104232" title="Click to go to the Author Index">Veloso, Manuela</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab947" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Entertainment_Robotics" title="Click to go to the Keyword Index">Entertainment Robotics</a></span><br>
                           <strong>Abstract:</strong> A labeled motion library, in which robot motions are associated with semantic meanings, e.g., words, is useful for human-robot interaction, as a robot can use it to autonomously select motions to support its non-verbal communication. Manually assigning labels to new motions to a motion library is time consuming. However, a new motion may be similar to motions in the labeled motion library, and can be mapped to existing labels. We formally define motions, labels, and mappings between motions and labels. We use a NAO humanoid robot as a motivating example, though our approach is general for use on a humanoid robot with rotational joints. We explain how we generate motions and labels, define eight distance metrics to determine the similarity between motions, and use the nearest neighbor algorithm to determine the labels of a new motion. The distance metrics are varied across three axes - Euclidean versus Hausdorff, joint angles versus points of interest (postures), and mirrored versus non-mirrored. We evaluate the efficacy of these eight distance metrics, using precision, recall, and computational complexity.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt8_05">15:35-15:50, Paper WeBT8.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1400.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1400'); return false" title="Click to show or hide the keywords and abstract">Validation of Cognitive Models for Collaborative Hybrid Systems with Discrete Human Input</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196707" title="Click to go to the Author Index">P. Vinod, Abraham</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193090" title="Click to go to the Author Index">Tang, Yuqing</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#118368" title="Click to go to the Author Index">Oishi, Meeko</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117857" title="Click to go to the Author Index">Sycara, Katia</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#186244" title="Click to go to the Author Index">Lebiere, Christian</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117861" title="Click to go to the Author Index">Lewis, Michael</a></td><td class="r">Univ. of Pittsburgh</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1400" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Formal_Methods_in_Robotics_and_Automation" title="Click to go to the Keyword Index">Formal Methods in Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Networked_Robots" title="Click to go to the Keyword Index">Networked Robots</a></span><br>
                           <strong>Abstract:</strong> We present a method to validate a cognitive model, based on the cognitive architecture ACT-R, in dynamic human-automation systems with discrete human input. We are inspired by the general problem of K-choice games as a proxy for many decision making applications in dynamical systems. We model the human as a Markovian controller based on gathered experimental data, that is, a non-deterministic control input with known likelihoods of control actions associated with certain configurations of the state-space. We use reachability analysis to predict the outcome of the resulting discrete-time stochastic hybrid system, in which the outcome is defined as a function of the system trajectory. We suggest that the resulting expected outcomes can be used to validate the cognitive model against actual human subject data. We apply our method to a two-choice game in which the human is tasked with maximizing net coverage of a robotic swarm that can operate under rendezvous or deployment dynamics. We validate the corresponding ACT-R cognitive model generated with the data from eight human subjects. The novelty of this work is 1) a method to compute expected outcome in a hybrid dynamical system with a Markov chain model of the human's discrete choice, and 2) application of this method to validation of cognitive models with a database of actual human subject data.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt9"><b>WeBT9</b></a></td>
               <td class="r">#204~205</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt9" title="Click to go to the Program at a Glance"><b>Force Control 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#192752" title="Click to go to the Author Index">Gonzales Marin, Antonio</a></td><td class="r">Robotics and Mechatronics Center (DLR)</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#119052" title="Click to go to the Author Index">Yu, Ningbo</a></td><td class="r">NanKai Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt9_01">14:35-14:50, Paper WeBT9.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0185.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('185'); return false" title="Click to show or hide the keywords and abstract">Impedance Control of a Cable-Driven Series Elastic Actuator with the 2-DOF Control Structure</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189006" title="Click to go to the Author Index">Zou, Wulin</a></td><td class="r">Nankai Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201089" title="Click to go to the Author Index">Yang, Zhuo</a></td><td class="r">Nankai Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201093" title="Click to go to the Author Index">Tan, Wen</a></td><td class="r">Nankai Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189905" title="Click to go to the Author Index">Wang, Meng</a></td><td class="r">Nankai Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106992" title="Click to go to the Author Index">Liu, Jingtai</a></td><td class="r">Nankai Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#119052" title="Click to go to the Author Index">Yu, Ningbo</a></td><td class="r">NanKai Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab185" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Series elastic actuators (SEAs) are growingly important in physical human-robot interaction (HRI) due to their inherent safety and compliance. Cable-driven SEAs also allow flexible installation and remote torque transmission, etc. However, there are still challenges for the impedance control of cable-driven SEAs, such as the reduced bandwidth caused by the elastic component, and the performance balance between reference tracking and robustness. In this paper, a velocity sourced cable-driven SEA has been set up. Then, a stabilizing 2 degrees of freedom (2-DOF) control approach was designed to separately pursue the goals of robustness and torque tracking. Further, the impedance control structure for human-robot interaction was designed and implemented with a torque compensator. Both simulation and practical experiments have validated the efficacy of the 2-DOF method for the control of cable-driven SEAs.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt9_02">14:50-15:05, Paper WeBT9.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0524.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('524'); return false" title="Click to show or hide the keywords and abstract">Unified Impedance and Hybrid Force-Position Controller with Kinestatic Filtering</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192752" title="Click to go to the Author Index">Gonzales Marin, Antonio</a></td><td class="r">Robotics and Mechatronics Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155744" title="Click to go to the Author Index">Weitschat, Roman</a></td><td class="r">Robotics and Mechatronics Center (DLR)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab524" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a></span><br>
                           <strong>Abstract:</strong> Interaction control is a mature, but still, current area of research in robotics. Various approaches have been developed for passive and active force regulation and tracking, e.g. impedance control, direct force and hybrid force-position control. The latter method implements a force feedback outer loop on top of a position controller inner loop, where commands are issued with respect to a compliant frame. However, if the compliant frame undergoes a rigid transformation, e.g. in order to specify the same task relative to another reference frame, then commands can be rendered non-compliant with the task at hand. As a consequence, the robot can be damaged or hurt somebody, this is further aggravated by the rigidness of a position controller. In the present paper, we propose a unified impedance and hybrid force-position control scheme to address such issues. The unified controller benefits from the impedance control compliance while an explicit force value can be achieved. Furthermore, we augment the designed controller with a kinestatic filter, which ensures that the commanded pose and wrench are consistent with a given task model. We validate the designed system through experiments with a lightweight robot (LWR). The proposed approach finds applications in industrial settings where interactions with the environment are required in order to fulfill a task and the system must be robust w.r.t. input commands.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt9_03">15:05-15:20, Paper WeBT9.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0900.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('900'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Soft Robotics for the Hydraulic Atlas Arms: Joint Impedance Control with Collision Detection and Disturbance Compensation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188412" title="Click to go to the Author Index">Vorndamme, Jonathan</a></td><td class="r">Inst. for Automatic Control, Leibniz Univ. Hannover</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188177" title="Click to go to the Author Index">Schappler, Moritz</a></td><td class="r">Inst. for Automatic Control, Leibniz Univ. Hannover</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188413" title="Click to go to the Author Index">Tödtheide, Alexander</a></td><td class="r">Leibniz Univ. Hannover, Inst. of Automatic Control</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108317" title="Click to go to the Author Index">Haddadin, Sami</a></td><td class="r">Leibniz Univ. Hanover</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab900" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0900.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Hydraulic_Pneumatic_Actuators" title="Click to go to the Keyword Index">Hydraulic/Pneumatic Actuators</a></span><br>
                           <strong>Abstract:</strong> Soft robotics methods such as impedance control and reflexive collision handling have proven to be a valuable tool to robots acting in partially unknown and potentially unstructured environments. Mainly, the schemes were developed with focus on classical electromechanically driven, torque controlled robots. There, joint friction, mostly coming from high gearing, is typically decoupled from link-side control via suitable rigid or elastic joint torque feedback. Extending and applying these algorithms to stiff hydraulically actuated robots poses problems regarding the strong influence of friction on joint torque estimation from pressure sensing, i.e. link-side friction is typically significantly higher than in electromechanical soft robots. In order to improve the performance of such systems, we apply state-of-the-art fault detection and estimation methods together with observer-based disturbance compensation control to the humanoid robot Atlas. With this it is possible to achieve higher tracking accuracy despite facing significant modeling errors. Compliant end-effector behavior can also be ensured by including an additional force/torque sensor into the generalized momentum-based disturbance observer algorithm from [1].
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt9_04">15:20-15:35, Paper WeBT9.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1064.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1064'); return false" title="Click to show or hide the keywords and abstract">Performance Improvement of Implicit Integral Robot Force Control through Constraint-Based Optimization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171285" title="Click to go to the Author Index">Parigi-Polverini, Matteo</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172074" title="Click to go to the Author Index">Rossi, Roberto</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103412" title="Click to go to the Author Index">Bascetta, Luca</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129139" title="Click to go to the Author Index">Zanchettin, Andrea Maria</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#10019" title="Click to go to the Author Index">Rocco, Paolo</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201402" title="Click to go to the Author Index">Morandi, Giacomo</a></td><td class="r">Pol. Di Milano</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1064" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a></span><br>
                           <strong>Abstract:</strong> Classical control approaches to robot force control have been extensively addressed by research in the last decades and are now considered a paradigm when dealing with force control for industrial robots. With this respect, the present paper exploits the capability of state-of-the-art Quadratic Programming (QP) solvers to specify a simple and intuitive constraint-based optimization strategy aiming at improving closed-loop performance of a classical force controller, such as the implicit force control with pure integral action for a position-controlled manipulator in contact with a compliant environment. The effectiveness of the proposed control strategy is experimentally validated on an industrial robot equipped with a force sensor.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt9_05">15:35-15:50, Paper WeBT9.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1531.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1531'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Touch-Based Admittance Control of a Robotic Arm Using Neural Learning of an Artificial Skin</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188176" title="Click to go to the Author Index">Pugach, Ganna</a></td><td class="r">ETIS - UMR CNRS 8051, ENSEA - Univ. of Cergy-Pontoise - CNR</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#145341" title="Click to go to the Author Index">Melnyk, Artem</a></td><td class="r">Univ. De Cergy-Pontoise</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195700" title="Click to go to the Author Index">Tolochko, Olga</a></td><td class="r">National Tech. Univ. of Ukraine "Kyiv Pol. Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156600" title="Click to go to the Author Index">Pitti, Alexandre</a></td><td class="r">Univ. of Cergy Pontoise</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117434" title="Click to go to the Author Index">Gaussier, Philippe</a></td><td class="r">CNRS UMR 8051, ENSEA, Cergy-Pontoise Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1531" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1531.VI.mpeg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Touch perception is an important sense to model in humanoid robots to interact physically and socially with humans. We present a neural controller that can adapt the compliance of the robot arm in four directions using as input the tactile information from an artificial skin and as output the estimated torque for admittance control-loop reference. This adaption is done in a self-organized fashion with a neural system that learns first the topology of the tactile map when we touch it and associates a torque vector to move the arm in the corresponding direction. The artificial skin is based on a large area piezoresistive tactile device (ungridded) that changes its electrical properties in the presence of the contact. Our results show the self-calibration of a robotic arm (2 degrees of freedom) controlled in the four directions and derived combination vectors, by the soft touch on all the tactile surface, even when the torque is not detectable (force applied near the joint). The neural system associates each tactile receptive field with one direction and the correct force. We show that the tactile-motor learning gives better interactive experiments than the admittance control of the robotic arm only. Our method can be used in the future for humanoid adaptive interaction with a human partner.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="webt10"><b>WeBT10</b></a></td>
               <td class="r">#206~208</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#webt10" title="Click to go to the Program at a Glance"><b>Legged Robots 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104048" title="Click to go to the Author Index">Schmiedeler, James</a></td><td class="r">Univ. of Notre Dame</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#102438" title="Click to go to the Author Index">Choi, Hyouk Ryeol</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt10_01">14:35-14:50, Paper WeBT10.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0538.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('538'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Fault-Tolerant Adaptive Gait Generation for Multi-Limbed Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195934" title="Click to go to the Author Index">Kawata, Takeyuki</a></td><td class="r">Osaka&#12288; Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107423" title="Click to go to the Author Index">Kamiyama, Kazuto</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133641" title="Click to go to the Author Index">Kojima, Masaru</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165924" title="Click to go to the Author Index">Horade, Mitsuhiro</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105114" title="Click to go to the Author Index">Mae, Yasushi</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100115" title="Click to go to the Author Index">Arai, Tatsuo</a></td><td class="r">Osaka Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab538" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0538.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Failure_Detection_and_Recovery" title="Click to go to the Keyword Index">Failure Detection and Recovery</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> The paper describes a method of fault-tolerant adaptive gait generation based on CPG controller with interlimb coordination for multi-limbed working robot. Multi-limbed robot is expected to work in dangerous, complicated narrow spaces, where human workers cannot reach. However, if one of the limbs is broken in the dangerous/narrow working space, human operators cannot go to the space to repair it. Even in these situations, the proposed method generates a new gait adaptively using the remaining usable limbs depending on the current situation of the multi-limbed robot. This fault-tolerant ability is effective for multi-limbed robots working in dangerous/narrow space. The method is implemented to a model of a multi-limbed robot &quot;ASTERISK&quot; in a dynamical simulator (ODE). Experimental results show effectiveness of the proposed method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt10_02">14:50-15:05, Paper WeBT10.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0649.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('649'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Hybrid Quadruped Bounding with a Passive Compliant Spine and Asymmetric Segmented Body</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170822" title="Click to go to the Author Index">Phan, Luong Tin</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158976" title="Click to go to the Author Index">Lee, Yoon Haeng</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187850" title="Click to go to the Author Index">Kim, Dong Youn</a></td><td class="r">School of Mechanical Engineering, Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169507" title="Click to go to the Author Index">Lee, Hyunyong</a></td><td class="r">Sungskyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102438" title="Click to go to the Author Index">Choi, Hyouk Ryeol</a></td><td class="r">Sungkyunkwan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab649" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0649.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a></span><br>
                           <strong>Abstract:</strong> Most legged animals exploit flexible body and supporting muscles to produce power for dynamic behaviors which results in fast locomotion and additional mobility. Previous works have focused on the symmetric flexible body with massless legs associated to the body. However, body bending in animals during running happens prior to the rear side instead of the middle point of body. Therefore, a quadruped model with a passive spinal joint, asymmetric segmented body, actuated hip joints and legs is introduced. By using a numerical return map, a periodic bounding locomotion of the model is found with optimal sets of initial conditions and proper system parameters. Moreover, this paper investigates the effects of spine flexibility in segmented body on quadrupedal bounding gait. The results show that asymmetric segmented body has bigger spine oscillation, shorter stride period and smaller cost of transport, which helps the robot run more efficiently.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt10_03">15:05-15:20, Paper WeBT10.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1268.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1268'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Gait Transitions and Disturbance Response for Planar Bipeds with Reaction Wheel Actuation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#125256" title="Click to go to the Author Index">Brown, Travis</a></td><td class="r">Univ. of Notre Dame</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104048" title="Click to go to the Author Index">Schmiedeler, James</a></td><td class="r">Univ. of Notre Dame</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1268" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1268.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> The reaction wheel stabilizer (RWS) concept for bipedal stabilization consists of a wheel that can be accelerated in order to impart a reaction torque on the rest of the biped. The beneficial effects of such a device (or emulation of such a device through limb motion) on transient body motions are not well understood. This work quantifies this phenomenon by comparing optimal trajectories for robots with and without an RWS in terms of energy efficiency and dynamic feasibility when attempting to execute speed transitions and disturbance response motions. Robots with RWS systems are able to more efficiently execute abrupt speed transitions, showing up to a 60% improvement in efficiency for single step transitions. In responding to forward push disturbances, the RWS improves efficiency by between 20 and 60% over the range of tested disturbances. These savings are significantly larger than those shown previously for periodic walking.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt10_04">15:20-15:35, Paper WeBT10.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1420.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1420'); return false" title="Click to show or hide the keywords and abstract">Optimized Energy Addition for a Planar SLIP Model with Redundant Joints</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105959" title="Click to go to the Author Index">Palmer III, Luther R.</a></td><td class="r">Wright State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184078" title="Click to go to the Author Index">Ashley, Kyle</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156100" title="Click to go to the Author Index">Eaton, Caitrin</a></td><td class="r">Univ. of California, Irvine</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1420" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a></span><br>
                           <strong>Abstract:</strong> The planar and energetically conservative Spring-Loaded Inverted Pendulum (SLIP) model with a linear spring has been modified in recent years to include an articulated knee, friction and contact losses, and energy thrusts during stance to stabilize forward velocity and hopping height. The work presented here advances the SLIP template toward a biological anchor by adding a third parallel articulating joint, which provides redundancy in the inverse kinematics solution space. Instead of one actuator into which an energy thrust can be added, the total thrust can be distributed between two actuators operating on the lower two leg joints (the hip joint remains passive during stance as in the original SLIP model). It is shown that a careless distribution of the thrust can lead to significant energy loss, so an offline search protocol is presented as a general approach for resolving the optimal thrust distribution ratio between these joints. The results of the offline search are then approximated for rapid computation of this ratio during hopping tests in a high-fidelity simulation engine.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="webt10_05">15:35-15:50, Paper WeBT10.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1486.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1486'); return false" title="Click to show or hide the keywords and abstract">On Passive Quadrupedal Bounding with Translational Spinal Joint</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196391" title="Click to go to the Author Index">Koutsoukis, Konstantinos</a></td><td class="r">National Tech. Univ. of Athens</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101814" title="Click to go to the Author Index">Papadopoulos, Evangelos</a></td><td class="r">National Tech. Univ. of Athens</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1486" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a></span><br>
                           <strong>Abstract:</strong> This paper studies the effect of flexible linear torso on the dynamics of passive quadruped bounding. A reduced-order passive and conservative model with translational spinal joint and springy legs is introduced. Numerical return map studies reveal the existence of a restricted area of fixed points generating high-speed cyclic bounding motions by exploiting the natural dynamics of the model. The corresponding motion features extensive bidirectional spine deformation. The model incorporates interesting techniques, such as increased flight phase duration and stride length, in order to achieve high-speed locomotion. The obtained reults show that the corresponding robot gaits and the associated performance resemble those of its natural counterparts even though the spinal joint lies beyond the bioinspired regime.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wespt12"><b>WeSpT12</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wespt12" title="Click to go to the Program at a Glance"><b>Special Forum 2: Autonomous Systems</b></a></td>
               <td class="r">Special Forum</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104593" title="Click to go to the Author Index">Shim, David Hyunchul</a></td><td class="r">KAIST</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weci1"><b>WeCI1</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weci1" title="Click to go to the Program at a Glance"><b>Poster Session 1</b></a></td>
               <td class="r">Poster session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#140339" title="Click to go to the Author Index">Seo, TaeWon</a></td><td class="r">Yeungnam Univ</td></tr>

<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_01">16:05-17:20, Paper WeCI1.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1781.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1781'); return false" title="Click to show or hide the keywords and abstract">Motion Planning for a Multi-Section Cable-Driven Continuum Surgical Manipulator by Learning from Demonstrations</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187937" title="Click to go to the Author Index">Chen, Jie</a></td><td class="r">The Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201268" title="Click to go to the Author Index">Qu, Tingyu</a></td><td class="r">THE Univ. OF HONG KONG</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134440" title="Click to go to the Author Index">Lau, Henry Y.K.</a></td><td class="r">Univ. of Hong Kong</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1781" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Tendon_Wire_Mechanisms" title="Click to go to the Keyword Index">Tendon/Wire Mechanisms</a></span><br>
                           <strong>Abstract:</strong> In cable-driven continuum manipulators, the cables are used to transmit the movement of the actuators to the joints. Therefore, the actuation system can be located remotely, which offers enormous possibilities for robot assisted minimally invasive surgeries (MIS). MIS is a form of surgery intended to provide great benefits to patients over conventional open surgery by minimizing unnecessary trauma caused in the process of performing a medical procedure. MIS leads to less pain, blood loss and better cosmesis, and reduces the recovery time for patients. However, due to the highly limited workspace, indirect visual and tactile information feedback, and specialized tools, MIS is very hard for surgeons to perform, which highlights the importance of robot assisted MIS.<p>In this paper, we suggest to use a novel motion planning paradigm, learning from demonstrations (LfD), to transfer three benchmarking clinical skills, e.g., insertion, targeting, and obstacle avoidance, for a cable-driven continuum manipulator. The advantages of the proposed approaches mainly lie on four folds: Firstly, a cable-driven manipulator with two sections (4 degrees-of-freedom) is implemented. Secondly, based on the piecewise constant curvature assumption, a parameterized model is derived to describe the kinematics of the cable-driven manipulator. Thirdly, an expectation-maximization based policy search algorithm is implemented to iteratively update the derived parameterized model to compensate for the nonlinearities in the system. And finally, a human operator teleoperates the manipulator to accomplish the aforementioned three tasks several times, then Gaussian Mixture Models and Gaussian Mixture Regression are applied to encode the demonstrations with a dynamical systems model and generalize corresponding actuator movements for the manipulator to reproduce the learned skills.<p>Our newly proposed cable-driven continuum manipulator is a soft snake-arm robot. Compared with the structures of formerly developed soft robots, this original prototype has three major superiorities. Firstly, each vertebra is designed as a flake-shaped node and the backbone is made by a 0.8-mm diameter Austenite-stainless-steel wire. This eliminates the friction between the adjacent nodes and reduces total weight of the skeleton to less than 10g, thus highly increasing the response rate and allowing the arm to reach a maximum bending angle of 17.5 degree for each joint. Secondly, the appropriate decrease of the reference circle diameter in the 2nd section minimizes its bending interferences on the 1st section, which improves the flexibility and controllability when both sections bend. Thirdly, two groups of steel cables (two pairs in each group for one section) are introduced to actuate the manipulator through via holes. The collaboration of the two groups of cables enables the manipulator to bend in an S-shape.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_02">16:05-17:20, Paper WeCI1.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1784.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1784'); return false" title="Click to show or hide the keywords and abstract">V-BTSLIP Model: Stabilization of the Biped Trunk-SLIP Walking Model Using Variable Stiffness</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196876" title="Click to go to the Author Index">Vu, Nhat Minh</a></td><td class="r">Univ. of Science and Tech. Korea Inst. of Science</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156191" title="Click to go to the Author Index">Lee, Jongwoo</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110832" title="Click to go to the Author Index">Oh, Yonghwan</a></td><td class="r">Korea Inst. of Science & Tech. (KIST)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1784" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a></span><br>
                           <strong>Abstract:</strong> In this study, we introduce the Variable stiffness - Biped Spring Loaded Inverted Pendulum (V-BTSLIP) which consists of a rigid trunk, hips actuation, and massless springy legs with controllable stiffness. We propose to stabilize trunk posture with the Virtual Pendulum concept while stabilizing the vertical position and velocity of the Center of Mass (CoM) trajectory by controlling the stiffness of the legs based on feedback linearization. The nonlinear dynamic simulation shows that the performance of the V-BTSLIP model is robust against disturbance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_03">16:05-17:20, Paper WeCI1.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1785.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1785'); return false" title="Click to show or hide the keywords and abstract">Effective Suppression of Residual Vibration by a Systematic MZ Shaper Design</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130232" title="Click to go to the Author Index">Kang, Chul-Goo</a></td><td class="r">Konkuk Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171491" title="Click to go to the Author Index">Ha, Manh-Tuan</a></td><td class="r">Konkuk Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203150" title="Click to go to the Author Index">Yoo, Jae Seon</a></td><td class="r">Dukin Co</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203152" title="Click to go to the Author Index">Lee, Sang-Kyu</a></td><td class="r">Dukin Co</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1785" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a></span><br>
                           <strong>Abstract:</strong> An LCD glass substrate transfer robot generally has residual vibrations when it moves from one point to another in space, and thus we need to remove the residual vibrations quickly to increase job productivity. Moreover, we need to remove residual vibrations robustly since payload change will vary vibration frequency and damping ratio.	 Input shaping control is an open-loop control technique for reducing residual vibrations in undamped or under-damped systems. An early form of input shaping control, ZV (zero vibration) shaping control, lacked robustness to modeling errors due to the open-loop control characteristics of it. This robustness problem of ZV shaping control to modeling errors was resolved by many researchers since late 1980s by adding additional constraints on the derivative of the residual vibration magnitudes, by relaxing zero vibration constraints at the modeling frequency, or repeatedly using residual vibration constraints for a specified range of frequencies. In this paper, we introduce a new systematic method to create a robust input shaper called MZ shaper (multi-ZV shaper), which is designed by convolving two simple ZV (zero vibration) shapers. Moreover, we verify the usefulness of the MZ shaper through simulation and experimental studies. Let the natural frequency and damping ratio of an oscillatory second-order plant be modeled. <p>Step 1. Determine the low ZV shaper frequency and high ZV shaper frequency from a given tolerance value of the residual vibration ratio V. The values of low and high frequencies can be selected in many ways according to the given specifications, but the simplest way is to select them symmetrically at both sides of modeled frequency. Now, the frequency shift for 5% residual vibration is calculated as half the frequency interval obtained, and curve-fitted approximate values are expressed in a polynomial form. Then, the low and high ZV shaper frequencies are given for a symmetric MZ shaper as the modeled frequency - and + the frequncy shift respectively.<p>Step 2. Design two ZV shapers for the low and high natural frequencies together with the modeled damping ratio. <p>Step 3. Convolve the two ZV shapers given in step 2 to design a MZ shaper.<p>This MZ shaper is robust to modeling errors in the natural frequency, but incurs a longer shaper duration penalty. Note that the MZ shaper can be designed by convolving more than two ZV or ZVD shapers. To experimentally show the validity of the residual vibration control of the MZ shaper, we have conducted experiments using an up-down motion control apparatus with flexible horizontal beams. <p>When the MZ shaper was applied to an actual motion control system with 15 % modeling error in the natural frequency, the residual vibration was eliminated up to 83% compared to the case without an input shaper.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_04">16:05-17:20, Paper WeCI1.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1786.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1786'); return false" title="Click to show or hide the keywords and abstract">Jumping Robot Design with a Compliant Pole</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202534" title="Click to go to the Author Index">Choi, JaeNeung</a></td><td class="r">Yeungnam Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178631" title="Click to go to the Author Index">Jeong, Kyungmin</a></td><td class="r">KAERI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140339" title="Click to go to the Author Index">Seo, TaeWon</a></td><td class="r">Yeungnam Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1786" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Joint_Mechanism_Design" title="Click to go to the Keyword Index">Joint/Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> Jumping robots are being developed using a variety of methods, such as springs, compressed air, and complaint link. We present a new robotic platform called Pol-E, which can jump over an obstacles using a compliant link based on the principle of pole vaulting and energy conservation theory. Wheeled locomotion is used to build up energy without additional actuators for jumping. Kinetic energy generated by moving on the ground is converted into elastic and potential energy by colliding with an obstacle through the compliant link. In the paper, we modeled the dynamics as stance and flight phase to predict the influences of design variables for the robot through a sensitivity analysis with respect to three important variables. Based on the results, we manufactured the prototype, and it successfully jumped over an obstacle with a height of 0.18m, about 3 times the robot sizes. We expected the proposed robot platform to be applied to inspection, environmental monitoring, search, and rescue.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_05">16:05-17:20, Paper WeCI1.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1787.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1787'); return false" title="Click to show or hide the keywords and abstract">Development of a Light-Weight 4-DOF Gravity-Compensated Robot Manipulator</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178638" title="Click to go to the Author Index">Lee, Dong Gyu</a></td><td class="r">Yeunnam Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140339" title="Click to go to the Author Index">Seo, TaeWon</a></td><td class="r">Yeungnam Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1787" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Joint_Mechanism_Design" title="Click to go to the Keyword Index">Joint/Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Green_Robotics" title="Click to go to the Keyword Index">Green Robotics</a></span><br>
                           <strong>Abstract:</strong> Industry robot generate torque due to a large weight. For this reason, the robot need high specification motor, which results in huge energy consumption. Energy consumption is becoming more and more important due to limited fuel and environmental problems. In order to resolve these problem, the mechanism for gravity compensation had been developed using spring and wire. But, the problem of spring and wire system is durability of wire. The winding mechanism is used to supplement the drawback of the wire. We propose a novel multi-DOF manipulator with a wire-driven gravity compensation mechanism to reduce the moving inertia. A multi-winding mechanism is used to increase durability by reducing the tension in the wire. To generate the reference frame for the multi-DOF manipulator, a belt and pulley system was adopted. A 4-DOF manipulator prototype was assembled using a belt and pulley system to maintain the reference plane for the series connection of the wires. In the path-tracking experiments, the mechanism reduced the operation torque by 40%. Also, the improved durability was proven in other experiments. The gravity-compensation mechanism could be used in an industrial manipulator to increase the energy efficiency during operation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_06">16:05-17:20, Paper WeCI1.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1790.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1790'); return false" title="Click to show or hide the keywords and abstract">Reference Compensated Neuro-Sliding Mode Control for Robot Manipulators</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100310" title="Click to go to the Author Index">Jung, Seul</a></td><td class="r">Chungnam National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203315" title="Click to go to the Author Index">Oh, M. S.</a></td><td class="r">Chungnam National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1790" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> When the sliding mode controller is used for the non model-based configuration in robot control, the nonlinear gain K should be selected large enough to guarantee the stability. Here neural network is introduced at the trajectory level to have the gain more intelligently in the framework of a sliding mode control scheme. Simulation studies of following the Cartesian trajectory for the three link rotary robot manipulator are conducted to confirm the control improvement by the neural network.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_07">16:05-17:20, Paper WeCI1.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1791.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1791'); return false" title="Click to show or hide the keywords and abstract">Turning Motion Control of a Spherical Robot Based on a Gyroscopic Actuation: G-Sphere</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181842" title="Click to go to the Author Index">Lee, Sangdeok</a></td><td class="r">Chungnam National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100310" title="Click to go to the Author Index">Jung, Seul</a></td><td class="r">Chungnam National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1791" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> In this paper, a small spherical robot called G-Sphere is introduced. G-Sphere is equipped with a gimbal system that induces the gyroscopic force by one flywheel and two motors. G-sphere is designed to aim for navigate in its terrain by avoiding obstacles. Therefore, generation and control of various motions become essential in addition to maintain balance. A gyroscopic motion control method for the typical motion of turning 90 degrees is presented. The feasibility of turning motion control is evaluated by the experimental studies.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_08">16:05-17:20, Paper WeCI1.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1797.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1797'); return false" title="Click to show or hide the keywords and abstract">Contact Force Estimation for Multiple Points of Contact</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196678" title="Click to go to the Author Index">Kutsuzawa, Kyo</a></td><td class="r">Saitama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158571" title="Click to go to the Author Index">Sakaino, Sho</a></td><td class="r">Saitama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116765" title="Click to go to the Author Index">Tsuji, Toshiaki</a></td><td class="r">Saitama Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1797" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a></span><br>
                           <strong>Abstract:</strong> When robots interact with the environment, it is necessary for them to detect and control contact forces. In many cases, force/torque sensors on robots do not contact the environment directly, but instead contact through end-effectors or grasped objects. This study aims to find a generalized method of estimating individual forces at multiple contact points. However, estimating multiple contact forces through insensitive objects is an ill-posed problem. Thus, it is necessary to clarify what components of contact forces can be found and what kinds of conditions are needed to determine the other components uniquely. This paper proposes methods of estimating individual forces on two or three points of contact. These methods need to be unified and extended to generalized theory for multiple points of contact.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_09">16:05-17:20, Paper WeCI1.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1798.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1798'); return false" title="Click to show or hide the keywords and abstract">Disassembly Robotic Tasks for Circular Economy: A Preliminary Study</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181418" title="Click to go to the Author Index">Morachioli, Annagiulia</a></td><td class="r">Istituto Di Biorobotica</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#176927" title="Click to go to the Author Index">Strazzulla, Ilaria</a></td><td class="r">Scuola Superiore Sant'Anna</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106001" title="Click to go to the Author Index">Bonsignorio, Fabio Paolo</a></td><td class="r">Heron Robots Srl and the Biorobotics Insitute Scuola Superiore S</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101839" title="Click to go to the Author Index">Dario, Paolo</a></td><td class="r">Scuola Superiore Sant'Anna</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1798" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a></span><br>
                           <strong>Abstract:</strong> The continued development of our economy and the fast growth of the population are endangering our world’s ecological stability. Not only natural resources are finite, but also the capability of the ecosystem to support the global economy’s side effects is limited. An eco-sustainable solution to guarantee a high quality of life to the billions of people living on Earth by 2040 can be moving away from the current paradigm of the “Linear Economy” towards the emerging paradigm of the “Circular Economy” (defined as a mode of economic development based on ecological circulation of natural materials and artefacts). Robotics will have a crucial role in the emergence and implementation of Circular Economy. Disassembly and recycling are fundamental procedures for Circular Economy, allowing to introduce the concept of the “Robotic Circular Production” (RCP), which closes the loop production cycle. The objective of this study is to present preliminary evidences on how intelligent robotics technologies, such as bio-inspired dexterous dual-arm manipulation combined with visual servoing, could be used to implement disassembly tasks that form the building blocks of more complex processes of the Circular Economy paradigm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_10">16:05-17:20, Paper WeCI1.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1800.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1800'); return false" title="Click to show or hide the keywords and abstract">Realizing Natural Springy Motion of a Robotic Leg by Cancelling the Undesired Damping Factors</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177871" title="Click to go to the Author Index">Cho, Jungsoo</a></td><td class="r">Sogang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100740" title="Click to go to the Author Index">Kong, Kyoungchul</a></td><td class="r">Sogang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1800" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a></span><br>
                           <strong>Abstract:</strong> A Spring-Loaded-Inverted Pendulum (SLIP) model has been applied to many legged robots, such as quadruped robots, for realizing trotting, bounding, and galloping motions. The indecipherable damping factors, however, hindered the implementation of the SLIP model in practice. In this work, a control algorithm is proposed to realize the ideal springy motion of a robotic leg. A Kalman filter with the reference system by a damped SLIP model is utilized for estimating the longitudinal velocity of a robotic leg (i.e., the length change rate between the proximal joint and the tip toe). By cancelling the undesired damping factors through positive feedback based on the Kalman filter estimate, the robotic leg is controlled to follow an undamped SLIP model. For the verification of the proposed method, the simulation model of an actual robotic leg is utilized. The simulation results showed that the proposed control algorithm enabled the robotic leg to keep continuously hopping as a spring even in the presence of nonlinear frictions.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_11">16:05-17:20, Paper WeCI1.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1802.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1802'); return false" title="Click to show or hide the keywords and abstract">Early Results in Underwater Mobile Manipulation Optimization by Belief Space Planning of the Reaching Movement</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108955" title="Click to go to the Author Index">Zereik, Enrica</a></td><td class="r">CNR - National Res. Council</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114202" title="Click to go to the Author Index">Di Paola, Donato</a></td><td class="r">National Res. Council (CNR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141366" title="Click to go to the Author Index">Petitti, Antonio</a></td><td class="r">National Council of Res</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196569" title="Click to go to the Author Index">Colella, Roberto</a></td><td class="r">Cnr Issia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116930" title="Click to go to the Author Index">Bibuli, Marco</a></td><td class="r">CNR</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116938" title="Click to go to the Author Index">Bruzzone, Gabriele</a></td><td class="r">C.N.R</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106001" title="Click to go to the Author Index">Bonsignorio, Fabio Paolo</a></td><td class="r">Heron Robots Srl and the Biorobotics Insitute Scuola Superiore S</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1802" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> Underwater environment is a particularly critical scenario in which quickly changing conditions and noisy observations affect the state estimation of the manipulator and cause difficulties in finding and grasping objects.This paper is an early report on a broader research activity aiming to achieve significantly more dexterous robotic manipulation in underwater applications by means on a radically innovative stochastic approach to the problem exploting soft materials and system dynamics.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_12">16:05-17:20, Paper WeCI1.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1803.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1803'); return false" title="Click to show or hide the keywords and abstract">Designing Human-Robot Exercise Games for Baxter</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160571" title="Click to go to the Author Index">Fitter, Naomi T.</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202819" title="Click to go to the Author Index">Hawkes, Dylan T.</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102762" title="Click to go to the Author Index">Johnson, Michelle J.</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107509" title="Click to go to the Author Index">Kuchenbecker, Katherine J.</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1803" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Companions_and_Social_Human_Robot_Interaction" title="Click to go to the Keyword Index">Robot Companions and Social Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> As the population of older adults increases beyond the capacity of nursing home facilities, we are faced with a growing need to keep an aging population safe and healthy in their own homes. In response to this situation, some researchers have designed robots to promote activity for both physical rehabilitation and general physical exercise. Our work explores using the Rethink Robotics Baxter Research Robot to promote exercise via six different games involving physical human-robot interaction. An upcoming proof-of-concept user study will help us explore the viability of using these games to engage older adults and promote exercise.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_13">16:05-17:20, Paper WeCI1.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1804.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1804'); return false" title="Click to show or hide the keywords and abstract">Robotic Assembly of Solar Array Modules: Hardware Verification</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202696" title="Click to go to the Author Index">Adhikari, Shaurav</a></td><td class="r">Univ. of Michigan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202695" title="Click to go to the Author Index">Glassner, Samantha</a></td><td class="r">Northeastern Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202694" title="Click to go to the Author Index">Kishen, Ashwin</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142980" title="Click to go to the Author Index">Komendera, Erik</a></td><td class="r">NASA Langley Res. Center</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1804" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Construction" title="Click to go to the Keyword Index">Robotics in Construction</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a></span><br>
                           <strong>Abstract:</strong> In-space assembly (ISA) of spacecraft systems has been proposed and demonstrated several times as a way of improving aperture size, decreasing deployment risk, assembling systems too large to fit into a single launch vehicle, and enabling repair and upgrade. Intelligent Precision Jigging Robots (IPJRs) enable a paradigm for ISA that can drastically reduce mission risk and cost while increasing performance, using 1) gross positioning using long reach manipulation, and 2) localized, high precision positioning (``jigging'') to support joining. This effort is investigating whether IPJRs and manipulators can assemble, disassemble, and reassemble solar arrays to high precision. By reducing the required complexity of the structural elements, IPJRs are more versatile, enabling reuse and lowering costs over time. In this work, the IPJR is a 6-DOF Stewart platform that can grasp and position a solar array relative to a backbone truss, and hold the module in place while an external manipulator joins the components in this order: 1) the external manipulator positions the IPJR near a stored solar panel; 2) the IPJR grasps the panel; 3) the external manipulator positions the IPJR and panel near the truss; 4) the IPJR attaches to the truss and detaches from the external manipulator; 5) the IPJR holds the panel in the correct location; and 6) the external manipulator joins the panel to the truss. This process repeats until the array is complete. This sequence can be modified to enable repairs, disassembly, and reassembly. To simulate welding and extrusion, the external manipulator is equipped with a heat gun that melts glue attached to the solar panel legs, forming extrusions joining the panels to aluminum plates on the truss. An assembly sequence and motion planner controls the IPJR and external manipulator using a state estimate updated at 100 Hz. The progress of the hardware verification is presented in this report. A complete assembly trial is defined as the joining of four solar panels to a truss in which all actions are taken with no direct human intervention. Human teleoperations (i.e., supervised autonomy) are used for minor corrections as a substitution for autonomy, which will be implemented after the hardware is verified. Early trials suggest a translational error of under 1 mm and a rotational error of under 1 degree are possible. Following these trials, full autonomy will be implemented, removing teleoperation and replacing it with error correction methods. Disassembly, servicing, and reassembly will be explored through cutting the bonds and reusing the solar panel modules.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_14">16:05-17:20, Paper WeCI1.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1805.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1805'); return false" title="Click to show or hide the keywords and abstract">IMU-Mediated Real-Time Human-Baxter Hand-Clapping Interaction</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160571" title="Click to go to the Author Index">Fitter, Naomi T.</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202820" title="Click to go to the Author Index">Huang, Yi-Lin Eileen</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202821" title="Click to go to the Author Index">Mayer, Jamie P.</a></td><td class="r">Univ. of Sussex</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107509" title="Click to go to the Author Index">Kuchenbecker, Katherine J.</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1805" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Companions_and_Social_Human_Robot_Interaction" title="Click to go to the Keyword Index">Robot Companions and Social Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Entertainment_Robotics" title="Click to go to the Keyword Index">Entertainment Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a></span><br>
                           <strong>Abstract:</strong> Interactions involving physical human-robot contact hold unique potential to enhance connections between people and robots. Combining our previous work on automatic classification of human hand motions with our robotic hand-clapping behaviors yields a preliminary robotic system that can playfully respond to natural human movements in real time. The current data processing pipeline allows for a Rethink Robotics Baxter Research Robot to learn simple bimanual hand-clapping games by rapidly responding to input movements from one member of our research team; the movements are sensed via wrist-worn inertial measurement units (IMUs) and processed by a decision tree. Soon, we will generalize this robot learning ability to process input data from any human in preparation for a user study that will help us analyze the effects of real-time robot learning abilities during gameplay.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_15">16:05-17:20, Paper WeCI1.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1806.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1806'); return false" title="Click to show or hide the keywords and abstract">Compliance Control Based on Motor Current for Wafer Handling Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188989" title="Click to go to the Author Index">Song, Jilai</a></td><td class="r">Univ. of Chinese Acad. of Sciences,</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148328" title="Click to go to the Author Index">Xu, Fang</a></td><td class="r">SIASUN Robot & Automation Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147225" title="Click to go to the Author Index">Zou, Fengshan</a></td><td class="r">Siasun</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202725" title="Click to go to the Author Index">Chen, Shouliang</a></td><td class="r">SIASUN</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1806" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperative_Manipulators" title="Click to go to the Keyword Index">Cooperative Manipulators</a></span><br>
                           <strong>Abstract:</strong> Compliance control is a classical research topic which has recently found new interest after the progress in the mechanical design and improved control and sensing principals. In this paper a new method based on motor current is introduced for compliance control, and experiments of towed teaching and collision protection are validated on wafer handling robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_16">16:05-17:20, Paper WeCI1.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1809.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1809'); return false" title="Click to show or hide the keywords and abstract">Optimal Formation of Mobile Robots Transporting a 6-DOF Payload through Tight Spaces</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195717" title="Click to go to the Author Index">Tallamraju, Rahul</a></td><td class="r">International Inst. of Information Tech. Hyderabad</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202830" title="Click to go to the Author Index">Sripada, Venkatesh</a></td><td class="r">International Inst. of Informtion Tech. Hyderabad</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113621" title="Click to go to the Author Index">Shah, Suril Vijaykumar</a></td><td class="r">Indian Inst. of Tech. Jodhpur</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1809" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Mobile_Manipulation" title="Click to go to the Keyword Index">Mobile Manipulation</a></span><br>
                           <strong>Abstract:</strong> This paper addresses the problem of identifying feasible optimal formations for a group of non-holonomic mobile robots manipulating a payload with 6-Degree Of Freedom(DoF) movement through narrow spaces. We solve this problem in two stages. Initially we find a feasible obstacle-free trajectory for the system. Subsequently, we arrive at optimal formation that efficiently moves through narrow spaces by simultaneously minimizing a kinetic energy metric and a geometric stability criterion. The best robot motion plans are devised through multi-objective optimization. We demonstrate that stable and energy efficient formations are achievable, independent of system dynamics for a multi-robot, quasi-static, payload transport system moving through narrow spaces.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_17">16:05-17:20, Paper WeCI1.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1812.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1812'); return false" title="Click to show or hide the keywords and abstract">Mechanism Design and Impedance Control of Fully Series Elastic Actuator Driven Bi-Articular Robotic Arm</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192921" title="Click to go to the Author Index">Lee, Chan</a></td><td class="r">DGIST (Daegu Gyeongbuk Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129982" title="Click to go to the Author Index">Oh, Sehoon</a></td><td class="r">DGIST (Daegu Gyeongbuk Inst. of Science and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1812" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a></span><br>
                           <strong>Abstract:</strong> In this paper, a novel SEA driven bi-articular robot mechanism is developed using a novel compact planetary geared elastic actuator. The newly developed SEA, which is compact and has little backlash, can achieve high force control performance, and thus the developed robot mechanism can present programmable impedance feature. The configuration of the robot is designed based on the bi-articular muscle, which can simplify the kinematics of the robot. The SEA and bi-articular actuator configuration of the developed robot provides work-space programmable impedance, which can be utilized for various applications.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_18">16:05-17:20, Paper WeCI1.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1814.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1814'); return false" title="Click to show or hide the keywords and abstract">Influence of Passivity of Trunk Mechanism and Active Swinging Arms on Behavior of Bipedal Locomotion</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104570" title="Click to go to the Author Index">Takuma, Takashi</a></td><td class="r">Osaka Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1814" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a></span><br>
                           <strong>Abstract:</strong> Among a lot of researches on bipedal locomotion, a few researches have equipped with upper body on a lower leg. Human has a characteristic upper body including trunk, head and arms that occupy large amount of mass. The trunk is supported by a spine that contains stiff vertebrae and elastic intervertebral discs, and behavior such as a twisting of the trunk largely influences a performance of the bipedal locomotion. The arms attach on a place distant from median line of the body, and swinging arms promotes passive twisting and bending of the trunk. This paper aims to observe an influence of the swinging arms on behavior of the locomotion, and it is recorded by the simulation running on Open Dynamics Engine (ODE).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_19">16:05-17:20, Paper WeCI1.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1815.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1815'); return false" title="Click to show or hide the keywords and abstract">Design, Fabrication and Kinematics of a 3D-Motion Soft Robotic Arm</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189940" title="Click to go to the Author Index">Gong, Zheyuan</a></td><td class="r">Beihang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189947" title="Click to go to the Author Index">Xie, ZheXin</a></td><td class="r">Beijing Univ. of Aeronautics and Astronautics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192823" title="Click to go to the Author Index">Yang, Xingbang</a></td><td class="r">Beihang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114200" title="Click to go to the Author Index">Wang, Tianmiao</a></td><td class="r">Beihang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128250" title="Click to go to the Author Index">Li, Wen</a></td><td class="r">Beihang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1815" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a></span><br>
                           <strong>Abstract:</strong> In this study, we present the design, fabrication and the kinematics of an entire soft robotic actuator with three-dimensional (3D) locomotion. We describe the design and fabrication of the 3D motion soft arm with a compliant gripper which enables complex 3D manipulation. Then we demonstrate the kinematic model of the soft actuators as well as its inverse kinematics, and the ability of the modeling control to achieve the 3D movement in free space. The force and speed of the three-dimensional movement are also characterized via actual experiments. We further demonstrate that manipulation performance of the soft arm with the soft robotic end effector was able to pick and place different objects with multiple shapes and sizes. The ability of the soft robotic arm and gripper shows high compliance and potential applications on manipulating in the unstructured environments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_20">16:05-17:20, Paper WeCI1.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1819.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1819'); return false" title="Click to show or hide the keywords and abstract">Crazyswarm: A Large Nano-Quadcopter Swarm</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#199492" title="Click to go to the Author Index">Preiss, James</a></td><td class="r">USC</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183179" title="Click to go to the Author Index">Hoenig, Wolfgang</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101856" title="Click to go to the Author Index">Sukhatme, Gaurav</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113756" title="Click to go to the Author Index">Ayanian, Nora</a></td><td class="r">Univ. of Southern California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1819" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a></span><br>
                           <strong>Abstract:</strong> We outline a system architecture for a large swarm of miniature quadcopters. We discuss onboard planning, control, state estimation, communications, and a method for motion-capture localization using identical marker arrangements. We validate the system with a 49-vehicle formation flight.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_21">16:05-17:20, Paper WeCI1.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1820.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1820'); return false" title="Click to show or hide the keywords and abstract">Expanded Guide Circle Method through Ego-Kinematic Transformation of the Obstacle Avoidance for Non-Holonomic Mobile Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104634" title="Click to go to the Author Index">Kim, Gon-Woo</a></td><td class="r">Chungbuk National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187414" title="Click to go to the Author Index">Shim, Young Bo</a></td><td class="r">Chungbuk National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1820" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a></span><br>
                           <strong>Abstract:</strong> The Expanded Guide Circle (EGC) method was proposed as a guidance navigation method for improving the efficiency of the remote operation using the sensory information. The modified EGC method is proposed for non-holonomic mobile robots to avoid obstacles simply and efficiently through Ego-Kinematic Transformation (EKT).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_22">16:05-17:20, Paper WeCI1.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1826.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1826'); return false" title="Click to show or hide the keywords and abstract">Group Decision Making Problems in Robotics Design</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202470" title="Click to go to the Author Index">Grazioso, Stanislao</a></td><td class="r">Univ. of Naples Federico II</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202848" title="Click to go to the Author Index">Gospodarczyk, Mateusz</a></td><td class="r">Univ. of Rome Tor Vergata</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114623" title="Click to go to the Author Index">Di Gironimo, Giuseppe</a></td><td class="r">Univ. of Napoli Federico II</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1826" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Formal_Methods_in_Robotics_and_Automation" title="Click to go to the Keyword Index">Formal Methods in Robotics and Automation</a></span><br>
                           <strong>Abstract:</strong> This work presents the use of ELIGERE, a new open-source distributed software platform for group decision making problems, in robotics design applications. This software is based on fuzzy Analytical Hierarchy Process (fuzzy AHP), a Multiple Criteria Decision Making (MCDM) method useful in group selection processes wherein a discrete set of alternatives is ranked with respect to different evaluation criteria. The distributed architecture of ELIGERE provides several features of interest in group decision making problems: a web-based interface where experts express their opinion, a remote computational module for ranking the alternatives, a database for collecting both the answers of the experts and the results of the calculations from the computational module. A sample application, the selection of a frame of ultrasonic sensors for mobile robotics, aims to validate ELIGERE as a possible solution for group decision making problems in robotics design.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_23">16:05-17:20, Paper WeCI1.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1827.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1827'); return false" title="Click to show or hide the keywords and abstract">Versatile Encountered-Type Haptic Display for VR Environment Using a 7-DoF Manipulator</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202844" title="Click to go to the Author Index">Kim, Yaesol</a></td><td class="r">Ewha Womans Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104431" title="Click to go to the Author Index">Kim, Young J.</a></td><td class="r">Ewha Womans Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1827" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Virtual_Reality_and_Interfaces" title="Click to go to the Keyword Index">Virtual Reality and Interfaces</a></span><br>
                           <strong>Abstract:</strong> We show our on-going work and system to enable haptic feedback using a 7-DoF manipulator suitable for simulating indoor VR environments, which are characterized and confined by a set of vertical walls and doors. At runtime, our system tracks hand motion using an RGBD sensor and locates its configuration. Then, the robotic manipulator plans a trajectory for the end-effector, attached to a rectangular rigid board, to make a contact with the hand to deliver a sense of touch, as long as the perceived hand contact force is substantial. We implement our system using a KUKA IIWA R800 robot and the Kinect sensor, and successfully demonstrate to provide an illusion to the user in a virtual environment with touch sensation to the surrounding environment.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_24">16:05-17:20, Paper WeCI1.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1828.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1828'); return false" title="Click to show or hide the keywords and abstract">Evaluation of Gimbal-Type End-Effector of Rehabilitation Robot for Reaching Movement Training</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202836" title="Click to go to the Author Index">Kim, Jongbum</a></td><td class="r">DGIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180960" title="Click to go to the Author Index">Kim, Jonghyun</a></td><td class="r">DGIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1828" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Performance_Augmentation" title="Click to go to the Keyword Index">Human Performance Augmentation</a></span><br>
                           <strong>Abstract:</strong> This paper is to check the validity of gimbal-type end-effector for robot-aided reaching movement. To achieve the goal, we designed the handle and reaching movement scenario. Six healthy subjects participated in this study and used both devices. We used two kinematic measurements to compare the both devices: number of peak of velocity profile, path error. Participants conducted reaching movements 96 trials on each device. There is no significant difference between handle and gimbal as well as among directions in path error, however number of peak of velocity profile showed significant difference between handle and gimbal. Gimbal showed more significant difference among directions than handle in number of peak of velocity.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_25">16:05-17:20, Paper WeCI1.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1829.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1829'); return false" title="Click to show or hide the keywords and abstract">Motion Planing and Control of Maneuverable Human-Powered Exoskeleton Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192133" title="Click to go to the Author Index">I. A. Ahmed, Abusabah</a></td><td class="r">UESTC</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159479" title="Click to go to the Author Index">Cheng, Hong</a></td><td class="r">Univ. of Electronic Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#120883" title="Click to go to the Author Index">Lin, Xichuan</a></td><td class="r">Univ. of Electronic Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183121" title="Click to go to the Author Index">Huang, Rui</a></td><td class="r">Univ. of Electronic Science and Tech. of China</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1829" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Animation_and_Simulation" title="Click to go to the Keyword Index">Animation and Simulation</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Performance_Augmentation" title="Click to go to the Keyword Index">Human Performance Augmentation</a></span><br>
                           <strong>Abstract:</strong> The Human brain is a complex information processing device made by the greatest God. The nervous system is responsible for transmitting impulses throughout the body.The function of our bodies throughout our lives are primarily supported by the nervous system. Online gait control in maneuverable human-powered exoskeleton systems is still rich research field and represents a step towards fully autonomous, safe and intelligent navigation. Variable Admittance Controller (VAC), Adaptive Central Patterns Generators and intelligent sensing technique are used for smooth navigation. We describe the finite states of the exoskeleton system using Markov Chain (MC). The proposed control method mixes the Human-Inspired Control (HIC) approach and Human Intention Estimator (HIE)to generate appropriate walking patterns according to the pilot intentions. MATLAB/Simulink is used to calculate the theory of human intention and the robot motion simulation. Based on adaptive Central Pattern Generators CPGs and high sensitive force sensors we develop a new control strategy for switches between different gates (flat terrain walking, stair ascent, stairs descent , speed up and slow down).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_26">16:05-17:20, Paper WeCI1.26</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1831.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1831'); return false" title="Click to show or hide the keywords and abstract">Collision-Free T-S Fuzzy Formation Tracking Control for Multi-Robot Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196689" title="Click to go to the Author Index">Chang, Yeong-Hwa</a></td><td class="r">Chang Gung Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196691" title="Click to go to the Author Index">Wu, Chun-I</a></td><td class="r">Chang Gung Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196694" title="Click to go to the Author Index">Lin, Hung-Wei</a></td><td class="r">Lee-Ming Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1831" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Neural_and_Fuzzy_Control" title="Click to go to the Keyword Index">Neural and Fuzzy Control</a></span><br>
                           <strong>Abstract:</strong> This study addresses the formation tracking and collision avoidance problems of the multi-robot systems. The T-S fuzzy model technique is adopted to describe the nonholonomic mobile robot. Furthermore, a strategy of collision avoidance is designed to avoid colliding with other robots and obstacles. Due to the formation controller is independent on the strategy of collision avoidance, the system states could be over the range of T-S parameters to make the T-S setting become infeasible. In this study, a limit mechanism is proposed to deal with this problem. Moreover, a danger factor is designed by fuzzy rule according to the distance and rate of distance to adjust the weighting between the formation control and collision-free control actions. In addition, the system stability can be guaranteed by using the Lyapunov theory with the graph theory and consensus algorithm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_27">16:05-17:20, Paper WeCI1.27</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1832.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1832'); return false" title="Click to show or hide the keywords and abstract">Light-Weight Exoskeleton for Haptic Feedback</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202869" title="Click to go to the Author Index">Kim, Hubert</a></td><td class="r">Virginia Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123799" title="Click to go to the Author Index">Asbeck, Alan</a></td><td class="r">Virginia Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1832" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Performance_Augmentation" title="Click to go to the Keyword Index">Human Performance Augmentation</a></span><br>
                           <strong>Abstract:</strong> We propose a new concept in haptic feedback where small torques are provided directly to a user's joints with a light-weight, portable system. This could be used for motion training in real-world environments or for rehabilitation. In this poster, we demonstrate a one degree of freedom system providing torques to the elbow joint of up to 2 Nm. The device uses a closed-loop Bowden cable transmission to connect an actuator unit worn on the back to a force transmission unit worn on the arm. The arm portion includes a rigid frame coupled to the wearer through a soft sleeve.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_28">16:05-17:20, Paper WeCI1.28</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1833.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1833'); return false" title="Click to show or hide the keywords and abstract">Design and Concept of the Sediment Sampling Robot and Dynamic Buoy</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#198739" title="Click to go to the Author Index">Bae, Jun Han</a></td><td class="r">Purdue Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202874" title="Click to go to the Author Index">Lee, Dong Hun</a></td><td class="r">Purdue Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164680" title="Click to go to the Author Index">Min, Byung-Cheol</a></td><td class="r">Purdue Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1833" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a>, <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Hazardous_Fields" title="Click to go to the Keyword Index">Robotics in Hazardous Fields</a></span><br>
                           <strong>Abstract:</strong> In this paper, we present a new design and concept of the sediment sampling robot capable of collecting samples for water quality monitoring. In addition, we describe a dynamic buoy designed to transport the sediment sampler to desired sampling point. With this improved concept and approach, we will be able to realize a fully autonomous water monitoring system that can be used in various environments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_29">16:05-17:20, Paper WeCI1.29</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1837.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1837'); return false" title="Click to show or hide the keywords and abstract">Inverse Kinematics Refinement for a Wire-Driven Serpentine Surgical Manipulator Based on Policy Gradient Methods</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187937" title="Click to go to the Author Index">Chen, Jie</a></td><td class="r">The Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134440" title="Click to go to the Author Index">Lau, Henry Y.K.</a></td><td class="r">Univ. of Hong Kong</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1837" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tendon_Wire_Mechanisms" title="Click to go to the Keyword Index">Tendon/Wire Mechanisms</a>, <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a></span><br>
                           <strong>Abstract:</strong> With the rapid development of robotic technologies, robot-assisted clinical interventions have emerged over last decades, and among which minimally invasive surgery (MIS) may be the most promising and exciting application [1]. MIS is a form of surgery designed to offer great benefits to patients over conventional open surgery by minimizing unnecessary trauma caused in the process of performing a surgery. MIS leads to less pain, blood loss and better cosmesis, and reduces the recovery time for patients. However, due to the highly limited workspace, indirect visual and tactile information feedback, and specialized tools, MIS is very difficult for surgeons to perform, which highlights the importance of robot-assisted MIS [2].<p>This paper presents a wire-driven two-section serpentine surgical manipulator intended to facilitate autonomous MIS. The superiorities of this system mainly lie on three folds: Firstly, compared with single-section manipulators, the flexibility and manipulability of the proposed system have improved a lot. Secondly, the modeling and control procedures have been simplified comparing to manipulators composing of three or more sections. And finally, with the wire-driven mechanism, the actuators can be located remotely, which not only reduces weight of the manipulator but enables performing MIS inside human cavity.<p>To effectively control the motion of such system, an accurate inverse kinematics model is required. Conventional analytical methods established mappings between three spaces, e.g., actuation space, configuration space, and task space, based on piecewise constant curvature assumption (PCC) [3]. In our previous work, three nonlinear regression approaches were used to directly learn a mapping from the actuation space to the task space by random exploration of the manipulator’s workspace [4]. However, due to the nonlinearities of wire-driven systems, such as viscoelasticity, friction loss, backlash, hysteresis and nonstationary behaviors, both methods failed to guarantee stable performance over long-term operation, especially when the wires became loose or the manipulator was loaded.<p>In this work, a modified DH method for continuum manipulator is implemented to derive the inverse kinematics of the proposed wire-driven two-section serpentine surgical manipulator [4][5]. Then in order to update the model online to cope with system nonlinearities or external perturbations, a state-of-the-art EM-based policy gradient method called PoWER is used [6]. Similar to policy gradient reinforcement learning algorithms, PoWER uses a parameterized policy and tries to search for values for the parameters which maximize the expected return of episodes under the corresponding policy. Two experiments have been carried out, e.g., trajectory tracking with loose wires and under external perturbations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_30">16:05-17:20, Paper WeCI1.30</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1838.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1838'); return false" title="Click to show or hide the keywords and abstract">Fabrication of Two Stage Pressure Switch for Robot Using Pressure Sensitive Rubber</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202860" title="Click to go to the Author Index">Woo, Sam-Yong</a></td><td class="r">Korea Res. Inst. of Standards and Science</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106014" title="Click to go to the Author Index">Yang, Tae-Heon</a></td><td class="r">KRISS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202868" title="Click to go to the Author Index">Song, Han Wook</a></td><td class="r">KRISS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202861" title="Click to go to the Author Index">Han, Moo-Pil</a></td><td class="r">PDK</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1838" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a></span><br>
                           <strong>Abstract:</strong> This paper presents the development and characterization of two stage pressure sensitive switch made of two different piezo-resistive rubbers. The piezo-resistive rubber is fabricated by mixing with several kinds of metal powders and polydimethylsiloxane. After that, it is attached to an interdigitated electrode which is patterned on flexible printed circuit board (FPCB). In order to fabricate a pressure sensitive rubber (PSR), we used common PDMS elastomers, Sylgard 184 from Dow Corning as the base material. In order to make the insulation matrix conductive, we interfused conductive fillers such as carbon particles and several sorts of metal powders into PDMS. The volume fraction of the conductive fillers must be adequate for proper electrical resistance change. Interdigitated copper electrodes were patterned on the flexible polyimide substrate for measuring the resistivity change of the composites subjected to pressure variations. PSR varies the resistance between their two electrodes according to the applied pressure changes. The resistance goes down as the applied pressure or force increases. For application to two stage pressure switch, we made two kinds of PSR which have different pressure sensitivities, respectively. One has low sensitivity to pressure and the other has high sensitivity. The two stage pressure switch can be used effectively as a sensation and actuation button for robots. This device has less number of parts and thinner construction than commercial mechanical one.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_31">16:05-17:20, Paper WeCI1.31</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1842.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1842'); return false" title="Click to show or hide the keywords and abstract">Collaborative UAV Type Robotic System for Mosquito Habitat Puddle Searching and Larvicide Spray</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195927" title="Click to go to the Author Index">Kim, Kyukwang</a></td><td class="r">KAIST (Korea Adv. Inst. Sci. & Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195939" title="Click to go to the Author Index">Lim, Hwijoon</a></td><td class="r">KAIST (Korea Adv. Inst. Sci. & Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195946" title="Click to go to the Author Index">Kim, Whimin</a></td><td class="r">Korea Adv. Inst. Sci. & Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195944" title="Click to go to the Author Index">Choi, Duckyu</a></td><td class="r">KAIST (Korea Adv. Inst. Sci. & Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189650" title="Click to go to the Author Index">Jung, Sungwook</a></td><td class="r">KAIST(Korea Advanced Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104490" title="Click to go to the Author Index">Myung, Hyun</a></td><td class="r">KAIST (Korea Adv. Inst. Sci. & Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1842" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> Mosquitoes are one of the most notorious pests, carrying many deadly diseases. This insect spends its larval stage in stagnated water such as puddles or septic tanks. This research presents preliminary results of using collaborating UAV type robots to find puddles with machine learning-combined image processing and delivering bacteria derived eco-friendly larvicide to the puddles for easier pest control.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_32">16:05-17:20, Paper WeCI1.32</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1843.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1843'); return false" title="Click to show or hide the keywords and abstract">Wire-Tension Control Using Compact Planetary Geared Elastic Actuator</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202951" title="Click to go to the Author Index">Kwak, Jihoo</a></td><td class="r">DGIST (Daegu Gyeongbuk Inst. of Science of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192921" title="Click to go to the Author Index">Lee, Chan</a></td><td class="r">DGIST (Daegu Gyeongbuk Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129982" title="Click to go to the Author Index">Oh, Sehoon</a></td><td class="r">DGIST (Daegu Gyeongbuk Inst. of Science and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1843" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> The tension control of wires can benefit from Series Elastic Actuator (SEA), which is a potential emerging actuator system. In this paper, it is verified that the tension of wires can be successfully controlled by a novel SEA, called Compact Planetary-geared Elastic Actuator (cPEA). The design of tension control by cPEA is introduced, and the experiments to show the effectiveness of the proposed control are provided.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_33">16:05-17:20, Paper WeCI1.33</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1846.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1846'); return false" title="Click to show or hide the keywords and abstract">On the Modelling of Flexible Manipulators with Finite Elements</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202470" title="Click to go to the Author Index">Grazioso, Stanislao</a></td><td class="r">Univ. of Naples Federico II</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190987" title="Click to go to the Author Index">Sonneville, Valentin</a></td><td class="r">Univ. De Liège, Department of Aerospace and Mechanical Engi</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1846" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a>, <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Hazardous_Fields" title="Click to go to the Keyword Index">Robotics in Hazardous Fields</a></span><br>
                           <strong>Abstract:</strong> This work deals with a new finite element based formulation for simulating the dynamics of flexible manipulators. The motivation behind it is the development of new control schemes which can take into account the arm flexibility with a more pregnant physical meaning. In the past years a lot of work has been done within the context of flexible manipulators. The most diffuse approach to model a flexible arm is to use the classical Euler-Bernoulli beam model and to discretize the resulting partial differential equations (PDE) with the assume mode method (AMM). This approach suits well for flexible arms rotating at modest angular rate (so that centrifugal stiffening can be ignored) and connected only with revolute joints, with the assumption of linear elasticity and light damping. This methodology is the natural extension of the rigid dynamics to the context of flexible multibody systems: small elastic deformations are superimposed on the classical overall rigid body motion of a floating frame attached to each flexible body. However, considering the motion of a component as a whole, the formulations based on the geometrically exact nonlinear beam theory are the most general and accurate to account for flexibility. Since these can take into account the geometric nonlinear effects, nonlinear finite elements are used for discretizing the Equations of Motion (EoM). Finite element procedures provide a general approach for modelling multibody systems: a manipulator can be designed with both rigid and flexible elements, there are no differences in modelling serial or parallel mechanism, all kind of low pair and high pair joints may be modelled for connecting bodies. Moreover, lighter (with nonlinear materials, also with variable cross-sections) and faster (since centrifugal stiffening is simply taken into account in the model) manipulators can be designed with model-based controllers. The last are great advantages for designing large robots working in challenging environments, such as in space or inside radioactive vessels, wherein reducing the time of working operations may save a lot of money. A drawback of the finite element approach is its major complexity, thus its higher computational cost in solving the EoM which may limit the possibility to implement this procedure in real-time applications. The idea behind the current work is to develop a formulation for flexible manipulators which may have the advantages of finite element methods providing at the same time a cost effective computation of the EoM, at least comparable with the floating frame approaches. Moreover, this formulation has led to the development of a very simple and modular simulator for the dynamics of both rigid and flexible multibody systems. In the future, it will be extended with motion planning and control capabilities.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_34">16:05-17:20, Paper WeCI1.34</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1850.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1850'); return false" title="Click to show or hide the keywords and abstract">Reactions and Continuous Adaptation in Collaborative Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115278" title="Click to go to the Author Index">Ratliff, Nathan</a></td><td class="r">Lula Robotics Inc</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137014" title="Click to go to the Author Index">Kappler, Daniel</a></td><td class="r">Max-Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147628" title="Click to go to the Author Index">Meier, Franziska</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132278" title="Click to go to the Author Index">Issac, Jan</a></td><td class="r">Max Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137310" title="Click to go to the Author Index">Mainprice, Jim</a></td><td class="r">Max Planck Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151290" title="Click to go to the Author Index">Wüthrich, Manuel</a></td><td class="r">Max-Planck-Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180866" title="Click to go to the Author Index">Garcia Cifuentes, Cristina</a></td><td class="r">Max Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158351" title="Click to go to the Author Index">Berenz, Vincent</a></td><td class="r">Max Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104592" title="Click to go to the Author Index">Fox, Dieter</a></td><td class="r">Univ. of Washington</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116883" title="Click to go to the Author Index">Bohg, Jeannette</a></td><td class="r">Max-Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102004" title="Click to go to the Author Index">Schaal, Stefan</a></td><td class="r">MPI Intelligent Systems & Univ. of Southern California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1850" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a></span><br>
                           <strong>Abstract:</strong> Collaborative robotics aims to bring humans and robots together to work as teams whose combined contributions and skills--superior perception and generalized dexterity in humans, and superior repeatability and precision in robots--surpass either party alone. But so far, collaborative robots in production environments have been largely agnostic of their surroundings, running through meticulously pre-programmed motions blindly, forcing their human collaborators to adapt and preventing the type of close proximity work required to fully leverage the benefits of human-robot teamwork. Perceptual systems improve at an aggressive pace, fueled by multidisciplinary incentives across both industry and academia. We need to develop new motion behavior and control technology to keep pace and leverage those perceptual systems in robotic systems. A tight perception integration allows for close quarter collaboration in unstructured and uncertain environments while maintaining the precision and repeatability advantages of robotic systems. <p>We have developed a system for behavior generation from visual stimuli for this purpose, leveraging a multi-time-scale architecture combining continuous motion optimization with reactive local controllers. Our system stacks the typical sense-plan-act loop into parallel continuously running and continuously communicating processes. Motion optimization updates are communicated as reactive kinematic LQR policies, treating them as infinite collections of motion trajectories (their integral curves) rather than just a single trajectory. At the lowest level it combines these motion policies with other acceleration policies using quadratic programming, obviating the need to bend or otherwise adapt a reference trajectory to perturbations or environmental changes between re-optimizations. <p>We will be demonstrating the current state of our system live (in simulation) and use that to motivate discussions around further research, especially into issues around the practical application of perceptual tools to physical real-time systems.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_35">16:05-17:20, Paper WeCI1.35</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1853.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1853'); return false" title="Click to show or hide the keywords and abstract">Kinematic Design Optimization of Anthropomorphic Robot Hand Using a Novel Performance Index</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133602" title="Click to go to the Author Index">You, Won Suk</a></td><td class="r">Sungkyunkwan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179698" title="Click to go to the Author Index">Lee, Young Hun</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179697" title="Click to go to the Author Index">Kang, Gitae</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196073" title="Click to go to the Author Index">Oh, Hyun Seok</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102438" title="Click to go to the Author Index">Choi, Hyouk Ryeol</a></td><td class="r">Sungkyunkwan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1853" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Gripper_and_Hand_Design" title="Click to go to the Keyword Index">Gripper and Hand Design</a>, <a href="IROS16_KeywordIndexMedia.html#Multifingered_Hands" title="Click to go to the Keyword Index">Multifingered Hands</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> This paper presents a new performance index, called “Interactivity of Fingers (IF)”, for anthropomorphic robot hand and kinematic design optimization process using this performance index and genetic algorithm. This performance index can quantify robot hands’ kinematic structures and used for optimizing the kinematic model of an anthropomorphic robot hand collaborating with Genetic algorithm. With this procedure position and orientation of the thumb’s saddle joint are systematically determined. For the verification of proposed performance index’s usefulness, optimized hand model’s and existing hands’ IFs are calculated, compared and discussed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_36">16:05-17:20, Paper WeCI1.36</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1856.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1856'); return false" title="Click to show or hide the keywords and abstract">Quick Target Position Command for Quadrotor in 3D Indoor Map of Disaster Accident Management Using Robot System</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154198" title="Click to go to the Author Index">Kim, Dong Yeop</a></td><td class="r">KETI (Korea Electronics Tech. Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203078" title="Click to go to the Author Index">Lee, Jae Min</a></td><td class="r">KETI (Korea Electronics Tech. Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203067" title="Click to go to the Author Index">Shin, Dong-In</a></td><td class="r">KETI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203071" title="Click to go to the Author Index">Shin, Seol</a></td><td class="r">KETI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115550" title="Click to go to the Author Index">Hwang, Jung-Hoon</a></td><td class="r">Korea Eletronics Tech. Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185955" title="Click to go to the Author Index">Kim, YoungOuk</a></td><td class="r">Korea Electronics Tech. Inst</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1856" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Nature and human-made disasters have extremely increased and caused damage has also been severer. We have researched robot systems for disaster accident management. In this paper, we proposed a method that generates target position command for quadrotor drones in 3D map. Because the method is used in the disaster site, it should be intuitive and quick to use. We divided 3D coordinate to 1D for height and 2D for plane and applied input devices for 1D and 2D, respectively.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_37">16:05-17:20, Paper WeCI1.37</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1858.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1858'); return false" title="Click to show or hide the keywords and abstract">Body-Powered Prosthetic Index Finger for Self-Adaptive Grasping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189654" title="Click to go to the Author Index">Yoon, Dukchan</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132978" title="Click to go to the Author Index">Lee, Geon</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106608" title="Click to go to the Author Index">Choi, Youngjin</a></td><td class="r">Hanyang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1858" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Gripper_and_Hand_Design" title="Click to go to the Keyword Index">Gripper and Hand Design</a>, <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a></span><br>
                           <strong>Abstract:</strong> An underactuated prosthetic index finger is presented for implementing both self-adaptive grasping and natural motion. It has three degrees-of-freedom mechanism composed of one active joint maneuvered by remaining finger of amputee and a couple of passive joints having torsional springs and mechanical stoppers. In addition, the proposed prosthetic finger consists of two five-bar and one four-bar linkages in mechanical viewpoint. Each five-bar linkage contains passive components only affected by external forces, and it allows the prosthetic finger to conduct adaptive grasping as well as natural motion. The experiment results for both motions are suggested to show the feasibility of the proposed prosthetic finger.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_38">16:05-17:20, Paper WeCI1.38</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1859.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1859'); return false" title="Click to show or hide the keywords and abstract">Robotic Transfemoral Prosthesis Capable of Walking Pattern Recognition and Posture Stabilization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203073" title="Click to go to the Author Index">Lee, Seok-Hoon</a></td><td class="r">SEOUL NATIONAL Univ. OF SCIENCE AND Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102937" title="Click to go to the Author Index">Kim, Jung-Yup</a></td><td class="r">Seoul National Univ. of Science & Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1859" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a></span><br>
                           <strong>Abstract:</strong> This article describes a walking pattern generation algorithm for a robotic transfemoral prosthesis that is synchronized with the walking motion of a transfemoral amputee, and a posture stabilization for ground adaptation and maintaining balance on inclined grounds. It has a knee joint for climbing or descending stairs, and roll and pitch joints at the ankle for walking on complex slopes. In particular, the walking motion data obtained from the motion capture system is used as the standard walking pattern data to accurately imitate the inherent gait of the wearer. Walking intention, percent of gait cycle (PGC), and walking stride are predicted through two inertial sensors attached at both thighs, and the joint angles of the robotic transfemoral prosthesis are then generated in real-time from the PGC and the standard walking pattern data. In addition, variable impedance control and zero moment point (ZMP) control are carried out with a force/torque sensor for posture stabilization against variable ground slopes, and ground slope compensation and disturbance rejection are also done with the use of inertial sensors at the foot and shank. Consequently, the performance of the walking pattern generation algorithm and posture stabilization control was verified through walking experiments on normal street roads.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_39">16:05-17:20, Paper WeCI1.39</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1861.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1861'); return false" title="Click to show or hide the keywords and abstract">Design of a Robot Arm Based on Joint Modules with Torque Sensors</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#173205" title="Click to go to the Author Index">Min, Jae-Kyung</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203080" title="Click to go to the Author Index">Zietz, Maximilian</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195903" title="Click to go to the Author Index">Lee, Won-Bum</a></td><td class="r">Korea Univ. Intelligence Robotics Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104776" title="Click to go to the Author Index">Song, Jae-Bok</a></td><td class="r">Korea Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1861" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Cooperative_Manipulators" title="Click to go to the Keyword Index">Cooperative Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Joint_Mechanism_Design" title="Click to go to the Keyword Index">Joint/Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> As safe cooperation between humans and robots has become increasingly important, much research has been conducted including collision detection and force control based on the force measured at the end-effector of a robot arm. However, this method requires an expensive force/torque sensor and cannot detect collisions that occur at the robot body except the end-effector. Therefore, in this research, we developed a robot joint module that includes a joint torque sensor. This robot joint module was designed to support the moment loads which can affect the torque sensing depending on the robot posture and to measure the torque in the rotating direction. Furthermore, we designed a multi-DOF robot arm equipped with the proposed joint modules that can carry out collision detection and force control based on joint torques.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci1_40">16:05-17:20, Paper WeCI1.40</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1862.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1862'); return false" title="Click to show or hide the keywords and abstract">Onboard Real-Time Object Recognition Based High-Level Landmark Extraction for RGB-D SLAM in Indoor Navigation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177166" title="Click to go to the Author Index">Chae, Hee-Won</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192018" title="Click to go to the Author Index">Yu, Hyejun</a></td><td class="r">Korea Univ. Intelligent Robotics Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203079" title="Click to go to the Author Index">Kim, Jihwan</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104776" title="Click to go to the Author Index">Song, Jae-Bok</a></td><td class="r">Korea Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1862" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a></span><br>
                           <strong>Abstract:</strong> Various approaches for robot perception and simultaneous localization and mapping (SLAM) using a vision sensor has been widely investigated in recent years. Especially, SLAM using a RGB-depth sensor (RGB-D SLAM) shows promising results while the sensor cost is becoming low. However, since RGB-D SLAM performance highly relies on the feature correspondence, it is essential to extract robust and highly distinctive features. To this end, unlike the conventional RGB-D SLAM which adopts low-level feature-based approaches such as SIFT, FAST, and ORB, we adopt a novel object recognition algorithm to enhance SLAM performance by using high-level features. In addition, high-level features allows a robot to understand the environment structure in the object level.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weci2"><b>WeCI2</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weci2" title="Click to go to the Program at a Glance"><b>Poster Session 2</b></a></td>
               <td class="r">Poster session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#115971" title="Click to go to the Author Index">Kwak, Sonya Sona</a></td><td class="r">Ewha Womans Univ</td></tr>

<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_01">16:05-17:20, Paper WeCI2.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1780.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1780'); return false" title="Click to show or hide the keywords and abstract">A Telepresence Robot System for Triggering Informal Communication</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201127" title="Click to go to the Author Index">Xu, Jianfeng</a></td><td class="r">KDDI R&D Lab. Inc</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201129" title="Click to go to the Author Index">Sakazawa, Shigeyuki</a></td><td class="r">KDDI R&D Lab. Inc</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201130" title="Click to go to the Author Index">Ariyoshi, Ryohei</a></td><td class="r">Tsukuba Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129971" title="Click to go to the Author Index">Kuzuoka, Hideaki</a></td><td class="r">Univ. of Tsukuba</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182049" title="Click to go to the Author Index">Harada, Etsuko,T.</a></td><td class="r">Univ. of Tsukuba</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1780" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Companions_and_Social_Human_Robot_Interaction" title="Click to go to the Keyword Index">Robot Companions and Social Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a></span><br>
                           <strong>Abstract:</strong> In spite of the growing need for telecommuting, one of its problems is the loneliness that a telecommuter feels mainly due to the lack of informal communication. Meanwhile, a telepresence robot is a powerful and promising tool used in the office as a proxy for telecommuters. For example, an employee can work at home and talk with colleagues in the office via a robot with a video conference feature. Based on our experiences with the proxy robot for telecommuting, however, simply placing a proxy robot like Kubi is not effective in promoting informal communication. To solve this problem, our robot system simulates the social behavior that is effective in naturally triggering informal communication.<p>It is well-known that a human understands and naturally uses non-verbal social behaviors before starting informal communication. In this study, we focus on two-salutation behavior, which was reported by Kendon as a typical process for social greetings. For instance, people salute to each other twice, first in a far distance and next in a close distance. The first salutation motivates people to move closer and the second one shows a clearer cue to greet each other which often leads to conversation. The salutation behavior may be verbal or non-verbal like eye contact, nodding, or smiling.<p>Inspired by Kendon's findings, we are developing a novel robot system that automatically tracks a passerby in a far distance and, after he/she approaches and observes the robot, it displays nodding motion to him/her at a close distance. We expect that the person in the office would notice the robot/telecommuter when it tracks him/her in a far distance, and perceive the motion as the first salutation. We also expect that the robot's nodding motion at a close distance may be perceived as the second salutation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_02">16:05-17:20, Paper WeCI2.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1782.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1782'); return false" title="Click to show or hide the keywords and abstract">Autonomous Robotic Manipulation Tasks with Programming by Demonstrations and Robot-Assisted Large-Scale Direct SLAM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187937" title="Click to go to the Author Index">Chen, Jie</a></td><td class="r">The Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#200745" title="Click to go to the Author Index">Sun, Peng</a></td><td class="r">Hong Kong Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134440" title="Click to go to the Author Index">Lau, Henry Y.K.</a></td><td class="r">Univ. of Hong Kong</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1782" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a></span><br>
                           <strong>Abstract:</strong> With the rapid development of robotic technologies, autonomous dexterous manipulation has been raised as a significant research issue in the last decade. Conventional industrial manipulator follows predefined trajectories to accomplish simple and limited tasks without perception of and interaction with the environment. However, due to the requirement of applying robots to domestic and nursing areas, adaptation to unknown and cluttered environment becomes necessary. Central motion generator and sensing system are two main pillars for autonomous robotic manipulation<p>In this paper, we suggest to use a novel motion planning paradigm, Programming by Demonstrations (PbD), to transfer a benchmark manipulation skill, e.g., autonomous pick and place, for a six degrees-of-freedom UR5 robot. However, to fully automate the whole task, the robot should be equipped with an efficient visual feedback system. This work presents a novel framework for visual perception procedure which consists of workspace reconstruction, object detection and target localization. <p>Firstly, a Large-Scale Direct Monocular SLAM method (LSD-SLAM), which uses only one camera attached to the gripper of the robot, is implemented to reconstruct a point-cloud model of the robot workspace. LSD-SLAM generates a consistent global map of the environment using direct image alignment and probabilistic, semi-dense depth maps instead of keypoints. Then the point-cloud model is clustered into several sub-clusters, each of which represents an independent object. A global descriptor similar to is used to represent the model of the objects. The human operator then manually implements the reconstruction and clustering task several times. The sub-clusters which represents a same object are recorded. These sub-clusters, which are incomplete due to the occlusion and noise, are then merged into a complete standard model of the object. The standard model is applied in the autonomous picking task. We use method to compare every object in the workspace with the standard library to match and localize the target object, thus the position and orientation of the object are estimated. The quality of LSD-SLAM is calculated, and a policy gradient approach will be implemented to iteratively adapt the trajectory of the robot end-effector to improve the performance of LSD-SLAM.<p>The proposed methods mainly have four advantages: Firstly, LSD-SLAM requires only one camera which avoids the inconvenience of setting an observing system in advance. Secondly, with the policy gradient approach, the robot will automatically update its trajectory to improve the quality of LSD-SLAM. Thirdly, a global descriptor is developed to compare clustered point-cloud model with that in an automatically generated standard object library to identify its characteristic. And finally, imitation learning is investigated to model human demonstrations and generalize trajectories for the robot to accomplish the pick and place task autonomously.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_03">16:05-17:20, Paper WeCI2.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1783.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1783'); return false" title="Click to show or hide the keywords and abstract">Automatic Fall Detection Monitoring System Using Thermal Camera</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194771" title="Click to go to the Author Index">Kim, Dae-Eon</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182254" title="Click to go to the Author Index">Nho, Young-Hoon</a></td><td class="r">KAIST, HRI Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100050" title="Click to go to the Author Index">Kwon, Dong-Soo</a></td><td class="r">KAIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1783" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surveillance_Systems" title="Click to go to the Keyword Index">Surveillance Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a></span><br>
                           <strong>Abstract:</strong> Fall detection has received a great deal of interest for its applications such as automatic surveillance, home care service, activity recognition and situation awareness fields. Fall accidents are a major challenge in the public health care industry. This paper presents a vision-based fall detection system to automatically monitor and detect people's fall accidents, particularly those of elderly people or patients. The system is able to detect two different types of fall, falls from walking or standing and falls from bed, using a thermal imaging camera. With a thermal camera, we propose a solution to several issues regarding usability, day and night surveillance and privacy concerns. Our approach is based on a combination of multiple features for learning a human's fall patterns. The system can understand various fall events using a support vector machine (SVM) as a binary classifier. We design a pan-tilt camera to extend the range of view. Performance is evaluated on our TCL Fall Detection dataset compared with a simple threshold-based method. The proposed system outperforms the previous system on all measures.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_04">16:05-17:20, Paper WeCI2.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1788.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1788'); return false" title="Click to show or hide the keywords and abstract">A Teaching Method for a Life-Support Robot by Real-World Click - Proposal of Real Object Position Management Database</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201907" title="Click to go to the Author Index">Sato, Kenjiro</a></td><td class="r">Hiroshima City Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202592" title="Click to go to the Author Index">Hidaka, Yuta</a></td><td class="r">Hiroshima City Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104830" title="Click to go to the Author Index">Iwaki, Satoshi</a></td><td class="r">Hiroshima City Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101594" title="Click to go to the Author Index">Ikeda, Tetsushi</a></td><td class="r">Hiroshima City Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1788" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Virtual_Reality_and_Interfaces" title="Click to go to the Keyword Index">Virtual Reality and Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Domestic_Robots_and_Home_Automation" title="Click to go to the Keyword Index">Domestic Robots and Home Automation</a></span><br>
                           <strong>Abstract:</strong> We have been studying a novel interface that enables us to &quot;click&quot; a real object just like a familiar GUI manner in a PC. In this paper, exploiting the interface, we propose how easily to resister some real objects into our developed real object position management database. We also show some merits of the database to easily and efficiently access real objects. Finally we confirm the validity of the proposed idea using a life-support mobile robot with an arm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_05">16:05-17:20, Paper WeCI2.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1789.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1789'); return false" title="Click to show or hide the keywords and abstract">Safety Evaluation for Object Motion Detection Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106752" title="Click to go to the Author Index">Kim, Bong Keun</a></td><td class="r">National Inst. of Advanced Industrial Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117991" title="Click to go to the Author Index">Sumi, Yasushi</a></td><td class="r">National Inst. of Advanced Industrial ScienceandTechnology(A</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110630" title="Click to go to the Author Index">Yamada, Yoji</a></td><td class="r">Nagoya Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1789" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a></span><br>
                           <strong>Abstract:</strong> Object motion detection technology is a key technology for autonomous mobile robot system and the development of high reliable and safe technology aiming at preventing collisions with approaching object under various environments poses new challenges. To this end, an evaluation method for safety integrity of an object motion detection system is proposed in this paper. First, safety integrity levels for continuous operation and low demand operation are introduced. Next, the undetected dangerous failure rate in the critical zones of the object motion detection system is explained. Finally, the confusion matrix for failure rate calculation of the object motion detection system is proposed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_06">16:05-17:20, Paper WeCI2.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1792.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1792'); return false" title="Click to show or hide the keywords and abstract">Control of a Two-Wheel Mobile Robot by Hand Gestures Learned from Images of a Kinect Sensor</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#200250" title="Click to go to the Author Index">Kim, Hyunwoo</a></td><td class="r">Chungnam National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100310" title="Click to go to the Author Index">Jung, Seul</a></td><td class="r">Chungnam National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1792" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a>, <a href="IROS16_KeywordIndexMedia.html#AI_Reasoning_Methods" title="Click to go to the Keyword Index">AI Reasoning Methods</a></span><br>
                           <strong>Abstract:</strong> This paper presents a hand gesture-based control of a two-wheel mobile robot. Images of hand gestures are captured by a Kinect sensor and learned by neural network a priori. Several patterns of hand gestures for controlling the movement of the robot are move forward and back, turn right and left, stop and quit. Those 6 gestures are commanded to robot and the robot moves according to the command through an identifying process by a neural network. Experimental studies are conducted to confirm the proposition.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_07">16:05-17:20, Paper WeCI2.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1794.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1794'); return false" title="Click to show or hide the keywords and abstract">Morphological Computation in Tactile Sensing: A New Approach in Implementation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202732" title="Click to go to the Author Index">Yamashita, Hideyasu</a></td><td class="r">Ryukoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122439" title="Click to go to the Author Index">Ho, Van</a></td><td class="r">Ryukoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107801" title="Click to go to the Author Index">Shibuya, Koji</a></td><td class="r">Ryukoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102549" title="Click to go to the Author Index">Hirai, Shinichi</a></td><td class="r">Ritsumeikan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1794" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> In this research, we attempted to utilize the merit of wrinkled morphology in actively changing the sensing function depending on interaction with environment. The prototype proposed in this paper is an integration of a pneumatic actuator and strain gauge sensing elements. Under air pressurization, wrinkle patterns can be created or withdrawn, thus altering the posture of sensing element underneath the skin, resulting in changes at sensors' output. This sensing device is both sensitive to contact action and sliding action by using only one types of strain gauges. This work can be extended to a wide range of sensing elements (not only strain gauges), and considered to give impact to the field.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_08">16:05-17:20, Paper WeCI2.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1795.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1795'); return false" title="Click to show or hide the keywords and abstract">How Much Do I Look Like a Human?: The Impact of the Response Types on People's Perception of a Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#163586" title="Click to go to the Author Index">Choi, Jung Ju</a></td><td class="r">Ewha Womans Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#197256" title="Click to go to the Author Index">Kang, Hyemee</a></td><td class="r">Ewha Womans Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167084" title="Click to go to the Author Index">Song, Sekyong</a></td><td class="r">FutureRobot</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202741" title="Click to go to the Author Index">Yun, Jung Sik</a></td><td class="r">DesignMU</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115971" title="Click to go to the Author Index">Kwak, Sonya Sona</a></td><td class="r">Ewha Womans Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1795" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a></span><br>
                           <strong>Abstract:</strong> The purpose of this study is to examine the effect of the response types on people’s perception of a robot in social interaction. We executed a 3 (response types: none vs. conditioned emotional response vs. unconditioned reflex) within-participants experiment (N=24). Participants perceived a robot with unconditioned reflex as more anthropomorphic and animate than a robot with conditioned emotional response while a robot without response was perceived as the least.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_09">16:05-17:20, Paper WeCI2.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1799.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1799'); return false" title="Click to show or hide the keywords and abstract">Intent Recognition for Robot-Aided, Active Training in Early Stage Stroke Rehabilitation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202769" title="Click to go to the Author Index">Bai, Ou</a></td><td class="r">FIU</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1799" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a></span><br>
                           <strong>Abstract:</strong> Active robot-aided training, in contrast to the passive training, in which the robot provides assist to move only after detecting the user’s ‘active’ intents, will provide an increased neuronal plasticity that may lead to reduced consequences after a stroke event. However, it is difficult to detect or recognize user’s active intents reliably in severely paralyzed patients in the early stage of stroke recovery due to their extended weakness; traditional approaches using kinetics as well as torque signals are unable to recognize active intents from paralyzed person who have difficulty to move their limbs. In this study, we investigated the feasibility to use human electromyography (EMG) signals as well as highly sensitive pressure/force signals to detect user’s active intents. We have designed algorithms and devices to ensure a reliable detection from the weak muscles with extended paresis. Preliminary results demonstrated that the fusion of EMG and force signals is able to recognize ‘active’ intents without actual movements nor isometric muscle contractions. In the future study, we will integrate the recognized, ‘active’ intents into the robotic control to achieve an efficient robot-aided stroke rehabilitation in the early stage of recovery.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_10">16:05-17:20, Paper WeCI2.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1801.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1801'); return false" title="Click to show or hide the keywords and abstract">The SLAM Constructor Framework for ROS</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#200087" title="Click to go to the Author Index">Krinkin, Kirill</a></td><td class="r">Saint-Petersburg Electrotechnical Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#200431" title="Click to go to the Author Index">Huletski, Arthur</a></td><td class="r">The Acad. Univ. Saint-Petersburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#200441" title="Click to go to the Author Index">Kartashov, Dmitriy</a></td><td class="r">The Acad. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1801" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> Most of the methods that try to solve the SLAM problem use a prediction-correction approach to estimate current robot pose and map and can be spitted into several groups depending on a set of sensors they use and details of their implementation (e.g. a type of map, feature usage, etc.). Methods that belong to the same group usually differ only by cost functions and ad-hoc optimizations. To the best of our knowledge, a framework that provides a common set of components in order to speed up SLAM research is not publicly available. This work introduces a framework that is under development and provides a set of components that simplify creation of methods based on 2D laser scan processing.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_11">16:05-17:20, Paper WeCI2.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1807.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1807'); return false" title="Click to show or hide the keywords and abstract">A Novel Laser-Based Perception System for UGV's Navigation in GPS-Denied Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194976" title="Click to go to the Author Index">Wang, Fei</a></td><td class="r">Dalian Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168882" title="Click to go to the Author Index">He, Guojian</a></td><td class="r">Dalian Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141884" title="Click to go to the Author Index">Yan, Fei</a></td><td class="r">Dalian Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140896" title="Click to go to the Author Index">Zhuang, Yan</a></td><td class="r">Dalian Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148328" title="Click to go to the Author Index">Xu, Fang</a></td><td class="r">SIASUN Robot & Automation Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202829" title="Click to go to the Author Index">Yang, Qifeng</a></td><td class="r">SIASUN Robot & Automation Co., Ltd</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1807" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a></span><br>
                           <strong>Abstract:</strong> Perceptive laser sensors which provide information from the surrounding environments are a critical aspect of many robotics applications. In this paper, we presented a novel laser-based perception system for UGV's navigation in GPS-denied environments, especially urban outdoors. The system can operate in two modes to support both precise localization and accurate obstacle detection. The performance of our system has been demonstrated in a series of field tests, during which the robot autonomously navigated over a path of about 1.3km in our University Campus.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_12">16:05-17:20, Paper WeCI2.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1808.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1808'); return false" title="Click to show or hide the keywords and abstract">Cross-Domain Self-Localization Using NBNN Scene Descriptor</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202785" title="Click to go to the Author Index">Murase, Tomoya</a></td><td class="r">Univ. of FUKUI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182446" title="Click to go to the Author Index">Tsukamoto, Taisho</a></td><td class="r">Univ. of Fukui</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109542" title="Click to go to the Author Index">Tanaka, Kanji</a></td><td class="r">Univ. of Fukui</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1808" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> In this study, we address the problem of visual robot self-localization across domain. Although the bag-of-words method constitutes a popular approach to single-view localization, it fails badly when it's visual vocabulary is learned and tested in different domains. To address this issue, our strategy is to mine a cross-domain visual experience, a library of raw visual images collected in different domains, to discover the relevant visual patterns that effectively explain the input scene, and use them for scene retrieval. In particular, we show that the appearance and the pose of the mined visual patterns of a query scene can be efficiently and discriminatively matched against those of the database scenes by employing image-to-class distance and spatial pyramid matching.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_13">16:05-17:20, Paper WeCI2.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1810.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1810'); return false" title="Click to show or hide the keywords and abstract">Fly a Drone Freely: A Concept of the Single-Handed Remote Control</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143280" title="Click to go to the Author Index">Cho, Kwangsu</a></td><td class="r">Yonsei Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202833" title="Click to go to the Author Index">Jeon, Jongwoo</a></td><td class="r">Graduate Program in Cognitive Science, Yonsei Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202834" title="Click to go to the Author Index">Yu, Sanghyeong</a></td><td class="r">Yonsei Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1810" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a></span><br>
                           <strong>Abstract:</strong> The Federal Aviation Administration(FAA) recently mitigated regulations for commercial and private use of unmanned aerial vehicles(UAVs), the ease of regulation now allows individuals to use drones freely for diverse applications such as entertainments and arts. However, along with the popularization of private drones, there is also an increasing risk of casualty and social damage caused by poor flight control of inexperienced amateur pilots. This study analyses the human cognitive characteristic related with drone operation failure then proposes a single-handed remote controller as the solution. The single-handed remote controller and the drone moves as if the drone is connected to the head of the controller by an invisible wire. This study proposes a single-handed remote controller which eliminates the mental rotation process and enables the drone to fly to the target point through controller motion and pointing.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_14">16:05-17:20, Paper WeCI2.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1811.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1811'); return false" title="Click to show or hide the keywords and abstract">A Study of Gesture Design for Controlling Drone</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143280" title="Click to go to the Author Index">Cho, Kwangsu</a></td><td class="r">Yonsei Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202207" title="Click to go to the Author Index">Yoo, Young Jae</a></td><td class="r">Yonsei Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202800" title="Click to go to the Author Index">Kim, Yunjung</a></td><td class="r">Yonsei Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1811" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> The number of accidents of drone controlling is increased as personal drones being popular. We can say that people who are not professional for controlling drone are exposed to serious danger of accident. To make controlling drones more intuitive and easier, pre-programming methods which let drones fly as planned or gesture - controlling methods were suggested. In this study, natural gesture design for controlling drones more intuitive is suggested. By taking metaphor from joystick which users can face commonly when controlling motion of object in digital interface, immediacy and naturalness were increased. In case of controlling drones, users have to go outside which is too variable environment in brightness of light or distance between drone and user. For this reason, it is better to use Data – Glove method than Vision Based method to implement gesture controller for drone since Vision Based method is critical to angle and brightness of light. Using suggested gesture design which came from joystick metaphor, users will be able to control drones with four basic commands more intuitive and easier without long period of training.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_15">16:05-17:20, Paper WeCI2.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1813.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1813'); return false" title="Click to show or hide the keywords and abstract">Achieving Robust Auditory Scene Analysis by Aerial Robot under Ego Noise Environment</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148169" title="Click to go to the Author Index">Mun, Seongkyu</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110881" title="Click to go to the Author Index">Ko, Hanseok</a></td><td class="r">Korea Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1813" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Audition" title="Click to go to the Keyword Index">Robot Audition</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Search_and_Rescue_Robots" title="Click to go to the Keyword Index">Search and Rescue Robots</a></span><br>
                           <strong>Abstract:</strong> Due to the moving and flight motions, aerial robot platform suffers a large uncertainty of acoustic data consistency and differences with normal ground condition. Therefore, it is important to address the acoustic problems under harsh environments such as ego/ wind/ propeller fan noise of aerial robot so that desirable target sound events can be detected for time critical scene understanding. To estimate the target sound direction under harsh environments, this paper proposes a novel method using basis and associated weights of non-negative matrix factorization for separating target sound from noise of the input signal. Additionally, in order to extract noise robust and discriminative acoustic characteristics from input signal, this paper proposes to use bottleneck features. The experimental results validate effectiveness of the proposed algorithm in terms of representative performance measures compared to the conventional methods.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_16">16:05-17:20, Paper WeCI2.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1816.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1816'); return false" title="Click to show or hide the keywords and abstract">Action Generation As Conceptual Processing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202837" title="Click to go to the Author Index">Olier, Juan Sebastian</a></td><td class="r">Eindhoven Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116556" title="Click to go to the Author Index">Barakova, Emilia I.</a></td><td class="r">Eindhoven Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202839" title="Click to go to the Author Index">Regazzoni, Carlo</a></td><td class="r">Univ. of Genoa</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202838" title="Click to go to the Author Index">Rauterberg, Matthias</a></td><td class="r">Eindhoven Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1816" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> Learning to behave through interaction with the environment implies to actively structure its elements through internalizations in the sensory-motor system. In the present work, that is understood in relation to concepts acquisition and conceptual processing. With that in mind, the definition of concepts is framed from views in the cognitive sciences, and the main characteristics found are used to frame the development of a learning architecture for a given embodiment. Particularly, the problem is addressed under the framework of deep learning (DL), behavior generation based on predictive coding and prediction error minimization, and multi-modal integration as part of the learning and prediction capabilities. An sample scenario in which such ideas are to be tested is the navigation of an agent, where obstacles and paths are to be conceptualize through action. The proposals in the present work are based on architectures that focused on schemes based on predictive coding for unsupervised learning of generative models, which use recursion and prediction error minimization to infer the observed dynamics of the environment. The work focuses on the problems of integration of different modalities and the relation between perception and actions as a way to fulfill expectations in the learning of generaitve models. In particular, these two problems are stated in similar terms given that actions generate proprioceptive data, which in turn might be seen as a specific sensory modality. Then solving the problem of integrating modalities in the same process, in turn solves the problem of learning the relation between motion and perception in observed data. Moreover, if proprioception is linked to the motor system it could actively generate actions to reduce uncertainty as a kind of experiments on hypotheses about perceived states. By doing so, actions are not a consequences of a processing on conceptual representations, but are an essential and active part of it. The results of the proposed approach are measured in terms of the accuracy in reproducing the behavior from which training data is drawn, in this case navigation. The expected outcomes are an increased capability to deal with noisy inputs, as well as the creation of knowledge about obstacles for successful navigation based on the internal conceptual representations built in the whole network.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_17">16:05-17:20, Paper WeCI2.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1817.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1817'); return false" title="Click to show or hide the keywords and abstract">OTP: Novel Point Cloud Parameterization for ND-Based Sweep Matching</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146207" title="Click to go to the Author Index">Ryu, Soo-Hyun</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150776" title="Click to go to the Author Index">Kang, Jaehyeon</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146209" title="Click to go to the Author Index">Choi, Hyunga</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184684" title="Click to go to the Author Index">Cho, HyunGi</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117481" title="Click to go to the Author Index">Doh, Nakju</a></td><td class="r">Korea Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1817" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> This paper proposes a novel representation of a point cloud for normal distribution (ND)-based sweep matching. In the ND-based sweep matching, as ND features are extracted based on initial trajectory, they have inertial distortions. And these distortions cause inaccurate trajectory estimation. To minimize the distortions, ND features could be re-extracted from the point cloud at each iteration. However, it costs too much computing time. To replace the method, we propose a novel representation called `One-Two Parameterization (OTP)'. Simulations validate that the ND with using the OTP shows better accuracy than the ND without using it. Also, by applying the OTP to sweep matching experiments, the method with using the OTP demonstrates better accuracy than the method without using it.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_18">16:05-17:20, Paper WeCI2.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1821.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1821'); return false" title="Click to show or hide the keywords and abstract">Factor Graph Based Visual SLAM with Geometric Pose Estimation of a Rectangle Feature</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187382" title="Click to go to the Author Index">Lee, Jae-Min</a></td><td class="r">Chungbuk National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202847" title="Click to go to the Author Index">Yoo, Jooung Sun</a></td><td class="r">Chungbuk National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104634" title="Click to go to the Author Index">Kim, Gon-Woo</a></td><td class="r">Chungbuk National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1821" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> In this paper, a visual simultaneous localization and mapping(SLAM) method which uses rectangle features is proposed in factor graph manner. Using the rectangle reconstruction method called coupled line camera algorithm which calculates analytically the aspect ratio of the rectangle from perspectively warped quadrilateral in the image plane, the plane homography is derived. The stereo configuration of the camera is proposed in order to solve the ambiguity arising from we not know the true size of the rectangle without additional information with corresponding modification of the coupled line camera algorithm to reconstruct the rectangle even the scale. A relative pose between rectangle in the real world plane and the camera is calculated for each quadrilateral from normalized homography with the intrinsic parameters of the camera which is constant in images captured by the identically same camera. the performance of this pose estimation method is showed in the simulated environment with ground truth value.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_19">16:05-17:20, Paper WeCI2.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1822.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1822'); return false" title="Click to show or hide the keywords and abstract">Dynamic Window Navigation for a Quadrotor Using RGBD Sensor</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148004" title="Click to go to the Author Index">Lee, Daewon</a></td><td class="r">UPENN</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192960" title="Click to go to the Author Index">Di Cicco, Maurilio</a></td><td class="r">Sapienza Univ. of Rome</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107200" title="Click to go to the Author Index">Grisetti, Giorgio</a></td><td class="r">Sapienza Univ. of Rome</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106613" title="Click to go to the Author Index">Lee, Daniel D.</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1822" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> This paper presents a high speed indoor navi- gation and collision avoidance strategy for a quadrotor us- ing RGBD sensor. We propose a new objective function of Dynamic Window Approach (DWA) that is suitable for autonomous quadrotor applications. The suggested method enables a quadrotor system to avoid obstacles while maintaining high speed to navigate to a goal position. With the proposed objective function, the reachable velocity vector space is nar- rowed by considering the limited line-of-sight of the vision- sensor and the dynamics of the quadrotor. Velocity commands that maximize the objective function are selected from this vector space and feed them into control loop at each time step. We present hardware and software architecture for state estimation that runs at 30Hz on onboard computer. It allows the quadrotor to fly fully autonomously to test and validate the proposed algorithm. Experiments show satisfactory results regarding path generation, which is not only more efficient in time, but also lacks the local minima problem which plague other such algorithms (e.g. potential field).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_20">16:05-17:20, Paper WeCI2.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1823.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1823'); return false" title="Click to show or hide the keywords and abstract">Distributed Shapte-Formation Control for Robotic Swarms and ROS-Based Simulations</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#200108" title="Click to go to the Author Index">Liu, Yang</a></td><td class="r">Case Western Res. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103527" title="Click to go to the Author Index">Lee, Kiju</a></td><td class="r">Case Western Res. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1823" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a></span><br>
                           <strong>Abstract:</strong> This abstract presents decentralized shape forma- tion algorithms for a ``primitive&quot; robotic swarm with highly limited sensing, processing, and memory capacities. Shape for- mation, which is necessary to perform a task in a coordinated manner, is one of the fundamental engineering problems in a robotic swarm. The formations of our interests are dispersion, aggregation, and line formation. These three specific shapes are considered for potential practical applications of mapping and localization in an unknown environment to perform search and/or exploratory tasks. The presented formation algorithms aim to demonstrate decentralized control of a robotic swarm, consisting of a group of primitive mobile robots whose sensing capability is limited to relative positions of the neighbor robots within the sensing range. The algorithms were simulated in Robot Operating System (ROS) with Gazebo and the results are presented in this abstract.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_21">16:05-17:20, Paper WeCI2.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1824.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1824'); return false" title="Click to show or hide the keywords and abstract">High-Accuracy Preintegration for Visual-Inertial Navigation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191701" title="Click to go to the Author Index">Eckenhoff, Kevin</a></td><td class="r">Univ. of Delaware</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114431" title="Click to go to the Author Index">Huang, Guoquan</a></td><td class="r">Univ. of Delaware</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202853" title="Click to go to the Author Index">Geneva, Patrick</a></td><td class="r">Univ. of Delaware</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1824" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a></span><br>
                           <strong>Abstract:</strong> Visual-inertial navigation that is able to provide accurate 3D localization in GPS-denied environments has seen popularity in recent years due to the proliferation of cost-effective cameras and inertial measurement units (IMUs). While an extended Kalman filter (EKF) is often used for sensor fusion, factor graph-based optimization has recently revealed its superior performance, which, however, is still compromised by the lack of rigorous IMU preintegration (i.e., integrating IMU measurements in a local frame of reference). To address this issue, in this work, we analytically derive the high-accuracy preintegration based on closed-form solutions of the continuous integration equations of IMU measurements. These expressions allow us to analytically compute the mean, covariance, and bias Jacobians for a set of IMU preintegration factors. These accurate factors are subsequently fused with the visual information via visual-inertial factor graph optimization to provide high-precision trajectory estimates.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_22">16:05-17:20, Paper WeCI2.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1825.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1825'); return false" title="Click to show or hide the keywords and abstract">Logical Conjunction Based 3D Line Segments Matching between Observed Line Segments and Pre-Constructed 3D Wire Frame Model</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202855" title="Click to go to the Author Index">Kaneko, Naoshi</a></td><td class="r">Aoyama Gakuin Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110506" title="Click to go to the Author Index">Takahashi, Junji</a></td><td class="r">Aoyama Gakuin Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202854" title="Click to go to the Author Index">Yoshida, Takeshi</a></td><td class="r">Aoyama Gakuin Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1825" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> We tackle localization problems of range sensor with the assumption that the system has a pre-constructed 3D map represented as wire frames. The localization is done by the process of finding out the most similar combination of frames in the map against the line segments observed by the sensor. In this process, the observation distortion of sensor makes the problem difficult. For example, even if the range sensor observes rectangular window frame, line segments reconstructed from the sensing data are not orthogonal in most cases. In order to cope with the observation distortion, we propose a new matching method that takes logical conjunction between sensed line segments and dilated wire frame. We evaluate our proposed method with some experiments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_23">16:05-17:20, Paper WeCI2.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1830.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1830'); return false" title="Click to show or hide the keywords and abstract">Human Motion Recognition Based on Topic Model</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202862" title="Click to go to the Author Index">Ogura, Tadashi</a></td><td class="r">The Graduate Univ. for Advanced Studies</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202863" title="Click to go to the Author Index">Sakato, Tatsuya</a></td><td class="r">National Inst. of Informatics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106586" title="Click to go to the Author Index">Inamura, Tetsunari</a></td><td class="r">National Inst. of Informatics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1830" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a></span><br>
                           <strong>Abstract:</strong> Continuous human motion, which consists of several sequential motions, should be recognized using current context. However, methods of human motion recognition based on the context have not been clearly solved. This study focuses on topic model used for estimating hidden context in natural language processing. We propose a method applying the topic model to human motion recognition. Our method demonstrates improvement of accuracy in human motion recognition with Latent Dirichlet Allocation (LDA) and Hidden Markov Model (HMM).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_24">16:05-17:20, Paper WeCI2.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1834.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1834'); return false" title="Click to show or hide the keywords and abstract">Human Motion Recognition Based on Dynamic Topic Model</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202863" title="Click to go to the Author Index">Sakato, Tatsuya</a></td><td class="r">National Inst. of Informatics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202862" title="Click to go to the Author Index">Ogura, Tadashi</a></td><td class="r">The Graduate Univ. for Advanced Studies</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106586" title="Click to go to the Author Index">Inamura, Tetsunari</a></td><td class="r">National Inst. of Informatics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1834" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a></span><br>
                           <strong>Abstract:</strong> Recognizing human motion is important for human-robot interaction. Robot systems often misrecognize human motion without context information. Human never fail to recognize because they recognizes each motion not as an independent motion but as one of sequential motions in a context. We therefore propose a recognition method for sequences of human motion based on context information. In this paper, we adopt the dynamic topic model. Experimental results showed that the proposed method reduced recognition error using the estimated dynamic topic.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_25">16:05-17:20, Paper WeCI2.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1835.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1835'); return false" title="Click to show or hide the keywords and abstract">Expansion of LRF Measurement Range for Application to a Desktop Interface Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202828" title="Click to go to the Author Index">Shimoyama, Mirai</a></td><td class="r">Shibaura Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110644" title="Click to go to the Author Index">Matsuhira, Nobuto</a></td><td class="r">Shibaura Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1835" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a></span><br>
                           <strong>Abstract:</strong> Laser rangefinders (LRFs) are often used for the detection of people by robots. However, a robot cannot always respond accordingly to human movement if its LRF has a limited detection area. Previous studies have looked at using multiple LRFs; however, this increases costs and creates problems of interference. Therefore, we propose an active sensing mechanism that moves the sensor in order to enable accurate detection of people. We theoretically and experimentally assess the extent to which a sensor displacement of 300 mm improves the detection capability. We find an 80% reduction in blind-spot area theoretically. We confirmed human detection in blind spot in general experimentally.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_26">16:05-17:20, Paper WeCI2.26</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1836.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1836'); return false" title="Click to show or hide the keywords and abstract">Image-Based Algal Blooms Detection Using Local Binary Pattern</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189650" title="Click to go to the Author Index">Jung, Sungwook</a></td><td class="r">KAIST(Korea Advanced Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137327" title="Click to go to the Author Index">Kim, Donghoon</a></td><td class="r">KAIST(Korea Advanced Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195927" title="Click to go to the Author Index">Kim, Kyukwang</a></td><td class="r">KAIST (Korea Adv. Inst. Sci. & Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104490" title="Click to go to the Author Index">Myung, Hyun</a></td><td class="r">KAIST (Korea Adv. Inst. Sci. & Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1836" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a></span><br>
                           <strong>Abstract:</strong> Algal blooms have caused great damage to the ecosystem of river and lake. For this reason, fast and exact warning of algal blooms becomes far more important. In this paper, we propose an image-based algal bloom detection method by classifying the texture of images using Local Binary Pattern(LBP). We have combined unsupervised texture segmentation algorithm using LBP and the pre-trained texture information, and the experimental results show good performance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_27">16:05-17:20, Paper WeCI2.27</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1839.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1839'); return false" title="Click to show or hide the keywords and abstract">4D Optical Coherence Tomography Imaging Guided SMART Handheld Microsurgical System</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#199203" title="Click to go to the Author Index">Song, Cheol</a></td><td class="r">DGIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202865" title="Click to go to the Author Index">Park, Taiwoo</a></td><td class="r">Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#199204" title="Click to go to the Author Index">Koo, Dongwoo</a></td><td class="r">DGIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1839" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a></span><br>
                           <strong>Abstract:</strong> This paper proposes an interactive and assisted microsurgical system featuring a graphical processing unit (GPU)-accelerated 4D real-time target area visualization as well as guided SMART micro-forceps for active tremor cancellation, which are enabled by common path swept source optical coherence tomography (CP SS-OCT). The visualization and active tremor cancellation are implemented in one integrated system, while sharing one OCT source as well as multiple GPU cores. The system aims to assist micro surgeons to accurately and rapidly locate a surgical target at the desired position and thereby accomplishing given surgical tasks with enhanced interactivity.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_28">16:05-17:20, Paper WeCI2.28</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1840.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1840'); return false" title="Click to show or hide the keywords and abstract">April Tag Detection: Calculating Distance Use ROS Transform Package</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202628" title="Click to go to the Author Index">Tadesse, Kirubel</a></td><td class="r">Jackson State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189645" title="Click to go to the Author Index">Fricke, George Matthew</a></td><td class="r">The Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157419" title="Click to go to the Author Index">Hecker, Joshua Peter</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156591" title="Click to go to the Author Index">Moses, Melanie</a></td><td class="r">Univ. of New Mexico</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1840" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a></span><br>
                           <strong>Abstract:</strong> This research focuses on determining the distance between a tag and a rover. Based on the incoming camera image, the rover navigates to the location of April tag cube, which is an ideal food for the Swarmie. When the tag is within the rover camera view area, the rover calculates the distance between the tag and its current location. The most effective way to accomplish this is using ROS TF (Transform) to broadcast and listen to the transform between the incoming tag coordinates and base_link coordinate frame. By using the transform frame published by the apriltag_detection package, the coordinate points of the April tag is obtained. The broadcaster node then subscribes to this tag_detection topic and broadcasts the transformation from the head_camera to the base_link. Once the transform tree
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_29">16:05-17:20, Paper WeCI2.29</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1841.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1841'); return false" title="Click to show or hide the keywords and abstract">Human-Robot Emotional Interaction Framework with Consensus-Based Approach</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109904" title="Click to go to the Author Index">Park, Chung Hyuk</a></td><td class="r">George Washington Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1841" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Companions_and_Social_Human_Robot_Interaction" title="Click to go to the Keyword Index">Robot Companions and Social Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Agent_Based_Systems" title="Click to go to the Keyword Index">Agent-Based Systems</a></span><br>
                           <strong>Abstract:</strong> This late breaking results report presents a social robotic emotional interaction framework using a consensus-based algorithm, especially for achieving emotional regulation through social interaction with a robotic agent. This model-based framework provides an efficient and controllable approach for emotional interaction between a human and a robotic agent, which can be applied to robot-based or virtual agent-based therapeutic sessions with social and emotional interactions.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_30">16:05-17:20, Paper WeCI2.30</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1844.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1844'); return false" title="Click to show or hide the keywords and abstract">Multiple Drones Driven Hexagonally Partitioned Area Exploration Using Reverse Nearest Neighbors: Simulation and Evaluation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195820" title="Click to go to the Author Index">Datta, Ayush</a></td><td class="r">International Inst. of Information Tech. Hyderabad</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195861" title="Click to go to the Author Index">Karlapalem, Kamalakar</a></td><td class="r">IIIT-Hyderabad/IIT Gandhinagar</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195717" title="Click to go to the Author Index">Tallamraju, Rahul</a></td><td class="r">International Inst. of Information Tech. Hyderabad</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1844" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperating_Robots" title="Click to go to the Keyword Index">Cooperating Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a></span><br>
                           <strong>Abstract:</strong> This paper proposes a distributed, cooperative path planning technique for multiple drones (&#8764;200) to explore an unknown region (&#8764;10,000 connected units) in the presence of obstacles. The unknown map is split into hexagonal unit regions and is dynamically created based on the information obtained from sensors and other drones. Long range communication helps in deciding next optimal sub area to be targeted by individual drones and another more frequently used short range communication to avoid re-exploration of cells already explored by companion drones located in same subarea. Simulation results show that the two types of communication in a weighted hexagonal representation of subareas makes exploration more efficient, scalable and more resilient to communication failures.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_31">16:05-17:20, Paper WeCI2.31</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1845.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1845'); return false" title="Click to show or hide the keywords and abstract">Understanding the Adoption of Robot in Medical Field with Socio-Technical Systems Framework</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194483" title="Click to go to the Author Index">Jang, Seojeong</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202879" title="Click to go to the Author Index">Kwon, Gyu Hyun</a></td><td class="r">Hanyang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1845" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a></span><br>
                           <strong>Abstract:</strong> The adoption of robot technology becomes more popular. This research aims to understand effects of robot technologies in medical field. To support the main theme, we analyzed bi-directional factors between actors and a robot technical system based on Geels’ Socio-Technical Systems (STS) framework. In conclusion, actors show different reactions for the robot according to their roles. Consequently, actor-robot’s bi-directional interaction gives implications in adopting new robot technologies in medical field or adopting robots in long term periodic phase.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_32">16:05-17:20, Paper WeCI2.32</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1847.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1847'); return false" title="Click to show or hide the keywords and abstract">Human Body Digitization Using INBODY</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202470" title="Click to go to the Author Index">Grazioso, Stanislao</a></td><td class="r">Univ. of Naples Federico II</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114623" title="Click to go to the Author Index">Di Gironimo, Giuseppe</a></td><td class="r">Univ. of Napoli Federico II</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1847" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Networks" title="Click to go to the Keyword Index">Sensor Networks</a></span><br>
                           <strong>Abstract:</strong> This work presents a general scanner for the instant acquisition of human body measurements and 3-d models. The motivation behind it is the real time acquisition of human body models needed for the digital manufacturing process of orthoses and prosthesis. Since often patients present mobility impairments, a strict requirement for the overall scanner is to allow instant acquisition. The prototype developed by the authors, INBODY, consists in a photogrammetric 3-d full body scanner presenting the following features: (i) instant acquisition of the human body model; (ii) precision and accuracy of the resulting 3D model comparable with laser systems; (iii) affordable cost. INBODY is built upon a modular and distributed architecture. From the hardware point of view, it is composed by a series of micro-cameras each one connected with its own micro-controller. All micro-controllers are connected between them and with a remote management controller via ethernet. The control and management software is based upon a client-multiserver architecture: the client is represented by the remote management controller, while each micro-controller connected with its proper micro-camera represents a server. Each server has to guarantee a series of services, each one represented by a thread: taking and transferring pictures, shutting down each micro-controller. A multi-thread software architecture provides the synchronization of threads on each server: when the remote management controller sends the signal corresponding to one of the three threads, all servers provide the corresponding service instantaneously ,without delay between them. Moreover, the client provides the 3-d reconstruction starting from the pictures. INBODY has been tested with a lot of experiments, to test the synchronization of the threads (in particular of the acquisition phase) and the 3-d reconstruction of the human models. The tests stated that it can be a good solution in digitizing human bodies.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_33">16:05-17:20, Paper WeCI2.33</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1852.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1852'); return false" title="Click to show or hide the keywords and abstract">Trajectory Planning of Mobile Robot under Existence of Moving Obstacles Using Improved Potential Field Approach</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170079" title="Click to go to the Author Index">Xu, Hao</a></td><td class="r">Anhui Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172738" title="Click to go to the Author Index">Li, Yan</a></td><td class="r">Anhui Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167643" title="Click to go to the Author Index">Xu, Xiangrong</a></td><td class="r">Anhui Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1852" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a></span><br>
                           <strong>Abstract:</strong> This paper presents an approach of mobile robot trajectory planning under the existence of moving obstacles by using improved artificial potential field method. The potential field intensity and strength instead of force vectors was adopted in the planning. Considering the speed-effect of mobile obstacles and mobile robot, the velocity information was introduced into potential field function and an “added potential field” was also applied to guide the mobile robot to be free of collision with local obstacles. Based on the new method, all the potential field intensity was considered and summed by algebraic style, then the genetic trust region algorithm was used to search the minimum sum points of potential field intensity within the motion space and scope which the mobile robot can reach target during a sampling period, and the global optimization trajectory was consisted of all the minimum points. Simulation and experiment results show that better results of path planning for mobile robot in complex environment with existence of moving obstacles can be achieved using this new approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_34">16:05-17:20, Paper WeCI2.34</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1854.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1854'); return false" title="Click to show or hide the keywords and abstract">Distributed Intelligent Ball-Type Robots Supporting Seamless Network Connectivity for Search and Rescue Mission</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157185" title="Click to go to the Author Index">Lee, Chang-Eun</a></td><td class="r">ETRI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107991" title="Click to go to the Author Index">Cho, Young-Jo</a></td><td class="r">Electronics and Telecommunications Res. Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#121307" title="Click to go to the Author Index">Sung, Tae-Kyung</a></td><td class="r">Chungnam National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1854" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a></span><br>
                           <strong>Abstract:</strong> --Enter the abstract-- For practical robotic search and rescue missions in disaster areas, the multi-hop mesh network connecting all robots and the operator station have to be guaranteed even in the environment where the network infrastructure is destroyed. Addressing these issues, V. Kumar et al [1], [2] proposed a k-connectivity method and resolved the end-to-end network connectivity problem using a probabilistic approach. In the DARPA LANdroids project [3], a self-configuring network scheme was developed, where the global network connectivity is maintained even in the case of a local connection failure. However, most previous approaches assumed that the network was connected within a fixed range of communication and relied on the direct line-of-sight signals. Therefore, the network connection might fail in a real environment. This paper proposes distributed intelligent ball-type robots which support seamless network connectivity. The proposed architecture makes the ball-type robots move around in order not to disconnect the network link between explorer and the human operator located at a remote station by considering the strength of the network signal and link quality. The proposed scheme assuring network connectivity is validated through experiments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_35">16:05-17:20, Paper WeCI2.35</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1855.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1855'); return false" title="Click to show or hide the keywords and abstract">Autonomous T-Branch Navigation Control of Hyper-Redundant In-Pipe Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166383" title="Click to go to the Author Index">Lee, Geonuk</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111437" title="Click to go to the Author Index">Koo, Ja Choon</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102438" title="Click to go to the Author Index">Choi, Hyouk Ryeol</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104237" title="Click to go to the Author Index">Moon, Hyungpil</a></td><td class="r">Sungkyunkwan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1855" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a></span><br>
                           <strong>Abstract:</strong> In this report, we present our progress toward autonomous navigation of a hyper-redundant in-pipe robot. We focus on the navigation through a T-branch because of the difficulty and importance of such a task. Our robot is an overly constrained serially connected modules with actively controlled joints. Each driving module has two driving wheels which roll on the inside of the pipe surface. Proper poses of the robot are necessary for autonomous navigation through T-branch to avoid jamming of the robot. In this work, we show experimental results of the RRT-based path planning, the particle filter localization of the hyper-redundant in-pipe robot, and tracking control of the robot for autonomous navigation in T-branch.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_36">16:05-17:20, Paper WeCI2.36</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1857.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1857'); return false" title="Click to show or hide the keywords and abstract">Speed Evaluation of the Kinect for Rescue Robot System Using ICP Cloud Registration</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203071" title="Click to go to the Author Index">Shin, Seol</a></td><td class="r">KETI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203067" title="Click to go to the Author Index">Shin, Dong-In</a></td><td class="r">KETI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154198" title="Click to go to the Author Index">Kim, Dong Yeop</a></td><td class="r">KETI (Korea Electronics Tech. Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115550" title="Click to go to the Author Index">Hwang, Jung-Hoon</a></td><td class="r">Korea Eletronics Tech. Inst</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1857" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Hazardous_Fields" title="Click to go to the Keyword Index">Robotics in Hazardous Fields</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Performance_Evaluation_and_Benchmarking" title="Click to go to the Keyword Index">Performance Evaluation and Benchmarking</a></span><br>
                           <strong>Abstract:</strong> This research evaluates the ability of point clouds registration using the Kinect depth sensor at varying speed rates. Our approach is to provide the guidance for designing a rescue robot under the remote control. The system computes ICP algorithm to reconstruct 3D map and minimize noise levels. We intend to find the rated velocity of sensors to reconstruct 3D objects.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_37">16:05-17:20, Paper WeCI2.37</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1860.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1860'); return false" title="Click to show or hide the keywords and abstract">Auto-Balancing Stackable Mechanism in Presence of Variable Payload</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106263" title="Click to go to the Author Index">Yi, Byung-Ju</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166113" title="Click to go to the Author Index">Woo, Jae Hong</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123204" title="Click to go to the Author Index">Seo, Jong Tae</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169322" title="Click to go to the Author Index">Kang, Long</a></td><td class="r">Hanyang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1860" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a></span><br>
                           <strong>Abstract:</strong> The stackable mechanism architecture has been proven as an effective way for gravity-balancing over the whole workspace. Auto-balancing is required when the balancing is broken by changing the surgical tool at the distal end of the mechanism. In this paper, auto-balancing of the stackable mechanism for variable payload is investigated. For this, balancing conditions for three auto-balancing methods are suggested and a new balancing method combining spring and counter-weight is considered as an effective means of auto-balancing to cope with variable payload.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_38">16:05-17:20, Paper WeCI2.38</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1863.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1863'); return false" title="Click to show or hide the keywords and abstract">Development of a Wire-Driven End-Effector Device for Frozen Shoulder Treatment</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203082" title="Click to go to the Author Index">Park, Chulmin</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191374" title="Click to go to the Author Index">Kwon, Seong-il</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105736" title="Click to go to the Author Index">Kang, Sungchul</a></td><td class="r">Korea Inst. of Science & Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203148" title="Click to go to the Author Index">Hong, Hanpyo</a></td><td class="r">Asan Medical Center, Ulsan Univ. School of Medicine</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203149" title="Click to go to the Author Index">Jeon, In-Ho</a></td><td class="r">Asan Medical Center, Ulsan Univ. School of Medicine</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111202" title="Click to go to the Author Index">Park, Shinsuk</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157498" title="Click to go to the Author Index">Kim, Keri</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1863" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a></span><br>
                           <strong>Abstract:</strong> In this paper, a wire-driven end-effector device for electrocautery has been developed for capsular release of arthroscopic surgery. The device has a cylindrical cannula that can accommodate surgical tools of various sizes, and is required to have a suitable bending radius for the surgery. The end-effector is made of an elastic material called polyamide-imide (PAI) with an outer diameter of 4 mm and a total length of 19 mm. The device is controlled by a wire connected to a motor, and is capable of bending up to 90° in the upward and downward directions. In order to test the feasibility of the developed device, we conducted quantitative and qualitative evaluations followed by a set of experiments on a shoulder model. From the experiments, we confirmed that the end-effector can be perfectly bent up to 90° in upward and downward directions and our target region, the inferior glenohumeral ligament (IGHL), is safely reachable for a surgeon using the developed device with little difficulty.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_39">16:05-17:20, Paper WeCI2.39</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1864.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1864'); return false" title="Click to show or hide the keywords and abstract">Design of Genderless Connection Mechanism for Modular Manipulator</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123459" title="Click to go to the Author Index">Hong, SeongHun</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#203049" title="Click to go to the Author Index">Kim, KangGyun</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171087" title="Click to go to the Author Index">Choi, Wooseok</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105736" title="Click to go to the Author Index">Kang, Sungchul</a></td><td class="r">Korea Inst. of Science & Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#112925" title="Click to go to the Author Index">Lee, Woosub</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1864" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Joint_Mechanism_Design" title="Click to go to the Keyword Index">Joint/Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Cellular_and_Modular_Robots" title="Click to go to the Keyword Index">Cellular and Modular Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> Gender characteristics of connecting side between modules affects the number of configurations after assembly of modular manipulator systems. A module connection mechanism capable of genderless coupling of mechanical and electrical connection between modules is introduced. The connection can be established between two modules via four types of relative positions of 90 degrees intervals.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="weci2_40">16:05-17:20, Paper WeCI2.40</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1865.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1865'); return false" title="Click to show or hide the keywords and abstract">Novel Mechanism with Torque-Coil Driven Wrist Toward 2mm-Diameter Minimally Invasive Surgery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180706" title="Click to go to the Author Index">Kim, Jongwoo</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106199" title="Click to go to the Author Index">Cho, Kyu-Jin</a></td><td class="r">Seoul National Univ. Biorobotics Lab</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1865" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Dexterous_Manipulation" title="Click to go to the Keyword Index">Dexterous Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> We developed novel 3R joint steerable cannula to proceed minimally invasive surgery. The steerable cannula mainly consists of 3 metal tubes. We applied pre-curvature and patterning on the tubes to broaden workspace with more dexterity. To have extra d.o.f., we employ torque coil driven wrist at the distal end. Thanks to high torsional stiffness and low bending stiffness of torque coil, the wrist rotates independently from interference of other tubes while transmitting torsional force from proximal end. The wrist enables to steer the orientation of the end-effector without changing the configuration of the other tubes. In collaboration with medical team, we proceeded the clinical test of 3-tube-robot on frozen porcine shoulder: physicians successfully got rid of inflammations without pre-training. The wrist is less than 1.1mm in diameter so the proposed mechanism shows great potential on minimally invasive surgery.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect1"><b>WeCT1</b></a></td>
               <td class="r">#101</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect1" title="Click to go to the Program at a Glance"><b>Field Robots 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100175" title="Click to go to the Author Index">Dubey, Rajiv</a></td><td class="r">Univ. of South Florida</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#107898" title="Click to go to the Author Index">Clark, Christopher M.</a></td><td class="r">Harvey Mudd Coll</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect1_01">16:05-16:20, Paper WeCT1.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0044.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('44'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Vision-Guided State Estimation and Control of Robotic Manipulators Which Lack Proprioceptive Sensors</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160214" title="Click to go to the Author Index">Ortenzi, Valerio</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164119" title="Click to go to the Author Index">Marturi, Naresh</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104289" title="Click to go to the Author Index">Stolkin, Rustam</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#176896" title="Click to go to the Author Index">Jeffrey, Kuo</a></td><td class="r">National Nuclear Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104322" title="Click to go to the Author Index">Mistry, Michael</a></td><td class="r">Univ. of Birmingham</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab44" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0044.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Hazardous_Fields" title="Click to go to the Keyword Index">Robotics in Hazardous Fields</a>, <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a></span><br>
                           <strong>Abstract:</strong> This paper presents a vision-based approach for estimating the configuration of, and providing control signals for, an under-sensored robot manipulator using a single monocular camera. Some remote manipulators, used for decommissioning tasks in the nuclear industry, lack proprioceptive sensors because electronics are vulnerable to radiation. Additionally, even if proprioceptive joint sensors could be retrofitted, such heavy-duty manipulators are often deployed on mobile vehicle platforms, which are significantly and erratically perturbed when powerful hydraulic drilling or cutting tools are deployed at the end-effector. In these scenarios, it would be beneficial to use external sensory information, e.g. vision, for estimating the robot configuration with respect to the scene or task. Conventional visual servoing methods typically rely on joint encoder values for controlling the robot. In contrast, our framework assumes that no joint encoders are available, and estimates the robot configuration by visually tracking several parts of the robot, and then enforcing equality between a set of transformation matrices which relate the frames of the camera, world and tracked robot parts. To accomplish this, we propose two alternative methods based on optimisation. We evaluate the performance of our developed framework by visually tracking the pose of a conventional robot arm, where the joint encoders are used to provide ground-truth for evaluating the precision of the vision system. Additionally, we evaluate the precision with which visual feedback can be used to control the robot’s end-effector to follow a desired trajectory.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect1_02">16:20-16:35, Paper WeCT1.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0127.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('127'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Blade-Type Crawler Vehicle with Wings in Ground Effect for Traversing Uneven Terrain at High Speed</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157192" title="Click to go to the Author Index">Yamada, Yasuyuki</a></td><td class="r">Chuo Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107755" title="Click to go to the Author Index">Endo, Gen</a></td><td class="r">Tokyo Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102634" title="Click to go to the Author Index">Nakamura, Taro</a></td><td class="r">Chuo Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab127" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0127.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Hazardous_Fields" title="Click to go to the Keyword Index">Robotics in Hazardous Fields</a></span><br>
                           <strong>Abstract:</strong> Unmanned rescue, observation and/or research vehicles with high terrain adaptability, high speed, and high reliability are needed to reach difficult locations. However, most vehicles achieve improved performance over rough terrain at the expense of low speed and/or complex mechanisms. We developed a blade-type crawler robot with a very simple and reliable mechanism, capable of traversing uneven terrain at high speed, using aerodynamic devices. As these small devices are in the low Reynolds number region, we tested a wing that made use of the ground effect. We experimentally confirmed the success of this approach in improving the traveling speed and ability to traverse uneven terrain. The robot with aerodynamic lift was climbed 1.5 times higher obstacle than without wings.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect1_03">16:35-16:50, Paper WeCT1.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0493.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('493'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Experimental Analysis of a Variable Autonomy Framework for Controlling a Remotely Operating Mobile Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187662" title="Click to go to the Author Index">Chiou, Manolis</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104289" title="Click to go to the Author Index">Stolkin, Rustam</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195857" title="Click to go to the Author Index">Bieksaite, Goda</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116406" title="Click to go to the Author Index">Hawes, Nick</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195855" title="Click to go to the Author Index">Shapiro, Kimron</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195858" title="Click to go to the Author Index">Harrison, Timothy</a></td><td class="r">Defense Science and Tech. Lab</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab493" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0493.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Hazardous_Fields" title="Click to go to the Keyword Index">Robotics in Hazardous Fields</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Semi_Autonomous_Robots" title="Click to go to the Keyword Index">Semi-Autonomous Robots</a></span><br>
                           <strong>Abstract:</strong> This paper presents a principled experimental analysis of a variable autonomy control approach to mobile robot navigation. A Human-Initiative (HI) variable autonomy system is investigated, in which a human operator is able to switch the Level of Autonomy (LOA) between teleoperation (joystick control) and autonomous control (robot navigates autonomously towards waypoints selected by the human) on-the-fly. Our hypothesis is that the HI system will enable superior navigation performance compared to either teleoperation or autonomy alone, especially in scenarios where the performance of both the human and the robot may at times become degraded. We evaluate our hypothesis through carefully controlled and repeatable experiments using a significant number of human test-subjects.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect1_04">16:50-17:05, Paper WeCT1.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0521.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('521'); return false" title="Click to show or hide the keywords and abstract">Robust Motion Planning Methodology for Autonomous Tracked Vehicles in Rough Environment Using Online Slip Estimation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191269" title="Click to go to the Author Index">Lee, Sang Uk</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105225" title="Click to go to the Author Index">Iagnemma, Karl</a></td><td class="r">MIT</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab521" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a></span><br>
                           <strong>Abstract:</strong>  This paper presents a robust motion planning methodology for autonomous tracked vehicles navigating in a rough and unknown environment. Two fields of study are dealt with in this paper: motion planning and slip estimation. For the motion planner, the CC-RRT* algorithm is combined with LQG-MP. The motion planner uses a chance-constrained approach and considers the role of compensator in the planning step to provide a robust yet non-conservative planner. For the slip estimator, a stable yet practical online approach known as IPEM is used. IPEM compares the integrated prediction with the measurement to calculate appropriate parameters. The methodology performs online slip estimation and re-planning iteratively. This guarantees the safe travel of the vehicle even when there is an unexpected terrain change that can be fatal. The simulation result shows that the iterative estimation and re-planning plays a significant role in ensuring the safety of the vehicle.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect1_05">17:05-17:20, Paper WeCT1.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0944.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('944'); return false" title="Click to show or hide the keywords and abstract">A Kinematic-Based Rough Terrain Control for Traction and Energy Saving of an Exploration Rover</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133064" title="Click to go to the Author Index">Kim, Jayoung</a></td><td class="r">Chungnam Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110826" title="Click to go to the Author Index">Lee, Jihong</a></td><td class="r">Chungnam National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab944" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a></span><br>
                           <strong>Abstract:</strong> This paper proposes a novel algorithm to control wheels of a rover in rough terrains with keeping traction and minimizing energy consumption on the basis of observing a change of a robot velocity from a 4WD Kinematic model. Proposed kinematic-based rough terrain control (KRTC) can satisfy a rover to meet an integrated performance of following a desired velocity while keeping maximum traction and minimizing energy use without an estimator of wheel sinkage and an observer of a dynamic parameter. KRTC consists of two main parts; a slip optimizer and a slip controller. For slip optimization, optimal slip values regarding maximum traction and tractive efficiency are derived from indoor experimental data during a wheel-terrain interaction. Optimized slip ratio is used as an input of a PID slip controller. KRTC only uses the desired velocity of the robot as an input value and gets the two feedback data of actual slip and actual velocity of each wheel. For verification, KRTC was applied to a 4WD rover and the performance was analyzed based on acquired experimental data on a variety of rough terrains.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect2"><b>WeCT2</b></a></td>
               <td class="r">#102</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect2" title="Click to go to the Program at a Glance"><b>Visual Odometry and Navigation</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#191510" title="Click to go to the Author Index">Abramov, Alexey</a></td><td class="r">Continental Teves AG</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#106877" title="Click to go to the Author Index">Taylor, Camillo Jose</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect2_01">16:05-16:20, Paper WeCT2.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0520.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('520'); return false" title="Click to show or hide the keywords and abstract">Inertial Aided Dense and Semi-Dense Methods for Robust Direct Visual Odometry</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151785" title="Click to go to the Author Index">Falquez, Juan</a></td><td class="r">Univ. of Colorado - Boulder</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181083" title="Click to go to the Author Index">Kasper, Michael</a></td><td class="r">Univ. of Colorado, Boulder</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106248" title="Click to go to the Author Index">Sibley, Gabe</a></td><td class="r">Univ. of Colorado</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab520" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> In this paper we give an evaluation of different direct methods for computing frame-to-frame motion estimates of a moving sensor rig composed of an RGB-D camera and an inertial measurement unit. In particular, we compare how semi-dense and fully dense tracking methods, with and without the aid of an inertial measurement unit (IMU), perform with respect to changes in image resolution, shutter speed, frame-rates, as well as image and depth noise. To perform an accurate and unbiased evaluation we employ a series of synthetically generated datasets using a simulated sensor rig composed of an RGB-D camera and an IMU. Our findings show that in the absence of motion blur or for cameras with high enough frame-rates relative to the camera motion, the methods are comparable when taking in consideration both accuracy and computation time.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect2_02">16:20-16:35, Paper WeCT2.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0582.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('582'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Terrain-Adaptive Obstacle Detection</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160074" title="Click to go to the Author Index">Suger, Benjamin</a></td><td class="r">Univ. of Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110224" title="Click to go to the Author Index">Steder, Bastian</a></td><td class="r">Univ. of Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101785" title="Click to go to the Author Index">Burgard, Wolfram</a></td><td class="r">Univ. of Freiburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab582" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0582.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a></span><br>
                           <strong>Abstract:</strong> Reliable detection and avoidance of obstacles is a crucial prerequisite for autonomously navigating robots as both guarantee safety and mobility. To ensure safe mobility, the obstacle detection needs to run online, thereby taking limited resources of autonomous systems into account. At the same time, robust obstacle detection is highly important. Here, a too conservative approach might restrict the mobility of the robot, while a more reckless one might harm the robot or the environment it is operating in. In this paper, we present a terrain-adaptive approach to obstacle detection that relies on 3D-Lidar data and combines computationally cheap and fast geometric features, like step height and steepness, which are updated with the frequency of the lidar sensor, with semantic terrain information, which is updated with at lower frequency. We provide experiments in which we evaluate our approach on a real robot on an autonomous run over several kilometers containing different terrain types. The experiments demonstrate that our approach is suitable for autonomous systems that have to navigate reliable on different terrain types including concrete, dirt roads and grass.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect2_03">16:35-16:50, Paper WeCT2.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0788.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('788'); return false" title="Click to show or hide the keywords and abstract">Performance Evaluation in Obstacle Avoidance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196270" title="Click to go to the Author Index">Nous, Clint Wilhelmus Maria</a></td><td class="r">TU Delft</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196268" title="Click to go to the Author Index">Meertens, Roland</a></td><td class="r">TU Delft</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131961" title="Click to go to the Author Index">De Wagter, Christophe</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131959" title="Click to go to the Author Index">de Croon, Guido</a></td><td class="r">TU Delft / ESA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab788" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a>, <a href="IROS16_KeywordIndexMedia.html#Performance_Evaluation_and_Benchmarking" title="Click to go to the Keyword Index">Performance Evaluation and Benchmarking</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> No quantitative procedure currently exists to evaluate the obstacle avoidance capabilities of robotic systems. Such an evaluation method is not only needed to compare different avoidance methods, but also to determine the operational limits of autonomous systems. This work proposes an evaluation framework which can find such limits. The framework comprises two types of tests: detection tests and avoidance tests. For each type, both environment and performance metrics need to be defined. For detection tests such metrics are well known, but for avoidance tests such metrics are not readily available. Therefore a new set of metrics is proposed. The framework is applied to a UAV that uses stereo vision to detect obstacles. Three different avoidance methods are compared in environments of varying difficulty.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect2_04">16:50-17:05, Paper WeCT2.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1020.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1020'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>The Path Less Taken: A Fast Variational Approach for Scene Segmentation Used for Closed Loop Control</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196445" title="Click to go to the Author Index">Suleymanov, Tarlan</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104229" title="Click to go to the Author Index">Paz, Lina María</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104702" title="Click to go to the Author Index">Pinies, Pedro</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196447" title="Click to go to the Author Index">Geoff, Hester</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105828" title="Click to go to the Author Index">Newman, Paul</a></td><td class="r">Oxford Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1020" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1020.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> In this paper we propose an on-line system that discovers and drives collision-free traversable paths, using a variational approach to dense stereo vision. Our system is light weight, can be run on low cost hardware and is remarkably quick to predict the semantics. In addition to the scene’s path affordance it yields a segmentation of the local scene as a composite of distinctive labels – e.g, ground, sky, obstacles and vegetation. To estimate the labels, we combine a very fast and light weight (shallow) image classifier which considers informative feature channels derived from colour images and dense depth maps estimates. Unlike other approaches, we do not use local descriptors around pixel features. Instead, we encompass label-predicted probabilities with a variational approach for image segmentation. Akin to dense depth map estimation, we obtain semantically segmented images by means of convex regularisation. We show how our system can rapidly obtain the required semantics and paths at VGA resolution. Extensive experiments on the KITTI dataset support the robustness of our system to derive collision-free local routes. An accompanied video supports the robustness of the system at live execution in an outdoor experiment.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect2_05">17:05-17:20, Paper WeCT2.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1410.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1410'); return false" title="Click to show or hide the keywords and abstract">Recovering Relative Orientation and Scale from Visual Odometry and Ranging Radio Measurements</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196937" title="Click to go to the Author Index">Shariati, Armon</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148231" title="Click to go to the Author Index">Mohta, Kartik</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106877" title="Click to go to the Author Index">Taylor, Camillo Jose</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1410" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> In this paper we propose a new approach to recovering the relative position and orientation of a pair of platforms moving on the plane by fusing the kinds of estimates provided by visual odometry systems with distance measurements obtained from ranging radio systems. By combining these two complementary sources of information we are able to provide estimates that could not be obtained using either source separately. We show that the localization problem can be phrased as an optimization problem where we are interested in maximizing a convex function subject to a set of convex constraints and we propose an efficient and effective solution scheme that leverages the structure of the problem. Experimental results are provided to demonstrate that the proposed method performs creditably on actual robotic platforms.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect3"><b>WeCT3</b></a></td>
               <td class="r">#103</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect3" title="Click to go to the Program at a Glance"><b>Trajectory Generation 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#129139" title="Click to go to the Author Index">Zanchettin, Andrea Maria</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#109387" title="Click to go to the Author Index">Rubenstein, Michael</a></td><td class="r">Northwestern Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect3_01">16:05-16:20, Paper WeCT3.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0186.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('186'); return false" title="Click to show or hide the keywords and abstract">Robust Constraint-Based Control of Robot Manipulators: An Application to a Visual Aided Grasping Task</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129139" title="Click to go to the Author Index">Zanchettin, Andrea Maria</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#10019" title="Click to go to the Author Index">Rocco, Paolo</a></td><td class="r">Pol. Di Milano</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab186" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a></span><br>
                           <strong>Abstract:</strong> Despite the availability in the literature of several constraint-based motion generation algorithms, modest atten- tion has been paid to their robustness with respect to noise, and more in general, to unstructured uncertainties. Especially in the case of sensor-related constraints, the envisaged robustness properties are clearly crucial to enforce the correct and expected behaviour of these algorithms. This paper contributes with a method to explicitly account for different sources of uncertainty. We also suggest a computational efficient way to consistently modify the constraint specification in order to obtain such robustness. An experimental verification on a visual aided grasping task where visibility of the object is to be maintained, enlighten the benefits of the proposed approach in terms of achieving the desired robustness as well as of reducing the possible chattering in terms of activation and deactivation of the constraints.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect3_02">16:20-16:35, Paper WeCT3.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0908.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('908'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Numerical Search for Local (Partial) Differential Flatness</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195795" title="Click to go to the Author Index">Sferrazza, Carmelo</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160059" title="Click to go to the Author Index">Pardo, Diego</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107589" title="Click to go to the Author Index">Buchli, Jonas</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab908" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0908.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a></span><br>
                           <strong>Abstract:</strong> Differential flatness is a property of certain systems that greatly simplifies the generation of optimal and dynamically feasible trajectories. Using a differentially flat model, there is no need to integrate the system dynamics to retrieve the states and therefore the constraints of the optimization problem are simpler. Recently, the concept of partial differential flatness has been introduced covering a broader class of systems. In particular, it allows to reduce the need for integration by limiting it to a subset of the states.	However, finding an analytical expression for the (partial) differential flatness requires the manipulation of the equations of motion in a very specific manner such that a series of properties are fulfilled. In general, finding such analytical model is not straightforward nor compatible with algorithmic models. In order to tackle this problem, in this paper we present a numerical method to find a (partially) differentially flat model of a system around a collection of states and inputs trajectories. We present results on three underactuated nonlinear systems (cart-pole, planar ballbot and a 3D	quadrotor). As use case examples, we show online trajectory re-planning tasks. The validity of the trajectories obtained with the locally flat models is verified by forward integrating the original equations of motion together with an optimal stabilizer.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect3_03">16:35-16:50, Paper WeCT3.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1072.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1072'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Autonomous Mobile Robot with Independent Control and Externally Driven Actuation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195390" title="Click to go to the Author Index">Wang, Hanlin</a></td><td class="r">Northwestern Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109387" title="Click to go to the Author Index">Rubenstein, Michael</a></td><td class="r">Northwestern Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1072" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1072.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> Complexity, cost, and power requirements for actuation of individual robots is a large factor in limiting the size of robotic swarms. Here we present a prototype robotic system that allows for externally powered motion in 2D without sacrificing individual autonomy, which simplifies the robot hardware, possibly enabling larger swarm sizes. This is accomplished using a table surface that is moving in an orbital fashion, and where robots can move to any point on the table surface simply through a series of carefully timed attachment and detachment steps.	We present a model for the robot's motion, and use this model to create a motion controller that allows the robot to move from its current position to any other position on the table in approximately a straight line. We show this controller working in simulation as well as on an experimental hardware system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect3_04">16:50-17:05, Paper WeCT3.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1327.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1327'); return false" title="Click to show or hide the keywords and abstract">Design of a Nonlinear Adaptive Natural Oscillator: Towards Natural Dynamics Exploitation in Cyclic Tasks</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169608" title="Click to go to the Author Index">Nasiri, Rezvan</a></td><td class="r">Univ. of Tehran</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147501" title="Click to go to the Author Index">Khoramshahi, Mahdi</a></td><td class="r">Univ. of Tehran</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100730" title="Click to go to the Author Index">Nili Ahmadabadi, Majid</a></td><td class="r">Univ. of Tehran</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1327" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> In this paper, we present the dynamical equations of a nonlinear adaptive natural oscillator (NANO) in order to exploit the natural dynamics in robotic systems. The presented oscillator tries to minimize an energy-based cost function by adapting the shape and frequency of the reference trajectory. Stability, convergence, and optimality of this oscillator are guaranteed analytically. Moreover, the performance of this oscillator is investigated by applying it to three different types of robotic models; i.e., the pendulum, the adaptive-toy, and the hopper-leg.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect4"><b>WeCT4</b></a></td>
               <td class="r">#104</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect4" title="Click to go to the Program at a Glance"><b>Surgical Robotics 1</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#117925" title="Click to go to the Author Index">Yang, Guang-Zhong</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#105736" title="Click to go to the Author Index">Kang, Sungchul</a></td><td class="r">Korea Inst. of Science & Tech</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect4_01">16:05-16:20, Paper WeCT4.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0173.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('173'); return false" title="Click to show or hide the keywords and abstract">Needle-Tissue Interaction Force State Estimation for Robotic Surgical Suturing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141277" title="Click to go to the Author Index">Jackson, Russell</a></td><td class="r">Case Western Res. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195181" title="Click to go to the Author Index">Desai, Viraj</a></td><td class="r">Case Western Res. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195373" title="Click to go to the Author Index">Castillo, Jean Pierre</a></td><td class="r">Case Western Res. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102610" title="Click to go to the Author Index">Cavusoglu, M. Cenk</a></td><td class="r">Case Western Res. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab173" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a></span><br>
                           <strong>Abstract:</strong> Robotically Assisted Minimally Invasive Surgery (RAMIS) offers many advantages over manual surgical techniques. Most of the limitations of RAMIS stem from its non-intuitive user interface and costs. One way to mitigate some of the limitations is to automate surgical subtasks (e.g. suturing) such that they are performed faster while allowing the surgeon to plan the next step of the procedure. One component of successful suture automation is minimizing the internal tissue deformation forces generated by driving a needle through tissue. Minimizing the internal tissue forces requires segmenting the tissue deformation forces from other components of the needle tissue interaction (e.g. friction force). This paper proposes an Unscented Kalman Filter which can successfully model the force components, in particular the internal deformation force, generated by a needle as it is driven through a sample of tissue.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect4_02">16:20-16:35, Paper WeCT4.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0282.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('282'); return false" title="Click to show or hide the keywords and abstract">3-D Force Measurement Using Single Axis Force Sensors in a New Single Port Parallel Kinematics Surgical Manipulator</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159334" title="Click to go to the Author Index">Matich, Sebastian</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159335" title="Click to go to the Author Index">Neupert, Carsten</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159336" title="Click to go to the Author Index">Kirschniak, Andreas</a></td><td class="r">Univ. Hospital Tuebingen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124499" title="Click to go to the Author Index">Schlaak, Helmut F.</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159344" title="Click to go to the Author Index">Pott, Peter</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab282" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong>  Single port surgery is an innovative approach in the &#64257;eld of minimally invasive surgery. Although several telemanipulators exist to perform operations through only a single incision they all suffer from the lack of haptic feedback. To generate kinesthetic feedback the intracorporeal forces need to be measured, which is a challenging task. To overcome these limitations we investigate in this paper the force sensing capability of a new single port robot that has two parallelkinematic manipulators. Because	of the rigidity and	excellent controllability	the tip force is measured using proximally arranged force sensors. To minimize friction effects a longitudinal vibration of 6 Hz with an amplitude of 20 µm is applied to the manipulator while the tip force is varied in the three main coordinate axes. Within the analysis 32320 values are investigated showing that a vibration has a signi&#64257;cant impact and dramatically improves the signal quality by minimizing the crosstalk by a factor of up to 12.7 enabling to measure the tip force exactly.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect4_03">16:35-16:50, Paper WeCT4.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0627.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('627'); return false" title="Click to show or hide the keywords and abstract">Expeditious Design Optimization of a Concentric Tube Robot with a Heat-Shrink Plastic Tube</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181640" title="Click to go to the Author Index">Noh, Gunwoo</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196038" title="Click to go to the Author Index">Yoon, Si Yeop</a></td><td class="r">Korea Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196042" title="Click to go to the Author Index">Yoon, Sung</a></td><td class="r">Yonsei Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157498" title="Click to go to the Author Index">Kim, Keri</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#112925" title="Click to go to the Author Index">Lee, Woosub</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105736" title="Click to go to the Author Index">Kang, Sungchul</a></td><td class="r">Korea Inst. of Science & Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102562" title="Click to go to the Author Index">Lee, Deukhee</a></td><td class="r">KIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab627" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Redundant_Robots" title="Click to go to the Keyword Index">Redundant Robots</a></span><br>
                           <strong>Abstract:</strong> Concentric tube robots require long design optimization and fabrication procedures because of their complex workspaces and the material characteristics of commonly used superelastic tubes. This paper explores a procedure for expeditious design and fabrication of a concentric tube robot for applications requiring rapid tube preparation, but having less complex design constraints. In this procedure, a 3D workspace optimization problem is reduced to a 2D problem. A heat-shrink tube is used as a component for the continuum robot to reduce fabrication time and to have a small radius of curvature. Experimental results are provided to illustrate the feasibility of the proposed procedure.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect4_04">16:50-17:05, Paper WeCT4.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1532.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1532'); return false" title="Click to show or hide the keywords and abstract">Design of a Smart 3D-Printed Wristed Robotic Surgical Instrument with Embedded Force Sensing and Modularity</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166016" title="Click to go to the Author Index">Seneci, Carlo Alberto</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157759" title="Click to go to the Author Index">Leibrandt, Konrad</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169470" title="Click to go to the Author Index">Wisanuvej, Piyamate</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132129" title="Click to go to the Author Index">Shang, Jianzhong</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117917" title="Click to go to the Author Index">Darzi, Ara</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117925" title="Click to go to the Author Index">Yang, Guang-Zhong</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1532" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Joint_Mechanism_Design" title="Click to go to the Keyword Index">Joint/Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> This paper introduces the design and characterization of a robotic surgical instrument produced mainly with rapid prototyping techniques. Surgical robots have generally complex structures and have therefore an elevate price on the market. This instrument was designed to incorporate minimal number of components to simplify the assembly process by leveraging the unique strength of rapid prototyping for producing complex, assemble-free components. The modularity, cost-effectiveness and fast manufacturing and assembly features offer the possibility of producing patient or task specific instruments. The proposed robot incorporates an integrated force measurement system, thus allowing the determination of the force exchanged between the instrument and the environment. Detailed experiments were performed to validate the functionality and force sensing capability of the instrument.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect4_05">17:05-17:20, Paper WeCT4.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1622.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1622'); return false" title="Click to show or hide the keywords and abstract">Development of Surgical Forceps Integrated with Multi-Axial Force Sensor for Minimally Invasive Robotic Surgery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150528" title="Click to go to the Author Index">Kim, Uikyum</a></td><td class="r">SungKyunKwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169516" title="Click to go to the Author Index">Kim, Yong Bum</a></td><td class="r">Sungskyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192032" title="Click to go to the Author Index">Seok, Dong-Yeop</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196879" title="Click to go to the Author Index">So, JinHo</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102438" title="Click to go to the Author Index">Choi, Hyouk Ryeol</a></td><td class="r">Sungkyunkwan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1622" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a></span><br>
                           <strong>Abstract:</strong> This paper aims to develop novel surgical forceps integrated with a three-axis force sensor for robot-assisted minimally invasive surgery (RMIS). To detect accurate force sensing, a force sensing system is integrated to a gripper of a surgical instrument. At the gripper side, two possible locations are considered, and the sensing system is installed to the distal region of the gripper, which gives major advantages such as the gripper’s minimization, palpation function, and multi-axis force sensing. Based on the capacitive-type sensing method, the sensor enables the direct measurement of the three-axis force applied to surgical gripper tip. The sensorized gripper is simply designed at a low cost, composed of only four mechanical parts, and, the forceps including two grippers are installed to an instrument that is able to conduct a grasping motion. Therefore, it is used to evaluate the performance of the force sensing system. The sensorized forceps are experimentally validated by using a commercial sensor in an experimental set-up.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect5"><b>WeCT5</b></a></td>
               <td class="r">#105</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect5" title="Click to go to the Program at a Glance"><b>Motion and Path Planning 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102662" title="Click to go to the Author Index">Amato, Nancy</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#142460" title="Click to go to the Author Index">Whittaker, William</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect5_01">16:05-16:20, Paper WeCT5.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0058.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('58'); return false" title="Click to show or hide the keywords and abstract">Motion Planning for a Reversing General 2-Trailer Configuration Using Closed-Loop RRT</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195125" title="Click to go to the Author Index">Evestedt, Niclas</a></td><td class="r">Linköpings Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195130" title="Click to go to the Author Index">Ljungqvist, Oskar</a></td><td class="r">Linköping Univ. ISY, Automatic Control</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195126" title="Click to go to the Author Index">Axehill, Daniel</a></td><td class="r">Linköping Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab58" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> Reversing with a dolly steered trailer configuration is a hard task for any driver without extensive training. In this work we present a motion planning and control framework that can be used to automatically plan and execute complicated manoeuvres. The unstable dynamics of the reversing general 2-trailer configuration with off-axle hitching is first stabilised by an LQ-controller and then a pure pursuit path tracker is used on a higher level giving a cascaded controller that can track piecewise linear reference paths. This controller together with a kinematic model of the trailer configuration is then used for forward simulations within a Closed-Loop Rapidly Exploring Random Tree framework to generate motion plans that is not only kinematically feasible but also include the limitations of the controller's tracking performance when reversing. The approach is evaluated over a series of Monte Carlo simulations on three different scenarios and impressive success rates are achieved. Finally the approach is successfully tested on a small scale test platform where the motion plan is calculated and then sent to the platform for execution.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect5_02">16:20-16:35, Paper WeCT5.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0161.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('161'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Redundancy Embedding for Search Space Reduction Using Deep Auto-Encoder: Application to Collision-Free Posture Generation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164475" title="Click to go to the Author Index">Noda, Shintaro</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117479" title="Click to go to the Author Index">Nozawa, Shunichi</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135552" title="Click to go to the Author Index">Kakiuchi, Yohei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106350" title="Click to go to the Author Index">Okada, Kei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106348" title="Click to go to the Author Index">Inaba, Masayuki</a></td><td class="r">The Univ. of Tokyo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab161" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0161.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a></span><br>
                           <strong>Abstract:</strong> For generating motions of robots, global search in configuration space is time consuming although it is sometimes indispensable (e.g. collision avoidance in complex environment). Our idea is to use global sampling algorithm not in the state space but in the task nullspace, which is the redundant degrees of freedom of the state space with respect to the task space. Because the task nullspace is smaller than the original search space (state space), fast global sampling is possible. For embedding this hidden task nullspace parameters, we propose a new deep-auto-encoder-based neural network structure. Our approach learns the map from task and task nullspace towards robot’s state (Task-State Map, TSM). As the demonstration, the relationship between 28-dof joint angles (state) and the endeffector coordinates of all limbs (task) is learned, and egress postures and reaching postures are generated.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect5_03">16:35-16:50, Paper WeCT5.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0473.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('473'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Navigation among Movable Obstacles with Learned Dynamic Constraints</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137719" title="Click to go to the Author Index">Scholz, Jonathan</a></td><td class="r">Google Deepmind</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195832" title="Click to go to the Author Index">Jindal, Nehchal</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137102" title="Click to go to the Author Index">Levihn, Martin</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155300" title="Click to go to the Author Index">Isbell, Charles</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102379" title="Click to go to the Author Index">Christensen, Henrik Iskov</a></td><td class="r">Georgia Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab473" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0473.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mobile_Manipulation" title="Click to go to the Keyword Index">Mobile Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a></span><br>
                           <strong>Abstract:</strong> In this paper we present the first planner for the problem of Navigation Among Movable Obstacles (NAMO) on a real robot that can handle environments with under-specified object dynamics. This result makes use of recent progress from two threads of the Reinforcement Learning literature. The first is a hierarchical Markov-Decision Process formulation of the NAMO problem designed to handle dynamics uncertainty. The second is a physics-based Reinforcement Learning framework which offers a way to ground this uncertainty in a compact model space that can be efficiently updated from data received by the robot online. Our results demonstrate the ability of a robot to adapt to unexpected object behavior in a real office scenario.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect5_04">16:50-17:05, Paper WeCT5.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0566.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('566'); return false" title="Click to show or hide the keywords and abstract">BI^2RRT*: An Efficient Sampling-Based Path Planning Framework for Task-Constrained Mobile Manipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160145" title="Click to go to the Author Index">Burget, Felix</a></td><td class="r">Univ. of Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113220" title="Click to go to the Author Index">Bennewitz, Maren</a></td><td class="r">Univ. of Bonn</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101785" title="Click to go to the Author Index">Burgard, Wolfram</a></td><td class="r">Univ. of Freiburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab566" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> Mobile manipulators installed in warehouses and factories for conveying goods between working stations need to meet the requirements of time-critical workflows. Moreover, the systems are expected to deal with changing tasks, cluttered environments and constraints imposed by the goods to be delivered. In this paper, we present a novel planning framework for generating asymptotically optimal paths for mobile manipulators subject to task constraints. Our approach introduces the Bidirectional Informed RRT* (BI^2RRT*) that extends the Informed RRT* [1] towards bidirectional search and satisfaction of end-effector task constraints. In various experiments, we demonstrate the efficiency of BI^2RRT* for both unconstrained and constrained mobile manipulation planning problems. As the results show, our planning framework finds better solutions than Informed RRT* and Bidirectional RRT* in less planning.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect5_05">17:05-17:20, Paper WeCT5.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1328.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1328'); return false" title="Click to show or hide the keywords and abstract">Computationally Efficient Information-Theoretic Exploration of Pits and Caves</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191266" title="Click to go to the Author Index">Tabib, Wennie</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180547" title="Click to go to the Author Index">Corah, Micah</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111260" title="Click to go to the Author Index">Michael, Nathan</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142460" title="Click to go to the Author Index">Whittaker, William</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1328" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> We present a real-time, kinodynamic planning and information-theoretic exploration framework that enables high-resolution mapping of three-dimensional environments featuring complex concavities and disjoint objects. The proposed approach targets planetary exploration applications and seeks to achieve real-time operation on computationally constrained systems while ensuring energy-efficient information acquisition. Trajectories are selected by maximizing a measure of information gain per an expected execution cost (e.g., time or energy). The proposed trajectory generation formulation is based on state-lattice motion primitives and evaluation of the Cauchy-Schwarz Quadratic Mutual Information (CSQMI) at each lattice state. An expanded search structure is proposed that extends the state-lattice to a finite horizon to enable expansive space coverage while remaining real-time viable. Additionally, we utilize compression techniques that reduce the computational burden associated with the CSQMI calculation over expansive environments while preserving fidelity. The performance of the proposed methodology is evaluated through simulated exploration of a three-dimensional pit environment by a quadrotor aerial robot, an effective platform for terrestrial exploration and a reasonable surrogate for a propulsive vehicle operating on an airless body.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect6"><b>WeCT6</b></a></td>
               <td class="r">#106</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect6" title="Click to go to the Program at a Glance"><b>Optimal Control and Optimization</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#175180" title="Click to go to the Author Index">Wahrburg, Arne</a></td><td class="r">ABB AG, Corp. Res. Germany</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#104326" title="Click to go to the Author Index">Peters, Jan</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect6_01">16:05-16:20, Paper WeCT6.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0296.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('296'); return false" title="Click to show or hide the keywords and abstract">Particle Filter Framework for 6D Seam Tracking under Large External Forces Using 2D Laser Sensors</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165299" title="Click to go to the Author Index">Bagge Carlson, Fredrik</a></td><td class="r">Lund Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185080" title="Click to go to the Author Index">Karlsson, Martin</a></td><td class="r">Lund Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104739" title="Click to go to the Author Index">Robertsson, Anders</a></td><td class="r">LTH, Lund Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#10013" title="Click to go to the Author Index">Johansson, Rolf</a></td><td class="r">Lund Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab296" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> We provide a framework for 6 DOF pose estimation in seam-tracking applications using particle filtering. The particle filter algorithm developed incorporates measurements from both a 2 DOF laser seam tracker and the robot forward kinematics under an assumed external force. Special attention is paid to modeling of disturbances in the respective measurements, and methods are developed to assist the selection of sensor configurations for optimal estimation performance. The developed estimation algorithm and simulation environment are provided as an open-source, extendable package, written with an intended balance between readability and performance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect6_02">16:20-16:35, Paper WeCT6.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0573.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('573'); return false" title="Click to show or hide the keywords and abstract">Improving Contact Force Estimation Accuracy by Optimal Redundancy Resolution</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#175180" title="Click to go to the Author Index">Wahrburg, Arne</a></td><td class="r">ABB AG, Corp. Res. Germany</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104739" title="Click to go to the Author Index">Robertsson, Anders</a></td><td class="r">LTH, Lund Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159302" title="Click to go to the Author Index">Matthias, Björn</a></td><td class="r">ABB AG, Corp. Res. Center Germany</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191926" title="Click to go to the Author Index">Dai, Fan</a></td><td class="r">ABB AG, Corp. Res. Germany</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#120269" title="Click to go to the Author Index">Ding, Hao</a></td><td class="r">ABB Corp. Res. Center Germany</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab573" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Redundant_Robots" title="Click to go to the Keyword Index">Redundant Robots</a></span><br>
                           <strong>Abstract:</strong> Estimating Cartesian contact forces and torques enables external force supervision for robotic manipulators and even force-controlled applications while avoiding the need for additional external sensing. Redundant manipulators facilitate the problem of Cartesian contact force and torque estimation (CCFE) at the TCP, since an increased amount of joint level information is available for estimating the six components of external wrench. In this paper, we point out that the errors in CCFE estimates arising from inevitable uncertainties in available joint level information (either measurements or estimates) depend on the manipulator configuration. Based on this, an algorithm is proposed that resolves redundancy in an optimal way with respect of the achievable CCFE quality. For a given TCP pose, the joint configuration resulting in minimized CCFE errors is calculated. The proposed method is verified by means of experimental data gathered from a 7DOF manipulator.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect6_03">16:35-16:50, Paper WeCT6.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0949.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('949'); return false" title="Click to show or hide the keywords and abstract">Pareto-Optimal Search Over Configuration Space Beliefs for Anytime Motion Planning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195811" title="Click to go to the Author Index">Choudhury, Shushman</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148218" title="Click to go to the Author Index">Dellin, Christopher</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105832" title="Click to go to the Author Index">Srinivasa, Siddhartha</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab949" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a></span><br>
                           <strong>Abstract:</strong> We present POMP (Pareto Optimal Motion Planner), an anytime algorithm for geometric path planning on roadmaps. For robots with several degrees of freedom, collision checks are computationally expensive and often dominate planning time. Our goal is to minimize the number of collision checks for obtaining the first feasible path and successively shorter feasible paths. We assume that the roadmaps we search over are embedded in a continuous ambient space, where nearby points tend to share the same collision state. This enables us to formulate a probabilistic model that assigns to unevaluated configurations their probability of being collision-free. We update the model over time as more checks are performed. This model lets us define a weighting function for roadmap edges that is related to the probability of the edge being in collision. Our approach is to trade off between these two weights, gradually prioritizing edge length over collision likelihood. We also show that this tradeoff is approximately equivalent to minimizing the expected path length, with a penalty of being in collision. Our experiments demonstrate that POMP performs comparably with RRTConnect and LazyPRM for the first feasible path, and BIT* for anytime performance, both in terms of collision checks and total planning time.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect6_04">16:50-17:05, Paper WeCT6.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1079.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1079'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A New Trajectory Generation Framework in Robotic Table Tennis</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155749" title="Click to go to the Author Index">Koc, Okan</a></td><td class="r">Max Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135672" title="Click to go to the Author Index">Maeda, Guilherme Jorge</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104326" title="Click to go to the Author Index">Peters, Jan</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1079" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1079.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a></span><br>
                           <strong>Abstract:</strong> In highly dynamic tasks that involve moving targets, planning is necessary to figure out when, where and how to intercept the target. In robotic table tennis in particular, motion planning can be very challenging due to time constraints, dimension of the search space and modelling uncertainties. To simplify the problem, conventional planning algorithms often rely on a fixed virtual hitting plane to construct robot striking trajectories. These algorithms however generate restrictive strokes and can result in unnatural strategies when compared with human playing. In this paper, we introduce a new trajectory generation framework for robotic table tennis. We use a free-time optimal control approach to construct a novel planning algorithm that does not involve a fixed hitting plane. Furthermore, we estimate the parameters of our prediction models using human demonstrations. The resulting trajectories have lower accelerations while the joint constraints are enforced at all times. Our algorithm returns the balls with a higher probability to the opponent's court in our realistic simulation environment when compared with a virtual hitting plane based method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect6_05">17:05-17:20, Paper WeCT6.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1100.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1100'); return false" title="Click to show or hide the keywords and abstract">Sequential Alternating Least Squares for Solving High Dimensional Linear Hamilton-Jacobi-Bellman Equation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195554" title="Click to go to the Author Index">Stefansson, Elis</a></td><td class="r">KTH Royal Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195403" title="Click to go to the Author Index">Leong, Yoke Peng</a></td><td class="r">California Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1100" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> This paper presents a technique to efficiently solve the Hamilton-Jacobi-Bellman (HJB) equation for a class of stochastic affine nonlinear dynamical systems in high dimensions. The HJB solution provides a globally optimal controller to the associated dynamical system. However, the curse of dimensionality, commonly found in robotic systems, prevents one from solving the HJB equation naively. This work avoids the curse by representing the linear HJB equation using tensor decomposition. An alternating least squares (ALS) based technique finds an approximate solution to the linear HJB equation. A straightforward implementation of the ALS algorithm results in ill-conditioned matrices that prevent approximation to a high order of accuracy. This work resolves the ill-conditioning issue by computing the solution sequentially and introducing boundary condition rescaling. Both of these additions reduce the condition number of matrices in the ALS-based algorithm. A MATLAB tool, Sequential Alternating Least Squares (SeALS), that implements the new method is developed. The performance of SeALS is illustrated using three engineering examples: an inverted pendulum, a Vertical Takeoff and Landing aircraft, and a quadcopter with state up to twelve.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect7"><b>WeCT7</b></a></td>
               <td class="r">#107</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect7" title="Click to go to the Program at a Glance"><b>Learning from Demonstration</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#131870" title="Click to go to the Author Index">Wu, Yan</a></td><td class="r">A*STAR Inst. for Infocomm Res</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#109029" title="Click to go to the Author Index">Lesire, Charles</a></td><td class="r">ONERA</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect7_01">16:05-16:20, Paper WeCT7.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0151.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('151'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Dynamic Movement Primitives Plus: For Enhanced Reproduction Quality and Efficient Trajectory Modification Using Truncated Kernels and Local Biases</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195319" title="Click to go to the Author Index">Wang, Ruohan</a></td><td class="r">A*STAR Inst. of Infocomm Res</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131870" title="Click to go to the Author Index">Wu, Yan</a></td><td class="r">A*STAR Inst. for Infocomm Res</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177053" title="Click to go to the Author Index">Chan, Wei Liang</a></td><td class="r">Inst. for Infocomm Res</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107157" title="Click to go to the Author Index">Tee, Keng Peng</a></td><td class="r">Inst. for Infocomm Res</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab151" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0151.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Motor_Skill_Learning" title="Click to go to the Keyword Index">Motor Skill Learning</a></span><br>
                           <strong>Abstract:</strong> Dynamic Movement Primitives (DMPs) are a generic approach for trajectory modeling in an attractor landscape based on differential dynamical systems. DMPs guarantee stability and convergence properties of learned trajectories, and scale well to high dimensional data. In this paper, we propose DMP+, a modified formulation of DMPs which, while preserving the desirable properties of the original, 1) achieves lower mean square error (MSE) with equal number of kernels, and 2) allows learned trajectories to be efficiently modified by updating a subset of kernels. The ability to efficiently modify learned trajectories i) improves reusability of existing primitives, and ii) reduces user fatigue during imitation learning as errors during demonstration may be corrected later without requiring another complete demonstration. In addition, DMP+ may be used with existing DMP techniques for trajectory generalization and thus complements them. We compare the performance of our proposed approach against DMPs in learning trajectories of handwritten characters, and show that DMP+ achieves lower MSE in position deviation. We demonstrate in a second experiment that DMP+ can efficiently update a learned trajectory by updating only a subset of kernels. The update algorithm achieves modeling accuracy comparable to learning the adapted trajectory with the original DMPs.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect7_02">16:20-16:35, Paper WeCT7.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1067.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1067'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Learning Manipulation Actions from Human Demonstrations</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177085" title="Click to go to the Author Index">Welschehold, Tim</a></td><td class="r">Albert-Ludwigs-Univ. Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109383" title="Click to go to the Author Index">Dornhege, Christian</a></td><td class="r">Univ. of Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101785" title="Click to go to the Author Index">Burgard, Wolfram</a></td><td class="r">Univ. of Freiburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1067" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1067.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Centered_Robotics" title="Click to go to the Keyword Index">Human Centered Robotics</a></span><br>
                           <strong>Abstract:</strong> Learning from demonstration is a popular approach for teaching robots as it allows service robots to acquire new skills without explicit programming. However, for manipulation actions mostly kinesthetic teaching is used as these actions require precise knowledge about the interactions between the robot and the object. In this paper, we present a novel approach that allows a robot to learn actions carried out by a teacher from observations. We achieve this by first transforming RGBD observations to consistent hand-object trajectories, which are then adapted to the robot's grasping capabilities. Experimental results show that the robot is able to learn complex tasks such as opening doors or drawers.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect7_03">16:35-16:50, Paper WeCT7.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1332.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1332'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Do What I Want, Not What I Did: Imitation of Skills by Planning Sequences of Actions</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171475" title="Click to go to the Author Index">Paxton, Chris</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196553" title="Click to go to the Author Index">Jonathan, Felix</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124270" title="Click to go to the Author Index">Kobilarov, Marin</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104128" title="Click to go to the Author Index">Hager, Gregory</a></td><td class="r">Johns Hopkins Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1332" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1332.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong>  We propose a learning-from-demonstration approach for grounding actions from expert data and an algorithm for using these actions to perform a task in new environments. Our approach is based on an application of sampling-based motion planning to search through the tree of discrete, high-level actions constructed from a symbolic representation of a task. Recursive sampling-based planning is used to explore the space of possible continuous-space instantiations of these actions. We demonstrate the utility of our approach with a magnetic structure assembly task, showing that the robot can intelligently select a sequence of actions in different parts of the workspace and in the presence of obstacles. This approach can better adapt to new environments by selecting the correct high-level actions for the particular environment while taking human preferences into account.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect7_04">16:50-17:05, Paper WeCT7.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1453.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1453'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Learning Dexterous Manipulation for a Soft Robotic Hand from Human Demonstrations</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180419" title="Click to go to the Author Index">Gupta, Abhishek</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122977" title="Click to go to the Author Index">Eppner, Clemens</a></td><td class="r">Tech. Univ. Berlin</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156706" title="Click to go to the Author Index">Levine, Sergey</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107568" title="Click to go to the Author Index">Abbeel, Pieter</a></td><td class="r">UC Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1453" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1453.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a></span><br>
                           <strong>Abstract:</strong> Dexterous multi-fingered hands can accomplish fine manipulation behaviors that are infeasible with simple robotic grippers. However, sophisticated multi-fingered hands are often expensive and fragile. Low-cost soft hands offer an appealing alternative to more conventional devices, but present considerable challenges in sensing and actuation, making them difficult to apply to more complex manipulation tasks. In this paper, we describe an approach to learning from demonstration that can be used to train soft robotic hands to perform dexterous manipulation tasks. Our method uses object-centric demonstrations, where a human demonstrates the desired motion of manipulated objects with their own hands, and the robot autonomously learns to imitate these demonstrations using reinforcement learning. We propose a novel algorithm that allows us to blend and select a subset of the most feasible demonstrations, which we use with an extension of the guided policy search framework that learns generalizable neural network policies. We demonstrate our approach on the RBO Hand 2, with learned motor skills for turning a valve, manipulating an abacus, and grasping.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect8"><b>WeCT8</b></a></td>
               <td class="r">#108</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect8" title="Click to go to the Program at a Glance"><b>Swarm Robotics</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#110886" title="Click to go to the Author Index">Dorigo, Marco</a></td><td class="r">Univ. Libre De Bruxelles</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#118282" title="Click to go to the Author Index">Chung, Soon-Jo</a></td><td class="r">Caltech</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect8_01">16:05-16:20, Paper WeCT8.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0445.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('445'); return false" title="Click to show or hide the keywords and abstract">Buzz: An Extensible Programming Language for Heterogeneous Swarm Robotics</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122871" title="Click to go to the Author Index">Pinciroli, Carlo</a></td><td class="r">Ec. Pol. De Montreal</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189409" title="Click to go to the Author Index">Beltrame, Giovanni</a></td><td class="r">Ec. Pol. De Montreal</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab445" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Control_Architectures_and_Programming" title="Click to go to the Keyword Index">Control Architectures and Programming</a></span><br>
                           <strong>Abstract:</strong> We present Buzz, a novel programming language for heterogeneous robot swarms. Buzz advocates a compositional approach, offering primitives to define swarm behaviors both from the perspective of the single robot and of the overall swarm.	Single-robot primitives include robot-specific instructions and manipulation of neighborhood data. Swarm-based primitives allow for the dynamic management of robot teams, and for sharing information globally across the swarm. Self-organization stems from the completely decentralized mechanisms upon which the Buzz run-time platform is based. The language can be extended to add new primitives (thus supporting heterogeneous robot swarms), and its run-time platform is designed to be laid on top of other frameworks, such as Robot Operating System. We showcase the capabilities of Buzz by providing code examples, and analyze scalability and robustness of the run-time platform through realistic simulated experiments with representative swarm algorithms.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect8_02">16:20-16:35, Paper WeCT8.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0531.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('531'); return false" title="Click to show or hide the keywords and abstract">Consensus-Based Data Sharing for Large-Scale Aerial Swarm Coordination in Lossy Communications Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128560" title="Click to go to the Author Index">Davis, Duane</a></td><td class="r">Naval Postgraduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106700" title="Click to go to the Author Index">Chung, Timothy H.</a></td><td class="r">DARPA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178888" title="Click to go to the Author Index">Clement, Michael</a></td><td class="r">Naval Postgraduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155837" title="Click to go to the Author Index">Day, Michael A.</a></td><td class="r">U.S. Naval Postgraduate School</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab531" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a></span><br>
                           <strong>Abstract:</strong> Increasing unmanned aerial vehicle (UAV) capabilities and decreasing costs have facilitated growing interest in the development of large, multi-UAV systems, or swarms. The constrained communications environments in which these swarms operate, however, have limited the development of behaviors that require a high degree of deliberative coordination. This work presents two algorithms that use a consensus-algorithm approach to reliably exchange information throughout large swarms as a means of facilitating swarm behavior coordination. Results from experiments conducted in simulation and live-fly exercises are presented and discussed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect8_03">16:35-16:50, Paper WeCT8.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0946.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('946'); return false" title="Click to show or hide the keywords and abstract">Kilogrid: A Modular Virtualization Environment for the Kilobot Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195661" title="Click to go to the Author Index">Antoun, Anthony</a></td><td class="r">Univ. Libre De Bruxelles</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167529" title="Click to go to the Author Index">Valentini, Gabriele</a></td><td class="r">Univ. Libre De Bruxelles</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192917" title="Click to go to the Author Index">Hocquard, Etienne</a></td><td class="r">Inst. De Recherche Tech. Jules Verne</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195743" title="Click to go to the Author Index">Wiandt, Bernát</a></td><td class="r">Budapest Univ. of Tech. and Ec</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147423" title="Click to go to the Author Index">Trianni, Vito</a></td><td class="r">Consiglio Nazionale Delle Ricerche</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110886" title="Click to go to the Author Index">Dorigo, Marco</a></td><td class="r">Univ. Libre De Bruxelles</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab946" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a></span><br>
                           <strong>Abstract:</strong> We introduce the Kilogrid, a modular and scalable virtualization environment aimed at swarm robotics research with the Kilobot robot. The main purpose of the Kilogrid is to complement the Kilobots by overcoming some of their limitations (i.e., limited sensors and actuators), making it easier to experiment and to collect data with large groups of robots. The Kilogrid allows researchers to study scenarios featuring a level of complexity that cannot be reached using the Kilobots alone. The Kilogrid is composed of several modules, where each module contains four cells of 50 x 50 mm<sup>2</sup>. The cells allow for bi-directional communication with the Kilobots. Our first version of a Kilogrid is composed of 64 cells and covers a total area of 400 x 400 mm<sup>2</sup>. We demonstrate the features of the Kilogrid with two case studies in which: (i) we extend the sensory system of the Kilobots, (ii) we allow the Kilobots to modify the environment, and (iii) we collect data (e.g., position, state) from the Kilobots while the experiment is running.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect8_04">16:50-17:05, Paper WeCT8.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1417.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1417'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>The MPFA: A Multiple-Place Foraging Algorithm for Biologically-Inspired Robot Swarms</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189075" title="Click to go to the Author Index">Lu, Qi</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157419" title="Click to go to the Author Index">Hecker, Joshua Peter</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156591" title="Click to go to the Author Index">Moses, Melanie</a></td><td class="r">Univ. of New Mexico</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1417" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1417.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Evolutionary_Robotics" title="Click to go to the Keyword Index">Evolutionary Robotics</a></span><br>
                           <strong>Abstract:</strong> Finding and retrieving resources in unmapped environments is an important and difficult challenge for robot swarms. Central-place foraging algorithms can be tuned to produce efficient collective strategies for different resource distributions. However, efficiency decreases as swarm size scales up: larger swarms produce more inter-robot collisions and increase competition for resources. We propose a novel extension to central-place foraging in which multiple nests are distributed in the environment. In this multiple-place foraging algorithm, robots depart from a home nest but always return to the nest closest to them. We simulate robot swarms that mimic foraging ants using the multiple-place strategy, employing a genetic algorithm to optimize their behavior in the robot simulator ARGoS. Experiments show that multiple nests produce higher foraging rates and lower average travel time compared to central-place foraging for three different resource distributions. Time spent avoiding robot-robot collisions is not always reduced as was expected, primarily because the use of pheromone-like waypoints leads to more collisions when robots forage for clustered resources. These results demonstrate the importance of careful design in order to create efficient multiple collection points to mitigate the central-place bottleneck for foraging robot swarms.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect8_05">17:05-17:20, Paper WeCT8.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1437.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1437'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Probabilistic Eulerian Approach for Motion Planning of a Large-Scale Swarm of Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170358" title="Click to go to the Author Index">Bandyopadhyay, Saptarshi</a></td><td class="r">Univ. of Illinois at Urbana-Champaign</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#118282" title="Click to go to the Author Index">Chung, Soon-Jo</a></td><td class="r">Univ. of Illinois at Urbana-Champaign</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172606" title="Click to go to the Author Index">Hadaegh, Fred</a></td><td class="r">Jet Propulsion Lab</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1437" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1437.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a></span><br>
                           <strong>Abstract:</strong> We present a novel method for guiding a large-scale swarm of autonomous agents into a desired formation shape in a distributed and scalable manner. Our Probabilistic Swarm Guidance using Inhomogeneous Markov Chains (PSG–IMC) algorithm adopts an Eulerian framework, where the physical space is partitioned into bins and the swarm’s density distribution over each bin is controlled. Each agent determines its bin transition probabilities using a time-inhomogeneous Markov chain. These time-varying Markov matrices are constructed by each agent in real-time using the feedback from the current swarm distribution, which is estimated in a distributed manner. The PSG–IMC algorithm minimizes the expected cost of the transitions per time instant, required to achieve and maintain the desired formation shape, even when agents are added to or removed from the swarm. The algorithm scales well with a large number of agents and complex formation shapes. We demonstrate the effectiveness of this proposed swarm guidance algorithm by using results of numerical simulations and hardware experiments with multiple quadrotors.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect9"><b>WeCT9</b></a></td>
               <td class="r">#204~205</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect9" title="Click to go to the Program at a Glance"><b>Force Control 3</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#105401" title="Click to go to the Author Index">Tsagarakis, Nikos</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#103684" title="Click to go to the Author Index">Inoue, Takahiro</a></td><td class="r">Okayama Prefectural Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect9_01">16:05-16:20, Paper WeCT9.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0194.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('194'); return false" title="Click to show or hide the keywords and abstract">Force Control on Antagonistic Twist-Drive Actuator Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103684" title="Click to go to the Author Index">Inoue, Takahiro</a></td><td class="r">Okayama Prefectural Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183499" title="Click to go to the Author Index">Miyata, Ryuichi</a></td><td class="r">Okayama Prefectural Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102549" title="Click to go to the Author Index">Hirai, Shinichi</a></td><td class="r">Ritsumeikan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab194" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Joint_Mechanism_Design" title="Click to go to the Keyword Index">Joint/Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Variable_Stiffness_Actuator_Design_and_Control" title="Click to go to the Keyword Index">Variable Stiffness Actuator Design and Control</a></span><br>
                           <strong>Abstract:</strong> In recent researches relating to robotic fingers, a novel power transmission mechanism had been designed, and developed as Twist-drive Actuators or Twisted String Actuator systems (TSA). These actuation structures, state of the art, include compact designs, light-weight mechanical structures, inherent compliance, and variable gearing, resulting in the fabrication of anthropomorphic robotic hands. However, those studies mentioned position control of the joint, and focused on the control performance of the pulling forces of a twisted string. This paper, therefore, introduces a novel joint mechanism composed of an Antagonistically-twisted Round-belt Actuator (ARA), which is able to make rotating motion by means of contraction forces induced by twisting small-diameter elastic round-belts. A noteworthy point in this paper is that the ARA robot is extremely well-suited for contact force control, which is exerted on the tip of the single joint robot. First, we demonstrate the existence of hysteresis characteristics of static contraction forces induced by the round-belt twisting, in which three belts are simultaneously twisted at constant low-speed. In addition, there exists a stress relaxation phenomenon when strongly twisting the elastic round-belts. We reveal that such sorts of discontinuous and nonlinear properties do not influence control performance in either the contraction force on the belts or contact force on the tip of the robot. Finally, this paper clearly shows stable and accurate tracking performance of the contact force of the ARA robot. In these experiments, we newly develop a twin/triple-twisted round-belt structure for the agonist side actuator, thus enhancing the contact forces effectively.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect9_02">16:20-16:35, Paper WeCT9.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0514.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('514'); return false" title="Click to show or hide the keywords and abstract">Force-Mode Control of Rotary Series Elastic Actuators in a Lower Extremity Exoskeleton Using Model-Inverse Time Delay Control (MiTDC)</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185137" title="Click to go to the Author Index">Kim, Suin</a></td><td class="r">Ulsan National Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109405" title="Click to go to the Author Index">Bae, Joonbum</a></td><td class="r">UNIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab514" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a></span><br>
                           <strong>Abstract:</strong> For physical human-robot interaction (pHRI), it has been an important issue to control the output force of actuators. The aim of this study was to apply a new control strategy, named model-inverse time delay control (MiTDC), to series elastic actuators (SEA) in a lower extremity exoskeleton, even in the presence of uncertainties from pHRI. The law for time delay control (TDC) is derived and implementation issues are discussed, including the design of the state observer and the selection of the nominal value of the control distribution coefficient. Additionally, a new concept, a new reference position using the inverse of model dynamics, is introduced to realize satisfactory tracking performance without delay. Experimental results showed that the suggested controller achieved satisfactory performance without accurate information on system parameters, requiring only a nominal value of the control distribution coefficient.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect9_03">16:35-16:50, Paper WeCT9.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0699.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('699'); return false" title="Click to show or hide the keywords and abstract">Comparison of Open-Loop and Closed-Loop Disturbance Observers for Series Elastic Actuators</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159791" title="Click to go to the Author Index">Roozing, Wesley</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122490" title="Click to go to the Author Index">Malzahn, Jörn</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100179" title="Click to go to the Author Index">Caldwell, Darwin G.</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105401" title="Click to go to the Author Index">Tsagarakis, Nikos</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab699" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Joint_Mechanism_Design" title="Click to go to the Keyword Index">Joint/Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> This contribution compares two approaches for applying disturbance observers (DOBs) to the torque control problem of series elastic actuators (SEAs). It is demonstrated that they are in fact equivalent for linear models in terms of their ability to reject disturbances and enforce nominal model dynamics.<p>The closed loop and error transfer functions for the DOB-based approaches are compared to a fully linear plant and a nonlinear plant without DOB. Simulations demonstrate that the DOBs are able to increase the bandwidth of the nonlinear plant significantly, up to that of the linear plant. Furthermore, the DOBs significantly increase the tracking accuracy at low frequencies.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect9_04">16:50-17:05, Paper WeCT9.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0734.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('734'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Impedance Control of an Aerial-Manipulator: Preliminary Results</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165071" title="Click to go to the Author Index">Cataldi, Elisabetta</a></td><td class="r">Univ. of Cassino and Southern Lazio</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147577" title="Click to go to the Author Index">Muscio, Giuseppe</a></td><td class="r">Univ. Degli Studi Della Basilicata</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151070" title="Click to go to the Author Index">Trujillo, Miguel Angel</a></td><td class="r">Center for Advanced Aerospace Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192208" title="Click to go to the Author Index">Rodriguez, Yamnia</a></td><td class="r">DLR</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107212" title="Click to go to the Author Index">Pierri, Francesco</a></td><td class="r">Univ. Della Basilicata</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#10004" title="Click to go to the Author Index">Antonelli, Gianluca</a></td><td class="r">Univ. of Cassino and Southern Lazio</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#10006" title="Click to go to the Author Index">Caccavale, Fabrizio</a></td><td class="r">Univ. Degli Studi Della Basilicata</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104459" title="Click to go to the Author Index">Viguria, Antidio</a></td><td class="r">Center for Advanced Aerospace Tech. (CATEC)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#10029" title="Click to go to the Author Index">Chiaverini, Stefano</a></td><td class="r">Univ. Di Cassino E Del Lazio Meridionale</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104455" title="Click to go to the Author Index">Ollero, Anibal</a></td><td class="r">Univ. of Seville</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab734" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0734.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> In this paper, an impedance control scheme for aerial robotic manipulators is proposed with the aim of reducing the end-effector forces in the presence of interaction with the environment. The proposed control is characterized by a multilevel architecture: the outer loop is composed by a planner that designs the end-effector trajectory and an impedance control algorithm that modifies such trajectory to achieve the desired compliant behavior; the middle loop includes an inverse kinematics algorithm that generates the motion references; finally, the inner loop, composed of a dynamic controller, ensures motion tracking. The proposed control architecture has been experimentally tested.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect9_05">17:05-17:20, Paper WeCT9.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0754.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('754'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Snake Robots in Contact with the Environment: Influence of the Configuration on the Applied Wrench</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180366" title="Click to go to the Author Index">Reyes, Fabian</a></td><td class="r">Ritsumeikan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101808" title="Click to go to the Author Index">Ma, Shugen</a></td><td class="r">Ritsumeikan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab754" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0754.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a></span><br>
                           <strong>Abstract:</strong> Robots capable of both locomotion and interaction with the environment are necessary for robots to move from idea laboratory situations to real applications. Snake robots have been researched for locomotion in unstructured environments due to its unique and adaptable gaits. However, they have not been used to interact with the environment in a dexterous manner, for example to grasp or push an object. In this paper, the model of a snake robot in contact with external objects (or the environment) is derived. Metrics that are coordinate-independent are derived in order to quantify the wrench that a snake robot could exert into these objects. In particular, we show that the configuration of the robot plays a significant role in this metrics. The model and metrics are tested in a study case.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="wect10"><b>WeCT10</b></a></td>
               <td class="r">#206~208</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#wect10" title="Click to go to the Program at a Glance"><b>Legged Robots 3</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#106235" title="Click to go to the Author Index">Manocha, Dinesh</a></td><td class="r">Univ. of North Carolina at Chapel Hill</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#100730" title="Click to go to the Author Index">Nili Ahmadabadi, Majid</a></td><td class="r">Univ. of Tehran</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect10_01">16:05-16:20, Paper WeCT10.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0661.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('661'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Biped Robot Falling Motion Control with Human-Inspired Active Compliance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#152071" title="Click to go to the Author Index">Luo, Dingsheng</a></td><td class="r">Peking Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196107" title="Click to go to the Author Index">Deng, Yian</a></td><td class="r">Peking Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177014" title="Click to go to the Author Index">Han, Xiaoqiang</a></td><td class="r">School of EECS, Peking Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158375" title="Click to go to the Author Index">Wu, Xihong</a></td><td class="r">Peking Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab661" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0661.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> Protecting robot from broken of falling is always a challenge issue for a bipedal humanoid robot in dealing with various locomotion related tasks to serve human society, especially as the assigned tasks turns increasingly complicated and the corresponding real environment gets more and more complex. Unlike several previous successful approaches on humanoid falling control, in this study, a new approach is suggested in the light of how human do when a fall happens. The proposed approach takes a tripod-like falling controller followed by a human-inspired active compliance strategy using joints' active flexion and torque increment. Therefore, robot falling action covers both stages of a fall, i.e. before and after landing impact, so that to reduce the fall damage as far as possible. And the tripod like posture prevents accumulation of kinetic energy, while the active compliance absorbs the impact energy in a tender way. Meanwhile, considering the complexity of robot dynamics, other than taking expert experiences, the proposed human-inspired falling control strategy is parametrically modelled and optimized with policy gradient reinforcement learning. Experiments on both simulation and real robot PKU-HR5.1 are performed, and the results demonstrate this approach is effective and promising.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect10_02">16:20-16:35, Paper WeCT10.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0791.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('791'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Minimum Time Sprinting from Rest in a Planar Quadruped</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196179" title="Click to go to the Author Index">Steenkamp, Neil Francois</a></td><td class="r">Univ. of Cape Town</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164571" title="Click to go to the Author Index">Patel, Amir</a></td><td class="r">Univ. of Cape Town</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab791" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0791.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a></span><br>
                           <strong>Abstract:</strong> Animals are able to accelerate rapidly from rest with incredible dexterity but these transient motions are poorly understood. Here we present the first examination of the time optimal behaviour of a quadruped sprinting from rest. We develop a planar multi-body model and employ modern trajectory optimization methods to produce a motion without prescribing periodicity or foot contact order. Our trajectories produce several similarities with racing greyhounds. These results will inspire the design of feedback controllers for future manoeuvrable quadruped robots.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect10_03">16:35-16:50, Paper WeCT10.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0899.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('899'); return false" title="Click to show or hide the keywords and abstract">Probabilistic Foot Contact Estimation by Fusing Information from Dynamics and Differential/Forward Kinematics</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172467" title="Click to go to the Author Index">Hwangbo, Jemin</a></td><td class="r">Swiss Federal Inst. of Tech. Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193489" title="Click to go to the Author Index">Bellicoso, C. Dario</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146641" title="Click to go to the Author Index">Fankhauser, Péter</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114045" title="Click to go to the Author Index">Hutter, Marco</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab899" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_and_Compliant_Assembly" title="Click to go to the Keyword Index">Manipulation and Compliant Assembly</a></span><br>
                           <strong>Abstract:</strong> Legged robots require a robust and fast responding feet contact detection strategy. Common force sensors are often too heavy and can be easily damaged during impacts. Therefore, it is desirable to detect a contact without a force sensor. This paper introduces a probabilistic contact detection strategy which considers full dynamics and differential/forward kinematics to maximize the use of available information for contact estimation. We show that the proposed strategy is much more accurate than the state-of-the-art strategy that only take one measure into account, both in simulation and with a real robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect10_04">16:50-17:05, Paper WeCT10.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1631.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1631'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Towards Computationally Efficient Planning of Dynamic Multi-Contact Locomotion</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167370" title="Click to go to the Author Index">Thomas, Gray</a></td><td class="r">Univ. of Texas at Austin</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110037" title="Click to go to the Author Index">Sentis, Luis</a></td><td class="r">The Univ. of Texas at Austin</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1631" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1631.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> This paper considers the problem of numerically efficient planning for legged robot locomotion, aiming towards reactive multi-contact planning as a reliability feature. We propose to decompose the problem into two parts: an extremely low dimensional kinematic search, which only adjusts a geometric path through space; and a dynamic optimization, which we focus on in this paper. This dynamic optimization also includes the selection of foot steps and hand-holds---in the special case of instantaneous foot re-location. This case is interesting because 1) it is a limiting behavior for algorithms with a foot switching cost, 2) it may have merit as a heuristic to guide search, and 3) it could act as a building block towards algorithms which do consider foot transition cost. The algorithm bears similarity both to phase space locomotion planning techniques for bipedal walking and the minimum time trajectory scaling problem for robot arms. A fundamental aspect of the algorithm's efficiency is its use of linear programming with reuse of the active set of inequality constraints. Simulation results in a simplified setting are used to demonstrate the planning of agile locomotion behaviors.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="wect10_05">17:05-17:20, Paper WeCT10.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1717.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1717'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Tractable Terrain-Aware Motion Planning on Granular Media: An Impulsive Jumping Study</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148199" title="Click to go to the Author Index">Hubicki, Christian</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196853" title="Click to go to the Author Index">Aguilar, Jeffrey</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142549" title="Click to go to the Author Index">Goldman, Daniel</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134049" title="Click to go to the Author Index">Ames, Aaron</a></td><td class="r">Georgia Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1717" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1717.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> This work demonstrates fast motion planning for robot locomotion that is optimized for terrain with complex dynamics, specifically, rapid penetration of granular media. Gait planning is critical for many legged locomotion control approaches, but they typically assume rigid ground contact. We aim to extend these planning methods to include terrain dynamics we see in the natural world, like sand and dirt, which can both deform and fluidize. Using an emph{added-mass} dynamical description of collective grain motion, we formulated a model of hydrostatic and hydrodynamic terrain effects that is both principled and representable with closed-form dynamics. As a result, we present a model and fast optimization formulation which solves accurate motion plans on granular media with tractable solving times (between 1-10 seconds). For validation, we optimized open-loop motor trajectories for a testbed jumping robot to jump to a target apex height from a bed a loosely packed poppy seeds. While jumps optimized for rigid ground were anemic on granular media, terrain-aware trajectories consistently hit within 4mm of their target. This demonstrates the potential for optimizing robot locomotion trajectories which respect practical task specifications, all while being aware of the terrain beneath it.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="welt12"><b>WeLT12</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#welt12" title="Click to go to the Program at a Glance"><b>Lifetime Talk 1/2/3</b></a></td>
               <td class="r">Lifetime Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101031" title="Click to go to the Author Index">Lee, C. S. George</a></td><td class="r">Purdue Univ</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="weft11"><b>WeFT11</b></a></td>
               <td class="r">#301</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#weft11" title="Click to go to the Program at a Glance"><b>Entrepreneurship Forum and Start-Up Competition</b></a></td>
               <td class="r">Forum</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101762" title="Click to go to the Author Index">Prassler, Erwin</a></td><td class="r">Bonn-Rhein-Sieg Univ. of Applied Sciences</td></tr>

</table>
</div>

<p>&nbsp;<br>&nbsp;</p><p>&nbsp;<br>&nbsp;</p>



</div>

</body>

</html>
