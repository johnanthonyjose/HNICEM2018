<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml2/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
 <head>
  <title>IROS16</title>
  <link href="style.css" rel="stylesheet" type="text/css" media="screen" />


<script language="JavaScript">

function viewAbstract(number){
   var box = document.getElementById('Ab' + number);
   if (box.style.display == 'block'){
      box.style.display = 'none';
   }
   else if (box && box.style.display == 'none'){
      box.style.display = 'block';
   }
}
function openAllAbstracts(){
   var d = document.getElementsByTagName('div');
   var count = d.length;
   if (count == 0){return;}
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab' && d[i].style.display == 'none'){
         d[i].style.display = 'block';
      }
   }
}
function closeAllAbstracts(){
   var d = document.getElementsByTagName('div');
   for (var i=0; i<d.length; i++){
      if (d[i].id && d[i].id.substring(0,2) == 'Ab'){
         d[i].style.display = 'none';
      }
   }
}
</script>

</head>

<body leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">

<div class="c" id="TheTop">
</div>
<table border="0" cellspacing="0" cellpadding="1" width="85%" nowrap style="margin: auto">
<tr><td>
<h2>Technical Program for Thursday October 13, 2016</h2>
</td></tr></table>

<p class="c"></p>
<div class="c">

                  <span style="color:gray ">To show or hide the keywords and abstract of a paper (if available), click on the paper title</span><br>
                  <a href="javascript:openAllAbstracts()" title="Click to open all abstracts">Open all abstracts</a>&nbsp;&nbsp;
                  <a href="javascript:closeAllAbstracts()" title="Click to close all abstracts">Close all abstracts</a>
               
</div>

<div class="c">
<table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thpl"><b>ThPL</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thpl" title="Click to go to the Program at a Glance"><b>Plenary Talk 4. Guang-Zhong Yang: Perceptual Docking – Harmonising Human
<br>Robot Interaction</b></a></td>
               <td class="r">Plenary session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100050" title="Click to go to the Author Index">Kwon, Dong-Soo</a></td><td class="r">KAIST</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thk11"><b>ThK11</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thk11" title="Click to go to the Program at a Glance"><b>Keynote Talk 5. Dominik Boesl: Future of Robotics - Shaping a Sustainable
<br>Future for the Next Generation ‘R’ of Robotic Natives</b></a></td>
               <td class="r">Keynote session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100160" title="Click to go to the Author Index">Meng, Max Q.-H.</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thk12"><b>ThK12</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thk12" title="Click to go to the Program at a Glance"><b>Keynote Talk 6. in so Kweon: Robust Computer Vision Algorithms for
<br>Intelligent Robots</b></a></td>
               <td class="r">Keynote session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101287" title="Click to go to the Author Index">Ikeuchi, Katsushi</a></td><td class="r">Microsoft Res</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="tht11"><b>ThT11</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#tht11" title="Click to go to the Program at a Glance"><b>Learning in Robotics</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#155614" title="Click to go to the Author Index">del Pobil, Angel P.</a></td><td class="r">Jaume-I Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#101300" title="Click to go to the Author Index">Chatila, Raja</a></td><td class="r">ISIR</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_01">10:20-10:21, Paper ThT11.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0029.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('29'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Coupled Learning of Action Parameters and Forward Models for Manipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158601" title="Click to go to the Author Index">Höfer, Sebastian</a></td><td class="r">Tech. Univ. Berlin</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101767" title="Click to go to the Author Index">Brock, Oliver</a></td><td class="r">Tech. Univ. Berlin</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab29" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0029.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a></span><br>
                           <strong>Abstract:</strong> The effectiveness of robot interaction depends on the robot's ability to perform task-relevant actions and on the degree to which it is able to predict the outcomes of these actions. In this paper we argue that the two learning problems - learning actions and learning forward models - must be tightly coupled for each of them to be successful. We present an approach that is able to learn a set of continuous action parameters and relational forward models from the robot's own experience. We formalize our approach as simultaneously clustering experiences in a continuous and a relational representation. Our experiments in a simulated manipulation experiment show that this form of coupled subsymbolic and symbolic learning is required for the robot to acquire task-relevant action capabilities.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_02">10:21-10:22, Paper ThT11.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0052.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('52'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Shared Control Method for Online Human-In-The-Loop Robot Learning Based on Locally Weighted Regression</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156776" title="Click to go to the Author Index">Peternel, Luka</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104664" title="Click to go to the Author Index">Oztop, Erhan</a></td><td class="r">Ozyegin Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107479" title="Click to go to the Author Index">Babic, Jan</a></td><td class="r">Jozef Stefan Inst</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab52" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0052.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_Control" title="Click to go to the Keyword Index">Learning Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motor_Skill_Learning" title="Click to go to the Keyword Index">Motor Skill Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a></span><br>
                           <strong>Abstract:</strong> We propose a novel method that arbitrates the control between the human and the robot actors in a teaching-by-demonstration setting to form synergy between the two and facilitate effective skill synthesis on the robot. We employed the human-in-the-loop teaching paradigm to teleoperate and demonstrate a complex task execution to the robot in real-time. As the human guides the robot to perform the task, the robot obtains the skill online during the demonstration. To encode the robotic skill we employed Locally Weighted Regression that fits local models to specific state region of the task based on the human demonstration. If the robot is in the state region where no local models exist, the control over the robotic mechanism is given to the human to perform the teaching. When local models are gradually obtained in that region, the control is given to the robot so that the human can examine its performance already during the demonstration stage, and take actions accordingly. This enables a co-adaptation between the agents and contributes to a faster and more efficient teaching. As a proof-of-concept, we realised the proposed robot teaching system on a haptic robot with the task of generation of a desired vertical force on a horizontal plane with unknown stiffness properties.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_03">10:22-10:23, Paper ThT11.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0303.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('303'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Inverse Reinforcement Learning with Leveraged Gaussian Processes</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179481" title="Click to go to the Author Index">Lee, Kyungjae</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#163618" title="Click to go to the Author Index">Choi, Sungjoon</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#119971" title="Click to go to the Author Index">Oh, Songhwai</a></td><td class="r">Seoul National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab303" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0303.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Imitation_Learning" title="Click to go to the Keyword Index">Imitation Learning</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a novel inverse reinforcement learning algorithm with leveraged Gaussian processes that can learn from both positive and negative demonstrations. While most existing inverse reinforcement learning (IRL) methods suffer from the lack of information near low reward regions, the proposed method alleviates this issue by incorporating (negative) demonstrations of what not to do. To mathematically formulate negative demonstrations, we introduce a novel generative model which can generate both positive and negative demonstrations using a parameter, called proficiency. Moreover, since we represent a reward function using a leveraged Gaussian process which can model a nonlinear function, the proposed method can effectively estimate the structure of a nonlinear reward function.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_04">10:23-10:24, Paper ThT11.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0375.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('375'); return false" title="Click to show or hide the keywords and abstract">Gaussian Processes for Dynamic Movement Primitives with Application in Knowledge-Based Cooperation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195724" title="Click to go to the Author Index">Fanger, Yunis</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167994" title="Click to go to the Author Index">Umlauft, Jonas</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107646" title="Click to go to the Author Index">Hirche, Sandra</a></td><td class="r">Tech. Univ. München</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab375" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Imitation_Learning" title="Click to go to the Keyword Index">Imitation Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperating_Robots" title="Click to go to the Keyword Index">Cooperating Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> Dynamic Movement Primitives (DMPs) represent stable goal-directed or periodic movements, which are learned from observations or demonstrations. They rely on proper function approximators, which are sufficiently flexible to represent arbitrary movements but also ensure goal convergence in point-to-point motions. This work shows that Gaussian Processes (GPs) are suitable as a regressor for learning movements with DMPs ensuring stability. In addition, GPs provide a measure for the uncertainty about the current movement, which we exploit by proposing a new cooperation scheme for DMPs: For better reproduction of demonstrations, we follow the intuition, that individuals with more knowledge lead towards the goal, while others follow and focus on cooperation. Along with simulation results, we validate the presented methods in a robotic cooperative object manipulation task.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_05">10:24-10:25, Paper ThT11.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0407.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('407'); return false" title="Click to show or hide the keywords and abstract">Probabilistic Decomposition of Sequential Force Interaction Tasks into Movement Primitives</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171397" title="Click to go to the Author Index">Manschitz, Simon</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105270" title="Click to go to the Author Index">Gienger, Michael</a></td><td class="r">Honda Res. Inst. Europe</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117613" title="Click to go to the Author Index">Kober, Jens</a></td><td class="r">TU Delft</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104326" title="Click to go to the Author Index">Peters, Jan</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab407" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Imitation_Learning" title="Click to go to the Keyword Index">Imitation Learning</a></span><br>
                           <strong>Abstract:</strong> Learning sequential force interaction tasks from kinesthetic demonstrations is a promising approach to transfer human manipulation abilities to a robot. In this paper we propose a novel concept to decompose such demonstrations into a set of Movement Primitives (MPs). The decomposition is based on a probability distribution we call Directional Normal Distribution (DND). To capture the sequential properties of the manipulation task, we model the demonstrations with a Hidden Markov Model (HMM). Here, we employ mixtures of DNDs as the HMM’s output emissions. The combination of HMMs and mixtures of DNDs allows to infer the MP’s composition, i.e., its reference frames, control variables and target coordinates from the demonstration data. In addition, it permits to determine an appropriate number of MPs that explains the demonstrations best. We evaluate the approach on kinesthetic demonstrations of a light bulb unscrewing task. Decomposing the task leads to intuitive and meaningful MPs that reflect the natural structure of the task.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_06">10:25-10:26, Paper ThT11.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0577.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('577'); return false" title="Click to show or hide the keywords and abstract">Stable Reinforcement Learning with Autoencoders for Tactile and Visual Data</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151699" title="Click to go to the Author Index">van Hoof, Herke</a></td><td class="r">TU Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149404" title="Click to go to the Author Index">Chen, Nutan</a></td><td class="r">Tech. Univ. Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#175184" title="Click to go to the Author Index">Karl, Maximilian</a></td><td class="r">TU Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107642" title="Click to go to the Author Index">van der Smagt, Patrick</a></td><td class="r">TUM</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104326" title="Click to go to the Author Index">Peters, Jan</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab577" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a></span><br>
                           <strong>Abstract:</strong> For many tasks, tactile or visual feedback is helpful or even crucial. However, designing controllers that take such high-dimensional feedback into account is non-trivial. Therefore, robots should be able to learn tactile skills through trial and error by using reinforcement learning algorithms. The input domain for such tasks, however, might include strongly correlated or non-relevant dimensions, making it hard to specify a suitable metric on such domains. Auto-encoders specialize in finding compact representations, where defining such a metric is likely to be easier. Therefore, we propose a reinforcement learning algorithm that can learn non-linear policies in continuous state spaces, which leverages representations learned using auto-encoders. We first evaluate this method on a simulated toy-task with visual input. Then, we validate our approach on a real-robot tactile stabilization task.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_07">10:26-10:27, Paper ThT11.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0607.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('607'); return false" title="Click to show or hide the keywords and abstract">Trajectory Learning from Human Demonstrations Via Manifold Mapping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195931" title="Click to go to the Author Index">Hiratsuka, Michihisa</a></td><td class="r">Tokyo Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188171" title="Click to go to the Author Index">Makondo, Ndivhuwo</a></td><td class="r">Tokyo Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133178" title="Click to go to the Author Index">Rosman, Benjamin</a></td><td class="r">CSIR</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159799" title="Click to go to the Author Index">Hasegawa, Osamu</a></td><td class="r">Tokyo Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab607" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Imitation_Learning" title="Click to go to the Keyword Index">Imitation Learning</a></span><br>
                           <strong>Abstract:</strong> This work proposes a framework that enables robot arms to imitate human demonstrations to acquire a skill, and reproduce it in real-time. The number of different robots active in various environments is growing considerably, and it is preferable for users to be able to easily teach a skill to a robot with any body configuration. Our proposed method works as follows. First, a motion trajectory is obtained from human demonstrations via a Kinect sensor, and projected onto a corresponding human skeleton model. Second, the kinematics mapping between the robot and the human model is learned by employing Local Procrustes Analysis. Third, the mapping function transfers the demonstrated trajectory from the human model to the robot. Finally, the transferred trajectory is modeled to be reproduced in real-time, employing Dynamic Movement Primitives. Experiments in simulation on a 4 degree of freedom robot show that our method is able to correctly imitate a skill demonstrated by a human.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_08">10:27-10:28, Paper ThT11.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0617.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('617'); return false" title="Click to show or hide the keywords and abstract">Initial Weight Estimation for Learning the Internal Model Based on the Knowledge of the Robot Morphology</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177024" title="Click to go to the Author Index">Duran, Angel Juan</a></td><td class="r">Univ. Jaume I</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155614" title="Click to go to the Author Index">del Pobil, Angel P.</a></td><td class="r">Jaume-I Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab617" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_Control" title="Click to go to the Keyword Index">Learning Control</a></span><br>
                           <strong>Abstract:</strong> The information used to determine the internal model of a robot system emerges from individual interactions with the environment. Knowledge about a specific internal model can be acquired by means of model learning techniques based on supervised machine learning tools, such as neural networks. One of the main challenges is to specify the starting point for the learning process. We propose a methodology for initial weight estimation based on the robot morphology. We use the generation of saccades in a robotic head as a case study to evaluate the performance of this approach. Our results suggest that this methodology, based on learning the relationship between the morphological parameters of the robot and those in its internal model, improves the quality of weight initialization, resulting in a considerable speed-up in the process of learning the internal model.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_09">10:28-10:29, Paper ThT11.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0802.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('802'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Improved Deep Reinforcement Learning for Robotics through Distribution-Based Experience Retention</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188767" title="Click to go to the Author Index">de Bruin, Tim</a></td><td class="r">TU Delft</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117613" title="Click to go to the Author Index">Kober, Jens</a></td><td class="r">TU Delft</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154929" title="Click to go to the Author Index">Tuyls, Karl</a></td><td class="r">Univ. of Liverpool</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106780" title="Click to go to the Author Index">Babuska, Robert</a></td><td class="r">Delft Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab802" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0802.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_Control" title="Click to go to the Keyword Index">Learning Control</a>, <a href="IROS16_KeywordIndexMedia.html#Neural_and_Fuzzy_Control" title="Click to go to the Keyword Index">Neural and Fuzzy Control</a></span><br>
                           <strong>Abstract:</strong> Recent years have seen a growing interest in the use of deep neural networks as function approximators in reinforcement learning. In this paper, an experience replay method is proposed that ensures that the distribution of the experiences used for training is between that of the policy and a uniform distribution. Through experiments on a magnetic manipulation task it is shown that the method reduces the need for sustained exhaustive exploration during learning. This makes it attractive in scenarios where sustained exploration is in-feasible or undesirable, such as for physical systems like robots and for life long learning. The method is also shown to improve the generalization performance of the trained policy, which can make it attractive for transfer learning. Finally, for small experience databases the method performs favorably when compared to the recently proposed alternative of using the temporal difference error to determine the experience sample distribution, which makes it an attractive option for robots with limited memory capacity.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_10">10:29-10:30, Paper ThT11.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0911.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('911'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Multimodal Imitation Using Self-Learned Sensorimotor Representations</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#176937" title="Click to go to the Author Index">Zambelli, Martina</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114394" title="Click to go to the Author Index">Demiris, Yiannis</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab911" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0911.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Imitation_Learning" title="Click to go to the Keyword Index">Imitation Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a></span><br>
                           <strong>Abstract:</strong> Although many tasks intrinsically involve multiple modalities, often only data from a single modality are used to improve complex robots acquisition of new skills. We present a method to equip robots with multimodal learning skills to achieve multimodal imitation on-the-fly on multiple concurrent task spaces, including vision, touch and proprioception, only using self-learned multimodal sensorimotor relations, without the need of solving inverse kinematic problems or explicit analytical models formulation. We evaluate the proposed method on a humanoid iCub robot learning to interact with a piano keyboard and imitating a human demonstration. Since no assumptions are made on the kinematic structure of the robot, the method can be also applied to different robotic platforms.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_11">10:30-10:31, Paper ThT11.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0923.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('923'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Discovering Affordances through Perception and Manipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159630" title="Click to go to the Author Index">Chavez-Garcia, R. Omar</a></td><td class="r">Sorbonne Univ. UPMC Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196277" title="Click to go to the Author Index">Luce-Vayrac, Pierre</a></td><td class="r">Isir, Upmc</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101300" title="Click to go to the Author Index">Chatila, Raja</a></td><td class="r">ISIR</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab923" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0923.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Considering perception as an observation process only is the very reason for which robotic perception methods are to date unable to provide a general capacity of scene understanding. Related work in neuroscience has shown that there is a strong relationship between perception and action. We believe that considering perception in relation to action requires to interpret the scene in terms of the agent's own potential capabilities. In this paper, we propose a Bayesian approach for learning sensorimotor representations through the interaction between action and observation capabilities. We represent the notion of affordance as a probabilistic relation between three elements: objects, actions and effects. Experiments for affordances discovery were performed on a real robotic platform in an unsupervised way assuming a limited set of innate capabilities. Results show dependency relations that connect the three elements in a common frame: affordances. The increasing number of interactions and observations results in a Bayesian network that captures the relationships between them. The learned representation can be used for prediction tasks.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_12">10:31-10:32, Paper ThT11.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0954.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('954'); return false" title="Click to show or hide the keywords and abstract">Modular Active Curiosity-Driven Discovery of Tool Use</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#186399" title="Click to go to the Author Index">Forestier, Sébastien</a></td><td class="r">Inria and Univ. Bordeaux</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129717" title="Click to go to the Author Index">Oudeyer, Pierre-Yves</a></td><td class="r">Inria and Ensta ParisTech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab954" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Motor_Skill_Learning" title="Click to go to the Keyword Index">Motor Skill Learning</a></span><br>
                           <strong>Abstract:</strong> This article studies algorithms used by a learner to explore high-dimensional structured sensorimotor spaces such as in tool use discovery. In particular, we consider goal babbling architectures that were designed to explore and learn solutions to fields of sensorimotor problems, i.e. to acquire inverse models mapping a space of parameterized sensorimotor problems/effects to a corresponding space of parameterized motor primitives. However, so far these architectures have not been used in high-dimensional spaces of effects. Here, we show the limits of existing goal babbling architectures for efficient exploration in such spaces, and introduce a novel exploration architecture called Model Babbling (MB). MB exploits efficiently a modular representation of the space of parameterized problems/effects. We also study an active version of Model Babbling (the MACOB architecture). These architectures are compared in a simulated experimental setup with an arm that can discover and learn how to move objects using two tools with different properties, embedding structured high-dimensional continuous motor and sensory spaces.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_13">10:32-10:33, Paper ThT11.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0972.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('972'); return false" title="Click to show or hide the keywords and abstract">It's Like Déjà Vu All Over Again: Learning Place-Dependent Terrain Assessment for Visual Teach and Repeat</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180369" title="Click to go to the Author Index">Berczi, Laszlo-Peter</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115139" title="Click to go to the Author Index">Barfoot, Timothy</a></td><td class="r">Univ. of Toronto</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab972" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a></span><br>
                           <strong>Abstract:</strong> This paper presents a learned, place-dependent terrain-assessment classifier that improves over time. Whereas typical methods aim to assess all of the terrain in a given environment, we exploit the fact that many robotic navigation tasks are well-suited to visual-teach-and-repeat navigation where robot motion is restricted to previously driven paths. In such scenarios, we argue that general terrain assessment is not required, and we can instead solve the much easier problem of detecting changes along the path; we sacrifice the ability to generalize off the path in favour of improved performance on the path. Terrain along a pretaught path is compared to terrain seen at the same location during previous, human-supervised traverses, and any significant differences cause that location to be labelled as unsafe. By storing all of our previous experiences, we are able to continuously improve our estimates as we revisit the same locations multiple times. We tested our method on two datasets collected at the University of Toronto and show that we improve over existing place-independent (both learned and not) methods, enabling nearly full autonomy in challenging, varied terrain using only a stereo camera.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_14">10:33-10:34, Paper ThT11.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0973.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('973'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Learning Dynamic Graffiti Strokes with a Compliant Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195821" title="Click to go to the Author Index">Berio, Daniel</a></td><td class="r">Goldsmiths Coll. Univ. of London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107089" title="Click to go to the Author Index">Calinon, Sylvain</a></td><td class="r">Idiap Res. Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157937" title="Click to go to the Author Index">Fol Leymarie, Frederic</a></td><td class="r">Goldsmiths Coll. Univ. of London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab973" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0973.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robots_and_Embodied_Art" title="Click to go to the Keyword Index">Robots and Embodied Art</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Entertainment_Robotics" title="Click to go to the Keyword Index">Entertainment Robotics</a></span><br>
                           <strong>Abstract:</strong> We present an approach to generate rapid and fluid drawing movements on a compliant Baxter robot, by taking advantage of the kinematic redundancy and torque control capabilities of the robot. We concentrate on the task of reproducing graffiti-stylised letter-forms with a marker. For this purpose, we exploit a compact lognormal-stroke based representation of movement to generate natural drawing trajectories. An Expectation-Maximisation (EM) algorithm is used to iteratively improve tracking performance with low gain feedback control. The resulting system captures the aesthetic and dynamic features of the style under investigation and permits its reproduction with a compliant controller that is safe for users surrounding the robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_15">10:34-10:35, Paper ThT11.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0987.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('987'); return false" title="Click to show or hide the keywords and abstract">Deep Learning of Structured Environments for Robot Search</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183467" title="Click to go to the Author Index">Caley, Jeffrey</a></td><td class="r">Oregon State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122930" title="Click to go to the Author Index">Lawrance, Nicholas Robert Jonathon</a></td><td class="r">Oregon State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103610" title="Click to go to the Author Index">Hollinger, Geoffrey</a></td><td class="r">Oregon State Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab987" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a></span><br>
                           <strong>Abstract:</strong> Robots often operate in built environments con- taining underlying structure that can be exploited to help predict future observations. In this work, we present a deep learning based approach to predict exit locations of buildings. This technique exploits the inherent structure of buildings to create a model. A convolutional neural network is trained using a database of building blueprints and used to guide a search within a building. This technique is compared to standard fron- tier exploration and a traditional image processing approach of extracting features through histogram of gradients (HOG) and training a support vector machine (SVM). After validation through simulation, we show that the proposed deep learning technique reduces the amount of building exploration required to find the goal by 36%.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_16">10:35-10:36, Paper ThT11.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1049.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1049'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Lifelong Learning for Disturbance Rejection on Mobile Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165476" title="Click to go to the Author Index">Isele, David</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132033" title="Click to go to the Author Index">Luna, Jose Marcio</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196377" title="Click to go to the Author Index">Eaton, Eric</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196287" title="Click to go to the Author Index">de la Cruz, Gabriel</a></td><td class="r">Washington State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196319" title="Click to go to the Author Index">Irwin, James</a></td><td class="r">Washington State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196294" title="Click to go to the Author Index">Kallaher, Brandon</a></td><td class="r">Washington State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143233" title="Click to go to the Author Index">Taylor, Matthew</a></td><td class="r">Washington State Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1049" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1049.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_Control" title="Click to go to the Keyword Index">Learning Control</a></span><br>
                           <strong>Abstract:</strong> No two robots are exactly the same—even for a given model of robot, different units will require slightly different controllers. Furthermore, because robots change and degrade over time, a controller will need to change over time to remain optimal. This paper leverages lifelong learning in order to learn controllers for different robots. In particular, we show that by learning a set of control policies over robots with different (unknown) motion models, we can quickly adapt to changes in the robot, or learn a controller for a new robot with a unique set of disturbances. Furthermore, the approach is completely model-free, allowing us to apply this method to robots that have not, or cannot, be fully modeled.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_17">10:36-10:37, Paper ThT11.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1063.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1063'); return false" title="Click to show or hide the keywords and abstract">Learning Semantic Place Labels from Occupancy Grids Using CNNs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147572" title="Click to go to the Author Index">Goeddel, Robert</a></td><td class="r">Univ. of Michigan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107201" title="Click to go to the Author Index">Olson, Edwin</a></td><td class="r">Univ. of Michigan</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1063" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> The goal of this paper is to develop a robot with a grounded spatial vocabulary. Such a vocabulary would allow it to give and follow directions, and would give it valuable additional information in aiding localization and navigation. We approach the problem by defining and ontology of space (including corridor, doorway, and room) and by creating a Convolutional Neural Network (CNN) that allows the robot to classify LIDAR sensor data accordingly. In particular, we propose a CNN architecture that performs comparably or better than existing methods based on engineered features. Training CNNs can be fickle; we describe several specific aspects of our approach that are important for good performance in this task.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_18">10:37-10:38, Paper ThT11.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1115.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1115'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Learning Models for Constraint-Based Motion Parameterization from Interactive Physics-Based Simulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192030" title="Click to go to the Author Index">Fang, Zhou</a></td><td class="r">Inst. of Artificial Intelligence, Univ. of Bremen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159603" title="Click to go to the Author Index">Bartels, Georg</a></td><td class="r">Univ. Bremen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103133" title="Click to go to the Author Index">Beetz, Michael</a></td><td class="r">Univ. of Bremen</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1115" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1115.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_Control" title="Click to go to the Keyword Index">Learning Control</a>, <a href="IROS16_KeywordIndexMedia.html#Animation_and_Simulation" title="Click to go to the Keyword Index">Animation and Simulation</a></span><br>
                           <strong>Abstract:</strong> For robotic agents to perform manipulation tasks in human environments at a human level or higher, they need to be able to relate the physical effects of their actions to how they are executing them; small variations in execution can have very different consequences. This paper proposes a framework for acquiring and applying action knowledge from naive user demonstrations in an interactive simulation environment under varying conditions. The framework combines a flexible constraint-based motion control approach with games-with-a-purpose-based learning using Random Forest Regression. The acquired action models are able to produce context-sensitive constraint-based motion descriptions to perform the learned action. A pouring experiment is conducted to test the feasibility of the suggested approach and shows the learned system can perform comparable to its human demonstrators.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_19">10:38-10:39, Paper ThT11.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1129.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1129'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Poisson-Spectral Model for Modelling the Temporal Patterns in Human Data Observed by a Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193953" title="Click to go to the Author Index">Jovan, Ferdian</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128648" title="Click to go to the Author Index">Wyatt, Jeremy</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116406" title="Click to go to the Author Index">Hawes, Nick</a></td><td class="r">Univ. of Birmingham</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167573" title="Click to go to the Author Index">Krajník, Tomáš</a></td><td class="r">Univ. of Lincoln</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1129" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1129.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a></span><br>
                           <strong>Abstract:</strong> The efficiency of autonomous robots depends on how well they understand their operating environment. While most of the traditional environment models focus on the spatial representation, long-term mobile robot operation in human populated environments requires that the robots have a basic model of human behaviour.<p>We present a framework that allows us to retrieve and represent aggregate human behaviour in large, populated environments on extended temporal scales. Our approach, based on time-varying Poisson process models and spectral analysis, efficiently retrieves long-term, re-occurring patterns of human activity from robot-gathered observations and uses these patterns to i) predict human activity level at particular times and places and ii) classify locations based on their periodic patterns of activity.<p>The application of our framework on real-world data, gathered by a mobile robot operating in an indoor environment for one month, indicates that its predictive capabilities outperform other temporal modelling methods while being computationally more efficient. The experiment also demonstrates that spectral signatures act as features that allow us to classify room types which semantically match with humans' expectations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_20">10:39-10:40, Paper ThT11.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1340.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1340'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>One-Shot Learning of Manipulation Skills with Online Dynamics Adaptation and Neural Network Priors</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192455" title="Click to go to the Author Index">Fu, Justin</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156706" title="Click to go to the Author Index">Levine, Sergey</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107568" title="Click to go to the Author Index">Abbeel, Pieter</a></td><td class="r">UC Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1340" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1340.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Reinforcement_Learning" title="Click to go to the Keyword Index">Robot Reinforcement Learning</a></span><br>
                           <strong>Abstract:</strong> One of the key challenges in applying reinforcement learning to complex robotic control tasks is the need to gather large amounts of experience in order to find an effective policy for the task at hand. Model-based reinforcement learning can achieve good sample efficiency, but requires the ability to learn a model of the dynamics that is good enough to learn an effective policy. In this work, we develop a model-based reinforcement learning algorithm that combines prior knowledge from previous tasks with online adaptation of the dynamics model. These two ingredients enable highly sample-efficient learning even in regimes where estimating the true dynamics is very difficult, since the online model adaptation allows the method to locally compensate for unmodeled variation in the dynamics. We encode the prior experience into a neural network dynamics model, adapt it online by progressively refitting a local linear model of the dynamics, and use model predictive control to plan under these dynamics. Our experimental results show that this approach can be used to solve a variety of complex robotic manipulation tasks in just a single attempt, using prior data from other manipulation behaviors.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_21">10:40-10:41, Paper ThT11.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1454.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1454'); return false" title="Click to show or hide the keywords and abstract">Active Constrained Clustering Via Non-Iterative Uncertainty Sampling</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184798" title="Click to go to the Author Index">Stanitsas, Panagiotis</a></td><td class="r">Univ. of Minnesota</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122330" title="Click to go to the Author Index">Cherian, Anoop</a></td><td class="r">Australian National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122332" title="Click to go to the Author Index">Morellas, Vassilios</a></td><td class="r">U. of Minnesota</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101709" title="Click to go to the Author Index">Papanikolopoulos, Nikos</a></td><td class="r">Univ. of Minnesota</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1454" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a></span><br>
                           <strong>Abstract:</strong> Active Constraint Learning (ACL) is continuously gaining popularity in the area of constrained clustering due to its ability to achieve performance gains via incorporating minimal feedback from a human annotator for selected instances. For constrained clustering algorithms, such instances are integrated in the form of Must-Link (ML) and CannotLink (CL) constraints. Existing iterative uncertainty reduction schemes, introduce high computational burden particularly when they process larger datasets that are usually present in computer vision and visual learning applications. For scenarios that multiple agents (i.e., robots) require user feedback for performing recognition tasks, minimizing the interaction between the user and the agents, without compromising performance, is an essential task. In this study, a non-iterative ACL scheme with proven performance benefits is presented. We select to demonstrate the effectiveness of our methodology by building on the well known K-Means algorithm for clustering; one can easily extend it to alternative clustering schemes. The proposed methodology introduces the use of the Silhouette values, conventionally used for measuring clustering performance, in order to rank the degree of information content of the various samples. In addition, an efficient greedy selection scheme was devised for selecting the most informative samples for human annotation. To the best of our knowledge, this is the first active constrained clustering methodology with the ability to process computer vision datasets that this study targets. Performance results are shown on various computer vision benchmarks and support the merits of adopting the proposed scheme.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_22">10:41-10:42, Paper ThT11.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1468.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1468'); return false" title="Click to show or hide the keywords and abstract">Towards Robust Online Inverse Dynamics Learning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147628" title="Click to go to the Author Index">Meier, Franziska</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137014" title="Click to go to the Author Index">Kappler, Daniel</a></td><td class="r">Max-Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115278" title="Click to go to the Author Index">Ratliff, Nathan</a></td><td class="r">Lula Robotics Inc</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102004" title="Click to go to the Author Index">Schaal, Stefan</a></td><td class="r">MPI Intelligent Systems & Univ. of Southern California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1468" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Learning_Control" title="Click to go to the Keyword Index">Learning Control</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a></span><br>
                           <strong>Abstract:</strong> Learning of inverse dynamics modeling errors is key for compliant or force control when analytical models are only rough approximations. Thus, designing real time capable function approximation algorithms has been a necessary focus towards the goal of online model learning. However, because these approaches learn a mapping from actual state and acceleration to torque, good tracking is required to observe data points on the desired path. Recently it has been shown how online gradient descent on a simple modeling error offset term to minimize tracking at acceleration level can address this issue. However, to adapt to larger errors a high learning rate of the online learner is required, resulting in reduced compliancy. Thus, here we propose to combine both approaches: The online adapted offset term ensures good tracking such that a nonlinear function approximator is able to learn an error model on the desired trajectory. This, in turn, reduces the load on the adaptive feedback, enabling it to use a lower learning rate. Combined this creates a controller with variable feedback and low gains, and a feedforward model that can account for larger modeling errors. We demonstrate the effectiveness of this framework, in simulation and on a real system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_23">10:42-10:43, Paper ThT11.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1501.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1501'); return false" title="Click to show or hide the keywords and abstract">Nonparametric Bayesian Models for Unsupervised Activity Recognition and Tracking</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195867" title="Click to go to the Author Index">Dhir, Neil</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165629" title="Click to go to the Author Index">Perov, Yura</a></td><td class="r">Siberian Federal Univ. (Russia, Krasnoyarsk) / EPFL (Switze</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1501" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a></span><br>
                           <strong>Abstract:</strong> Human locomotion and activity recognition systems form a critical part in a robot's ability to safely and effectively operate in a environment populated with human end users. Previous work in this area relies upon strong assumptions about the labels in the training data; e.g. that are noise-free and that they exist at all. Our approach does not predefine the relevant behaviours or their number, as both are learned directly from observations, similar to real-world human-robot interactions, where labels are neither available. Instead we introduce models that make no assumptions about the state space, by presenting a fully unsupervised nonparametric Bayesian recognition approach, in which we leverage recent advances in state space modelling with automatic inference using probabilistic programming. We demonstrate the utility of full model optimisation using Bayesian optimisation and validate our approach on several challenging problems, using different feature modalities.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht11_24">10:43-10:44, Paper ThT11.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1525.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1525'); return false" title="Click to show or hide the keywords and abstract">Optimal Control and Inverse Optimal Control by Distribution Matching</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188783" title="Click to go to the Author Index">Arenz, Oleg</a></td><td class="r">TU Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180909" title="Click to go to the Author Index">Abdulsamad, Hany</a></td><td class="r">TU Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113579" title="Click to go to the Author Index">Neumann, Gerhard</a></td><td class="r">TU Darmstadt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1525" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Imitation_Learning" title="Click to go to the Keyword Index">Imitation Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_Control" title="Click to go to the Keyword Index">Learning Control</a></span><br>
                           <strong>Abstract:</strong> Optimal control is a powerful approach to achieve optimal behavior. However, it typically requires a manual specification of a cost function which often contains several objectives, such as reaching goal positions at different time steps or energy efficiency. Manually trading-off these objectives is often difficult and requires a high engineering effort. In this paper, we present a new approach to specify optimal behavior. We directly specify the desired behavior by a distribution over future states or features of the states. For example, the experimenter could choose to reach certain mean positions with given accuracy/variance at specified time steps. Our approach also unifies optimal control and inverse optimal control in one framework. Given a desired state distribution, we estimate a cost function such that the optimal controller matches the desired distribution. If the desired distribution is estimated from expert demonstrations, our approach performs inverse optimal control. We evaluate our approach on several optimal and inverse optimal control tasks on non-linear systems using incremental linearizations similar to differential dynamic programming approaches.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="tht12"><b>ThT12</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#tht12" title="Click to go to the Program at a Glance"><b>Robot Vision</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101938" title="Click to go to the Author Index">Marchand, Eric</a></td><td class="r">Univ. De Rennes 1, IRISA, INRIA Rennes</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#134944" title="Click to go to the Author Index">Zingg, Simon</a></td><td class="r">ETH Zurich</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_01">10:20-10:21, Paper ThT12.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0036.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('36'); return false" title="Click to show or hide the keywords and abstract">Low-Obstacle Detection Using Stereo Vision</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177813" title="Click to go to the Author Index">Bichsel, Robert</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133626" title="Click to go to the Author Index">Borges, Paulo Vinicius Koerich</a></td><td class="r">CSIRO</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab36" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a></span><br>
                           <strong>Abstract:</strong> Real-time obstacle detection is a key component of autonomous vehicles. In this context, low obstacles are particularly challenging, as they are often discarded by traditional algorithms. Curb detection methods that can potentially be suitable for the problem usually target roads with clearly defined curbs and sidewalks. We propose a real-time algorithm for the detection of low obstacles (including, but not restricted to curbs), merging 2-D and 3-D information from stereo imaging. A set of candidate object lines is extracted based on their combined 2-D and 3-D features, tracked over time and clustered according to a novel similarity metric. Finally, a 3rd order polynomial spline is fitted to each cluster to represent the obstacle. The proposed system can deal with noisy and incomplete point clouds and keeps the model assumptions to a minimum. To evaluate the algorithm, a new stereo dataset is provided and made available online. We present experiments in different scenarios and lighting conditions, illustrating the applicability of the method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_02">10:21-10:22, Paper ThT12.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0133.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('133'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Fast 6D Pose from a Single RGB Image Using Cascaded Forests Templates</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191553" title="Click to go to the Author Index">Munoz, Enrique</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149558" title="Click to go to the Author Index">Konishi, Yoshinori</a></td><td class="r">OMRON Corp</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195349" title="Click to go to the Author Index">Beltran, Carlos</a></td><td class="r">Istituto Italiano Di Tecnologia (IIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#139907" title="Click to go to the Author Index">Murino, Vittorio</a></td><td class="r">Istituto Italiano Di Tecnologia/Univ. Di Verona</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133775" title="Click to go to the Author Index">Del Bue, Alessio</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab133" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0133.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a></span><br>
                           <strong>Abstract:</strong> This paper presents a method for 6D pose estimation from a single RGB image for complex texture-less objects. This class of objects are common in any environment but still challenging to deal with. This is due the fact that the distribution of surface brightness makes difficult to compute interest points or appearance-based descriptors. Here we propose a novel part-based method using an efficient template matching approach where each template independently encodes the similarity function using a Forest trained over the templates. Moreover, accuracy is even more incremented by using a cascade of the learned forest. These templates forests together with the simplicity of the computed image features allow a quick estimate of the pose achieving real-time performance. Performance are demonstrated both on synthetic and real images with known ground truth.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_03">10:22-10:23, Paper ThT12.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0265.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('265'); return false" title="Click to show or hide the keywords and abstract">A Multiple Kernel Convolution Score Method for Bin Picking of Plastic Packed Object</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#163715" title="Click to go to the Author Index">Kim, Taewoo</a></td><td class="r">Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115961" title="Click to go to the Author Index">Lee, Jaeyeon</a></td><td class="r">ETRI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140367" title="Click to go to the Author Index">Lee, Hooman</a></td><td class="r">Eletronics and Telecommunications Res. Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102790" title="Click to go to the Author Index">Kim, Joong-Bae</a></td><td class="r">Electronics and Telecommunications Res. Inst</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab265" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a></span><br>
                           <strong>Abstract:</strong> In this paper, an object detection and localization method for bin picking of plastic wrapped objects is described. Since such objects are deformable and have non-Lambertian surfaces, it is difficult to apply conventional feature point approaches or edge based template matching. To solve this problem, we propose a new method which is called “KCS (kernel convolution score)”. It measures the total score of convolution between local image and multiple kernels which are generated according to the characteristics of the target object. The local image having maximum score is considered as the most promising object for picking. In the last part of this paper, the limitation of existing edge and template matching in the given problem is discussed with the experimental results. Performance evaluation shows that the proposed method could localize the object which is appropriate for picking up with 91.67% success rate.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_04">10:23-10:24, Paper ThT12.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0315.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('315'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Semi-Direct Visual Odometry for a Fisheye-Stereo Camera</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142210" title="Click to go to the Author Index">Heng, Lionel</a></td><td class="r">DSO National Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155781" title="Click to go to the Author Index">Choi, Benjamin</a></td><td class="r">DSO National Lab</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab315" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0315.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> We present a semi-direct visual odometry algorithm for a fisheye-stereo camera. In a tracking thread, we simultaneously track oriented patches and estimate the camera pose. In a mapping thread, we estimate the coordinates and surface normal for each new patch to be tracked. Estimation of the surface normals allows us to track patches over a wide variety of viewpoints. In our algorithm, we do not make use of descriptors and robust descriptor matching to find patch correspondences. Instead, we use photoconsistency-based techniques to find patch correspondences. For tracking, we use sparse model-based image alignment to find the relative motion estimate, and feature alignment to find 2D-3D patch correspondences. For mapping, we use plane-sweeping stereo to find matching patches between stereo images. We also implement a state estimator based on the Extended Kalman Filter (EKF) to fuse inertial measurements and relative pose estimates from our visual odometry implementation. We run experiments in two different outdoor environments to validate our algorithm, and discuss the experimental results. Our implementation runs at an average of 42 Hz on a commodity Intel CPU. To the best of our knowledge, there is no other existing semi-direct visual odometry algorithm for a fisheye-stereo camera.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_05">10:24-10:25, Paper ThT12.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0335.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('335'); return false" title="Click to show or hide the keywords and abstract">Recoverable Recommended Keypoint-Aware Visual Tracking Using Coupled-Layer Appearance Modelling</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195654" title="Click to go to the Author Index">Duan, Ran</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160488" title="Click to go to the Author Index">Fu, Changhong</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116193" title="Click to go to the Author Index">Kayacan, Erdal</a></td><td class="r">Nanyang Tech. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab335" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a></span><br>
                           <strong>Abstract:</strong> Object tracking over image sequences plays an remarkably crucial role in several computer vision applications, interalia, automated video surveillance, unmanned aerial vehicles and 3D reconstruction. In this paper, a novel, accurate, robust and recoverable real-time feature-based tracking framework is presented. The appearance modelling consists of a local and global layer. We propose a recommended keypoint-aware (RKA) tracker, which is fast and accurate, for the former, while the latter employs support vector machine (SVM) to determine the object and background, so that the RKA tracker can be recovered under possible target losing circumstances. Furthermore, the RKA tracker converts the tracking problem into the ranking of samples which provides a score of tracking confidence. Therefore, the priority switching between the local layer and global layer dependent upon the score becomes valid. Extensive experiments have been done by strictly following the visual tracking benchmark v1.0 protocol. The results demonstrate that the proposed novel method outperforms the start-of-the-art trackers in terms of robustness, speed and accuracy.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_06">10:25-10:26, Paper ThT12.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0383.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('383'); return false" title="Click to show or hide the keywords and abstract">Point Clouds Registration with Probabilistic Data Association</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181344" title="Click to go to the Author Index">Fontana, Simone</a></td><td class="r">Univ. of Milano Bicocca</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#118866" title="Click to go to the Author Index">Agamennoni, Gabriel</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103365" title="Click to go to the Author Index">Sorrenti, Domenico G.</a></td><td class="r">Univ. Di Milano - Bicocca</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab383" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> Although Point Clouds Registration is a very well studied problem, with many different solutions, most of the approaches in the literature aims at aligning two dense point clouds. Instead, we tackle the problem of aligning a dense point cloud with a sparse one: a problem that has to be solved, for example, to merge maps produced by different sensors, such as a vision-based sensor and laser scanner or two different laser-based sensors. The most used approach to point clouds registration, Iterative Closest Point (ICP), is also applicable to this sub-problem. We propose an improvement over the standard ICP data association policy and we called it Probabilistic Data Association. It was derived applying statistical inference techniques on a fully probabilistic model. In our proposal, each point in the source point cloud is associated with a set of points in the target point cloud; each association is then weighted so that the weights form a probability distribution. The result is an algorithm similar to ICP but more robust w.r.t. noise and outliers. While we designed our approach to deal with the problem of dense-sparse registration, it can be successfully applied also to standard point clouds registration.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_07">10:26-10:27, Paper ThT12.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0388.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('388'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Shearlet-Based vs. Photometric-Based Visual Servoing for Robot-Assisted Medical Applications</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191398" title="Click to go to the Author Index">Duflot, Lesley-Ann</a></td><td class="r">Inria Rennes Bretagne Atlantique, Femto-St Besançon</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104061" title="Click to go to the Author Index">Krupa, Alexandre</a></td><td class="r">INRIA Rennes - Bretagne Atlantique</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117023" title="Click to go to the Author Index">Tamadazte, Brahim</a></td><td class="r">Cnrs, Ufc/ensmm/utbm</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103294" title="Click to go to the Author Index">Andreff, Nicolas</a></td><td class="r">Univ. De Franche Comté</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab388" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0388.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> This paper deals with the development of a vision- based controller for robot-assisted medical applications. It concerns the use of shearlet coefficients in case of ultrasounds (US) images as visual signal inputs and the design of the associated interaction matrix. The proposed controller was validated in both simulation and on an experimental test bench which consists of a robotic arm holding an US probe in contact with a realistic abdominal phantom. Also, the proposed control scheme was compared to the photometry-based visual servoing approach in order to evaluate its efficiency in different conditions of use (nominal and unfavorable conditions).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_08">10:27-10:28, Paper ThT12.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0417.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('417'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Fast and Robust 3D Feature Extraction from Sparse Point Clouds</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171438" title="Click to go to the Author Index">Serafin, Jacopo</a></td><td class="r">Univ. Sapienza of Rome</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107201" title="Click to go to the Author Index">Olson, Edwin</a></td><td class="r">Univ. of Michigan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107200" title="Click to go to the Author Index">Grisetti, Giorgio</a></td><td class="r">Sapienza Univ. of Rome</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab417" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0417.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a></span><br>
                           <strong>Abstract:</strong> Matching 3D point clouds, a critical operation in map building and localization, is difficult with Velodyne-type sensors due to the sparse and non-uniform point clouds that they produce. Standard methods from dense 3D point clouds are generally not effective. In this paper, we describe a feature-based approach using Principal Components Analysis (PCA) of neighborhoods of points, which results in mathematically principled line and plane features. The key contribution in this work is to show how this type of feature extraction can be done efficiently and robustly even on non-uniformly sampled point clouds. The resulting detector runs in real-time and can be easily tuned to have a low false positive rate, simplifying data association. We evaluate the performance of our algorithm on an autonomous car at the MCity Test Facility using a Velodyne HDL-32E, and we compare our results against the state-of-the-art NARF keypoint detector.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_09">10:28-10:29, Paper ThT12.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0443.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('443'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Iterative Hough Forest with Histogram of Control Points for 6 DoF Object Registration from Depth Images</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195799" title="Click to go to the Author Index">Sahin, Caner</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147434" title="Click to go to the Author Index">Kouskouridas, Rigas</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147620" title="Click to go to the Author Index">Kim, Tae-Kyun</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab443" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0443.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a></span><br>
                           <strong>Abstract:</strong> State-of-the-art techniques proposed for 6D object pose recovery depend on occlusion-free point clouds to accurately register objects in 3D space. To reduce this dependency, we introduce a novel architecture called Iterative Hough Forest with Histogram of Control Points that is capable of estimating occluded and cluttered objects’ 6D pose given a candidate 2D bounding box. Our Iterative Hough Forest is learnt using patches extracted only from the positive samples. These patches are represented with Histogram of Control Points (HoCP), a “scale-variant” implicit volumetric description, which we derive from recently introduced Implicit B-Splines (IBS). The rich discriminative information provided by this scale-variance is leveraged during inference, where the initial pose estimation of the object is iteratively refined based on more discriminative control points by using our Iterative Hough Forest. We conduct experiments on several test objects of a publicly available dataset to test our architecture and to compare with the state-of-the-art.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_10">10:29-10:30, Paper ThT12.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0469.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('469'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Generic 3D Obstacle Detection for AGVs Using Time-Of-Flight Cameras</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183155" title="Click to go to the Author Index">Buck, Sebastian</a></td><td class="r">Univ. of Tübingen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183159" title="Click to go to the Author Index">Hanten, Richard</a></td><td class="r">Univ. of Tübingen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155957" title="Click to go to the Author Index">Bohlmann, Karsten</a></td><td class="r">Eberhard-Karls-Univ. Tübingen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105216" title="Click to go to the Author Index">Zell, Andreas</a></td><td class="r">Univ. of Tübingen</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab469" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0469.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Intelligent_Transportation_Systems" title="Click to go to the Keyword Index">Intelligent Transportation Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a></span><br>
                           <strong>Abstract:</strong> Automated guided vehicles (AGVs) are useful for a variety of transportation tasks. They usually detect obstacles on the path they are following using 2D laser scanners. If an AGV should be deployed in a shared space with people, 3D information has to be considered as well to detect unforeseen obstacles. These can be small objects on the floor or overhanging parts of larger objects, which cannot be seen by the standard 2D safety scanners. We propose a generic object detection pipeline using 3D time-of-flight cameras, that can be used in real-time on AGVs of low height and demonstrate its robustness to different measurement artefacts.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_11">10:30-10:31, Paper ThT12.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0525.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('525'); return false" title="Click to show or hide the keywords and abstract">RGB-D Multi-View Object Detection with Object Proposals and Shape Context</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195918" title="Click to go to the Author Index">Georgakis, Georgios</a></td><td class="r">George Mason Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195921" title="Click to go to the Author Index">Reza, Md</a></td><td class="r">George Mason Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107243" title="Click to go to the Author Index">Kosecka, Jana</a></td><td class="r">George Mason Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab525" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> We propose a novel approach for multi-view object detection in 3D scenes reconstructed from RGB-D sensor. We utilize shape based representation using local shape context descriptors along with the voting strategy which is supported by unsupervised object proposals generated from 3D point cloud data. Our algorithm starts with a single-view object detection where object proposals generated in 3D space are combined with object specific hypotheses generated by the voting strategy. To tackle the multi-view setting, the data association between multiple views enabled view registration and 3D object proposals. The evidence from multiple views is combined in simple bayesian setting. The approach is evaluated on the Washington RGB-D scenes datasets containing several classes of objects in a table top setting. We evaluated our approach against the other state-of-the-art methods and demonstrated superior performance on the same dataset.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_12">10:31-10:32, Paper ThT12.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0630.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('630'); return false" title="Click to show or hide the keywords and abstract">Inferring Human Body Posture Information from Reflective Patterns of Protective Work Garments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160241" title="Click to go to the Author Index">Mosberger, Rafael</a></td><td class="r">Örebro Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116069" title="Click to go to the Author Index">Schaffernicht, Erik</a></td><td class="r">Örebro Univ. AASS Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104082" title="Click to go to the Author Index">Andreasson, Henrik</a></td><td class="r">Örebro Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104036" title="Click to go to the Author Index">Lilienthal, Achim J.</a></td><td class="r">Örebro Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab630" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a></span><br>
                           <strong>Abstract:</strong> We address the problem of extracting human body posture labels, upper body orientation and the spatial location of individual body parts from near-infrared (NIR) images depicting patterns of retro-reflective markers. The analyzed patterns originate from the observation of humans equipped with protective high-visibility garments that represent common safety equipment in the industrial sector. Exploiting the shape of the observed reflectors we adopt shape matching based on the chamfer distance and infer one of seven discrete body posture labels as well as the approximate upper body orientation with respect to the camera. We then proceed to analyze the NIR images on a pixel scale and estimate a figure-ground segmentation together with human body part labels using classification of densely extracted local image patches. Our results indicate a body posture classification accuracy of 80% and figure-ground segmentations with 87% accuracy.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_13">10:32-10:33, Paper ThT12.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0701.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('701'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Appearance-Based Landmark Selection for Efficient Long-Term Visual Localization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167955" title="Click to go to the Author Index">Bürki, Mathias</a></td><td class="r">Autonomous Systems Lab, ETH Zürich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187957" title="Click to go to the Author Index">Gilitschenski, Igor</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165051" title="Click to go to the Author Index">Stumm, Elena</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101699" title="Click to go to the Author Index">Nieto, Juan</a></td><td class="r">ETH Zürich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab701" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0701.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a></span><br>
                           <strong>Abstract:</strong> In this paper, we present an online landmark selection method for distributed long-term visual localization systems in bandwidth-constrained environments.Sharing a common map for online localization provides a fleet of autonomous vehicles the possibility to maintain and access a consistent map source, and therefore reduce redundancy while increasing efficiency. However, connectivity over a mobile network imposes strict bandwidth constraints and thus the need to minimize the amount of exchanged data. The wide range of varying appearance conditions encountered during long-term visual localization offer the potential to reduce data usage by extracting only those visual cues which are relevant at the given time. Motivated by this, we propose an unsupervised method of adaptively selecting landmarks according to how likely these landmarks will be observable under the prevailing appearance condition. The ranking function this selection is based upon exploits landmark co-observability statistics collected in past traversals through the mapped area. % to infer about landmark observability at the current time. Evaluation is performed over different outdoor environments, large time-scales and varying appearance conditions, including the extreme transition from day-time to night-time, demonstrating that with our appearance-dependent selection method, we can significantly reduce the amount of landmarks used for localization while maintaining or even improving the localization performance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_14">10:33-10:34, Paper ThT12.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0776.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('776'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Fast Event-Based Harris Corner Detection Exploiting the Advantages of Event-Driven Cameras</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192424" title="Click to go to the Author Index">Vasco, Valentina</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130518" title="Click to go to the Author Index">Glover, Arren</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115929" title="Click to go to the Author Index">Bartolozzi, Chiara</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab776" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0776.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Neurorobotics" title="Click to go to the Keyword Index">Neurorobotics</a></span><br>
                           <strong>Abstract:</strong> The detection of consistent feature points in an image is fundamental for various kinds of computer vision techniques, such as stereo matching, object recognition, target tracking and optical flow computation. This paper presents an event-based approach to the detection of corner points, which benefits from the high temporal resolution, compressed visual information and low latency provided by an asynchronous neuromorphic event-based camera. The proposed method adapts the commonly used Harris corner detector to the event-based data, in which frames are replaced by a stream of asynchronous events produced in response to local light changes at (mu)s temporal resolution. Responding only to changes in its field of view, an event-based camera naturally enhances edges in the scene, simplifying the detection of corner features. We characterised and tested the method on both a controlled pattern and a real scenario, using the dynamic vision sensor (DVS) on the neuromorphic iCub robot. The method detects corners with a typical error distribution within 2 pixels. The error is constant for different motion velocities and directions, indicating a consistent detection across the scene and over time. We achieve a detection rate proportional to speed, higher than frame-based technique for a significant amount of motion in the scene, while also reducing the computational cost.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_15">10:34-10:35, Paper ThT12.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0895.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('895'); return false" title="Click to show or hide the keywords and abstract">Measuring the Performance of Single Image Depth Estimation Methods</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122912" title="Click to go to the Author Index">Cadena Lerma, Cesar Dario</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155702" title="Click to go to the Author Index">Latif, Yasir</a></td><td class="r">Univ. of Adelaide</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106056" title="Click to go to the Author Index">Reid, Ian</a></td><td class="r">Univ. of Adelaide</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab895" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a></span><br>
                           <strong>Abstract:</strong> We consider the question of benchmarking the performance of methods used for estimating the depth of a scene from a single image. We describe various measures that have been used in the past, discuss their limitations and demonstrate that each is deficient in one or more ways. We propose a new measure of performance for depth estimation that overcomes these deficiencies, and has a number of desirable properties. We show that in various cases of interest the new measure enables visualisation of the performance of a method that is otherwise obfuscated by existing metrics. Our proposed method is capable of illuminating the relative performance of different algorithms on different kinds of data, such as the difference in efficacy of a method when estimating the depth of the ground plane versus estimating the depth of other generic scene structure. We showcase the method by comparing a number of existing single-view methods against each other and against more traditional depth estimation methods such as binocular stereo.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_16">10:35-10:36, Paper ThT12.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1043.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1043'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>An Orthographic Descriptor for 3D Object Learning and Recognition</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169824" title="Click to go to the Author Index">Mohades Kasaei, Seyed Hamidreza</a></td><td class="r">Univ. De Aveiro</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108694" title="Click to go to the Author Index">Seabra Lopes, Luís</a></td><td class="r">Univ. De Aveiro</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169831" title="Click to go to the Author Index">Tomé, Ana Maria</a></td><td class="r">Univ. De Aveiro</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154460" title="Click to go to the Author Index">Oliveira, Miguel</a></td><td class="r">Univ. of Aveiro</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1043" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1043.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a></span><br>
                           <strong>Abstract:</strong> Object representation is one of the most challenging tasks in robotics because it must provide reliable information in real-time to enable the robot to physically interact with the objects in its environment. To ensure reliability, a global object descriptor must be computed based on a unique and repeatable object reference frame. Moreover, the descriptor should contain enough information enabling to recognize the same or similar objects seen from different perspectives. This paper presents a new object descriptor named Global Orthographic Object Descriptor (GOOD) designed to be robust, descriptive and efficient to compute and use. The performance of the proposed object descriptor is compared with the main state-of-the-art descriptors. Experimental results show that the overall classification performance obtained with GOOD is comparable to the best performances obtained with the state-of-the-art descriptors. Concerning memory and computation time, GOOD clearly outperforms the other descriptors. Therefore, GOOD is especially suited for real-time applications.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_17">10:36-10:37, Paper ThT12.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1061.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1061'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Object Detection and Tracking in RGB-D SLAM Via Hierarchical Feature Grouping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192848" title="Click to go to the Author Index">Ataer-Cansizoglu, Esra</a></td><td class="r">Mitsubishi Electric Res. Labs</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131561" title="Click to go to the Author Index">Taguchi, Yuichi</a></td><td class="r">Mitsubishi Electric Res. Labs</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1061" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1061.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> We present an object detection and tracking framework integrated into a simultaneous localization and mapping (SLAM) system using an RGB-D camera. We propose a compact representation of objects by grouping features hierarchically. Similar to a keyframe being a collection of features, an object is represented as a set of segments, where a segment is a subset of features in a frame. Just like keyframes, segments are registered with each other in a map, which we call an object map. We use the same SLAM procedure in both offline object scanning and online object detection modes. In the offline scanning mode, we scan an object using an RGB-D camera to generate an object map. In the online detection mode, a set of object maps for different objects is given, and the objects are detected via appearance-based matching between the segments in the current frame and in the object maps. In the case of a match, the object is localized with respect to the map being reconstructed by the SLAM system by a RANSAC registration. In the subsequent frames, the tracking is done by predicting the poses of the objects. We also incorporate constraints obtained from the objects into bundle adjustment to improve the object pose estimation accuracy as well as the SLAM reconstruction accuracy. We demonstrate our technique in an object picking scenario using a robot arm. Experimental results show that the system is able to detect and pick up objects successfully from different viewpoints and distances.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_18">10:37-10:38, Paper ThT12.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1102.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1102'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A System Implementation and Evaluation of a Cooperative Fusion and Tracking Algorithm Based on a Gaussian Mixture PHD Filter</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159663" title="Click to go to the Author Index">Vasic, Milos</a></td><td class="r">EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191046" title="Click to go to the Author Index">Mansolino, David</a></td><td class="r">EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102253" title="Click to go to the Author Index">Martinoli, Alcherio</a></td><td class="r">EPFL</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1102" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1102.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Intelligent_Transportation_Systems" title="Click to go to the Keyword Index">Intelligent Transportation Systems</a></span><br>
                           <strong>Abstract:</strong> This paper focuses on a real system implementation, analysis, and evaluation of a cooperative sensor fusion algorithm based on a Gaussian Mixture Probability Hypothesis Density (GM-PHD) filter, using simulated and real vehicles endowed with automotive-grade sensors. We have extended our previously presented cooperative sensor fusion algorithm with a fusion weight optimization method and implemented it on a vehicle that we denote as the ego vehicle. The algorithm fuses information obtained from one or more vehicles located within a certain range (that we call cooperative), which are running a multi-object tracking PHD filter, and which are sharing their object estimates. The algorithm is evaluated on two Citroen C-ZERO prototype vehicles equipped with Mobileye cameras for object tracking and lidar sensors from which the ground truth positions of the tracked objects are extracted. Moreover, the algorithm is evaluated in simulation using simulated C-ZERO vehicles and simulated Mobileye cameras. The ground truth positions of tracked objects are in this case provided by the simulator. Multiple experimental runs are conducted in both simulated and real-world conditions in which a few legacy vehicles were tracked. Results show that the cooperative fusion algorithm allows for extending the sensing field of view, while keeping the tracking accuracy and errors similar to the case in which the vehicles act alone.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_19">10:38-10:39, Paper ThT12.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1131.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1131'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Particle Filter-Based Direct Visual Servoing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179580" title="Click to go to the Author Index">Bateux, Quentin</a></td><td class="r">Univ. De Rennes 1, IRISA, Inria Rennes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101938" title="Click to go to the Author Index">Marchand, Eric</a></td><td class="r">Univ. De Rennes 1, IRISA, INRIA Rennes</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1131" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1131.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a></span><br>
                           <strong>Abstract:</strong> With respect to classical visual servoing (VS) technics based on geometrical features, the main drawback of direct visual servoing is its limited convergence area. In this paper we propose a new direct visual servoing control law that relies on a particle filter to achieve non-local and non-linear optimization in order to increase this convergence area. Thanks to multi-view geometry and image transfer techniques, a set of particles (which correspond to potential camera velocities) are drawn and evaluated in order to evaluate the best camera trajectory. This new control law is validated on a 6 DOF positioning task performed on a real gantry robot and statistical comparisons are also provided from simulation results.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_20">10:39-10:40, Paper ThT12.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1371.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1371'); return false" title="Click to show or hide the keywords and abstract">Person Identification Based on the Matching of Foot Strike Timings Obtained by LRFs and a Smartphone</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168862" title="Click to go to the Author Index">Koide, Kenji</a></td><td class="r">Toyohashi Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100116" title="Click to go to the Author Index">Miura, Jun</a></td><td class="r">Toyohashi Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1371" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> This paper describes a person identification method using a smartphone and laser range finders (LRFs) for a mobile service robot. The robot is equipped with LRFs and the target person holds a smartphone. The method first detects the foot strike timings of the target person using the smartphone and those of all people by using the LRFs. By finding the person whose foot strike timings captured by the LRFs are similar to those obtained by the smartphone, the robot can identify the target person. Person identification experiments and person following experiments are conducted in order to validate the method. Since the method only requires a person to simply hold a smartphone, it can be easily applied to daily situations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_21">10:40-10:41, Paper ThT12.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1377.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1377'); return false" title="Click to show or hide the keywords and abstract">AprilTag 2: Efficient and Robust Fiducial Detection</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151234" title="Click to go to the Author Index">Wang, John</a></td><td class="r">Univ. of Michigan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107201" title="Click to go to the Author Index">Olson, Edwin</a></td><td class="r">Univ. of Michigan</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1377" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Virtual_Reality_and_Interfaces" title="Click to go to the Keyword Index">Virtual Reality and Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> AprilTags and other passive fiducial markers require specialized algorithms to detect markers among other features in a natural scene. The vision processing steps generally dominate the computation time of a tag detection pipeline, so even small improvements in marker detection can translate to a faster tag detection system. We incorporated lessons learned from implementing and supporting the AprilTag system into this improved system.<p>This work describes AprilTag 2, a completely redesigned tag detector that improves robustness and efficiency compared to the original AprilTag system. The tag coding scheme is unchanged, retaining the same robustness to false positives inherent to the coding system. The new detector improves performance with higher detection rates, fewer false positives, and lower computational time. Improved performance on small images allows the use of decimated input images, resulting in dramatic gains in detection speed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_22">10:41-10:42, Paper ThT12.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1557.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1557'); return false" title="Click to show or hide the keywords and abstract">Geometrically Consistent Plane Extraction for Dense Indoor 3D Maps Segmentation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192904" title="Click to go to the Author Index">Pham, Trung</a></td><td class="r">The Univ. of Adelaide</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192893" title="Click to go to the Author Index">Eich, Markus</a></td><td class="r">Queensland Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106056" title="Click to go to the Author Index">Reid, Ian</a></td><td class="r">Univ. of Adelaide</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104541" title="Click to go to the Author Index">Wyeth, Gordon</a></td><td class="r">Queensland Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1557" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Modern SLAM systems with a depth sensor are able to reliably reconstruct dense 3D geometric maps of indoor scenes. Representing these maps in terms of meaningful entities is a step towards building semantic maps for autonomous robots. One approach is to segment the 3D maps into semantic objects using Conditional Random Fields (CRF), which requires large 3D ground truth datasets to train the classification model. Additionally, the CRF inference is often computationally expensive. In this paper, we present an unsupervised geometric-based approach for the segmentation of 3D point clouds into objects and meaningful scene structures. We approximate an input point cloud by an adjacency graph over surface patches, whose edges are then classified as being either on or off. We devise an effective classifier which utilises both global planar surfaces and local surface convexities for edge classification. More importantly, we propose a novel global plane extraction algorithm for robustly discovering the underlying planes in the scene. Our algorithm is able to enforce the extracted planes to be mutually orthogonal or parallel which conforms usually with human-made indoor environments. We reconstruct 654 3D indoor scenes from NYUv2 sequences to validate the efficiency and effectiveness of our segmentation method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_23">10:42-10:43, Paper ThT12.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1587.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1587'); return false" title="Click to show or hide the keywords and abstract">Visibility Maps for Any-Shape Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180210" title="Click to go to the Author Index">Pereira, Tiago</a></td><td class="r">Carnegie Mellon Univ. & Faculty of Engineering of Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104232" title="Click to go to the Author Index">Veloso, Manuela</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129151" title="Click to go to the Author Index">Moreira, Antonio Paulo</a></td><td class="r">Univ. of Porto, Faculty of Engineering</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1587" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a></span><br>
                           <strong>Abstract:</strong> We introduce in this paper visibility maps for robots of any shape, representing the reachability limit of the robot’s motion and sensing in a 2D gridmap with obstacles. The brute-force approach to determine the optimal visibility map is computationally expensive, and prohibitive with dynamic obstacles. We contribute the Robot-Dependent Visibility Map (RDVM) as a close approximation to the optimal, and an effective algorithm to compute it. The RDVM is a function of the robot’s shape, initial position, and sensor model. We first overview the computation of RDVM for the circular robot case in terms of the partial morphological closing operation and the optimal choice for the critical points position. We then present how the RDVM for any-shape robots is computed. In order to handle any robot shape, we introduce in the first step multiple layers that discretize the robot orientation. In the second step, our algorithm determines the frontiers of actuation, similarly to the case of the the circular robot case. We then derive the concept of critical points to the any-shape robot, as the points that maximize expected visibility inside unreachable regions. We compare our method with the ground-truth in a simulated map compiled to capture a variety of challenges of obstacle distribution and type, and discuss the accuracy of our approximation to the optimal visibility map.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_24">10:43-10:44, Paper ThT12.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1619.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1619'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>PL-SVO: Semi-Direct Monocular Visual Odometry by Combining Points and Line Segments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180446" title="Click to go to the Author Index">Gomez-Ojeda, Ruben</a></td><td class="r">Univ. of Málaga</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180436" title="Click to go to the Author Index">Briales, Jesus</a></td><td class="r">Univ. of Málaga</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151076" title="Click to go to the Author Index">González-Jiménez, Javier</a></td><td class="r">Univ. of Málaga</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1619" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1619.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> Most approaches to visual odometry estimates the camera motion based on point features, consequently, their performance deteriorates in low-textured scenes where it is difficult to find a reliable set of them. This paper extends a popular semi-direct approach to monocular visual odometry known as SVO [1] to work with line segments, hence obtaining a more robust system capable of dealing with both textured and structured environments. The proposed odometry system allows for the fast tracking of line segments since it eliminates the necessity of continuously extracting and matching features between subsequent frames. The method, of course, has a higher computational burden than the original SVO, but it still runs with frequencies of 60Hz on a personal computer while performing robustly in a wider variety of scenarios.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht12_25">10:44-10:45, Paper ThT12.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1722.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1722'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Calibration and Correction of Vignetting Effects with an Application to 3D Mapping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158810" title="Click to go to the Author Index">Alexandrov, Sergey</a></td><td class="r">Vienna Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131301" title="Click to go to the Author Index">Prankl, Johann</a></td><td class="r">Univ. of Tech. Vienna</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114937" title="Click to go to the Author Index">Zillich, Michael</a></td><td class="r">Vienna Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102411" title="Click to go to the Author Index">Vincze, Markus</a></td><td class="r">Vienna Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1722" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1722.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Cheap RGB-D sensors are ubiquitous in robotics. They typically contain a consumer-grade color camera that suffers from significant optical nonlinearities, often referred to as vignetting effects. For example, in Asus Xtion Live Pro cameras the pixels in the corners are two times darker than those in the center of the image. This deteriorates the visual appearance of 3D maps built with such cameras. We propose a simple calibration method that only requires a sheet of white paper as a calibration object and allows to reliably recover the vignetting response of a camera. We demonstrate calibration results for multiple popular RGB-D sensors and show that removal of vignetting effects using a nonparametric response model results in improved color coherence of the reconstructed maps. Furthermore, we show how to effectively compensate color variations caused by automatic white balance and exposure time control of the camera.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thk3t12"><b>ThK3T12</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thk3t12" title="Click to go to the Program at a Glance"><b>Keynote Talk 7. Seth Hutchinson: Robust Distributed Control Policies for
<br>Multi-Robot Systems</b></a></td>
               <td class="r">Keynote session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#107991" title="Click to go to the Author Index">Cho, Young-Jo</a></td><td class="r">Electronics and Telecommunications Res. Inst</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thai1"><b>ThAI1</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thai1" title="Click to go to the Program at a Glance"><b>Interactive Session: Learning in Robotics</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#155614" title="Click to go to the Author Index">del Pobil, Angel P.</a></td><td class="r">Jaume-I Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#101300" title="Click to go to the Author Index">Chatila, Raja</a></td><td class="r">ISIR</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thai2"><b>ThAI2</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thai2" title="Click to go to the Program at a Glance"><b>Interactive Session: Robot Vision</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101938" title="Click to go to the Author Index">Marchand, Eric</a></td><td class="r">Univ. De Rennes 1, IRISA, INRIA Rennes</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#134944" title="Click to go to the Author Index">Zingg, Simon</a></td><td class="r">ETH Zurich</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that1"><b>ThAT1</b></a></td>
               <td class="r">#101</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that1" title="Click to go to the Program at a Glance"><b>Motion Planning for Manipulators</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104009" title="Click to go to the Author Index">Taïx, Michel</a></td><td class="r">LAAS-CNRS/Univ. Paul Sabatier</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#106534" title="Click to go to the Author Index">Mozos, Oscar</a></td><td class="r">Tech. Univ. of Cartagena</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that1_01">10:55-11:10, Paper ThAT1.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0105.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('105'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Motion Planning for Fluid Manipulation Using Simplified Dynamics</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195288" title="Click to go to the Author Index">Pan, Zherong</a></td><td class="r">The Univ. of North Carolina at Chapel Hill</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106235" title="Click to go to the Author Index">Manocha, Dinesh</a></td><td class="r">Univ. of North Carolina at Chapel Hill</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab105" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0105.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a></span><br>
                           <strong>Abstract:</strong> Robot manipulation of liquid sees a lot of applications in daily lives. In this work, we present an optimization based planning framework to compute a smooth trajectory of a manipulator used to transfer a liquid from a source to target container. In order to handle the very high dimensional configuration space of a liquid body, we use a much reduced configuration space and simplified dynamics model based on simple heuristics and system identification to generate a path using trajectory optimization. Our optimization framework can readily incorporate various other constraints such as collision avoidance and different fluid properties. We demonstrate the performance of our planner on different benchmarks corresponding to various obstacle shape and fluid materials. Furthermore, we also evaluate its accuracy by comparing the resulting path with an expensive 3D liquid simulator governed by Navier-Stokes equation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that1_02">11:10-11:25, Paper ThAT1.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0154.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('154'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>An Anticipative Kinematic Limitation Avoidance Algorithm for Collaborative Robots: Two-Dimensional Case</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149886" title="Click to go to the Author Index">Campeau-Lecours, Alexandre</a></td><td class="r">Univ. Laval</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105379" title="Click to go to the Author Index">Gosselin, Clement</a></td><td class="r">Univ. Laval</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab154" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0154.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Performance_Augmentation" title="Click to go to the Keyword Index">Human Performance Augmentation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a></span><br>
                           <strong>Abstract:</strong> This paper presents an anticipative robot kinematic limitation avoidance algorithm for collaborative robots. The main objective is to improve the performance and the intuitivity of the physical human-robot interaction. One obstacle to achieve this goal is the management of limitations such as joint position limitation, singularities and collisions with the environment. Indeed, in addition to performing a given principal task, human users must pay a close attention to the manipulator configuration in order to handle the kinematic limitations. The proposed anticipative algorithm aims at relieving the human user from having to deal with such limitations. The algorithm is first presented and detailed for each individual limitation of a planar RR serial robot. The framework developed to manage several limitations occurring simultaneously is then presented. Finally, experiments are performed in order to assess the performance of the algorithm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that1_03">11:25-11:40, Paper ThAT1.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0427.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('427'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Combining Motion Planning and Task Assignment for a Dual-Arm System</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155122" title="Click to go to the Author Index">Rodriguez Pacheco, Carlos</a></td><td class="r">Univ. Pol. De Catalunya</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104168" title="Click to go to the Author Index">Suarez, Raul</a></td><td class="r">Univ. Pol. De Catalunya (UPC)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab427" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0427.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a></span><br>
                           <strong>Abstract:</strong> This paper deals with the problem of combining motion and task assignment for a dual-arm robotic system. Each arm of the system performs independent tasks in a cluttered environment. Robot actions are determined to remove potential obstacles from the environment and obtain collision-free paths to grasp the target objects. The approach uses the information provided by the motion planner to build a graph structure in order to represent the obstacles to be removed. The graph is used, first, to decide which is the next motion path to be computed, and, second, to assign the tasks to each arm of the robotic system. The approach has been implemented for a dual-arm robotic system and real experiments are presented in the paper.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that1_04">11:40-11:55, Paper ThAT1.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0472.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('472'); return false" title="Click to show or hide the keywords and abstract">I-RRT-C : Interactive Motion Planning with Contact</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195558" title="Click to go to the Author Index">Blin, Nassime Michel</a></td><td class="r">Laas-Cnrs, Lgp-Enit</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104009" title="Click to go to the Author Index">Taïx, Michel</a></td><td class="r">LAAS-CNRS/Univ. Paul Sabatier</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151995" title="Click to go to the Author Index">Fillatreau, Philippe</a></td><td class="r">ENIT Tarbes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107327" title="Click to go to the Author Index">Fourquet, Jean-Yves</a></td><td class="r">ENIT</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab472" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Virtual_Reality_and_Interfaces" title="Click to go to the Keyword Index">Virtual Reality and Interfaces</a></span><br>
                           <strong>Abstract:</strong> This work deals with interactive motion planning processes intended to assist a human operator when simulating industrial tasks such as assembly, maintenance or disassembly in Virtual Reality. Such applications need motion planning on surfaces. We propose an original interactive path planning algorithm with contact, I-RRT-C, based on a RRT-Connect approach. This algorithm is based on a real-time interactive approach allowing both an automatic motion planner and a human operator to jointly explore the workspace. A parameter balances the authority between the computer and the operator to reduce processing times. We improve the guidance by allowing to sample on the surfaces of obstacles. Our method allows to find a path in cluttered environments or to solve contact operations such as insertion or sliding tasks. Last, we present experimental results showing that our interactive path planner with contact brings a significant improvement over state of the art methods in both free and contact space.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that2"><b>ThAT2</b></a></td>
               <td class="r">#102</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that2" title="Click to go to the Program at a Glance"><b>Visual Servoing 1</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#103169" title="Click to go to the Author Index">Robuffo Giordano, Paolo</a></td><td class="r">Centre National De La Recherche Scientifique (CNRS)</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#103432" title="Click to go to the Author Index">Fumagalli, Matteo</a></td><td class="r">Aalborg Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that2_01">10:55-11:10, Paper ThAT2.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0205.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('205'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>FPGA-Based 6-DoF Pose Estimation with a Monocular Camera Using Non Co-Planer Marker and Application on Micro Quadcopter</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162666" title="Click to go to the Author Index">Konomura, Ryo</a></td><td class="r">Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158519" title="Click to go to the Author Index">Hori, Koichi</a></td><td class="r">Univ. of Tokyo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab205" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0205.VI.mpeg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a></span><br>
                           <strong>Abstract:</strong> Self-localization using visual markers is widely used for precise control of Unmanned aerial vehicles (UAVs). This paper presents a novel method of 6-DoF pose estimation using a monocular camera and non co-planar markers. We conducted numerical simulations comparing pose estimation using co-planar markers and using non co-planar markers, and designed a non co-planar marker feasible for robotics applications. Our method uses a single CPU core and a field programmable gate array (FPGA) and can conduct fast and precise 6-DoF pose estimation at the same frequency of the camera input (100 fps).In addition, to show the performance of our method, we applied our 6-DoF pose estimation algorithm to a palm-sized quadcopter and flew it autonomously using only an on-board system with a monocular camera and three-axis gyro sensor.To the authors' knowledge, this is the first study on fully on-board autonomous flight control of an MAV in 6-DoF space without an accelerometer.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that2_02">11:10-11:25, Paper ThAT2.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0587.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('587'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Adaptive Repetitive Visual-Servo Control of a Low-Flying Unmanned Aerial Vehicle with an Uncalibrated High-Flying Camera</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171796" title="Click to go to the Author Index">Guo, Dejun</a></td><td class="r">Univ. of Utah</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111336" title="Click to go to the Author Index">Yim, Woosoon</a></td><td class="r">Univ. of Nevada, Las Vegas</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115056" title="Click to go to the Author Index">Leang, Kam K.</a></td><td class="r">Univ. of Utah</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab587" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0587.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> This paper proposes a new adaptive repetitive visual-servo control system for a moving high-flying vehicle (HFV) with an uncalibrated camera to monitor, track, and precisely control the movements of a low-flying vehicle (LFV) or mobile ground robot. When deployed, a remote operator of the HFV defines the desired trajectory for the LFV in the HFV’s camera frame (image frame). Due to the circulatory motion of the HFV, the resulting motion trajectory of the LFV in the image frame is periodic in time, thus an adaptive repetitive control system is exploited to improve the tracking precision from one operating period to the next. Not only is the adaptive control law able to deal with uncertainties in the camera’s intrinsic and extrinsic parameters, but it can also tolerate uncertainties in the localization of the LFV. The design and stability analysis of the closed-loop control system is presented, where the Lyapunov approach is used to show stability. Simulations and experimental results are presented to demonstrate the effectiveness of the method for controlling the movement of a low-flying quadcopter vehicle. Results show good tracking performance for three simulated test cases, where the average maximum tracking error is reduced by approximately 75% compared to the performance of a standard adaptive visual-servo controller.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that2_03">11:25-11:40, Paper ThAT2.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0695.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('695'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Visual-Based Shared Control Architecture for Remote Telemanipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159840" title="Click to go to the Author Index">Abi-Farraj, Firas</a></td><td class="r">CNRS-Irisa</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162140" title="Click to go to the Author Index">Pedemonte, Nicolò</a></td><td class="r">CNRS at Irisa and Inria Rennes Bretagne Atlantique</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103169" title="Click to go to the Author Index">Robuffo Giordano, Paolo</a></td><td class="r">Centre National De La Recherche Scientifique (CNRS)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab695" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0695.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Telerobotics" title="Click to go to the Keyword Index">Telerobotics</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a></span><br>
                           <strong>Abstract:</strong> Cleaning up the past half century of nuclear waste represents the largest environmental remediation project in the whole Europe. Nuclear waste must be sorted, segregated and stored according to its radiation level in order to optimize maintenance costs. The objective of this work is to develop a shared control framework for remote manipulation of objects using visual information. In the presented scenario, the human operator must control a system composed of two robotic arms, one equipped with a gripper and the other one with a camera. In order to facilitate the operator’s task, a subset of the gripper motion are assumed to be regulated by an autonomous algorithm exploiting the camera view of the scene. At the same time, the operator has control over the remaining null-space motions w.r.t. the primary (autonomous) task by acting on a force feedback device. A novel force feedback algorithm is also proposed with the aim of informing the user about possible constraints of the robotic system such as, for instance, joint limits. Human/hardware-in-the-loop experiments with simulated slave robots and a real master device are finally reported for demonstrating the feasibility and effectiveness of the approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that2_04">11:40-11:55, Paper ThAT2.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0859.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('859'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Single Frequency-Based Visual Servoing for Microrobotics Applications</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179825" title="Click to go to the Author Index">Guelpa, Valérian</a></td><td class="r">FEMTO-ST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109843" title="Click to go to the Author Index">Laurent, Guillaume J.</a></td><td class="r">FEMTO-ST Inst. - CNRS - ENSMM - Univ. Defranche-Comté</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117023" title="Click to go to the Author Index">Tamadazte, Brahim</a></td><td class="r">Cnrs, Ufc/ensmm/utbm</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168687" title="Click to go to the Author Index">Sandoz, Patrick</a></td><td class="r">FEMTO-ST Inst. - CNRS UMR 6174</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123108" title="Click to go to the Author Index">Le Fort-Piat, Nadine</a></td><td class="r">FEMTO-ST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109781" title="Click to go to the Author Index">Clévy, Cédric</a></td><td class="r">Franche-Comté Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab859" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0859.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> Recently, high resolution visual methods based on direct-phase measurement of periodic patterns has been proposed with successful applications to microrobotics. This paper proposes a new implementation of direct-phase measurement methods to achieve 3-DoF (degrees of freedom) visual servoing. The proposed algorithm relies on a single frequency tracking rather than a complete 2D discrete Fourier transform that was required in previous works. The method does not require any calibration step and has many advantages such as high subpixelic resolution, high robustness and short computation time. Several experimental validations (in favorable and unfavorable conditions of use) were performed using a XYtheta microrobotic platform. The obtained results demonstrate the efficiency of the frequency-based controller, this in term of accuracy (micrometric error), convergence rate (30 iterations in nominal conditions) and robustness.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that3"><b>ThAT3</b></a></td>
               <td class="r">#103</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that3" title="Click to go to the Program at a Glance"><b>Novel Range Sensing</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#115227" title="Click to go to the Author Index">Mordohai, Philippos</a></td><td class="r">Stevens Inst. of Tech</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#107836" title="Click to go to the Author Index">Leutenegger, Stefan</a></td><td class="r">Imperial Coll. London</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that3_01">10:55-11:10, Paper ThAT3.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0555.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('555'); return false" title="Click to show or hide the keywords and abstract">Real-Time Height Map Fusion Using Differentiable Rendering</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166753" title="Click to go to the Author Index">Zienkiewicz, Jacek</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105540" title="Click to go to the Author Index">Davison, Andrew J</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151104" title="Click to go to the Author Index">Leutenegger, Stefan</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab555" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> We present a robust real-time method which performs dense reconstruction of high quality height maps from monocular video. By representing the height map as a triangular mesh, and using efficient differentiable rendering approach, our method enables rigorous incremental probabilistic fusion of standard locally estimated depth and colour into an immediately usable dense model. We present results for the application of free space and obstacle mapping by a low-cost robot, showing that detailed maps suitable for autonomous navigation can be obtained using only a single forward-looking camera.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that3_02">11:10-11:25, Paper ThAT3.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1094.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1094'); return false" title="Click to show or hide the keywords and abstract">Underwater Inspection Using Sonar-Based Volumetric Submaps</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195896" title="Click to go to the Author Index">Vaz Teixeira, Pedro</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104298" title="Click to go to the Author Index">Kaess, Michael</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114304" title="Click to go to the Author Index">Hover, Franz</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107631" title="Click to go to the Author Index">Leonard, John</a></td><td class="r">MIT</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1094" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> We propose a submap-based technique for mapping of underwater structures with complex geometries. Our approach relies on the use of probabilistic volumetric techniques to create submaps from multibeam sonar scans, as these offer increased outlier robustness. Special attention is paid to the problem of denoising/enhancing sonar data. Pairwise submap alignment constraints are used in a factor graph framework to correct for navigation drift and improve map accuracy. We provide experimental results obtained from the inspection of the running gear and bulbous bow of a 600-foot, Wright-class supply ship.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that3_03">11:25-11:40, Paper ThAT3.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1157.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1157'); return false" title="Click to show or hide the keywords and abstract">Fast Robust Monocular Depth Estimation for Obstacle Detection with Fully Convolutional Networks</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184454" title="Click to go to the Author Index">Mancini, Michele</a></td><td class="r">Univ. of Perugia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150020" title="Click to go to the Author Index">Costante, Gabriele</a></td><td class="r">Univ. of Perugia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#119696" title="Click to go to the Author Index">Valigi, Paolo</a></td><td class="r">Univ. Di Perugia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150004" title="Click to go to the Author Index">Ciarfuglia, Thomas Alessandro</a></td><td class="r">Univ. Degli Studi Di Perugia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1157" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a></span><br>
                           <strong>Abstract:</strong> Obstacle Detection is a central problem for any robotic system, and critical for autonomous systems that travel at high speeds in unpredictable environment. This is often achieved through scene depth estimation, by various means. When fast motion is considered, the detection range must be longer enough to allow for safe avoidance and path planning. Current solutions often make assumption on the motion of the vehicle that limit their applicability, or work at very limited ranges due to intrinsic constraints. We propose a novel appearance-based Object Detection system that is able to detect obstacles at very long range and at a very high speed (mathbf{sim300Hz}), without making assumptions on the type of motion. We achieve these results using a Deep Neural Network approach trained on real and synthetic images and trading some depth accuracy for fast, robust and consistent operation. We show how photo-realistic synthetic images are able to solve the problem of training set dimension and variety typical of machine learning approaches, and how our system is robust to massive blurring of test images.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that3_04">11:40-11:55, Paper ThAT3.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1654.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1654'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>2D and 3D Millimeter-Wave Synthetic Aperture Radar Imaging on a PR2 Platform</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196491" title="Click to go to the Author Index">Watts, Claire</a></td><td class="r">Univ. of Washington</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179917" title="Click to go to the Author Index">Lancaster, Patrick</a></td><td class="r">Univ. of Washington</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196888" title="Click to go to the Author Index">Pedross-Engel, Andreas</a></td><td class="r">Univ. of Washington</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106242" title="Click to go to the Author Index">Smith, Joshua R.</a></td><td class="r">Univ. of Washington</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#112853" title="Click to go to the Author Index">Reynolds, Matthew</a></td><td class="r">Univ. of Washington</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1654" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1654.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Navigation" title="Click to go to the Keyword Index">Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a></span><br>
                           <strong>Abstract:</strong> Optical depth cameras, including both time-of-flight and structured-light sensors, have led to dramatic improvement in robot sensing and perception. We propose the use of millimeter-wave (mmW) radar as an important complement to optical sensors. While the millimeter wavelengths of radar sensors do not support as high resolution as the nanometer wavelength of optical sensors, the ability of mmW signals to penetrate smoky and foggy environments as well as see through many opaque objects makes them a compelling sensor for navigation as well as manipulation in challenging environments. We present a series of 2D and 3D mmW images made with a hand-held antenna grasped by a PR2 robot. The radar image sensor uses a mechanical &quot;painting&quot; motion to acquire multiple views of the target object over the 17 to 26 GHz K-band. A GPU-based reconstruction algorithm synthesizes 2D and 3D images of the target object. We demonstrate a range resolution of 13.6 mm and a cross-range resolution of 7.1 mm for objects up to 0.5 m away from the robot. We further demonstrate imaging objects through fog, as well as through opaque paper.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that4"><b>ThAT4</b></a></td>
               <td class="r">#104</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that4" title="Click to go to the Program at a Glance"><b>Surgical Robotics 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101790" title="Click to go to the Author Index">Dupont, Pierre</a></td><td class="r">Children's Hospital Boston, Harvard Medical School</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#117925" title="Click to go to the Author Index">Yang, Guang-Zhong</a></td><td class="r">Imperial Coll. London</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that4_01">10:55-11:10, Paper ThAT4.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0423.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('423'); return false" title="Click to show or hide the keywords and abstract">A Dynamic Non-Energy-Storing Guidance Constraint with Motion Redirection for Robot-Assisted Surgery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132714" title="Click to go to the Author Index">Enayati, Nima</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191657" title="Click to go to the Author Index">Costa, Eva</a></td><td class="r">Univ. of Minho</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115335" title="Click to go to the Author Index">Ferrigno, Giancarlo</a></td><td class="r">Pol. Di Milano</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131482" title="Click to go to the Author Index">De Momi, Elena</a></td><td class="r">Pol. Di Milano</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab423" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> Haptically enabled hands-on or tele-operated surgical robotic systems provide a unique opportunity to integrate pre- and intra-operative information into physical actions through active constraints (also known as virtual fixtures). In many surgical procedures, including cardiac interventions, where physiological motion complicates tissue manipulation, dynamic active constraints can improve the performance of the intervention in terms of safety and accuracy. The non-energy-storing class of dynamic guidance constraints attempt to assist the clinician in following a reference path, while guaranteeing that the control system will not generate undesired motion due to stored potential energy. An important aspect that has not received much attention from the researchers is that while these methods help increase the performance, they should by no means distract the user systematically. In this paper, a viscosity-based dynamic guidance constraint is introduced that continuously redirects the tool’s motion towards the reference path. The proportionality and continuity of generated forces make the method less distracting and subjectively appealing. The performance is validated and compared with two existing non-energy-storing methods through extensive experimentation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that4_02">11:10-11:25, Paper ThAT4.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0928.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('928'); return false" title="Click to show or hide the keywords and abstract">Motor Channelling for Safe and Effective Dynamic Constraints in Minimally Invasive Surgery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167996" title="Click to go to the Author Index">Grammatikopoulou, Maria</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157759" title="Click to go to the Author Index">Leibrandt, Konrad</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117925" title="Click to go to the Author Index">Yang, Guang-Zhong</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab928" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperative_Manipulators" title="Click to go to the Keyword Index">Cooperative Manipulators</a></span><br>
                           <strong>Abstract:</strong> Motor channelling is a concept to provide navigation and sensory feedback to operators in master-slave surgical setups. It is beneficial since the introduction of robotic surgery creates a physical separation between the surgeon and patient anatomy. Active Constraints/Virtual Fixtures are proposed which integrate Guidance and Forbidden Region Constraints into a unified control framework. The developed approach provides guidance and safe manipulation to improve precision and reduce the risk of inadvertent tissue damage. Online three-degree-of-freedom motion prediction and compensation of the target anatomy is performed to complement the master constraints. The presented Active Constraints concept is applied to two clinical scenarios; surface scanning for in situ medical imaging and vessel manipulation in cardiac surgery. The proposed motor channelling control strategy is implemented on the da Vinci Surgical System using the da Vinci Research Kit (dVRK) and its effectiveness is demonstrated through a detailed user study.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that4_03">11:25-11:40, Paper ThAT4.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1046.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1046'); return false" title="Click to show or hide the keywords and abstract">Adaptive Nonparametric Kinematic Modeling of Concentric Tube Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122592" title="Click to go to the Author Index">Fagogenis, Georgios</a></td><td class="r">Heriot Watt Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114412" title="Click to go to the Author Index">Bergeles, Christos</a></td><td class="r">Univ. Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101790" title="Click to go to the Author Index">Dupont, Pierre</a></td><td class="r">Children's Hospital Boston, Harvard Medical School</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1046" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> Concentric tube robots comprise telescopic precurved elastic tubes. The robot’s tip and shape are controlled via relative tube motions, i.e. tube rotations and translations. Non-linear interactions between the tubes, e.g. friction and torsion, as well as uncertainty in the physical properties of the tubes themselves, e.g. the Young’s modulus, curvature, or stiffness, hinder accurate kinematic modelling. In this paper, we present a machine-learning-based methodology for kinematic modelling of concentric tube robots and in situ model adaptation. Our approach is based on Locally Weighted Projection Regression (LWPR). The model comprises an ensemble of linear models, each of which locally approximates the original complex kinematic relation. LWPR can accommodate for model deviations by adjusting the respective local models at run-time, resulting in an adaptive kinematics framework. We evaluated our approach on data gathered from a three-tube robot, and report high accuracy across the robot’s configuration space.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that4_04">11:40-11:55, Paper ThAT4.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1603.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1603'); return false" title="Click to show or hide the keywords and abstract">Reconfigurable Parallel Continuum Robots for Incisionless Surgery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181099" title="Click to go to the Author Index">Mahoney, Art</a></td><td class="r">Vanderbilt Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190469" title="Click to go to the Author Index">Anderson, Patrick</a></td><td class="r">Vanderbilt Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143320" title="Click to go to the Author Index">Swaney, Philip J.</a></td><td class="r">Vanderbilt Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202556" title="Click to go to the Author Index">Maldonado, Fabien</a></td><td class="r">Vanderbilt Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101891" title="Click to go to the Author Index">Webster III, Robert James</a></td><td class="r">Vanderbilt Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1603" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a></span><br>
                           <strong>Abstract:</strong> We propose a new class of robotic device for minimally-invasive surgery that lies at the intersection of continuum, parallel, and reconfigurable robotics. This Continuum Reconfigurable Incisionless Surgical Parallel (CRISP) paradigm involves the use of multiple needle-diameter devices inserted through the skin and assembled into parallel structures inside the body. The parallel structure can be reconfigured inside the patient's body to satisfy changing task requirements such as reaching initially inaccessible locations or modifying mechanical stiffness for manipulation or palpation. Another potential advantage of the CRISP concept is that many small (needle-sized) entry points into the patient may be preferable in terms of both patient healing and cosmesis to the single (or multiple) larger ports needed to admit current surgical robots. This paper presents a mechanics-based model for CRISP forward and inverse kinematics, along with experimental validation.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that5"><b>ThAT5</b></a></td>
               <td class="r">#105</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that5" title="Click to go to the Program at a Glance"><b>Mechanisms and Parallel Robots</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104776" title="Click to go to the Author Index">Song, Jae-Bok</a></td><td class="r">Korea Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#102662" title="Click to go to the Author Index">Amato, Nancy</a></td><td class="r">Texas A&M Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that5_01">10:55-11:10, Paper ThAT5.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0361.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('361'); return false" title="Click to show or hide the keywords and abstract">A Generic Numerical Continuation Scheme for Solving the Direct Kinematics of Cable-Driven Parallel Robot with Deformable Cables</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102001" title="Click to go to the Author Index">Merlet, Jean-Pierre</a></td><td class="r">INRIA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab361" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a>, <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a></span><br>
                           <strong>Abstract:</strong> Solving the direct kinematics (DK) of parallel robots, i.e. finding all the possible poses of the platform for given input values, is most of the time a difficult problem. This is evidently true for cable-driven parallel robots (CDPR) that are more complex than classical parallel robot because of the unilateral nature of the cable actions but also if cable deformations are taken into account. Furthermore there are many different deformable cable models and developing a DK algorithm for each of them will be a tremendous task. Consequently using a numerical continuation scheme that starts from the DK solutions for non-deformable cables and then moves toward the solution for deformable cables appears to be an interesting approach. We first investigate what assumption have to be satisfied by the cable model for using this approach and derive a possible maximum of solutions for the DK, whatever is the cable model. We then apply this approach for a specific complex cable model, the catenary case, to show that this approach is computer efficient but requires to address difficult theoretical issues in order to obtain a solving algorithm that is guaranteed to determine all DK solutions.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that5_02">11:10-11:25, Paper ThAT5.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0518.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('518'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Reduction in Gravitational Torques of an Industrial Robot Equipped with 2 DOF Passive Counterbalance Mechanisms</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192840" title="Click to go to the Author Index">Ahn, Kuk Hyun</a></td><td class="r">Korea Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195903" title="Click to go to the Author Index">Lee, Won-Bum</a></td><td class="r">Korea Univ. Intelligence Robotics Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104776" title="Click to go to the Author Index">Song, Jae-Bok</a></td><td class="r">Korea Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab518" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0518.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a></span><br>
                           <strong>Abstract:</strong> In most 6 DOF robot arms, considerable amounts of gravitational torques due to the robot’s own weight are applied to pitch joints of the robot, which causes most arms to use high capacity motors and speed reducers. A spring-based counterbalance mechanism can compensate for this gravitational torque, thus leading to a significant reduction in the effect of gravity. However, a simple installation of counterbalance mechanisms at each pitch joint does not work properly because the gravitational torque at each joint is dependent also on the other joints. To achieve multi-DOF counterbalancing, we propose a parallelogram linkage combined with dual counterbalance mechanisms, each being composed of a slider-crank mechanism and springs. Simulations and experimental results showed that the counterbalance robot arm based on the proposed counterbalance mechanisms effectively reduced the torques required to support the robot mass, thus allowing the prospective use of much smaller motors and speed reducers than traditional industrial robots.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that5_03">11:25-11:40, Paper ThAT5.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0879.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('879'); return false" title="Click to show or hide the keywords and abstract">Improving Cable Driven Parallel Robot Accuracy through Angular Position Sensors</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168189" title="Click to go to the Author Index">Fortin-Côté, Alexis</a></td><td class="r">Univ. Laval</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143407" title="Click to go to the Author Index">Cardou, Philippe</a></td><td class="r">Univ. Laval</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149886" title="Click to go to the Author Index">Campeau-Lecours, Alexandre</a></td><td class="r">Univ. Laval</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab879" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Parallel_Robots" title="Click to go to the Keyword Index">Parallel Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Tendon_Wire_Mechanisms" title="Click to go to the Keyword Index">Tendon/Wire Mechanisms</a></span><br>
                           <strong>Abstract:</strong> Conventionally, a cable driven parallel mechanism (CDPM) pose is obtained through the forward kinematics from measurements of the cable lengths. However, this estimation method can be limiting for some applications requiring more precision. This paper proposes to use cable angle position sensors in addition to cable length measurements in order to improve the accuracy of such mechanisms. The robot pose is first obtained individually by the cable length measurements and the cable angle position measurements. A data fusion scheme combining these two types of measurements is then proposed in order to improve the CPDM accuracy. Finally, simulations and experiments are presented in order to assess the benefits of using cable angle position sensors on the CDPM.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that5_04">11:40-11:55, Paper ThAT5.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1651.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1651'); return false" title="Click to show or hide the keywords and abstract">Design and Modeling of a Compact Rotational Nonlinear Spring</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147503" title="Click to go to the Author Index">Jalaly Bidgoly, Hamed</a></td><td class="r">Univ. of Tehran</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100730" title="Click to go to the Author Index">Nili Ahmadabadi, Majid</a></td><td class="r">Univ. of Tehran</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195949" title="Click to go to the Author Index">Zakerzadeh, Mohammad Reza</a></td><td class="r">Univ. of Tehran</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1651" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_and_Compliant_Assembly" title="Click to go to the Keyword Index">Manipulation and Compliant Assembly</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a new method for implementing a rotational nonlinear spring with user defined profile, based on the combination of a linear spring with a nonlinear transmission mechanism. The proposed structure consists of a non-circular cam, a roller which moves along outer circumference of the cam, and a stretched translational linear spring which is connected between center of the cam and center of the roller. We obtain a set of differential equations to design shape of the cam for any given torque-angle profile. Also, it will be shown that profiles with both positive and negative values can be implemented by the proposed method. At last, the cam of some popular nonlinear springs are designed, including constant, cubic, hyperbolic tangent and sinusoidal springs.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that6"><b>ThAT6</b></a></td>
               <td class="r">#106</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that6" title="Click to go to the Program at a Glance"><b>Space Robotics and Automation</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#180377" title="Click to go to the Author Index">Agogino, Alice</a></td><td class="r">Univ. of California Berkeley</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#137355" title="Click to go to the Author Index">Coltin, Brian</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that6_01">10:55-11:10, Paper ThAT6.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0434.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('434'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Image Space Based Path Planning for Reactionless Manipulation of Redundant Space Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191605" title="Click to go to the Author Index">Bhargava, Rachit</a></td><td class="r">IIIT Hyderabad</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192798" title="Click to go to the Author Index">P, Mithun</a></td><td class="r">International Inst. of Information Tech. Hyderabad</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166259" title="Click to go to the Author Index">Viswanadha Visagakoti, Anurag</a></td><td class="r">IIIT-Hyderabad</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104143" title="Click to go to the Author Index">Abdul Hafez, A. H.</a></td><td class="r">Hasan Kalyoncu Uiversity</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113621" title="Click to go to the Author Index">Shah, Suril Vijaykumar</a></td><td class="r">Indian Inst. of Tech. Jodhpur</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab434" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0434.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a></span><br>
                           <strong>Abstract:</strong> This work addresses path planning for reactionless visual servoing of a redundant dual-arm space robot through exploration in the image space. The planner explores the image moment based feature space, impends acceleration to the image features and extends the feature tree. A reactionless visual servoing control law is integrated to extend the tree in the configuration space simultaneously. The proposed algorithm is able to incorporate the necessary coupling between the motions of the the dual arms and the base of the robot to ensure zero base reactions. Additionally, it also gives the flexibility to apply multiple constraints in both the image space and the configuration space. The effectiveness of the proposed framework is exhibited by implementing the algorithm on a numerical model of a 14-DoF dual arm space robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that6_02">11:10-11:25, Paper ThAT6.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0876.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('876'); return false" title="Click to show or hide the keywords and abstract">Hopping and Rolling Locomotion with Spherical Tensegrity Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185089" title="Click to go to the Author Index">Kim, Kyunam</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196878" title="Click to go to the Author Index">Chen, Lee-Huang</a></td><td class="r">Univ. OF CALIFORNIA BERKELEY</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#175028" title="Click to go to the Author Index">Cera, Brian</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195794" title="Click to go to the Author Index">Daly, Mallory</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195630" title="Click to go to the Author Index">Zhu, Edward</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196870" title="Click to go to the Author Index">Despois, Julien</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172287" title="Click to go to the Author Index">Agogino, Adrian</a></td><td class="r">UC Santa Cruz, NASA Ames Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137052" title="Click to go to the Author Index">SunSpiral, Vytas</a></td><td class="r">SGT Inc. / NASA Ames Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180377" title="Click to go to the Author Index">Agogino, Alice</a></td><td class="r">Univ. of California Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab876" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> This work presents a 10 kg tensegrity ball probe that can quickly and precisely deliver a 1 kg payload over a 1 km distance on the Moon by combining cable-driven rolling and thruster-based hopping. Previous research has shown that cable-driven rolling is effective for precise positioning, even in rough terrain. However, traveling large distances using thruster-based hopping, which is made feasible by the lightweight and compliant nature of the tensegrity structure, has not been explored. To evaluate the feasibility of a thruster-based tensegrity robot, a centrally-positioned cold gas thruster with nitrogen propellant was selected, and the system was simulated using the NASA Tensegrity Robotics Toolkit (NTRT) for four hopping profiles on hilly terrains. Optimizing energy efficiency and mechanical capabilities of the tensegrity robot, hopping profiles with a long flight distance per hop, followed by the higher accuracy rolling, are recommended. Simulations also show that thrust regulation can improve energy efficiency. Regulation of thrust magnitude can be achieved using a pressure regulator, but regulation of thrust orientation calls for additional control effort. In this paper, it is demonstrated that gimbal systems as well as shape-shifting control of the tensegrity structure have the potential to regulate thrust orientation. Finally, algorithms for localization and path planning that combine hopping and rolling for energy-efficient navigation are presented.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that6_03">11:25-11:40, Paper ThAT6.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1147.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1147'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Localization from Visual Landmarks on a Free-Flying Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137355" title="Click to go to the Author Index">Coltin, Brian</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196536" title="Click to go to the Author Index">Fusco, Jesse</a></td><td class="r">NASA Ames Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133203" title="Click to go to the Author Index">Moratto, Zachary</a></td><td class="r">Kansas State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196542" title="Click to go to the Author Index">Alexandrov, Oleg</a></td><td class="r">NASA Ames Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196540" title="Click to go to the Author Index">Nakamura, Robert</a></td><td class="r">NASA Ames Res. Center</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1147" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1147.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> We present the localization approach for Astrobee, a new free-flying robot designed to navigate autonomously on the International Space Station (ISS). Astrobee will accommodate a variety of payloads and enable guest scientists to run experiments in zero-g, as well as assist astronauts and ground controllers. Astrobee will replace the SPHERES robots which currently operate on the ISS, whose use of fixed ultrasonic beacons for localization limits them to work in a 2 meter cube. Astrobee localizes with monocular vision and an IMU, without any environmental modifications. Visual features detected on a pre-built map, optical flow information, and IMU readings are all integrated into an extended Kalman filter (EKF) to estimate the robot pose. We introduce several modifications to the filter to make it more robust to noise, and extensively evaluate the localization algorithm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that6_04">11:40-11:55, Paper ThAT6.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1264.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1264'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Space CoBot: Modular Design of an Holonomic Aerial Robot for Indoor Microgravity Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196484" title="Click to go to the Author Index">Roque, Pedro</a></td><td class="r">Inst. Superior Técnico. Univ. De Lisboa</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122994" title="Click to go to the Author Index">Ventura, Rodrigo</a></td><td class="r">Inst. Superior Técnico</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1264" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1264.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a></span><br>
                           <strong>Abstract:</strong> This paper presents the design of a small aerial robot for inhabited microgravity environments, such as orbiting space stations (e.g., ISS). In particular, we target a fleet of robots, called Space CoBots, for collaborative tasks with humans, such as telepresence and cooperative mobile manipulation. The design is modular, comprising an hexrotor based propulsion system, and a stack of modules including batteries, cameras for navigation, a screen for telepresence, a robotic arm, space for extension modules, and a pair of docking ports. These ports can be used for docking and for mechanically attaching two Space CoBots together. The kinematics is holonomic, and thus the translational and the rotational components can be fully decoupled. We employ a multi-criteria optimization approach to determine the best geometric configuration for maximum thrust and torque across all directions. We also tackle the problem of motion control: we use separate converging controllers for position and attitude control. Finally, we present simulation results using a realistic physics simulator. These experiments include a sensitivity evaluation to sensor noise and to unmodeled dynamics, namely a load transportation.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that7"><b>ThAT7</b></a></td>
               <td class="r">#107</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that7" title="Click to go to the Program at a Glance"><b>Human-Robot Interaction 1</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#145551" title="Click to go to the Author Index">Gateau, Thibault</a></td><td class="r">ISAE</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#189087" title="Click to go to the Author Index">Zhu, Guangming</a></td><td class="r">Xidian Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that7_01">10:55-11:10, Paper ThAT7.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0220.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('220'); return false" title="Click to show or hide the keywords and abstract">Considering Human's Non-Deterministic Behavior and His Availability State When Designing a Collaborative Human-Robots System</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#145551" title="Click to go to the Author Index">Gateau, Thibault</a></td><td class="r">ISAE</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160521" title="Click to go to the Author Index">P. Carvalho Chanel, Caroline</a></td><td class="r">ISAE-SUPAERO</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195329" title="Click to go to the Author Index">Le, Mai Huy</a></td><td class="r">Univ. Toulouse 3 Paul Sabatier</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195205" title="Click to go to the Author Index">Dehais, Frederic</a></td><td class="r">ISAE</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab220" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> The objective of this study is to design a human-robots system that takes into account the non-deterministic nature of the human operator's behavior. Such a system is implemented in a proof of concept scenario relying on a (MO)MDP decision framework that takes advantage of an eye-tracker device to estimate the cognitive availability of the human operator, and, some human operator's inputs to deduce where he is focusing his attention. An experiment was conducted with ten participants interacting with a team of autonomous vehicles in a Search & Rescue scenario. Our results demonstrate the advantages of considering the cognitive availability of a human operator in a such complex context and also the interest of using such a decisional framework that can formally integrate the non-deterministic outcomes which model the human behavior.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that7_02">11:10-11:25, Paper ThAT7.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1091.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1091'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Iterative Path Optimisation for Personalised Dressing Assistance Using Vision and Force Information</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184298" title="Click to go to the Author Index">Gao, Yixing</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184299" title="Click to go to the Author Index">Chang, Hyung Jin</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114394" title="Click to go to the Author Index">Demiris, Yiannis</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1091" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1091.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Interaction" title="Click to go to the Keyword Index">Humanoid Interaction</a></span><br>
                           <strong>Abstract:</strong> We propose an online iterative path optimisation method to enable a Baxter humanoid robot to assist human users to dress. The robot searches for the optimal personalised dressing path using vision and force sensor information: vision information is used to recognise the human pose and model the movement space of upper-body joints; force sensor information is used for the robot to detect external force resistance and to locally adjust its motion. We propose a new stochastic path optimisation method based on adaptive moment estimation. We first compare the proposed method with other path optimisation algorithms on synthetic data. Experimental results show that the performance of the method achieves the smallest error with fewer iterations and less computation time. We also evaluate real-world data by enabling the Baxter robot to assist real human users with their dressing.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that7_03">11:25-11:40, Paper ThAT7.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1522.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1522'); return false" title="Click to show or hide the keywords and abstract">Human Activity Recognition Based on Weighted Limb Features</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189088" title="Click to go to the Author Index">Zhang, Liang</a></td><td class="r">Xidian Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196708" title="Click to go to the Author Index">Yang, WenHan</a></td><td class="r">Xidian Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189087" title="Click to go to the Author Index">Zhu, Guangming</a></td><td class="r">Xidian Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189089" title="Click to go to the Author Index">Shen, Peiyi</a></td><td class="r">Xidian Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189090" title="Click to go to the Author Index">Song, Juan</a></td><td class="r">Xidian Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1522" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> Human activity recognition plays an important role in personal assistive robot, being able to recognize human activity and perform corresponding assistive action is a great challenges for personal assistive robot. Human body is an articulated system of rigid segments that can be divided into five parts. Many existing methods always identify actions based on the motion trajectories of whole body. In this paper, taking into account the fact that most actions can be performed by a few limbs and the other limbs should not impact on the action recognition, we proposed an activity recognition method based on limb weights. The weight of each limb is composed of consistence weight and uniqueness weight, which are learned according to the similarity degree among different sequences for each specific action. The covariance descriptor, which is the concatenation of eigenvalues extracted from covariance matrices, is adapted to represent the motion trajectory of each limb. In order to distinguish action instances from each other in the feature sequences, a simple annotation method is used. Experimental results on the public dataset and the Lab dataset show that the proposed method not only can outperform the state-of-the-art algorithms, but also is appropriate to recognize the actions whose non-core limbs’ trajectories are different from each other.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that7_04">11:40-11:55, Paper ThAT7.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1667.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1667'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>UAV, Come to Me: End-To-End, Multi-Scale Situated HRI with an Uninstrumented Human and a Distant UAV</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160572" title="Click to go to the Author Index">Monajjemi, Valiallah (Mani)</a></td><td class="r">Simon Fraser Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196755" title="Click to go to the Author Index">MohaimenianPour, SeyedMehdi</a></td><td class="r">Simon Fraser Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106623" title="Click to go to the Author Index">Vaughan, Richard</a></td><td class="r">Simon Fraser Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1667" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1667.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Companions_and_Social_Human_Robot_Interaction" title="Click to go to the Keyword Index">Robot Companions and Social Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> We present the first demonstration of end-to-end far-to-near situated interaction between an uninstrumented human user and an initially distant outdoor autonomous Unmanned Aerial Vehicle (UAV). The user uses an arm-waving gesture as a signal to attract the UAV's attention from a distance. Once this signal is detected, the UAV approaches the user using appearance-based tracking until it is close enough to detect the human's face. Once in this close-range interaction setting, the user is able to use hand gestures to communicate its commands to the UAV. Throughout the interaction, the UAV uses colored-light-based feedback to communicate its intent to the user. We developed this system to work reliably with a low-cost consumer UAV, with only computation off-board. We describe each component of this interaction system, giving details of the depth estimation strategy and the cascade predictive flight controller for approaching the user. We also present experimental results on the performance of the complete system and its individual components.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that8"><b>ThAT8</b></a></td>
               <td class="r">#108</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that8" title="Click to go to the Program at a Glance"><b>Multi-Robot Systems 1</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#122186" title="Click to go to the Author Index">Sabattini, Lorenzo</a></td><td class="r">Univ. of Modena and Reggio Emilia</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#150492" title="Click to go to the Author Index">Chung, Jen Jen</a></td><td class="r">Oregon State Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that8_01">10:55-11:10, Paper ThAT8.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0706.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('706'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Hierarchical Coordination Strategy for Multi-AGV Systems Based on Dynamic Geodesic Environment Partitioning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122186" title="Click to go to the Author Index">Sabattini, Lorenzo</a></td><td class="r">Univ. of Modena and Reggio Emilia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168396" title="Click to go to the Author Index">Digani, Valerio</a></td><td class="r">Elettric80 Spa</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110186" title="Click to go to the Author Index">Secchi, Cristian</a></td><td class="r">Univ. of Modena & Reggio Emilia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111622" title="Click to go to the Author Index">Fantuzzi, Cesare</a></td><td class="r">Univ. Di Modena E Reggio Emilia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab706" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0706.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a></span><br>
                           <strong>Abstract:</strong> In this paper we consider the problem of coordinating the motion of a group of Automated Guided Vehicles (AGVs) utilized in industrial environments for logistics operations. In particular, we consider a hierarchical coordination strategy, where the environment is partitioned into sectors: coordination on the top layer defines the sequence of sectors to be traveled, while coordination on the bottom layer deals with traffic management inside each sector. In this paper we introduce a novel partitioning algorithm, that defines the sectors in a dynamic manner, taking into account both the shape of the (generally non-convex) environment, and the current distribution of the AGVs. This is achieved exploiting a clustering algorithm, and subsequently defining the sectors based on the geodesic distance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that8_02">11:10-11:25, Paper ThAT8.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1489.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1489'); return false" title="Click to show or hide the keywords and abstract">D++: Structural Credit Assignment in Tightly Coupled Multiagent Domains</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196455" title="Click to go to the Author Index">Rahmattalabi, Aida</a></td><td class="r">Oregon State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150492" title="Click to go to the Author Index">Chung, Jen Jen</a></td><td class="r">Oregon State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#161986" title="Click to go to the Author Index">Colby, Mitch</a></td><td class="r">Oregon State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172284" title="Click to go to the Author Index">Tumer, Kagan</a></td><td class="r">Oregon State Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1489" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a></span><br>
                           <strong>Abstract:</strong> Autonomous multi-robot teams can be used in complex coordinated exploration tasks to improve exploration performance in terms of both speed and effectiveness. However, use of multi-robot systems presents additional challenges. Specifically, in domains where the robots' actions are tightly coupled, coordinating multiple robots to achieve cooperative behavior at the group level is difficult. In this paper, we demonstrate that reward shaping can greatly benefit learning in multi-robot explorations tasks. We propose a novel reward framework based on the idea of counterfactuals to tackle the coordination problem in tightly coupled domains. We show that the proposed algorithm provides superior performance by at least one order of magnitude compared to policies learned using either the global reward or the difference reward.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that8_03">11:25-11:40, Paper ThAT8.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1549.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1549'); return false" title="Click to show or hide the keywords and abstract">A Distributed Deterministic Spiral Search Algorithm for Swarms</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189645" title="Click to go to the Author Index">Fricke, George Matthew</a></td><td class="r">The Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157419" title="Click to go to the Author Index">Hecker, Joshua Peter</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195478" title="Click to go to the Author Index">Griego, Antonio</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#189071" title="Click to go to the Author Index">Tran, Linh</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156591" title="Click to go to the Author Index">Moses, Melanie</a></td><td class="r">Univ. of New Mexico</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1549" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a>, <a href="IROS16_KeywordIndexMedia.html#Search_and_Rescue_Robots" title="Click to go to the Keyword Index">Search and Rescue Robots</a></span><br>
                           <strong>Abstract:</strong> As robot swarms become more viable, efficient solutions to fundamental tasks such as swarm search and collection are required. We propose the distributed deterministic spiral algorithm (DDSA) which generalises a spiral search pattern to robot swarms. While being an effective search strategy in its own right, the DDSA is also a useful point of comparison for other swarm search strategies. Such a benchmark for robot swarm search is currently needed but missing. As a case study, we compare the DDSA to a biologically-inspired central-place foraging algorithm that uses stochastic search, memory, and communication.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that8_04">11:40-11:55, Paper ThAT8.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1638.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1638'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Multi-Agent Push Behaviors for Large Sets of Passive Objects</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106418" title="Click to go to the Author Index">Rodriguez, Samuel</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105498" title="Click to go to the Author Index">Morales, Marco</a></td><td class="r">Inst. Tecnológico Autónomo De México</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102662" title="Click to go to the Author Index">Amato, Nancy</a></td><td class="r">Texas A&M Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1638" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1638.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Agent_Based_Systems" title="Click to go to the Keyword Index">Agent-Based Systems</a></span><br>
                           <strong>Abstract:</strong> We present a reactive multi-agent push system for a large set of objects. The behavior for the pushing agents consists of: 1) selecting and updating an object set to push, 2) reaching positions near the objects to start influencing, 3) pushing the objects along a path to the goal region, and 4) regrouping when needed to ensure the group is packed tightly enough. The emergent properties of the behavior allow us to test how effectively a group of agents can push a set of objects through the environment with different strategies.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that9"><b>ThAT9</b></a></td>
               <td class="r">#204~205</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that9" title="Click to go to the Program at a Glance"><b>Robotic Manipulation</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104455" title="Click to go to the Author Index">Ollero, Anibal</a></td><td class="r">Univ. of Seville</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#200409" title="Click to go to the Author Index">Yoshida, Ryuta</a></td><td class="r">Kikuchi Seisakusho CO., LTD</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that9_01">10:55-11:10, Paper ThAT9.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0735.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('735'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Bezier Curve Model for Efficient Bio-Inspired Locomotion of Low Cost Four Legged Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192906" title="Click to go to the Author Index">Saputra, Azhar Aulia</a></td><td class="r">Tokyo Metropolitan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196136" title="Click to go to the Author Index">Tay, Noel Nuo Wi</a></td><td class="r">Tokyo Metropolitan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151087" title="Click to go to the Author Index">Toda, Yuichiro</a></td><td class="r">Tokyo Metropolitan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151082" title="Click to go to the Author Index">Botzheim, Janos</a></td><td class="r">Tokyo Metropolitan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108727" title="Click to go to the Author Index">Kubota, Naoyuki</a></td><td class="r">Tokyo Metropolitan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab735" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0735.VI.mpg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a></span><br>
                           <strong>Abstract:</strong> This paper presents Bezier curve based passive neural control applied in bio-inspired locomotion in order to decrease the computational cost implemented for 4 legged animal robot which has 3 joints in each leg. Neural oscillator model is applied for generating the walking pattern in bio-inspired locomotion. Bezier curve based optimization represents passive neural control supported by evolutionary algorithm for representing the relationship equation between neuron signal and reference joint signal. Passive neural control is implemented in order to reduce the neuron complexity in neuro-based locomotion by controlling 3 joints with one signal without decreasing the performance both in walking pattern and in its stability level, whereas one leg is represented by one motor neuron. Therefore, the 4 legged robot is controlled by 4 motor neurons which have feedback connection with ground and inertial sensor. In order to prove the effectiveness, we implemented the model in computer simulation and in a small 4 legged robot. This model can decrease the computational cost so it is possible to apply the model in either animal or humanoid robot with low frequency processor.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that9_02">11:10-11:25, Paper ThAT9.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0925.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('925'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Lightweight Compliant Arm with Compliant Finger for Aerial Manipulation and Inspection</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169970" title="Click to go to the Author Index">Suarez, Alejandro</a></td><td class="r">Univ. of Seville</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106094" title="Click to go to the Author Index">Heredia, Guillermo</a></td><td class="r">Univ. of Seville</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104455" title="Click to go to the Author Index">Ollero, Anibal</a></td><td class="r">Univ. of Seville</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab925" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0925.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a></span><br>
                           <strong>Abstract:</strong> This paper presents the design and experimental validation of a compliant and lightweight 3-DOF robotic arm – shoulder yaw, shoulder pitch and elbow pitch joints – equipped with a compliant finger module intended for aerial inspection and manipulation in contact with the environment. A simple transmission mechanism consisting in a pair of compression springs and a flange bearing is integrated in the shoulder pitch and elbow pitch joints between the servo shaft and the output frame. Joint deflection measurement with potentiometer allows joint torque but also contact force estimation and control. The low stiffness of the compliant finger has been exploited for soft collision detection and obstacle localization, in such a way that the contact forces do not significantly affect UAV stability. Fixed-base experiments have been performed with the arm, including the characterization of the compliant joints and the control of the contact force at wrist point.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that9_03">11:25-11:40, Paper ThAT9.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1298.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1298'); return false" title="Click to show or hide the keywords and abstract">Kinematic Modeling and Simulation of Active-Caster Robotic Drive with a Ball Transmission (ACROBAT-S)</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100275" title="Click to go to the Author Index">Wada, Masayoshi</a></td><td class="r">Tokyo Univ. of Agriculture and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192934" title="Click to go to the Author Index">Kato, Kosuke</a></td><td class="r">Tokyo Univ. of Agriculture and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1298" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a></span><br>
                           <strong>Abstract:</strong> In this paper, new type of an active-caster with a single ball transmission (ACROBAT-S) is proposed. The proposed ball transmission is a novel mechanism which realizes combining of two motor powers together to rotate single ball in a 2Dway and simultaneously distributing the combined power to a wheel shaft and a steering shaft of an active-caster in an appropriate ratio. The transmission design enables to remove a sensor for detecting the wheel orientation for coordinated control. Also it would be possible to build an omnidirectional robot with three active casters to be controlled its 3D motion by three motors with no redundancy. <p>The new concept of ACROBAT-S gives many advantages compared with the original ACROBAT since the number of ball is reduced from two to one, therefore the number of friction drive between a ball and rollers or a ball to a ball is also reduced from five to three. These features contribute not only to simplify the mechanism design but also to enhance its performance since slippages and energy losses would be reduced. To verify the design concept, we derive and analyze a kinematic model of a single ball transmission mechanism. Furthermore the motions of ACROBAT-S are verified by Solid Works 3D simulator.<p>From the results, it is confirmed that the proposed single ball transmission is applicable for omnidirectional wheel mechanism to realize the omnidirectional motions.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that9_04">11:40-11:55, Paper ThAT9.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1737.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1737'); return false" title="Click to show or hide the keywords and abstract">Deep Learning a Grasp Function for Grasping under Gripper Pose Uncertainty</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137912" title="Click to go to the Author Index">Johns, Edward</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107836" title="Click to go to the Author Index">Leutenegger, Stefan</a></td><td class="r">Imperial Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105540" title="Click to go to the Author Index">Davison, Andrew J</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1737" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> This paper presents a new method for parallel-jaw grasping of isolated objects from depth images, under large gripper pose uncertainty. Whilst most approaches aim to predict the single best grasp pose from an image, our method first predicts a score for every possible grasp pose, which we denote the grasp function. With this, it is possible to achieve grasping robust to the gripper's pose uncertainty, by smoothing the grasp function with the pose uncertainty function. Therefore, if the single best pose is adjacent to a region of poor grasp quality, that pose will no longer be chosen, and instead a pose will be chosen which is surrounded by a region of high grasp quality. To learn this function, we train a Convolutional Neural Network which takes as input a single depth image of an object, and outputs a score for each grasp pose across the image. Training data for this is generated by use of physics simulation and depth image simulation with 3D object meshes, to enable acquisition of sufficient data without requiring exhaustive real-world experiments. We evaluate with both synthetic and real experiments, and show that the learned grasp score is more robust to gripper pose uncertainty than when this uncertainty is not accounted for.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="that10"><b>ThAT10</b></a></td>
               <td class="r">#206~208</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#that10" title="Click to go to the Program at a Glance"><b>Software and Framework</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#196062" title="Click to go to the Author Index">Dieber, Bernhard</a></td><td class="r">Joanneum Res</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#195881" title="Click to go to the Author Index">Li, Qingdu</a></td><td class="r">Chongqing Univ. of Posts and Telecommunications</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that10_01">10:55-11:10, Paper ThAT10.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0097.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('97'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Invariant Spatial Parametrization of Human Thoracohumeral Kinematics: A Feasibility Study</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190999" title="Click to go to the Author Index">Krishnan, Rakesh</a></td><td class="r">KTH (Royal Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191177" title="Click to go to the Author Index">Björsell, Niclas</a></td><td class="r">Univ. of Gävle</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104768" title="Click to go to the Author Index">Smith, Claes Christian</a></td><td class="r">KTH Royal Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab97" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0097.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Kinematics" title="Click to go to the Keyword Index">Kinematics</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Centered_Robotics" title="Click to go to the Keyword Index">Human Centered Robotics</a></span><br>
                           <strong>Abstract:</strong> In this paper, we present a novel kinematic framework using hybrid twists, that has the potential to improve the reliability of estimated human shoulder kinematics. This is important as the functional aspects of the human shoulder are evaluated using the information embedded in thoracohumeral kinematics. We successfully demonstrate in our results, that our approach is invariant of the body-&#64257;xed coordinate de&#64257;nition, is singularity free and has high repeatability; thus resulting in a &#64258;exible user-speci&#64257;c kinematic tracking not restricted to bony landmarks
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that10_02">11:10-11:25, Paper ThAT10.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0637.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('637'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Application-Level Security for ROS-Based Applications</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196062" title="Click to go to the Author Index">Dieber, Bernhard</a></td><td class="r">Joanneum Res</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196063" title="Click to go to the Author Index">Kacianka, Severin</a></td><td class="r">Tech. Univ. of Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196067" title="Click to go to the Author Index">Rass, Stefan</a></td><td class="r">Alpen-Adria Univ. Klagenfurt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196072" title="Click to go to the Author Index">Schartner, Peter</a></td><td class="r">Alpen-Adria Univ. Klagenfurt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab637" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0637.VI.mpg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Architectures__Protocols_And_Middle_Ware" title="Click to go to the Keyword Index">Architectures, Protocols And Middle-Ware</a>, <a href="IROS16_KeywordIndexMedia.html#Networked_Robots" title="Click to go to the Keyword Index">Networked Robots</a></span><br>
                           <strong>Abstract:</strong> While the topic of security in industrial applications has gained some momentum in recent years, there are still severe security vulnerabilities which are actively exploited for attacks. The robot operating system (ROS) is expected to further grow in usage and to be used in many industrial applications. Analysis, however, shows that it lacks several security enhancements in order to make it suitable for industrial use. In its current state, false data and commands can be injected posing a possible safety risk for the resulting product and humans in the production. In addition, data may be eavesdropped and used by outsiders to gain insight into the production process. In this paper we propose a security architecture intended for use on top of ROS on the application level. We use a dedicated authorization server to ensure that only valid nodes are part of the application. Cryptographic methods ensure data con&#64257;dentiality and integrity. We show in a demonstration with a collaborative robot how our architecture can be used to secure a ROS-based application.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that10_03">11:25-11:40, Paper ThAT10.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0870.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('870'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>OpenSwarm: An Event-Driven Embedded Operating System for Miniature Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#186044" title="Click to go to the Author Index">Trenkwalder, Stefan M.</a></td><td class="r">The Univ. of Sheffield</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167634" title="Click to go to the Author Index">Kaszubowski Lopes, Yuri</a></td><td class="r">The Univ. of Sheffield</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110781" title="Click to go to the Author Index">Kolling, Andreas</a></td><td class="r">Univ. of Sheffield</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109111" title="Click to go to the Author Index">Christensen, Anders Lyhne</a></td><td class="r">Univ. Inst. of Lisbon</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192846" title="Click to go to the Author Index">Prodan, Radu</a></td><td class="r">Univ. of Innsbruck</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110961" title="Click to go to the Author Index">Gross, Roderich</a></td><td class="r">The Univ. of Sheffield</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab870" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0870.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Architectures__Protocols_And_Middle_Ware" title="Click to go to the Keyword Index">Architectures, Protocols And Middle-Ware</a>, <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Programming_Environments" title="Click to go to the Keyword Index">Programming Environments</a></span><br>
                           <strong>Abstract:</strong> This paper presents OpenSwarm, a lightweight easy-to-use open-source operating system. To our knowledge, it is the first operating system designed for and deployed on miniature robots. OpenSwarm operates directly on a robot's microcontroller. It has a memory footprint of 1 kB RAM and 12 kB ROM. OpenSwarm enables a robot to execute multiple processes simultaneously. It provides a hybrid kernel that natively supports preemptive and cooperative scheduling, making it suitable for both computationally intensive and swiftly responsive robotics tasks. OpenSwarm provides hardware abstractions to rapidly develop and test platform-independent code. We show how OpenSwarm can be used to solve a canonical problem in swarm robotics--clustering a collection of dispersed objects. We report experiments, conducted with five e-puck mobile robots, that show that an OpenSwarm implementation performs as good as a hardware-near implementation. The primary goal of OpenSwarm is to make robots with severely constrained hardware more accessible, which may help such systems to be deployed in real-world applications.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="that10_04">11:40-11:55, Paper ThAT10.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1016.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1016'); return false" title="Click to show or hide the keywords and abstract">A Framework for Quality Assessment of ROS Repositories</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196434" title="Click to go to the Author Index">Santos, André</a></td><td class="r">Univ. of Minho</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196438" title="Click to go to the Author Index">Cunha, Alcino</a></td><td class="r">Univ. of Minho</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196440" title="Click to go to the Author Index">Macedo, Nuno</a></td><td class="r">Univ. of Minho</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196441" title="Click to go to the Author Index">Lourenço, Cláudio</a></td><td class="r">Univ. of Minho</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1016" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Software_and_Architecture" title="Click to go to the Keyword Index">Software and Architecture</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a></span><br>
                           <strong>Abstract:</strong> Robots are being increasingly used in safety-critical contexts, such as transportation and health. The need for flexible behavior in these contexts, due to human interaction factors or unstructured operating environments, led to a transition from hardware- to software-based safety mechanisms in robotic systems, whose reliability and quality is imperative to guarantee. Source code static analysis is a key component in formal software verification. It consists on inspecting code, often using automated tools, to determine a set of relevant properties that are known to influence the occurrence of defects in the final product. This paper presents HAROS, a generic, plug-in-driven, framework to evaluate code quality, through static analysis, in the context of the Robot Operating System (ROS), one of the most widely used robotic middleware. This tool (equipped with plug-ins for computing metrics and conformance to coding standards) was applied to several publicly available ROS repositories, whose results are also reported in the paper, thus providing a first overview of the internal quality of the software being developed in this community.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thlunch1"><b>ThLunch1</b></a></td>
               <td class="r">Korea Trade Exhibition Center</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thlunch1" title="Click to go to the Program at a Glance"><b>Award Ceremony</b></a></td>
               <td class="r">Awards ceremony</td>
             </tr>
            


</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thk21"><b>ThK21</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thk21" title="Click to go to the Program at a Glance"><b>Keynote Talk 8. Wolfram Burgard: Techniques for Probabilistic Robot
<br>Navigation and Perception and Beyond</b></a></td>
               <td class="r">Keynote session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104593" title="Click to go to the Author Index">Shim, David Hyunchul</a></td><td class="r">KAIST</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thk22"><b>ThK22</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thk22" title="Click to go to the Program at a Glance"><b>Keynote Talk 9. Nikos G. Tsagarakis: Compliant Actuation Technologies for
<br>Emerging High Performance Humanoids</b></a></td>
               <td class="r">Keynote session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#100179" title="Click to go to the Author Index">Caldwell, Darwin G.</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="tht21"><b>ThT21</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#tht21" title="Click to go to the Program at a Glance"><b>Navigation/SLAM</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#111986" title="Click to go to the Author Index">He, Bingwei</a></td><td class="r">Fuzhou Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#170332" title="Click to go to the Author Index">Chaves, Stephen</a></td><td class="r">Univ. of Michigan</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_01">14:05-14:06, Paper ThT21.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0014.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('14'); return false" title="Click to show or hide the keywords and abstract">Self-Localization from Images with Small Overlap</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109542" title="Click to go to the Author Index">Tanaka, Kanji</a></td><td class="r">Univ. of Fukui</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab14" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Performance_Evaluation_and_Benchmarking" title="Click to go to the Keyword Index">Performance Evaluation and Benchmarking</a></span><br>
                           <strong>Abstract:</strong> With the recent success of visual features from deep convolutional neural networks (DCNN) in visual robot self-localization, it has become important and practical to address more general self-localization scenarios. In this paper, we address the scenario of self-localization from images with small overlap. We explicitly introduce a localization difficulty index (LDI) as a decreasing function of view overlap between query and relevant database images and investigate performance versus difficulty for challenging cross-view self-localization tasks. We then reformulate the self-localization as a scalable bag-of-visual-features (BoVF) scene retrieval and present an efficient solution called PCA-NBNN, aiming to facilitate fast, yet discriminative correspondence between partially overlapping images. The proposed approach adopts recent findings in discriminativity preserving encoding of DCNN features using principal component analysis (PCA) and cross-domain scene matching using naive Bayes nearest neighbor distance metric (NBNN). We experimentally demonstrate that the proposed PCA-NBNN framework frequently achieves comparable results to previous DCNN features and that the BoVF model is significantly more efficient. We further address an important alternative scenario of ``self-localization from images with NO overlap&quot; and report the result.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_02">14:06-14:07, Paper ThT21.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0343.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('343'); return false" title="Click to show or hide the keywords and abstract">Incremental Real-Time Multibody VSLAM with Trajectory Optimization Using Stereo Camera</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171292" title="Click to go to the Author Index">Narapureddy, Dinesh Reddy</a></td><td class="r">International Inst. of Tech. Hyderabad</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167607" title="Click to go to the Author Index">Mondal, Amit Kumar</a></td><td class="r">Univ. of Petroleum and Energy Studies, Dehradun</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181628" title="Click to go to the Author Index">Devalla, Vindhya</a></td><td class="r">Univ. of Petroleum and Energy Studies</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202437" title="Click to go to the Author Index">Abbasnejad, Iman</a></td><td class="r">Cmu, Qut, Mpi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196059" title="Click to go to the Author Index">Arrabotu, Sheetal Reddy</a></td><td class="r">International Inst. of Information Tech. Hyderabad</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab343" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> Real-time outdoor navigation in highly dynamic environments is an crucial problem. The recent literature on real-time static SLAM don't scale up to dynamic outdoor environments. Most of these methods assume moving objects as outliers or discard the information provided by them. We propose an algorithm to jointly infer the camera trajectory and the moving object trajectory simultaneously. In this paper, we perform a sparse scene flow based motion segmentation using a stereo camera. The segmented objects motion models are used for accurate localization of the camera trajectory as well as the moving objects. We exploit the relationship between moving objects for improving the accuracy of the poses. We formulate the poses as a factor graph incorporating all the constraints. We achieve exact incremental solution by solving a full nonlinear optimization problem in real time. The evaluation is performed on the challenging KITTI dataset with multiple moving cars.Our method outperforms the previous baselines in outdoor navigation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_03">14:07-14:08, Paper ThT21.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0356.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('356'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Exploiting Building Information from Publicly Available Maps in Graph-Based SLAM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165811" title="Click to go to the Author Index">Vysotska, Olga</a></td><td class="r">Univ. of Bonn</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101642" title="Click to go to the Author Index">Stachniss, Cyrill</a></td><td class="r">Univ. of Bonn</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab356" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0356.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Range_Sensing" title="Click to go to the Keyword Index">Range Sensing</a></span><br>
                           <strong>Abstract:</strong> Maps are an important component of most robotic navigation systems and building maps under uncertainty is often referred to as simultaneous localization and mapping or SLAM. Most SLAM approaches start from scratch and build a map only based on their own observations and odometry information. In this paper, we address the problem of how additional information can be exploited, for example from OpenStreetMap. We extend the standard graph-based SLAM formulation by relating the nodes of the pose-graph with an existing map. As this paper suggests, we can relate the newly built maps with information from publicly available maps with the laser range finder data from the robot and in this way improve the map quality. We implemented and evaluated our approach using real world data taken in urban environments. We illustrate that our extension to graph-based SLAM provides better aligned maps and adds only a marginal computational overhead.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_04">14:08-14:09, Paper ThT21.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0400.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('400'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Towards Effective Localization in Dynamic Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109382" title="Click to go to the Author Index">Sun, Dali</a></td><td class="r">Univ. of Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191427" title="Click to go to the Author Index">Geißer, Florian</a></td><td class="r">Univ. of Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108179" title="Click to go to the Author Index">Nebel, Bernhard</a></td><td class="r">Albert-Ludwigs-Univ. Freiburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab400" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0400.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Localization in dynamic environments is still a challenging problem in robotics - especially if rapid and huge changes occur irregularly. Inspired by SLAM algorithms our Bayesian approach to this so-called dynamic localization problem divides it into a localization problem and a mapping problem, respectively. To tackle the localization problem we use a particle filter, coupled with a distance filter and a scan matching method, which achieves a more robust localization against dynamic obstacles. For the mapping problem we use an extended sensor model which results in an effective and precise map update effect. We compare our approach against other localization methods and evaluate the impact the map update effect has on the localization in dynamic environments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_05">14:09-14:10, Paper ThT21.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0487.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('487'); return false" title="Click to show or hide the keywords and abstract">Vision-Based Real-Time 3D Mapping for UAV with Laser Sensor</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195508" title="Click to go to the Author Index">Shi, Jinqiao</a></td><td class="r">Fuzhou Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111986" title="Click to go to the Author Index">He, Bingwei</a></td><td class="r">Fuzhou Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134128" title="Click to go to the Author Index">Zhang, Liwei</a></td><td class="r">Univ. of Hamburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106951" title="Click to go to the Author Index">Zhang, Jianwei</a></td><td class="r">Univ. of Hamburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab487" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> Real-time 3D mapping with MAV (Micro Aerial Vehicle) in GPS-denied environment is a challenging problem. In this paper, we present an effective vision-based 3D mapping system with 2D laser-scanner. All algorithms necessary for this system are on-board. In this system, two cameras work together with the laser-scanner for motion estimation. The distance of the points detected by laser-scanner are transformed and treated as the depth of image features, which improves the robustness and accuracy of the pose estimation. The output of visual odometry is used as an initial pose in the Iterative Closest Point (ICP) algorithm and the motion trajectory is optimized by the registration result. We finally get the MAV’s state by fusing IMU with the pose estimation from mapping process. This method maximizes the utility of the point clouds information and overcomes the scale problem of lacking depth information in the monocular visual odometry. The results of the experiments prove that this method has good characteristics in real-time and accuracy.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_06">14:10-14:11, Paper ThT21.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0501.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('501'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Encoding the Description of Image Sequences: A Two-Layered Pipeline for Loop Closure Detection</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191680" title="Click to go to the Author Index">Bampis, Loukas</a></td><td class="r">Democritus Univ. of Thrace</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142211" title="Click to go to the Author Index">Amanatiadis, Angelos</a></td><td class="r">Democritus Univ. of Thrace</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129384" title="Click to go to the Author Index">Gasteratos, Antonios</a></td><td class="r">Democritus Univ. of Thrace</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab501" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0501.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a></span><br>
                           <strong>Abstract:</strong> In this paper we propose a novel technique for detecting loop closures on a trajectory by matching sequences of images instead of single instances. We build upon well established techniques for creating a bag of visual words with a tree structure and we introduce a significant novelty by extending these notions to describe the visual information of entire regions using Visual-Word-Vectors. The fact that the proposed approach does not rely on a single image to recognize a site allows for a more robust place recognition, and consequently loop closure detection, while reduces the computational complexity for long trajectory cases. We present evaluation results for multiple publicly available indoor and outdoor datasets using Precision-Recall curves, which reveal that our method outperforms other state of the art algorithms.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_07">14:11-14:12, Paper ThT21.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0505.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('505'); return false" title="Click to show or hide the keywords and abstract">Probabilistic Binaural Multiple Sources Localization Based on Time-Delay Compensation Estimator and Clustering Analysis</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110768" title="Click to go to the Author Index">Liu, Hong</a></td><td class="r">Peking Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195187" title="Click to go to the Author Index">Yue, Mengdi</a></td><td class="r">Peking Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168161" title="Click to go to the Author Index">Zhang, Jie</a></td><td class="r">Peking Univ. Shenzhen Graduate School</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab505" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Audition" title="Click to go to the Keyword Index">Robot Audition</a>, <a href="IROS16_KeywordIndexMedia.html#Cognitive_Human_Robot_Interaction" title="Click to go to the Keyword Index">Cognitive Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Sound source localization (SSL) is an essential technique in many applications, such as robot audition, humanrobot interaction and speech capturing. However, SSL from a binaural input is still a challenging problem, particularly when multiple sources are active simultaneously. In this work, we propose a multi-sources localization framework based on the time-delay compensation (TDC) estimator and clustering analysis. The TDC estimator is a simultaneous operator to estimate binaural cues, which breaks the limitation of independent processors for binaural cues extraction. The multi-sources decision is realized by clustering analysis for the binaural cues of multiple signal frames. In experiments, we demonstrate that the localization performance is improved compared to the methods that assume the number of spatial stationary sources to be known. Results with both simulated and recorded impulse responses show that robust performance can be achieved with limited prior training, and our method is also adaptive to different sound activities.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_08">14:12-14:13, Paper ThT21.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0613.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('613'); return false" title="Click to show or hide the keywords and abstract">Multi-Modal Panoramic 3D Outdoor Datasets for Place Categorization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168313" title="Click to go to the Author Index">Jung, Hojung</a></td><td class="r">Kyushu Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195917" title="Click to go to the Author Index">Yuki Oto, Yuki</a></td><td class="r">Kyushu Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106534" title="Click to go to the Author Index">Mozos, Oscar</a></td><td class="r">Tech. Univ. of Cartagena</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103233" title="Click to go to the Author Index">Iwashita, Yumi</a></td><td class="r">Kyushu Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103231" title="Click to go to the Author Index">Kurazume, Ryo</a></td><td class="r">Kyushu Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab613" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> We present two multi-modal panoramic 3D outdoor (MPO) datasets for semantic place categorization with six categories: forest, coast, residential area, urban area and indoor/outdoor parking lot. The first dataset consists of 650 static panoramic scans of dense (~9,000,000 points) 3D color and reflectance point clouds obtained using a FARO laser scanner with synchronized color images. The second dataset consists of 34,200 real-time panoramic scans of sparse (~70,000 points) 3D reflectance point clouds obtained using a Velodyne laser scanner while driving a car. The datasets were obtained in the city of Fukuoka, Japan and are publicly available in [1], [2]. In addition, we compare several approaches for semantic place categorization with best results of 96.42% (dense) and 89.67% (sparse).
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_09">14:13-14:14, Paper ThT21.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0622.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('622'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>WiFi Localization in 3D</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196034" title="Click to go to the Author Index">Jirku, Michal</a></td><td class="r">Czech Tech. Univ. in Prague, Faculty of Electrical Engi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149723" title="Click to go to the Author Index">Kubelka, Vladimir</a></td><td class="r">Czech Tech. Univ. in Prague</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140865" title="Click to go to the Author Index">Reinstein, Michal</a></td><td class="r">Czech Tech. Univ. in Prague</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab622" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0622.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> Localization of mobile robots can be challenging in highly dynamic environments (airport terminals, stores, hospitals) yet these areas offer great potential for robotics applications. High WiFi coverage provides a way to localize even low-cost robots that do not need to be equipped with expensive exteroceptive sensors or excessive computational power to run visual-based SLAM algorithms. Since current trend in robotics is in mass-deployment of low-cost, replaceable robots, we focus our efforts in this direction as well. Possible solution is combination of high-tech robots deployed as support assuring reliable localization for the low-cost robots that are actually doing the job. The proposed scenario is to use one SLAM robot to map WiFi signal strength in the working area and provide it to a low-cost robot to correct drift of its 6-DOF gyro-odometry localization system. For this purpose, we extend Gaussian-processes-based WiFi localization algorithms to full 3D and experimentally evaluate the proposed approach in 2 mapping and 7 localization sorties performed on different dates spanning four months.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_10">14:14-14:15, Paper ThT21.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0642.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('642'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Persistent Localization and Life-Long Mapping in Changing Environments Using the Frequency Map Enhancement</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167573" title="Click to go to the Author Index">Krajník, Tomáš</a></td><td class="r">Univ. of Lincoln</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#120687" title="Click to go to the Author Index">Pulido Fentanes, Jaime</a></td><td class="r">Univ. of Lincoln</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104948" title="Click to go to the Author Index">Hanheide, Marc</a></td><td class="r">Univ. of Lincoln</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104029" title="Click to go to the Author Index">Duckett, Tom</a></td><td class="r">Univ. of Lincoln</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab642" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0642.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a></span><br>
                           <strong>Abstract:</strong> We present a lifelong mapping and localisation system for long-term autonomous operation of mobile robots in changing environments. The core of the system is a spatio-temporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future. During navigation, our robot builds temporally local maps and integrates then into the global spatio-temporal grid. Through re-observation of the same locations, the spatio-temporal grid learns the long-term environment dynamics and gains the ability to predict the future environment states. This predictive ability allows to generate time-specific 2d maps used by the robot's localisation and planning modules. By analysing data from a long-term deployment of the robot in a human-populated environment, we show that the proposed representation improves localisation accuracy and the efficiency of path planning. We also show how to integrate the method into the ROS navigation stack for use by other roboticists.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_11">14:15-14:16, Paper ThT21.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0755.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('755'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Map2DFusion: Real-Time Incremental UAV Image Mosaicing Based on Monocular SLAM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184274" title="Click to go to the Author Index">Bu, Shuhui</a></td><td class="r">Northwestern Pol. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184329" title="Click to go to the Author Index">Zhao, Yong</a></td><td class="r">Northwestern Pol. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184339" title="Click to go to the Author Index">Wan, Gang</a></td><td class="r">Information Engineering Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184335" title="Click to go to the Author Index">Liu, Zhenbao</a></td><td class="r">Northwestern Pol. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab755" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0755.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Environment_Monitoring_and_Management" title="Click to go to the Keyword Index">Environment Monitoring and Management</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> In this paper we present a real-time approach to stitch large-scale aerial images incrementally. A monocular SLAM system is used to estimate camera position and attitude, and meanwhile 3D point cloud map is generated. When GPS information is available, the estimated trajectory is transformed to WGS84 coordinates after time synchronized automatically. Therefore, the output orthoimage retains global coordinates without ground control points. The final image is fused and visualized instantaneously with a proposed adaptive weighted multiband algorithm. To evaluate the effectiveness of the proposed method, we create a publicly available aerial image dataset with sequences of different environments. The experimental results demonstrate that our system is able to achieve high efficiency and quality compared to state-of-the-art methods. In addition, we share the code on the website with detailed introduction and results.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_12">14:16-14:17, Paper ThT21.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0842.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('842'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Erasing Bad Memories: Agent-Side Summarization for Long-Term Mapping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178436" title="Click to go to the Author Index">Dymczyk, Marcin Tomasz</a></td><td class="r">ETH Zurich, Autonomous Systems Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190619" title="Click to go to the Author Index">Schneider, Thomas</a></td><td class="r">ETH Zürich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187957" title="Click to go to the Author Index">Gilitschenski, Igor</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165051" title="Click to go to the Author Index">Stumm, Elena</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab842" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0842.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> Precisely estimating the pose of an agent in a global reference frame is a crucial goal that unlocks a multitude of robotic applications, including autonomous navigation and collaboration. In order to achieve this, current state-of-the-art localization approaches collect data provided by one or more agents and create a single, consistent localization map, maintained over time. However, with the introduction of lengthier sorties and the growing size of the environments, data transfers between the backend server where the global map is stored and the agents are becoming prohibitively large. While some existing methods partially address this issue by building compact summary maps, the data transfer from the agents to the backend can still easily become unmanageable. In this paper, we propose a method that is designed to reduce the amount of data that needs to be transferred from the agent to the backend, functioning in large-scale, multi-session mapping scenarios. Our approach is based upon a landmark selection method that exploits information coming from multiple, possibly weak and correlated, landmark utility predictors; fused using learned feature coefficients. Such a selection yields a drastic reduction in data transfer while maintaining localization performance and the ability to efficiently summarize environments over time. We evaluate our approach on a data set that was autonomously collected in a dynamic indoor environment over a period of several months.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_13">14:17-14:18, Paper ThT21.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0893.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('893'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Robustness to Connectivity Loss for Collaborative Mapping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195195" title="Click to go to the Author Index">Quraishi, Anwar Ahmad</a></td><td class="r">École Pol. Fédérale De Lausanne</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178462" title="Click to go to the Author Index">Cieslewski, Titus</a></td><td class="r">Univ. of Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150378" title="Click to go to the Author Index">Lynen, Simon</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab893" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0893.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> Having a team of robots to perform a task such as mapping is faster and more reliable than doing the same with a single robot, which can be crucial in scenarios such as search and rescue. We are developing a fully distributed framework for collaborative mapping with large robot swarms that is robust to abrupt departure of robots due to malfunctions or network problems. While several approaches to multi-robot mapping have been proposed, most of them either build a collection of local sub-maps, or rely on a central authority to merge maps built by individual robots. Our framework is unique in that it requires no central authority, yet allows robots to simultaneously contribute to a single global map, which is stored in a decentralized fashion. This greatly improves the scalability of our system with respect to number of robots. However, our approach requires systematic coordination among robots in order to make modifications to the map. Unannounced departure of the robots makes coordination challenging, and can potentially make the map inconsistent or result in loss of data. We borrow ideas from the domain of distributed computing to address those challenges. Further, we demonstrate the robustness of the proposed system by subjecting it to various conditions in which participating robots fail.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_14">14:18-14:19, Paper ThT21.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0909.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('909'); return false" title="Click to show or hide the keywords and abstract">Optimal Placement of Passive Sensors for Robot Localisation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196380" title="Click to go to the Author Index">Zenatti, Fabiano</a></td><td class="r">Univ. of Trento</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#112613" title="Click to go to the Author Index">Fontanelli, Daniele</a></td><td class="r">Univ. of Trento</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115820" title="Click to go to the Author Index">Palopoli, Luigi</a></td><td class="r">Univ. of Trento</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192620" title="Click to go to the Author Index">Macii, David</a></td><td class="r">Univ. of Trento</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192666" title="Click to go to the Author Index">Nazemzadeh, Payam</a></td><td class="r">Univ. of Trento</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab909" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a></span><br>
                           <strong>Abstract:</strong>  We consider the problem of self-localisation for a mobile robot in an environment with a requested level of accuracy. The robot moves in a known environment following typical trajectories, which can be characterised in statistical terms. One of the main drivers of this paper is its application to assistive robots guiding senior or impaired users in shopping centres or in other public spaces. To localise itself the robot uses onboard sensors such as encoders and inertial platforms. The level of noise in these sensors and the lack of absolute measurements determines a steady growth of the uncertainty on its position. To alleviate the problem, we assume the presence of a number of visual markers deployed in the environment. Whenever the robot comes across one of these sensors, the uncertainty on its position is reset. In the paper, we show a methodology to minimise the number of these sensors and to select their position so that the uncertainty is never worse than a given target threshold with an assigned probability.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_15">14:19-14:20, Paper ThT21.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0918.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('918'); return false" title="Click to show or hide the keywords and abstract">Path Planning in Graph SLAM Using Expected Uncertainty</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105228" title="Click to go to the Author Index">Fermín-León, Leonardo</a></td><td class="r">Simón Bolívar Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101695" title="Click to go to the Author Index">Neira, José</a></td><td class="r">Univ. De Zaragoza</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104849" title="Click to go to the Author Index">Castellanos, Jose A.</a></td><td class="r">Univ. of Zaragoza</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab918" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> In this work we address the problem of trajectory planning in Graph SLAM. We propose the use of Expected Value of the Final Uncertainty, which summarizes all the possible uncertainties that should be considered. In fully explored environments, this is used to determine the most reliable path to the final position. In partially explored environments, this criteria quantifies the reliability of the path planned in the free space. Tests demonstrate its ability to avoid unreliable paths in fully explored environments as compared to other uncertainty based criteria. In the exploration scenario, potential paths not present in the original graph are proposed using Voronoi Diagram of the space ahead observed by the sensors. A cost function is proposed considering the length of the path as well as the expected final uncertainty, thus including potentially shorter, but still reliable paths. Tests demonstrate the shortest path is preferred as long as it contains loop closures with low uncertainty.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_16">14:20-14:21, Paper ThT21.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1000.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1000'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>SLAM with Objects Using a Nonparametric Pose Graph</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#186252" title="Click to go to the Author Index">Mu, Beipeng</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#139022" title="Click to go to the Author Index">Liu, Shih-Yuan</a></td><td class="r">U.C. Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#136946" title="Click to go to the Author Index">Paull, Liam</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107631" title="Click to go to the Author Index">Leonard, John</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104610" title="Click to go to the Author Index">How, Jonathan Patrick</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1000" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1000.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Mapping and self-localization in unknown environments are fundamental capabilities in many robotic applications. These tasks typically involve the identification of objects as unique features or landmarks, which requires the objects both to be detected and then assigned a unique identifier that can be maintained when viewed from different perspectives and in different images. The data association and simultaneous localization and mapping (SLAM) problems are, individually, well-studied in the literature. But these two problems are inherently tightly coupled, and that has not been well-addressed. Without accurate SLAM, possible data associations are combinatorial and become intractable easily. Without accurate data association, the error of SLAM algorithms diverge easily. This paper proposes a novel nonparametric pose graph that models data association and SLAM in a single framework. An algorithm is further introduced to alternate between inferring data association and performing SLAM. Experimental results show that our approach has the new capability of associating object detections and localizing objects at the same time, leading to significantly better performance on both the data association and SLAM problems than achieved by considering only one and ignoring imperfections in the other.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_17">14:21-14:22, Paper ThT21.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1029.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1029'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Improving Gaussian Processes Based Mapping of Wireless Signals Using Path Loss Models</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187810" title="Click to go to the Author Index">Miyagusuku, Renato</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102952" title="Click to go to the Author Index">Yamashita, Atsushi</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106691" title="Click to go to the Author Index">Asama, Hajime</a></td><td class="r">The Univ. of Tokyo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1029" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1029.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> Indoor robot localization systems using wireless signal measurements have gained popularity in recent years, as wireless Local Area Networks can be found practically everywhere. In this field, a popular approach is the use of fingerprinting techniques, such as Gaussian Processes. In our approach, we improve Gaussian Processes based mapping using path loss models as priors. Path loss models encode information regarding the signal propagation phenomena into the mapping. Our approach first fits training data to a simple path loss model, to then train a zero-mean Gaussian Process with the mismatches between the models and the data. Signal strength mean predictions are done using both the path loss model and the Gaussian Process output, while variances are calculated by bounding the Gaussian Process variance using the path loss models. Notably, the main improvement generated by our approach is not an enhanced mean value prediction, but rather a better model variance prediction. This translates into better likelihood estimations, leading to higher localization accuracy. Experiments using data acquired in an indoor environment and our approach as the perceptual likelihood of a dual Monte Carlo localization algorithm are used to demonstrate this improvement. Furthermore, this idea can be extrapolated to other fingerprinting techniques and to applications other than wireless-based localization.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_18">14:22-14:23, Paper ThT21.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1068.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1068'); return false" title="Click to show or hide the keywords and abstract">Visual Localization and Loop Closing Using Decision Trees and Binary Features</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195793" title="Click to go to the Author Index">Schlegel, Dominik</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107200" title="Click to go to the Author Index">Grisetti, Giorgio</a></td><td class="r">Sapienza Univ. of Rome</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1068" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> In this paper we present an approach for efficiently retrieving the most similar image, based on point-to-point correspondences, within a sequence that has been acquired through continuous camera movement. Our approach is entailed to the use of standardized binary feature descriptors and exploits the temporal form of the input data to dynamically adapt the search structure. While being straightforward to implement, our method exhibits very fast response times and its Precision/Recall rates compete with state of the art approaches. Our claims are supported by multiple large scale experiments on publicly available datasets.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_19">14:23-14:24, Paper ThT21.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1182.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1182'); return false" title="Click to show or hide the keywords and abstract">Human-Guided Robot 3D Mapping Using Virtual Reality Technology</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147018" title="Click to go to the Author Index">Du, Jianhao</a></td><td class="r">Oklahoma State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100881" title="Click to go to the Author Index">Sheng, Weihua</a></td><td class="r">Oklahoma State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164059" title="Click to go to the Author Index">Liu, Meiqin</a></td><td class="r">Zhejiang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1182" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Virtual_Reality_and_Interfaces" title="Click to go to the Keyword Index">Virtual Reality and Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Map building is a fundamental task in many robotic applications. In this paper, we propose a novel approach for 3D mapping of indoor environments which allows a robot avatar to collaborate with a human seamlessly through a virtual reality (VR) device. The 3D map is created using the 3D data from an RGB-D camera mounted on the robot and simultaneously transmitted to a remote server, and then rendered to the VR device. On the other hand, the intentions of the user are inferred using the motion of the head movement based on hidden Markov models (HMMs), and then interpreted into commands to control the robot. We implement the proposed approach based on a modified Pioneer robot platform. The experimental results show the feasibility of the proposed system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_20">14:24-14:25, Paper ThT21.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1217.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1217'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Fast Global Optimality Verification in 3D SLAM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180436" title="Click to go to the Author Index">Briales, Jesus</a></td><td class="r">Univ. of Málaga</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151076" title="Click to go to the Author Index">González-Jiménez, Javier</a></td><td class="r">Univ. of Málaga</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1217" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1217.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Graph-based SLAM has proved to be one of the most effective solutions to the Simultaneous Localization and Mapping problem. This approach relies on nonlinear iterative optimization methods that in practice perform both accurately and efficiently. However, due to the non-convexity of the problem, the obtained solutions come with no guarantee of global optimality and may get stuck in local minima. The application of SLAM to many real-world applications cannot be conceived without additional control tools that detect possible suboptimalities as soon as possible in order to take corrective action and avoid catastrophic failure of the entire system. This paper builds upon the state-of-the-art framework [1] in verification for this problem and introduces a novel superior formulation that leads to a much higher efficiency. While retaining the same high effectiveness, the verification times of our proposal reduce up to >50x, paving the way for faster verification in critical real applications or in embedded low-power systems. We support our claims with extensive experiments with real and simulated data.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_21">14:25-14:26, Paper ThT21.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1357.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1357'); return false" title="Click to show or hide the keywords and abstract">Calibration of a Dynamic Camera Cluster for Multi-Camera Visual SLAM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156165" title="Click to go to the Author Index">Das, Arun</a></td><td class="r">Univ. of Waterloo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115221" title="Click to go to the Author Index">Waslander, Steven Lake</a></td><td class="r">Univ. of Waterloo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1357" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> Multi-camera clusters used for visual SLAM assume a fixed calibration between the cameras, which places many limitations on its performance, and directly excludes all configurations where a camera in the cluster is mounted to a moving component. In this work, we present a calibration method for dynamic multi-camera clusters, where one or more of the cluster cameras is mounted to an actuated mechanism, such as a gimbal or robotic manipulator. Our calibration approach parametrizes the actuated mechanism using the Denavit-Hartenberg convention, then determines the calibration parameters which allow for the estimation of the time varying extrinsic transformations between camera frames. We validate our calibration approach using a dynamic camera cluster consisting of a static camera and a camera mounted to a pan-tilt unit, and demonstrate that the dynamic camera cluster can provide accurate tracking when used to perform SLAM.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_22">14:26-14:27, Paper ThT21.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1408.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1408'); return false" title="Click to show or hide the keywords and abstract">Curating Long-Term Vector Maps</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195481" title="Click to go to the Author Index">Nashed, Samer</a></td><td class="r">Univ. of Massachusetts Amherst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#127043" title="Click to go to the Author Index">Biswas, Joydeep</a></td><td class="r">Univ. of Massachusetts Amherst</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1408" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Model_Learning" title="Click to go to the Keyword Index">Model Learning</a></span><br>
                           <strong>Abstract:</strong> Autonomous service mobile robots need to consistently, accurately, and robustly localize in human environments despite changes to such environments over time. Episodic non-Markov Localization~(EnML) addresses the challenge of localization in such changing environments by classifying observations as arising from Long-Term, Short-Term, or Dynamic Features. However, EnML relies on an estimate of the Long-Term Vector Map (LTVM) that does not change over time. In this paper, we introduce a recursive algorithm to build and update the LTVM over time by reasoning about visibility constraints of objects observed over multiple robot deployments. Using a signed distance function (SDF) to filter out observations of short-term and dynamic features, the remaining long-term observations are used to build a vector map by robust local linear regression, with uncertainty in the resulting LTVM computed by Monte Carlo resampling. Using scatter matrix decomposition, the map features remain faithful to the entire observation history without storing each observation explicitly, leading to significant memory savings. We present experimental results demonstrating the accuracy, robustness, and compact nature of the extracted LTVMs from several long-term robot datasets.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_23">14:27-14:28, Paper ThT21.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1446.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1446'); return false" title="Click to show or hide the keywords and abstract">Recalibration-Free Indoor Localization with Wi-Fi Fingerprinting of Invariant Received Signal Strength</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101622" title="Click to go to the Author Index">Lee, Sukhan</a></td><td class="r">Sungkyunkwan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196751" title="Click to go to the Author Index">Husen, Mohd Nizam</a></td><td class="r">Univ. Kuala Lumpur</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1446" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a></span><br>
                           <strong>Abstract:</strong> Localization of a human or a robot in indoor environment prior to initial human-robot interaction is the motivation of this paper. The utilization of Wi-Fi received signal strength (RSS) by adopting fingerprinting technique is used to compute the location estimation. However, Wi-Fi RSS instability incurred by mutable channel characteristics hampers a wide-spread adoption of RSS based location fingerprinting to real world applications. To overcome RSS instability problem, we propose a new method based on the concept of “invariant RSS statistics”, where it is defined as the RSS samples collected at each calibration location under minimal random spatiotemporal disturbances. The invariant RSS statistics thus collected forms the reference pattern classes in the space formed by Wi-Fi sources. Fingerprinting is done by identifying the reference pattern class that maximally supports the RSS readings collected at an unknown location for available Wi-Fi sources. The support of RSS readings is defined here as the sum of the likelihood probabilities of individual RSS readings. Experimental results show that the proposed method provides superior performance to conventional ones with the success rate higher by 17%, the printing resolution finer by 30% and, naturally, no performance degradation in time without recalibration. Lastly, we present a design guideline that relates statistically the different levels of the random spatiotemporal disturbances inducing RSS instability to the minimum number of Wi-Fi sources required for achieving a certain class separation degree under the given number of calibration locations to be identified.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_24">14:28-14:29, Paper ThT21.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1451.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1451'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Fusion and Binarization of CNN Features for Robust Topological Localization across Seasons</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172000" title="Click to go to the Author Index">Arroyo, Roberto</a></td><td class="r">Univ. of Alcalá</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123356" title="Click to go to the Author Index">Fernández Alcantarilla, Pablo</a></td><td class="r">Irobot Corp</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109701" title="Click to go to the Author Index">Bergasa, Luis Miguel</a></td><td class="r">Univ. of Alcala</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182391" title="Click to go to the Author Index">Romera, Eduardo</a></td><td class="r">Univ. of Alcala</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1451" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1451.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> The extreme variability in the appearance of a place across the four seasons of the year is one of the most challenging problems in life-long visual topological localization for mobile robotic systems and intelligent vehicles. Traditional solutions to this problem are based on the description of images using hand-crafted features, which have been shown to offer moderate invariance against seasonal changes. In this paper, we present a new proposal focused on automatically learned descriptors, which are processed by means of a technique recently popularized in the computer vision community: Convolutional Neural Networks (CNNs). The novelty of our approach relies on fusing the image information from multiple convolutional layers at several levels and granularities. In addition, we compress the redundant data of CNN features into a tractable number of bits for efficient and robust place recognition. The final descriptor is reduced by applying simple compression and binarization techniques for fast matching using the Hamming distance. An exhaustive experimental evaluation confirms the improved performance of our proposal (CNN-VTL) with respect to state-of-the-art methods over varied long-term datasets recorded across seasons.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht21_25">14:29-14:30, Paper ThT21.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1526.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1526'); return false" title="Click to show or hide the keywords and abstract">Efficient Planning with the Bayes Tree for Active SLAM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170332" title="Click to go to the Author Index">Chaves, Stephen</a></td><td class="r">Univ. of Michigan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104535" title="Click to go to the Author Index">Eustice, Ryan</a></td><td class="r">Univ. of Michigan</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1526" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a></span><br>
                           <strong>Abstract:</strong> This paper reports on an active SLAM framework that leverages the Bayes tree data structure for efficient planning. Evaluating information-theoretic objective functions in the context of active SLAM is a very expensive process that requires significant computational overhead. The contributions of this work involve exploiting the structure of the planning problem integrated with SLAM via the Bayes tree graphical model. Specifically, we propose a constrained variable ordering and subtree caching scheme that reduce computational complexity by eliminating redundant computations between candidate actions that are similar. We also propose an active SLAM framework that utilizes these concepts, and demonstrate the benefits of the approach with an underwater robot performing visual SLAM in a hybrid simulation environment.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="tht22"><b>ThT22</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#tht22" title="Click to go to the Program at a Glance"><b>Motion and Path Planning</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102610" title="Click to go to the Author Index">Cavusoglu, M. Cenk</a></td><td class="r">Case Western Res. Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#101783" title="Click to go to the Author Index">Xiao, Jing</a></td><td class="r">UNC Charlotte</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_01">14:05-14:06, Paper ThT22.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0144.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('144'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Real-Time Monocular Obstacle Avoidance Using Underwater Dark Channel Prior</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116485" title="Click to go to the Author Index">Drews-Jr, Paulo</a></td><td class="r">Federal Univ. of Rio Grande (FURG)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105814" title="Click to go to the Author Index">Hernandez, Emili</a></td><td class="r">CSIRO</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106796" title="Click to go to the Author Index">Elfes, Alberto</a></td><td class="r">CSIRO</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147371" title="Click to go to the Author Index">Nascimento, Erickson</a></td><td class="r">Univ. Federal De Minas Gerais (UFMG)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105884" title="Click to go to the Author Index">Campos, Mario Montenegro</a></td><td class="r">Univ. Federal De Minas Gerais</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab144" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0144.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a></span><br>
                           <strong>Abstract:</strong> In this paper we propose a new vision-based obstacle avoidance strategy using the Underwater Dark Channel Prior (UDCP) that can be applied to any Unmanned Underwater Vehicle (UUV) equipped with a simple monocular camera and minimal on-board processing capabilities. For each incoming image, our method first computes a relative depth map to estimate the obstacles nearby. Then, the map is segmented and the most promising Region of Interest (RoI) is identified. Finally, an escape direction is computed within the RoI and a control action is performed accordingly to avoid the obstacles. We tested our approach on a video sequence in a natural environment and compared it against a state-of-the-art method showing better performance, specially in light changing conditions. We also provide online results on a low-cost Remotely Operated Vehicle (ROV) in a controlled environment.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_02">14:06-14:07, Paper ThT22.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0224.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('224'); return false" title="Click to show or hide the keywords and abstract">Active Sensing for Continuous State and Action Spaces Via Task-Action Entropy Minimization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172356" title="Click to go to the Author Index">Greigarn, Tipakorn</a></td><td class="r">Case Western Res. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102610" title="Click to go to the Author Index">Cavusoglu, M. Cenk</a></td><td class="r">Case Western Res. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab224" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a></span><br>
                           <strong>Abstract:</strong> In this paper, a new task-oriented active-sensing method is presented. Most active sensing methods choose sensing actions that minimize the uncertainty of the state according to some information-theoretic measure. While this is reasonable for most applications, minimizing state uncertainty may not be most relevant when the state information is used to perform a task. This is because the uncertainty in some subspace of the state space could have more impact on the performance of the task than the others at a given time. The active-sensing method presented in this paper takes the task into account when selecting sensing actions by minimizing the uncertainty in future task action.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_03">14:07-14:08, Paper ThT22.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0297.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('297'); return false" title="Click to show or hide the keywords and abstract">Motion Guidance Using Haptic Feedback Based on Vibrotactile Illusions</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194967" title="Click to go to the Author Index">Salazar Luces, Jose Victorio</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100909" title="Click to go to the Author Index">Hirata, Yasuhisa</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100707" title="Click to go to the Author Index">Kosuge, Kazuhiro</a></td><td class="r">Tohoku Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab297" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Motor_Skill_Learning" title="Click to go to the Keyword Index">Motor Skill Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a></span><br>
                           <strong>Abstract:</strong> In this paper we present a wearable Haptic Feedback Device to convey intuitive motion direction to the user through haptic feedback based on vibrotactile illusions. Vibrotactile illusions occur on the skin when two or more vibrotactile actuators in proximity are actuated in coordinated sequence, causing the user to feel combined sensations, instead of separate ones. By combining these illusions we can produce various sensation patterns that are discernible by the user, thus allowing to convey different information with each pattern. <p>A method to provide information about direction through vibrotactile illusions is introduced on this paper. This method uses a grid of vibrotactile actuators around the arm actuated in coordination. The sensation felt on the skin is consistent with the desired direction of motion, so the desired motion can be intuitively understood. We show that the users can recognize the conveyed direction, and implemented a proof of concept of the proposed method to guide users' elbow flexion/extension motion.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_04">14:08-14:09, Paper ThT22.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0336.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('336'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Real-Time Adaptive Non-Holonomic Motion Planning in Unforeseen Dynamic Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191716" title="Click to go to the Author Index">McLeod, Sterling</a></td><td class="r">Univ. of North Carolina at Charlotte</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101783" title="Click to go to the Author Index">Xiao, Jing</a></td><td class="r">UNC Charlotte</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab336" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0336.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Reactive_and_Sensor_Based_Planning" title="Click to go to the Keyword Index">Reactive and Sensor-Based Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a></span><br>
                           <strong>Abstract:</strong> This paper addresses the problem of real-time, non-holonomic motion planning in environments with moving obstacles of unforeseen, arbitrary motion. An approach is introduced to smoothly switch trajectories by generating feasible non-holonomic trajectory segments on the fly as the robot moves in such an environment, extending the real-time adaptive motion planning (RAMP) approach that is used for holonomic motion. It allows efficient on-line simultaneous planning and execution of non-holonomic trajectories and enables a robot to adapt to changes in the environment while taking into account robot motion uncertainty. The effectiveness and efficiency of the method has been verified through real experiments with a mobile robot and several dynamic obstacles of unforeseen motion to the robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_05">14:09-14:10, Paper ThT22.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0404.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('404'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Semi-Autonomous Framework for Human-Aware and User Intention Driven Wheelchair Mobility Assistance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171960" title="Click to go to the Author Index">K. Narayanan, Vishnu</a></td><td class="r">Inria Rennes, INSA Rennes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107673" title="Click to go to the Author Index">Spalanzani, Anne</a></td><td class="r">INRIA / Univ. Grenoble Alpes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154230" title="Click to go to the Author Index">Babel, Marie</a></td><td class="r">IRISA UMR CNRS 6074 - INRIA - INSA Rennes</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab404" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0404.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> An important aspect to be taken care of while designing assistive robots for mobility is that they need to operate among humans. Thus understanding human spatial social conventions and incorporating them in the assistive solutions, is important. In this paper, we introduce a semi-autonomous framework for assistive wheelchair navigation in human environments, which is driven by the intention of the wheelchair user. Safe and textit{socially compliant} motion provided by a user intention driven local motion planner is fused with user teleoperation in order to create such a system. Taking into account the fact that the user is the primary controller, our proposed system aims to provide progressive assistance whenever the user is in danger of collision or at risk of disturbance to other humans. We also thus propose generalized formulations for estimating user intentions and for sharing control within the context of wheelchair mobility assistance, that is adaptable in order to be deployed in real world systems. We then evaluate the proposed framework in simulation in order to obtain a quantitative analysis. We also provide experimental evidence using an off-the-shelf robotized wheelchair equipped with a single 2D laser scanner.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_06">14:10-14:11, Paper ThT22.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0426.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('426'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Motion Planning for Autonomous Vehicles in Highly Constrained Urban Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171295" title="Click to go to the Author Index">Fassbender, Dennis</a></td><td class="r">Univ. of the Bundeswehr Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195770" title="Click to go to the Author Index">Heinrich, Benjamin C.</a></td><td class="r">Univ. of the Bundeswehr Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107635" title="Click to go to the Author Index">Wuensche, Hans J</a></td><td class="r">UniBw Munich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab426" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0426.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_based_Planning" title="Click to go to the Keyword Index">Sensor-based Planning</a></span><br>
                           <strong>Abstract:</strong> In this paper, we present a motion planning algorithm for autonomous navigation in highly constrained urban environments. Since common approaches to on-road trajectory planning turned out to be unsuitable for this task, we instead extended an A*-based planner originally designed for navigation in unstructured environments. Two novel node expansion methods were added to obtain smooth and accurate trajectories that consider the structure of the environment. The first one attempts to find a trajectory connecting the current node directly to the goal by solving a boundary value problem using numerical optimization. The second method leverages a simulated pure-pursuit controller to generate edges (i.e. short motion primitives) that guide the vehicle toward or along the global reference path. As a result, the planner is able to produce smooth paths while retaining the explorative power of A* that is needed to deal with challenging situations in urban driving (e.g., reversing in order to pass a vehicle that stopped unexpectedly). Its practical usefulness was demonstrated during extensive tests on an electric vehicle navigating a mock urban environment as well as on our own autonomous vehicle MuCAR-3.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_07">14:11-14:12, Paper ThT22.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0554.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('554'); return false" title="Click to show or hide the keywords and abstract">Morphological Design for Controlled Tensegrity Quadruped Locomotion</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195415" title="Click to go to the Author Index">Hustig-Schultz, Dawn</a></td><td class="r">Univ. of California, Santa Cruz</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137052" title="Click to go to the Author Index">SunSpiral, Vytas</a></td><td class="r">SGT Inc. / NASA Ames Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193055" title="Click to go to the Author Index">Teodorescu, Mircea</a></td><td class="r">UCSC</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab554" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a></span><br>
                           <strong>Abstract:</strong> From the viewpoint of evolution, vertebrates first accomplished locomotion via motion of the spine. Legs evolved later, to enhance mobility, but the spine remains central. Contrary to this, most robots have rigid torsos and rely primarily on movement of the legs for mobility. The force distributing properties of tensegrity structures presents a potential means of developing compliant spines for legged robots, with the goal of driving motion from the robots core. We present an initial exploration of the morphological design of a tensegrity quadruped robot, the first to the authors’ knowledge, which we call MountainGoat, and its impact on controllable locomotion. All parts of the robot, including legs and spine, are compliant. Locomotion is aided by the use of central pattern generators, feedback control via a neural network, and machine learning techniques involving the Monte Carlo method as well as genetic evolution for parameter optimization. Control is demonstrated with three variations of MountainGoat, focusing on actuation of the spine as central to the locomotion process.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_08">14:12-14:13, Paper ThT22.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0591.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('591'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Whole-Body Motion Planning for Humanoid Robots with Heuristic Search</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195528" title="Click to go to the Author Index">Athar, Ali</a></td><td class="r">National Univ. of Sciences and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195532" title="Click to go to the Author Index">Zafar, Abdul Moeed</a></td><td class="r">National Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195531" title="Click to go to the Author Index">Asif, Rizwan</a></td><td class="r">National Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195798" title="Click to go to the Author Index">Khan, Armaghan Ahmad</a></td><td class="r">National Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#176507" title="Click to go to the Author Index">Islam, Fahad</a></td><td class="r">National Univ. of Sciences and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113371" title="Click to go to the Author Index">Ayaz, Yasar</a></td><td class="r">National Univ. of Sciences and Tech. (NUST)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169517" title="Click to go to the Author Index">Hasan, Osman</a></td><td class="r">National Univ. of Science and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab591" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0591.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a></span><br>
                           <strong>Abstract:</strong> The task of whole-body motion planning for humanoid robots is challenging due to its high-DOF nature, stability constraints, and the need for obstacle avoidance and movements that appear human-like. Over the years, various approaches have been adopted to solve this problem such as bounding-box models and jacobian-based techniques. More commonly though, sampling-based algorithms are employed for this task since they perform admirably well in high dimensional spaces. As an alternative, search-based planners offer improvements in terms of optimality and consistency of the solution. However, they are normally considered impractical for motion planning because their performance in high dimensional spaces is generally considered to be poor. In this paper, we present a heuristic search-based motion planning framework for humanoid robots that circumvents the drawbacks traditionally associated with search-based planners while catering to the specific requirements of humanoid motion planning. This is achieved primarily through a combination of informative yet computationally inexpensive heuristics, carefully crafted motion primitives as atomic actions, and a whole body inverse kinematics (IK) solver for achieving desired end effector orientations. The experimental results show the ability of our framework to perform complex motion planning tasks quickly and efficiently.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_09">14:13-14:14, Paper ThT22.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0604.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('604'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Trajectory Representation by Nonlinear Scaling of Dynamic Movement Primitives</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102502" title="Click to go to the Author Index">Ude, Ales</a></td><td class="r">Jozef Stefan Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158307" title="Click to go to the Author Index">Vuga, Rok</a></td><td class="r">Jozef Stefan Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106954" title="Click to go to the Author Index">Nemec, Bojan</a></td><td class="r">Jozef Stefan Inst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104947" title="Click to go to the Author Index">Morimoto, Jun</a></td><td class="r">ATR Computational Neuroscience Labs</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab604" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0604.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Motor_Skill_Learning" title="Click to go to the Keyword Index">Motor Skill Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> An effective robot trajectory representation should encode all relevant aspects of the desired motion. For kinematic representations, this means that both the spatial course of the trajectory and its speed profile must be specified. The concept of dynamic movement primitives (DMP) provides a kinematic representation that fully specifies these two aspects of motion. They are, however, not separated from each other within the DMP representation. This can be problematic when movements with significant speed variations are compared within movement recognition and skill learning algorithms. In such comparisons it is often important to distinguish between the spatial and temporal aspects of motion. In this paper we propose a new representation based on dynamic movement primitives, where spatial and temporal aspects are well separated. We demonstrate the effectiveness of the proposed representation for statistical learning of robot skills and movement recognition and compare the performance with standard DMPs, where temporal and spatial aspects of motion are intertwined.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_10">14:14-14:15, Paper ThT22.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0648.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('648'); return false" title="Click to show or hide the keywords and abstract">Desired Orientation RRT (DO-RRT) for Autonomous Vehicle in Narrow Cluttered Spaces</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148346" title="Click to go to the Author Index">Shin, Seho</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195706" title="Click to go to the Author Index">Ahn, JoonWoo</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101200" title="Click to go to the Author Index">Park, Jaeheung</a></td><td class="r">Seoul National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab648" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Intelligent_Transportation_Systems" title="Click to go to the Keyword Index">Intelligent Transportation Systems</a></span><br>
                           <strong>Abstract:</strong> Autonomous vehicles are actively being developed from ADAS(Advanced Driver Assistance Systems) toward fully autonomous vehicles. Motion planning is one of the most important key technologies for fully autonomous vehicles, especially when they are operated in constrained narrow space such as parking lot. In this environment, the motion planning is challenging because it requires many changes in forward and reverse directions and adjustments of position and orientation. In this paper, an efficient motion planning algorithm is proposed based on Rapidly-exploring Random Trees (RRT) by specifying desired orientation during the tree expansion. A tangential vector space for desired orientation is used to model nonholonomic constraints of a vehicle and geometric constraints of obstacles. The proposed algorithm has been tested on various situations and its results demonstrated much faster performance compared to a nonholonomic RRT algorithm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_11">14:15-14:16, Paper ThT22.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0780.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('780'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Expressive Navigation and Local Path-Planning of Independent Steering Autonomous Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196264" title="Click to go to the Author Index">Todoran, George</a></td><td class="r">Vienna Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164214" title="Click to go to the Author Index">Bader, Markus</a></td><td class="r">Vienna Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab780" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0780.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Planning_and_Control" title="Click to go to the Keyword Index">Integrated Planning and Control</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a></span><br>
                           <strong>Abstract:</strong> This paper presents a novel Local-Path Planning approach for an independent four-wheel steering (I4WS) mobile base. The approach smoothly drives and rotates the platform while still following a given path and avoiding obstacles. I4WS vehicles are omnidirectional vehicles, similar to shopping carts, if one neglects the time needed to steer the wheels. However, due to the danger of mechanical parts breaking while actuating the wheels, they are commonly controlled in a stop-and-go fashion, where the vehicle stops to turn its wheels perpendicular to a desired instantaneous center of curvature (ICC) before starting to move again. The approach overcomes this limitation and ensures an ICC-based kinematic constraint during continuous motion using a flat-input controller running at 100 Hz. Therefore, the trajectory of the ICC is both predictable and suitable for model predictive control (MPC). The MPC implemented generates optimized collision-free trajectories of up to several meters ahead at 10 Hz, given a set of points along a path and laser contour readings. Furthermore, the planner realized here is able to deal with additional constraints such as the vehicle's view direction to focus on attention points while driving. Experimental results highlight the capabilities of the approach on a simulated robot, using GazeboSim, and demonstrate its applicability for the field of service robotics.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_12">14:16-14:17, Paper ThT22.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0807.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('807'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Co-Optimizing Task and Motion Planning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193008" title="Click to go to the Author Index">Zhang, Chongjie</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140740" title="Click to go to the Author Index">Shah, Julie A.</a></td><td class="r">MIT</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab807" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0807.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a></span><br>
                           <strong>Abstract:</strong> Solutions to robotic manipulation problems can be substantially improved through integrated task and motion planning. Existing approaches typically focus on satisfaction, finding a feasible solution, instead of optimization. We formulate large-scale robotic manipulation problems as multi-level optimization, incorporating task, action, and motion planning. We develop an integrated planning approach for solving this optimization problem and generating a combined motion plan for a robot to optimize a task-level objective. This approach utilizes a combinatorial search algorithm for task planning and incrementally exploits information from lower-level optimization to improve the high-level task plan. Empirical results show that this integrated approach not only significantly outperforms a traditional top-down approach in solution quality, but also avoids infeasible lower-level motion plans.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_13">14:17-14:18, Paper ThT22.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0833.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('833'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Power Modulating Leg Mechanism for Monopedal Hopping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155271" title="Click to go to the Author Index">Haldane, Duncan</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192394" title="Click to go to the Author Index">Plecnik, Mark</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195833" title="Click to go to the Author Index">Yim, Justin K.</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101253" title="Click to go to the Author Index">Fearing, Ronald</a></td><td class="r">Univ. of California at Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab833" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0833.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> New work in robotics targets the development of controllable agile motions such as leaping. In this work, we examine animal and robotic systems on the metric of jumping agility and find that animals can outperform the most agile robots by a factor of two. These specially adapted animals use a jumping strategy we term power modulation to generate more peak power for jumping than otherwise possible. A novel eight-bar revolute mechanism designed with a new linkage synthesis approach encodes the properties for power modulation as well as constraints which assure rotation-free jumping motion. We fabricate an 85 gram prototype and demonstrate that it can perform a range of jumps while constrained by a linear slide. The prototype can deliver 3.63 times more peak jumping power than the maximum its motor can produce. A simulation matched to the physical parameters of the prototype predicts that the robot can attain an agility exceeding that of the most agile animals if the actuator power is increased to 15W.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_14">14:18-14:19, Paper ThT22.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0896.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('896'); return false" title="Click to show or hide the keywords and abstract">Online Trajectory Optimization to Improve Object Recognition</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143005" title="Click to go to the Author Index">Potthast, Christian</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101856" title="Click to go to the Author Index">Sukhatme, Gaurav</a></td><td class="r">Univ. of Southern California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab896" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Reactive_and_Sensor_Based_Planning" title="Click to go to the Keyword Index">Reactive and Sensor-Based Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> We present an online trajectory optimization approach that optimizes a trajectory such that object recognition performance is improved. Inspired by prior work, we formulate the optimization as a derivative-free stochastic optimization, allowing us to express the cost function in an arbitrary way. The cost function is defined such that information acquisition of target objects is improved, while simultaneously moving towards the goal point. We show the evaluation of our approach on a quadrotor platform in simulation as well as on a real robot. The results show that by using an online optimization approach recognition accuracy is greatly improved, but more importantly the optimized trajectory reduces the uncertainty of the posterior class distribution greatly. Hence, verifying that the optimized trajectory collects more valuable information.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_15">14:19-14:20, Paper ThT22.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1151.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1151'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>From Indoor GIS Maps to Path Planning for Autonomous Wheelchairs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#152187" title="Click to go to the Author Index">Guzzi, Jerome</a></td><td class="r">Idsia, Usi-Supsi</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#145880" title="Click to go to the Author Index">Di Caro, Gianni A.</a></td><td class="r">Usi - Supsi</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1151" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1151.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a></span><br>
                           <strong>Abstract:</strong> This work focuses on how to compute trajectories for an autonomous wheelchair based on indoor GIS maps, in particular on IndoorGML maps, which set the standard in this context. Good wheelchair trajectories are safe and comfortable for the user and the people sharing the space with him, turn gently, are high legible, and smooth (at least G<sup>2</sup> continuos). We derive a navigation graph from a given IndoorGML map. We define and solve an optimization problem to find the desired path: given a succession of cells to traverse, the path corresponds to the best composite B'ezier trajectory for the wheelchair. We discuss a related multi-objective path planning problem. Experimental results and an implementation on real robots show the planner performance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_16">14:20-14:21, Paper ThT22.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1164.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1164'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Optimal Control for Geometric Motion Planning of a Robot Diver</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196564" title="Click to go to the Author Index">Shu, Roberto</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166257" title="Click to go to the Author Index">Siravuru, Avinash</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147370" title="Click to go to the Author Index">Rai, Akshara</a></td><td class="r">ÉCOLE Pol. FÉDÉRALE DE LAUSANNE EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171057" title="Click to go to the Author Index">Dear, Tony</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#138299" title="Click to go to the Author Index">Sreenath, Koushil</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104011" title="Click to go to the Author Index">Choset, Howie</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1164" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1164.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> Inertial reorientation of articulated bodies has been an active area of research in the robotics community, as this behavior can help guide dynamic robots to a safe landing with minimal damage. The main objective of this work is emulating the aggressive and large angle correction maneuvers, like somersaults, that are performed by human divers. To this end, a planar three link robot, called DiverBot, is proposed. By considering a gravity-free scenario, a local connection is obtained between joint angles and the body orientation, resulting in a reduction in the system dynamics. An optimal control policy applied on this reduced configuration space yielded diving maneuvers that appear human-like while being dynamically feasible. Numerical results show that the DiverBot can execute one somersault without drift and multiple somersaults with drift.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_17">14:21-14:22, Paper ThT22.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1229.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1229'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Anytime RRBT for Handling Uncertainty and Dynamic Objects</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193058" title="Click to go to the Author Index">Yang, Hyunchul</a></td><td class="r">Korea Advanced Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117882" title="Click to go to the Author Index">Lim, Jongwoo</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#120231" title="Click to go to the Author Index">Yoon, Sung-eui</a></td><td class="r">KAIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1229" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1229.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> We present an efficient anytime motion planner for mobile robots that considers both other dynamic obstacles and uncertainty caused by various sensors and low-level controllers. Our planning algorithm, which is an anytime extension of the Rapidly-exploring Random Belief Tree (RRBT), maintains the best possible path throughout the robot execution, and the generated path gets closer to the optimal one as more computation resources are allocated. We propose a branch-andbound method to cull out unpromising areas by considering path lengths and uncertainty. We also propose an uncertaintyaware velocity obstacle as a simple local analysis to avoid dynamic obstacles efficiently by finding a collision-free velocity. We have tested our method with three benchmarks that have non-linear measurement regions or potential collisions with dynamic obstacles. By using the proposed methods, we achieve up to five times faster performance given a fixed path cost.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_18">14:22-14:23, Paper ThT22.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1262.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1262'); return false" title="Click to show or hide the keywords and abstract">On the Theory of User-Guided Planning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133541" title="Click to go to the Author Index">Denny, Jory</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190482" title="Click to go to the Author Index">Colbert, Jonathan</a></td><td class="r">Blinn Coll</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190481" title="Click to go to the Author Index">Qin, Hongsen</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102662" title="Click to go to the Author Index">Amato, Nancy</a></td><td class="r">Texas A&M Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1262" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> Sampling-based techniques are often employed to solve various complex motion planning problems — the problem of computing a valid path under various robot and/or obstacle constraints. As these methods are random in nature, the probability of their success is directly related to the expansiveness, or openness, of the underlying planning space. However, little is known theoretically in qualifying the conditions under which user (human)-guided approaches improve the efficiency of sampling-based planners.<p>In this paper, we classify and create simplistic models of common user-guided approaches, and we extend the concept of expansiveness to analyze these models to understand both when and how much user-guidance aids sampling-based planners.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_19">14:23-14:24, Paper ThT22.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1282.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1282'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Runtime SES Planning: Online Motion Planning in Environments with Stochastic Dynamics and Uncertainty</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180165" title="Click to go to the Author Index">Chiang, Hao-Tien</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184152" title="Click to go to the Author Index">Rackley, Nathanael</a></td><td class="r">Univ. of New Mexico</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107965" title="Click to go to the Author Index">Tapia, Lydia</a></td><td class="r">Univ. of New Mexico</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1282" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1282.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> Motion planning in stochastic dynamic uncertain environments is critical in several applications such as human interacting robots, autonomous vehicles and assistive robots. In order to address these complex applications, several methods have been developed. The most successful methods often predict future obstacle locations in order identify collision-free paths. Since prediction can be computationally expensive, offline computations are commonly used ,and simplifications such as the inability to consider the dynamics of interacting obstacles or possible stochastic dynamics are often applied. Online methods can be preferable to simulate potential obstacle interactions, but recent methods have been restricted to Gaussian interaction processes and uncertainty.<p>In this paper we present an online motion planning method, Runtime Stochastic Ensemble Simulation (Runtime SES) planning, an inexpensive method for predicting obstacle motion with generic stochastic dynamics while maintaining a high planning success rate despite the potential presence of obstacle position error. Runtime SES planning evaluates the likelihood of collision for any state-time coordinate around the robot by performing Monte Carlo simulations online. This prediction is used to construct a customized Rapidly Exploring Random Tree (RRT) in order to quickly identify paths that avoid obstacles while moving toward a goal. We demonstrate Runtime SES planning in problems that benefit from online predictions, environments with strongly-interacting obstacles with stochastic dynamics and positional error. Through experiments that explore the impact of various parametrizations, robot dynamics and obstacle interaction models, we show that real-time capable planning with a high success rate is achievable in several complex environments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_20">14:24-14:25, Paper ThT22.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1326.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1326'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Persistent Robot Formation Flight Via Online Substitution</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157817" title="Click to go to the Author Index">Mitchell, Derek</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180657" title="Click to go to the Author Index">Cappo, Ellen</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111260" title="Click to go to the Author Index">Michael, Nathan</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1326" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1326.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong>  This paper presents an online optimization-based approach to compute trajectories to enable substitution of robots in formation-based deployments with durations that exceed the energy capacity of individual systems. The proposed algorithm computes trajectories in a multi-robot context to ensure a collision-free exchange, even where congestion is a concern. The quality of the resulting trajectories is determined by the amount of time spent deviating from the original plan while maintaining collision-free, speed-limited polynomial splines. The algorithm is shown through simulation and experiments to be viable with average deviation time gaps of less than 20 seconds and average computation times of under 3 minutes for the presented scenarios with varying numbers of robots and deployment specifications.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_21">14:25-14:26, Paper ThT22.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1389.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1389'); return false" title="Click to show or hide the keywords and abstract">Classification of Dynamical Vertical Climbing Gaits</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196338" title="Click to go to the Author Index">Brown, Jason</a></td><td class="r">Florida State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133397" title="Click to go to the Author Index">Miller, Bruce</a></td><td class="r">Florida State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104389" title="Click to go to the Author Index">Clark, Jonathan</a></td><td class="r">Florida State Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1389" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> While numerous gaits in the horizontal regime (e.g. walking or running) have been defined for legged systems on level ground, no dynamically grounded definitions have been developed for dynamic vertical running. Gaits have clear implications to robotic control strategy, efficiency, and stability. However, while several climbing robotic systems have been described as achieving `running', the question of whether distinct dynamic gaits exist and what classifies these gaits has not been rigorously explored. In this paper, by applying definitions developed in the horizontal regime, we show evidence of three distinct gaits as well as discuss the implications of these gaits on the development of dynamic climbing systems.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_22">14:26-14:27, Paper ThT22.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1426.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1426'); return false" title="Click to show or hide the keywords and abstract">Template-Based Human Supervised Robot Task Programming</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166022" title="Click to go to the Author Index">Long, Xianchao</a></td><td class="r">Northeastern Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#129456" title="Click to go to the Author Index">Padir, Taskin</a></td><td class="r">Northeastern Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1426" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Cloud_Robotics" title="Click to go to the Keyword Index">Cloud Robotics</a></span><br>
                           <strong>Abstract:</strong> Motions of a robot interacting with its environment can be described by a set of constraints. This paper introduces an approach, called motion template, which can quickly program and compose the constraints for the motion planner to generate the trajectory. Two types of motion templates, grasp and turn, are speci&#64257;cally described to explain the details of the technique. The reusability and shareability properties of the motion template are demonstrated using a variety of the motion planning applications across different robot platforms. A motion template framework is used to implement the motion template with the trajectory optimization.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_23">14:27-14:28, Paper ThT22.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1512.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1512'); return false" title="Click to show or hide the keywords and abstract">Modeling of Human-Like Reaching Movements in the Manipulation of Parallel Flexible Objects</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105095" title="Click to go to the Author Index">Svinin, Mikhail</a></td><td class="r">Kyushu Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117995" title="Click to go to the Author Index">Goncharenko, Igor</a></td><td class="r">3D Incorporated</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196812" title="Click to go to the Author Index">Lee, Hagchang</a></td><td class="r">Kyushu Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106559" title="Click to go to the Author Index">Yamamoto, Motoji</a></td><td class="r">Kyushu Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1512" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a>, <a href="IROS16_KeywordIndexMedia.html#Virtual_Reality_and_Interfaces" title="Click to go to the Keyword Index">Virtual Reality and Interfaces</a></span><br>
                           <strong>Abstract:</strong> The paper presents an analysis of human-like reaching movements in manipulation of parallel flexible objects. To predict the trajectory of human hand, a minimum hand jerk model, based on the minimization of integral of squared hand jerk over the movement duration is established. It is shown that within this model the optimal hand trajectory is composed of a fifth order polynomial and two trigonometric terms depending on the natural frequencies of the system and the movement time. A virtual reality-based experimental setup with a haptic simulator is designed, and the prediction by the minimum hand jerk model is verified against experimental data. The theoretical prediction matches the collected data with a reasonable accuracy. The initial experimental results confirm the applicability of the minimum hand jerk model for modeling of human-like reaching movements in dynamic environments.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht22_24">14:28-14:29, Paper ThT22.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1566.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1566'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Formation Change for Robot Groups in Occluded Environments</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183179" title="Click to go to the Author Index">Hoenig, Wolfgang</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196847" title="Click to go to the Author Index">Kumar, T. K. Satish</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196849" title="Click to go to the Author Index">Ma, Hang</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107126" title="Click to go to the Author Index">Koenig, Sven</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113756" title="Click to go to the Author Index">Ayanian, Nora</a></td><td class="r">Univ. of Southern California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1566" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1566.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a></span><br>
                           <strong>Abstract:</strong> We study formation change for robot groups in known environments. We are given a team of robots partitioned into groups, where robots in the same group are interchangeable with each other. A formation specifies the locations occupied by each group. The objective is to find collision-free paths that move all robots from a given start formation to a given goal formation. Our algorithm TAPF* has the following features: (a) it incorporates kinematic constraints of robots in form of velocity limits; (b) it maintains a user-specified safety distance between robots; (c) it attempts to minimize the makespan; and (d) it runs efficiently for hundreds of robots and dozens of groups even in dense 3D environments with narrow corridors and other occlusions. We demonstrate the efficiency and effectiveness of TAPF* in simulation and on robots.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbi1"><b>ThBI1</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbi1" title="Click to go to the Program at a Glance"><b>Interactive Session: Navigation/SLAM</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#111986" title="Click to go to the Author Index">He, Bingwei</a></td><td class="r">Fuzhou Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#170332" title="Click to go to the Author Index">Chaves, Stephen</a></td><td class="r">Univ. of Michigan</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbi2"><b>ThBI2</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbi2" title="Click to go to the Program at a Glance"><b>Interactive Session: Motion and Path Planning</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102610" title="Click to go to the Author Index">Cavusoglu, M. Cenk</a></td><td class="r">Case Western Res. Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#101783" title="Click to go to the Author Index">Xiao, Jing</a></td><td class="r">UNC Charlotte</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt1"><b>ThBT1</b></a></td>
               <td class="r">#101</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt1" title="Click to go to the Program at a Glance"><b>(Special Session) towards the Realization of the Aerial Robotic Workers</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#105882" title="Click to go to the Author Index">Nikolakopoulos, George</a></td><td class="r">Luleå Univ. of Tech</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#103432" title="Click to go to the Author Index">Fumagalli, Matteo</a></td><td class="r">Aalborg Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt1_01">14:35-14:50, Paper ThBT1.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0670.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('670'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Mechatronic Design of a Robotic Manipulator for Unmanned Aerial Vehicles</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103432" title="Click to go to the Author Index">Fumagalli, Matteo</a></td><td class="r">Aalborg Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100035" title="Click to go to the Author Index">Stramigioli, Stefano</a></td><td class="r">Univ. of Twente</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110966" title="Click to go to the Author Index">Carloni, Raffaella</a></td><td class="r">Univ. of Twente</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab670" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0670.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> The paper focuses on the mechatronic design of a robotic manipulator that is meant to be mounted on an Unmanned Aerial Vehicle (UAV) and to be used in industrial applications, for both aerial inspection by contact and aerial manipulation. The combination of an UAV and the robotic manipulator realizes the aerial manipulator. The robotic manipulator is designed to be versatile so that the aerial manipulator can perform both trajectory tracking in free flight and physical interaction. Moreover, the robotic manipulator can be mounted on commercially available UAVs a modular way without interfering with the existing onboard control architecture. Experimental test are validating the overall mechatronic design.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt1_02">14:50-15:05, Paper ThBT1.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0860.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('860'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Decoupled Design of Controllers for Aerial Manipulation with Quadrotors</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168850" title="Click to go to the Author Index">Ótão Pereira, Pedro Miguel</a></td><td class="r">KTH Royal Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196331" title="Click to go to the Author Index">Zanella, Riccardo</a></td><td class="r">KTH Royal Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103919" title="Click to go to the Author Index">Dimarogonas, Dimos V.</a></td><td class="r">Royal Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab860" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0860.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Mobile_Manipulation" title="Click to go to the Keyword Index">Mobile Manipulation</a></span><br>
                           <strong>Abstract:</strong> In this paper, we model an aerial vehicle, specifically a quadrotor, and a load attached to each other by a rigid link. We assume a torque input at the joint between the aerial vehicle and the rigid link is available. After modeling, we decouple the system dynamics in two separate subsystems, one concerning the position of the center of mass, which we control independently from the chosen torque input; and a second subsystem, concerning the attitude of the rigid link, which we control by appropriately designing a torque control law. Differential flatness is used to show that controlling these two separate systems is equivalent to controlling the complete system. We design control laws for the quadrotor thrust, the quadrotor angular velocity and the torque input, and provide convergence proofs that guarantee that the quadrotor follows asymptotically a desired position trajectory while the manipulator follows a desired orientation. Simulation and experimental works are presented which validate the proposed algorithms.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt1_03">15:05-15:20, Paper ThBT1.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1025.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1025'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Tree Cavity Inspection Using Aerial Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195683" title="Click to go to the Author Index">Steich, Kelly</a></td><td class="r">ETHZ, Disney Res. Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192445" title="Click to go to the Author Index">Kamel, Mina</a></td><td class="r">Autonomous Systems Lab, ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142438" title="Click to go to the Author Index">Beardsley, Paul</a></td><td class="r">Disney Res. Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195727" title="Click to go to the Author Index">Obrist, Martin, K.</a></td><td class="r">Swiss Federal Res. Inst. WSL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195689" title="Click to go to the Author Index">Lachat, Thibault</a></td><td class="r">WSL</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1025" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1025.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robotics_in_Agriculture_and_Forestry" title="Click to go to the Keyword Index">Robotics in Agriculture and Forestry</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> We present an aerial robotic platform for remote tree cavity inspection, based on a hexacopter Micro-Aerial vehicle (MAV) equipped with a dexterous manipulator. The goal is to make the inspection process safer and more efficient and facilitate data collection about tree cavities, which are important for the conservation of biodiversity in forest ecosystems. This work focuses on two key enabling technologies, namely a vision- based cavity detection system and strategies for high level control of the MAV and manipulator. The results of both simulation and real-world experiments are discussed at the end of the paper and demonstrate the effectiveness of our approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt1_04">15:20-15:35, Paper ThBT1.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1166.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1166'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Real-Time Mesh-Based Scene Estimation for Aerial Inspection</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190634" title="Click to go to the Author Index">Teixeira, Lucas</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115127" title="Click to go to the Author Index">Chli, Margarita</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1166" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1166.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> With society and industry pushing for robot-assisted systems to automate cumbersome tasks, such as inspection and maintenance, a vast amount of research effort has been dedicated to relevant technologies. Right at the forefront are small Unmanned Aerial Vehicles (UAVs) equipped with onboard cameras, recently demonstrating that vision-based autonomous flights without reliance on GPS are possible, sparking great interest in a plethora of areas. Current solutions, however, still lack in portability and generality struggling to perform outside the controlled laboratory environment, with onboard robotic perception constituting the biggest impediment.<p>Driven by the need for real-time denser scene estimation, in this work we present a dramatically low-computation approach enabling estimation of the immediate surroundings of a UAV using the inertial and visual cues from a single onboard camera. Instead of following the recent trend towards dense scene reconstruction, we trade detail of reconstruction for efficiency of estimation, albeit without compromising accuracy. We present results against scene ground truth obtained by a millimetre-precise laser scanner which we make publicly available together with our code. The ETHZ CAB Building dataset contains the ground-truth and visual-inertial data captured from both handheld and flying setups.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt1_05">15:35-15:50, Paper ThBT1.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1528.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1528'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Design and Modeling of Dexterous Aerial Manipulator</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192445" title="Click to go to the Author Index">Kamel, Mina</a></td><td class="r">Autonomous Systems Lab, ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132933" title="Click to go to the Author Index">Alexis, Kostas</a></td><td class="r">Univ. of Nevada, Reno</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1528" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1528.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Dexterous_Manipulation" title="Click to go to the Keyword Index">Dexterous Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> In this paper, the design, modeling and experimental verification of a large workspace parallel aerial manipulator is presented. The proposed manipulator has 3 Degrees of Freedom (DoFs) and enables physical interaction on the sides, as well as below the aerial robot. The design parameters of the manipulator are chosen such that it achieves large and singularity-free workspace in combination with high dexterity. A textit{Global Conditioning Index (GCI)} is defined and used as a performance index for the manipulator over its complete workspace. Given the manipulator design parameters, a holistic model of the redundant aerial manipulation system is derived capturing the coupled dynamics of the aerial vehicle and the manipulator. Free flight experimental studies are utilized to validate the system, demonstrate its redundant DoFs, and evaluate its performance.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt2"><b>ThBT2</b></a></td>
               <td class="r">#102</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt2" title="Click to go to the Program at a Glance"><b>Visual Learning</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#111056" title="Click to go to the Author Index">Natale, Lorenzo</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#128778" title="Click to go to the Author Index">Posada, Luis Felipe</a></td><td class="r">Univ. EAFIT</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt2_01">14:35-14:50, Paper ThBT2.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0337.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('337'); return false" title="Click to show or hide the keywords and abstract">RL-IAC: An Exploration Policy for Online Saliency Learning on an Autonomous Mobile Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#186314" title="Click to go to the Author Index">Craye, Céline</a></td><td class="r">ENSTA Paristech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103035" title="Click to go to the Author Index">Filliat, David</a></td><td class="r">ENSTA ParisTech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#186316" title="Click to go to the Author Index">Goudou, Jean-François</a></td><td class="r">Thales SIX Theresis</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab337" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a></span><br>
                           <strong>Abstract:</strong> In the context of visual object search and localization, saliency maps provide an efficient way to find object candidates in images. Unlike most approaches, we propose a way to learn saliency maps directly on a robot, by exploring the environment, discovering salient objects using geometric cues, and learning their visual aspects. More importantly, we provide an autonomous exploration strategy able to drive the robot for the task of learning saliency. For that, we describe the Reinforcement Learning-Intelligent Adaptive Curiosity algorithm (RL-IAC), a mechanism based on IAC (Intelligent Adaptive Curiosity) able to guide the robot through areas of the space where learning progress is high, while minimizing the time spent to move in its environment without learning. We demonstrate first that our saliency approach is an efficient tool to generate relevant object boxes proposal in the input image and significantly outperforms the state-of-the-art EdgeBoxes algorithm. Second, we show that RL-IAC can drastically decrease the required time for learning saliency compared to random exploration.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt2_02">14:50-15:05, Paper ThBT2.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0439.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('439'); return false" title="Click to show or hide the keywords and abstract">Efficient Deep Models for Monocular Road Segmentation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123142" title="Click to go to the Author Index">Oliveira, Gabriel</a></td><td class="r">Univ. of Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101785" title="Click to go to the Author Index">Burgard, Wolfram</a></td><td class="r">Univ. of Freiburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151845" title="Click to go to the Author Index">Brox, Thomas</a></td><td class="r">Univ. of Freiburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab439" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> This paper addresses the problem of road scene segmentation in conventional RGB images by exploiting recent advances in semantic segmentation via convolutional neural networks (CNNs). Segmentation networks are very large and do not currently run at interactive frame rates. To make this technique applicable to robotics we propose several architecture refinements that provide the best trade-off between segmentation quality and runtime. This is achieved by a new mapping between classes and filters at the expansion side of the network. The network is trained end-to-end and yields precise road/lane predictions at the original input resolution in roughly 50ms. Compared to the state of the art, the network achieves top accuracies on the KITTI dataset for road and lane segmentation while providing a 20x speed-up. We demonstrate that the improved efficiency is not due to the road segmentation task. Also on segmentation datasets with larger scene complexity, the accuracy does not suffer from the large speed-up.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt2_03">15:05-15:20, Paper ThBT2.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0468.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('468'); return false" title="Click to show or hide the keywords and abstract">Parameter Learning for Improving Binary Descriptor Matching</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142104" title="Click to go to the Author Index">Sankaran, Bharath</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135596" title="Click to go to the Author Index">Ramalingam, Srikumar</a></td><td class="r">Mitsubishi Electric Res. Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131561" title="Click to go to the Author Index">Taguchi, Yuichi</a></td><td class="r">Mitsubishi Electric Res. Labs</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab468" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> Binary descriptors allow fast detection and matching algorithms in computer vision problems. Though binary descriptors can be computed at almost two orders of magnitude faster than traditional gradient-based descriptors, they suffer from poor matching accuracy in challenging conditions. In this paper, we propose three improvements for binary descriptors in their computation and matching that enhance their performance in comparison to traditional binary and non-binary descriptors without compromising their speed. This is achieved by learning some weights and threshold parameters that allow customized matching under some variations such as lighting and viewpoint. Our suggested improvements can be easily applied to any binary descriptor. We demonstrate our approach on the ORB (Oriented FAST and Rotated BRIEF) descriptor and compare its performance with the traditional ORB and SIFT descriptors on a wide variety of datasets. In all instances, our enhancements outperform standard ORB and is comparable to SIFT.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt2_04">15:20-15:35, Paper ThBT2.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1002.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1002'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Simultaneous Place Learning and Recognition for Real-Time Appearance-Based Mapping</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194627" title="Click to go to the Author Index">Kazmi, S. M. Ali Musa</a></td><td class="r">Univ. of Paderborn</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137474" title="Click to go to the Author Index">Mertsching, Bärbel</a></td><td class="r">Univ. of Paderborn</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1002" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1002.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> Recent research in appearance-based mapping has introduced a diverse range of techniques to deal with environments under varying conditions. Common to almost all the existing methods is that they expect a supervised or offline training. Furthermore, some approaches match sequences, assuming constant velocity over the routes. This work addresses the challenges of appearance-based mapping in an online setup without making assumptions or acquiring prior knowledge of the environment. For this purpose, we exploit the topology preserving capability of self-organizing neural networks and learn the perceptual representation of environments using GIST features. Due to the fact that real-world environments are complex and large-scale, we let the network grow while accounting for the amount of error in the network due to perceptual differences among the places. Given the current state of the network and a query image at any time instant, it is possible to identify whether a place comes from the visited location by computing maximum a posteriori estimate over the network. The extensive experiments on three standard datasets, St. Lucia (4 videos), KITTI (2 sequences), and the Oxford City Center dataset, demonstrate the strength of our approach for real-time place recognition while concurrently learning the spatial representation of scenes.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt2_05">15:35-15:50, Paper ThBT2.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1211.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1211'); return false" title="Click to show or hide the keywords and abstract">Object Identification from Few Examples by Improving the Invariance of a Deep Convolutional Neural Network</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180351" title="Click to go to the Author Index">Pasquale, Giulia</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134065" title="Click to go to the Author Index">Ciliberto, Carlo</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160981" title="Click to go to the Author Index">Rosasco, Lorenzo</a></td><td class="r">Istituto Italiano Di Tecnologia & MassachusettsInstitute Oftechn</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111056" title="Click to go to the Author Index">Natale, Lorenzo</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1211" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> The development of reliable and robust visual recognition systems is a main challenge towards the deployment of autonomous robotic agents in unconstrained environments. Learning to recognize objects requires image representations that are discriminative to relevant information while being invariant to nuisances, such as scaling, rotations, light and background changes, and so forth. Deep Convolutional Neural Networks can learn such representations from large web-collected image datasets and a natural question is how these systems can be best adapted to the robotics context where little supervision is often available.<p>In this work, we investigate different training strategies for deep architectures on a new dataset collected in a real-world robotic setting. In particular we show how deep networks can be tuned to improve invariance and discriminability properties and perform object identification tasks with minimal supervision.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt3"><b>ThBT3</b></a></td>
               <td class="r">#103</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt3" title="Click to go to the Program at a Glance"><b>Tactile Sensing</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#150004" title="Click to go to the Author Index">Ciarfuglia, Thomas Alessandro</a></td><td class="r">Univ. Degli Studi Di Perugia</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#104326" title="Click to go to the Author Index">Peters, Jan</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt3_01">14:35-14:50, Paper ThBT3.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0142.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('142'); return false" title="Click to show or hide the keywords and abstract">A Multi-Modal Approach to Continuous Material Identification through Tactile Sensing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191882" title="Click to go to the Author Index">Gómez Eguíluz, Augusto</a></td><td class="r">Univ. of Ulster</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117855" title="Click to go to the Author Index">Rano, Inaki</a></td><td class="r">Ulster Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105281" title="Click to go to the Author Index">Coleman, Sonya</a></td><td class="r">Univ. of Ulster</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142095" title="Click to go to the Author Index">McGinnity, Martin</a></td><td class="r">Univ. of Ulster</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab142" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> Tactile sensing has been used in robotics for object identification, grasping, and material recognition. Most material recognition approaches use vibration signals from a tactile exploration, typically above one second long, to identify the material. This work proposes a tactile multi-modal (vibration and thermal) material identification approach based on recursive Bayesian estimation. Through the frequency response of the vibration induced by the material and thermal features, like an estimate of the thermal power loss of the finger, we show that it is possible to identify materials in less than half a second. Moreover, a comparison between vibration only and multi-modal identification shows that both recognition time and classification errors are reduced by adding thermal information.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt3_02">14:50-15:05, Paper ThBT3.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0438.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('438'); return false" title="Click to show or hide the keywords and abstract">Event-Based Signaling for Large-Scale Artificial Robotic Skin - Realization and Performance Evaluation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179230" title="Click to go to the Author Index">Bergner, Florian</a></td><td class="r">Tech. Univ. of Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154981" title="Click to go to the Author Index">Dean-Leon, Emmanuel</a></td><td class="r">Tech. Univ. Muenchen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101793" title="Click to go to the Author Index">Cheng, Gordon</a></td><td class="r">Tech. Univ. Munich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab438" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Networks" title="Click to go to the Keyword Index">Sensor Networks</a></span><br>
                           <strong>Abstract:</strong> In this paper we describe how we realized event-based signaling for large scale artificial robotic skin. We developed a new algorithm for the event generation on multi-modal skin cells. The skin cells have two modes, the conventional data sampling mode and the event mode. A comprehensive performance evaluation and comparison of these two modes is presented. We perform different experiments on our robot TOMM which has two UR5 robot arms, each covered with 260 multi-modal skin cells. Each skin cell samples 9 signals of 4 different modalities. Finally we derive models for extrapolating CPU usage and network traffic for larger numbers of skin cells and higher sample rates. The results show that the event-based system has superior performance and its performance edge increases with larger numbers of skin cells and higher sample rates. Experimental validation on our real robot system shows that in reactive control the event-based system reduces in comparison to the conventional system the packet rate by 48.2% and the CPU usage by 17.79%. We extrapolate the worst case for 5000 cells and show that the event-based system can at least reduce the packet rate by 21.2% and the CPU usage by 17.46%.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt3_03">15:05-15:20, Paper ThBT3.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0797.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('797'); return false" title="Click to show or hide the keywords and abstract">Active Tactile Object Exploration with Gaussian Processes</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195103" title="Click to go to the Author Index">Yi, Zhengkun</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155792" title="Click to go to the Author Index">Calandra, Roberto</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156276" title="Click to go to the Author Index">Veiga, Filipe Fernandes</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151699" title="Click to go to the Author Index">van Hoof, Herke</a></td><td class="r">TU Darmstadt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142053" title="Click to go to the Author Index">Hermans, Tucker</a></td><td class="r">Univ. of Utah</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195407" title="Click to go to the Author Index">Zhang, Yilei</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104326" title="Click to go to the Author Index">Peters, Jan</a></td><td class="r">Tech. Univ. Darmstadt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab797" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a></span><br>
                           <strong>Abstract:</strong> Accurate object shape knowledge provides important information for performing stable grasping and dexterous manipulation. When modeling an object using tactile sensors, touching the object surface at a fixed grid of points can be sample inefficient. In this paper, we present an active touch strategy to efficiently reduce the surface geometry uncertainty by leveraging a probabilistic representation of object surface. In particular, we model the object surface using a Gaussian process and use the associated uncertainty information to efficiently determine the next point to explore. We validate the resulting method for tactile object surface modeling using a real robot to reconstruct multiple, complex object surfaces.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt3_04">15:20-15:35, Paper ThBT3.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1316.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1316'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Triangle Histogram for Object Classification by Tactile Sensing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169921" title="Click to go to the Author Index">Zhang, Mabel M.</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191308" title="Click to go to the Author Index">Kennedy, Monroe</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106150" title="Click to go to the Author Index">Hsieh, M. Ani</a></td><td class="r">Drexel Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101818" title="Click to go to the Author Index">Daniilidis, Kostas</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1316" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1316.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a></span><br>
                           <strong>Abstract:</strong> We present a new descriptor for tactile 3D object classification. It is invariant to object movement and simple to construct, using only the relative geometry of points on the object surface. We demonstrate successful classification of 185 objects in 10 categories, at sparse to dense surface sampling rate in point cloud simulation, with an accuracy of 77.5% at the sparsest and 90.1% at the densest. In a physics-based simulation, we show that contact clouds resembling the object shape can be obtained by a series of gripper closures using a robotic hand equipped with sparse tactile arrays. Despite sparser sampling of the object's surface, classification still performs well, at 74.7%. On a real robot, we show the ability of the descriptor to discriminate among different object instances, using data collected by a tactile hand.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt3_05">15:35-15:50, Paper ThBT3.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1379.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1379'); return false" title="Click to show or hide the keywords and abstract">Novel Apparatus for Light Touch Threshold Measurement</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141805" title="Click to go to the Author Index">Kim, Junghoon</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103566" title="Click to go to the Author Index">You, Bum Jae</a></td><td class="r">KIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106608" title="Click to go to the Author Index">Choi, Youngjin</a></td><td class="r">Hanyang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1379" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a></span><br>
                           <strong>Abstract:</strong> All the people have their own individual force ranges to feel the sense of touch and its minimum value is called light touch threshold (in short LTT). For instance, if a touching force is very weak, people do not know whether the object is contacted to their skin, even though it is pushing the skin already. This paper presents a novel apparatus to measure the LTT felt by each subject, which is referred to as Active von Frey (AvF) in this paper. As far as the authors know, the LTT measurement device is for the first time proposed in this paper. It is possible for the AvF to provide the touching force ranges from 1[mgf] to 400[mgf]. In order to provide an accurate touching force for the subject, D’Arsonval movement is chosen as an actuator to rotate a touching AvF pin. Both an electric current applied to the D’Arsonval movement and a rotational angle of AvF pin are utilized to calculate the touching force by the electro-mechanical statics. In addition, the image processing technique is used to measure the rotational angle of AvF pin. Finally we show that the LTTs are very different from individual to individual through the experimental results of 10 participants. We hope that the personalized parameters is used to design or control haptic or tele-operation devices for various applications.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt4"><b>ThBT4</b></a></td>
               <td class="r">#104</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt4" title="Click to go to the Program at a Glance"><b>Biologically-Inspired Robots</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#103183" title="Click to go to the Author Index">Floreano, Dario</a></td><td class="r">Ec. Pol. Federal, Lausanne</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#109405" title="Click to go to the Author Index">Bae, Joonbum</a></td><td class="r">UNIST</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt4_01">14:35-14:50, Paper ThBT4.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0020.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('20'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Steering Control of a Water-Running Robot by Using an Active Tail</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178636" title="Click to go to the Author Index">Kim, Hyungyu</a></td><td class="r">YeungNam Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#178631" title="Click to go to the Author Index">Jeong, Kyungmin</a></td><td class="r">KAERI</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100047" title="Click to go to the Author Index">Sitti, Metin</a></td><td class="r">Max-Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140339" title="Click to go to the Author Index">Seo, TaeWon</a></td><td class="r">Yeungnam Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab20" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0020.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a></span><br>
                           <strong>Abstract:</strong> Many kinds of mobile robots have been developed through biomimetic research. In this research, we mimicked a basilisk lizard’s ability to run on water for the maneuverability of a hexapedal robot, especially steering locomotion on the water. The robot has a circular plate as a tail, which the robot rotates to steer on water. We dynamically modeled the platform and conducted simulations and experiments on steering locomotion with a bang-bang controller. The robot can steer on water by rotating the tail, and the controlled steering locomotion is stable. The dynamic modelling approximates the robot’s steering locomotion and the trends of the simulation and experiment are similar, although there are errors between the desired and actual angles. The robot’s maneuverability on water can be improved through further research.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt4_02">14:50-15:05, Paper ThBT4.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0200.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('200'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>An Underwater Electrosensory Membrane Bio-Inspired by Weakly Electric Fish</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195474" title="Click to go to the Author Index">Wang, Ke</a></td><td class="r">Curtin Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#120525" title="Click to go to the Author Index">Cui, Lei</a></td><td class="r">Curtin Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103290" title="Click to go to the Author Index">Do, Khac Duc</a></td><td class="r">Univ. of Western Australia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab200" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0200.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> Artificial sensory system is promising to navigate in cluttered and turbid underwater environment by achieving similar functions of biological electrosense of weakly electric fish. In this paper we designed an electrosensory membrane that can operate in a full 3-dimensional mode. Algorithms on the object localization were also designed and tested based on numerical methods of electric field forward simulation. We combined the statistic learning method by training a multi-layer neural network and a probabilistic approach by applying a constrained unscented Kalman filter (CUKF). This exploits the merits of fast estimation and precise signal marching process. Experimental results showed that the detection and localization with the reported sensor were quick and accurate, with errors of around 10 mm using one-step neural network mapping and about 5 mm in close-range using CUKF. This work demonstrated the effectiveness of proposed electrosensory membrane and algorithms.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt4_03">15:05-15:20, Paper ThBT4.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0456.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('456'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Biomimetic Underwater Robots Based on Dielectric Elastomer Actuators</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133372" title="Click to go to the Author Index">Shintake, Jun</a></td><td class="r">École Pol. Fédérale De Lausanne</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183142" title="Click to go to the Author Index">Shea, Herbert</a></td><td class="r">EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103183" title="Click to go to the Author Index">Floreano, Dario</a></td><td class="r">Ec. Pol. Federal, Lausanne</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab456" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0456.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a></span><br>
                           <strong>Abstract:</strong> Dielectric elastomer actuators (DEAs), a soft actuator technology, hold great promise for biomimetic underwater robots. The high-voltages required to drive DEAs can however make them challenging to use in water. This paper demonstrates a method to create DEA-based biomimetic swimming robots that operate reliably even in conductive liquids. We ensure the insulation of the high-voltage DEA electrodes without degrading actuation performance by laminating silicone layers. A fish and a jellyfish were fabricated and tested in water. The fish robot has a length of 120 mm and a mass of 3.8 g. The jellyfish robot has a 61 mm diameter for a mass of 2.6 g. The measured swimming speeds for a periodic 3 kV drive voltage were ~8 mm/s for the fish robot, and ~1.5 mm/s for the jellyfish robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt4_04">15:20-15:35, Paper ThBT4.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1048.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1048'); return false" title="Click to show or hide the keywords and abstract">Free Flight Force Estimation of a 23.5 G Flapping Wing MAV Using an On-Board IMU</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#152407" title="Click to go to the Author Index">Karásek, Mat&#283;j</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196433" title="Click to go to the Author Index">Koopmans, Jan Andries</a></td><td class="r">TU Delft</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196333" title="Click to go to the Author Index">Armanini, Sophie Franziska</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131960" title="Click to go to the Author Index">Remes, Bart</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131959" title="Click to go to the Author Index">de Croon, Guido</a></td><td class="r">TU Delft / ESA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1048" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> Despite an intensive research on flapping flight and flapping wing MAVs in recent years, there are still no accurate models of flapping flight dynamics. This is partly due to lack of free flight data, in particular during manoeuvres. In this work, we present, for the first time, a comparison of free flight forces estimated using solely an on-board IMU with wind tunnel measurements. The IMU based estimation brings higher sampling rates and even lower variation among individual wingbeats, compared to what has been achieved with an external motion tracking system in the past. A good match was found in comparison to wind tunnel measurements; the slight differences observed are attributed to clamping effects. Further insight was gained from the on-board rpm sensor, which showed motor speed variation of +/- 15% due to load variation over a wingbeat cycle. The IMU based force estimation represents an attractive solution for future studies of flapping wing MAVs as, unlike wind tunnel measurements, it allows force estimation at high temporal resolutions also during manoeuvres.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt4_05">15:35-15:50, Paper ThBT4.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1435.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1435'); return false" title="Click to show or hide the keywords and abstract">Design of a Robot with Biologically-Inspired Swimming Hairs for Fast and Efficient Mobility in Aquatic Environment</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179130" title="Click to go to the Author Index">Kwak, Bokeon</a></td><td class="r">Ulsan National Inst. of Science and Tech. (UNIST)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109405" title="Click to go to the Author Index">Bae, Joonbum</a></td><td class="r">UNIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1435" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> A water beetle is skillful at drag-powered swimming by using its oar-like legs. Inspired by this mechanism, a miniature robot, whose mobility is obtained by a pair of legs attached with swimming hairs, was studied in this work. The robot in this paper has optimally designed linkage structures to maximize the sweep angle, which is actuated by a single DC motor with series of gears and a spring. A simplified swimming hair model was proposed to calculate deflection by drag force applied, and COMSOL simulations were used to verify our model. Also, each of swimming hair was optimized individually by considering the attached locations on the legs using the two fitness functions, and three different configurations were selected. In the experiments, the performance of the proposed robots was verified using a high-speed camera, and motion capture cameras. The robot with the proposed configuration showed the fastest movement comparing with other robots.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt5"><b>ThBT5</b></a></td>
               <td class="r">#105</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt5" title="Click to go to the Program at a Glance"><b>UAV-Vision</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#142369" title="Click to go to the Author Index">Loianno, Giuseppe</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#106846" title="Click to go to the Author Index">Nuske, Stephen</a></td><td class="r">CMU Robotics Inst</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt5_01">14:35-14:50, Paper ThBT5.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0237.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('237'); return false" title="Click to show or hide the keywords and abstract">Long Distance Visual Ground-Based Signaling for Unmanned Aerial Vehicles</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#145852" title="Click to go to the Author Index">Grabe, Volker</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106846" title="Click to go to the Author Index">Nuske, Stephen</a></td><td class="r">CMU Robotics Inst</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab237" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> We present a long-range visual signal detection system that is suitable for an unmanned aerial vehicle to find an optical signal released at a desired landing site for the purposes of cargo delivery or rescue situations where radio signals or other communication systems are not available or the wind conditions at the landing site need to be signaled. The challenge here is to have a signal and detection system that works from long range (> 1000m) amongst ground clutter during various seasonal conditions on passive imagery. We use a smoke-grenade as a ground signal, which has the advantageous properties of being easy to carry by ground crews because of its light weight and small size, but when released has a long visual signaling range. We employ a camera system on the UAV with a visual texture feature extraction approach in a machine learning framework to classify image patches as 'signal' or 'background'. We study conventional approaches and develop a visual feature descriptor that can better differentiate the appearance of the visual signal under varying conditions and, when used to train a random-forest classifier, outperforms commonly used feature descriptors. The system was rigorously and quantitatively evaluated on data collected from a camera mounted on a helicopter and flown towards a plume of signal smoke over a variety of seasons, ground conditions, weather conditions, and environments. Our system was capable of detecting the smoke cloud with both precision and recall rates greater than 0.95 from ranges between 1000m and 1500m. Further, we develop a method to estimate wind orientation and approximate wind strength by assessing the shape of the smoke signal. We present a preliminary evaluation of the wind estimation in conditions with different wind intensities and orientations relative to the approach direction.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt5_02">14:50-15:05, Paper ThBT5.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0374.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('374'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Self-Calibrating Multi-Camera Visual-Inertial Fusion for Autonomous MAVs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185016" title="Click to go to the Author Index">Yang, Zhenfei</a></td><td class="r">Hong Kong Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192354" title="Click to go to the Author Index">Liu, Tianbo</a></td><td class="r">Hong Kong Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142354" title="Click to go to the Author Index">Shen, Shaojie</a></td><td class="r">Hong Kong Univ. of Science and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab374" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0374.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> We address the important problem of achieving robust and easy-to-deploy visual state estimation for micro aerial vehicles (MAVs) operating in complex environments. We use a sensor suite consisting of multiple cameras and an IMU to maximize perceptual awareness of the surroundings and provide sufficient redundancy against sensor failures. Our approach starts with an online initialization procedure that simultaneously estimates the transformation between each camera and the IMU, as well as the initial velocity and attitude of the platform, without any prior knowledge about the mechanical configuration of the sensor suite. Based on the initial calibrations, a tightly-coupled, optimization-based, generalized multi-camera-inertial fusion method runs onboard the MAV with online camera-IMU calibration refinement and identification of sensor failures. Our approach dynamically configures the system into monocular, stereo, or other multi-camera visual-inertial settings, with their respective perceptual advantages, based on the availability of visual measurements. We show that even under random camera failures, our method can be used for feedback control of the MAVs. We highlight our approach in challenging indoor-outdoor navigation tasks with large variations in vehicle height and speed, scene depth, and illumination.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt5_03">15:05-15:20, Paper ThBT5.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0752.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('752'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Multi-Target Detection and Tracking from a Single Camera in Unmanned Aerial Vehicles (UAVs)</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195564" title="Click to go to the Author Index">Li, Jing</a></td><td class="r">Purdue Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195203" title="Click to go to the Author Index">Ye, Dong Hye</a></td><td class="r">Purdue Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106700" title="Click to go to the Author Index">Chung, Timothy H.</a></td><td class="r">DARPA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151929" title="Click to go to the Author Index">Kolsch, Mathias</a></td><td class="r">Naval Postgraduate School</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146275" title="Click to go to the Author Index">Wachs, Juan</a></td><td class="r">Purdue Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195381" title="Click to go to the Author Index">Bouman, Charles</a></td><td class="r">Purdue Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab752" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0752.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> Despite the recent flight control regulations, Unmanned Aerial Vehicles (UAVs) are still gaining popularity in civilian and military applications, as much as for personal use. Such emerging interest is pushing the development of effective collision avoidance systems. Such systems play a critical role UAVs’ operations especially in a crowded airspace setting. Because of cost and weight limitations associated with UAVs’ payload, camera based technologies are the de-facto choice for collision avoidance navigation systems. This requires multi-target detection and tracking algorithms from a video, which can be run on board efficiently. While there has been a great deal of research on object detection and tracking from a stationary camera, few have attempted to detect and track small UAVs from a moving camera.<p>In this paper, we present a new approach to detect and track UAVs from a single camera mounted on a different UAV. Initially, we estimate background motions via a perspective transformation model and then identify distinctive points in the background subtracted image. We find spatio-temporal traits of each moving object through optical flow matching and then classify those candidate targets based on their motion patterns compared with the background. The performance is boosted through Kalman filter tracking. This results in temporal consistency among the candidate detections. The algorithm was validated on video datasets taken from a UAV. Results show that our algorithm can effectively detect and track small UAVs with limited computing resources.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt5_04">15:20-15:35, Paper ThBT5.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1715.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1715'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Towards Fully Autonomous Visual Inspection of Dark Featureless Dam Penstocks Using MAVs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196288" title="Click to go to the Author Index">Ozaslan, Tolga</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148231" title="Click to go to the Author Index">Mohta, Kartik</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105338" title="Click to go to the Author Index">Keller, James</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160721" title="Click to go to the Author Index">Mulgaonkar, Yash</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106877" title="Click to go to the Author Index">Taylor, Camillo Jose</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104342" title="Click to go to the Author Index">Kumar, Vijay</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1715" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1715.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Service_Robots" title="Click to go to the Keyword Index">Service Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a></span><br>
                           <strong>Abstract:</strong> In the last decade, multi-rotor Micro Aerial Vehicles (MAVs) have attracted great attention from robotics researchers. Offering affordable agility and maneuverability, multi-rotor aircrafts have become the most commonly used platforms for robotics applications. Amongst the most promising applications are inspection of power-lines, cell-towers, large and constrained infrastructures and precision agriculture. While GPS offers an easy solution for outdoor autonomy, using on-board sensors is the only solution for autonomy in constrained indoor environments. In this paper, we present our results on autonomous inspection of completely dark, featureless, symmetric dam penstocks using cameras and range sensors. We use a hex-rotor platform equipped with an IMU, four cameras and two lidars. One of the cameras tracks features on the walls using the on-board illumination to estimate the position along the tunnel axis unobservable to range sensors while all of the cameras are used for panoramic image construction. The two lidars estimate the remaining degrees of freedom (DOF). Outputs of the two estimators are fused using an Unscented Kalman Filter (UKF). A moderately trained operator defines waypoints using the Remote Control (RC). We demonstrate our results from Carters Dam, GA and Glen Canyon Dam, AZ which include panoramic images for crack and rusty spot detection and 6-DOF estimation results with ground truth comparisons. To our knowledge ours is the only study that can autonomously inspect environments with no geometric cues and poor to no external illumination using MAVs.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt5_05">15:35-15:50, Paper ThBT5.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1726.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1726'); return false" title="Click to show or hide the keywords and abstract">Real-Time Restoration of Aerial Inspection Images by Recognizing and Removing Passive Rotating Shell of a UAV</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110231" title="Click to go to the Author Index">Okada, Yoshito</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184204" title="Click to go to the Author Index">Ishii, Takuma</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107167" title="Click to go to the Author Index">Ohno, Kazunori</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100118" title="Click to go to the Author Index">Tadokoro, Satoshi</a></td><td class="r">Tohoku Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1726" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Search_and_Rescue_Robots" title="Click to go to the Keyword Index">Search and Rescue Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Image_Processing" title="Click to go to the Keyword Index">Image Processing</a></span><br>
                           <strong>Abstract:</strong> This paper presents a real-time image restoration method for aerial inspection images that are degraded by the appearance of a passive rotating shell of an unmanned aerial vehicle (UAV).<p>Only images are required as the input. The method mainly consists of feature-based object detection for joints of the UAV shell, outlier rejection based on a sample consensus (SAC) approach and the geometrical model of the shell, reconsuruction of the entire region that the shell appears in, and inpainting of the shell.<p>Not only a pure algorithm for general UAVs with passive rotating shells but also an implementation specialized for a UAV that we have been developing are presented. The successfully implemented algorithm was evaluated for actual inspection flights under different conditions. The average rate of successful image restorations was 81.1% at 4.3 fps.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt6"><b>ThBT6</b></a></td>
               <td class="r">#106</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt6" title="Click to go to the Program at a Glance"><b>Planning and Scheduling</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#137542" title="Click to go to the Author Index">Busoniu, Lucian</a></td><td class="r">Tech. Univ. of Cluj-Napoca</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#195031" title="Click to go to the Author Index">Pall, Elod</a></td><td class="r">Tech. Univ. of Cluj Napoca</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt6_01">14:35-14:50, Paper ThBT6.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0041.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('41'); return false" title="Click to show or hide the keywords and abstract">Analysis and a Home Assistance Application of Online AEMS2 Planning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195031" title="Click to go to the Author Index">Pall, Elod</a></td><td class="r">Tech. Univ. of Cluj Napoca</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122463" title="Click to go to the Author Index">Tamas, Levente</a></td><td class="r">BFH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137542" title="Click to go to the Author Index">Busoniu, Lucian</a></td><td class="r">INRIA Lille</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab41" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Domestic_Robots_and_Home_Automation" title="Click to go to the Keyword Index">Domestic Robots and Home Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Planning_and_Control" title="Click to go to the Keyword Index">Integrated Planning and Control</a></span><br>
                           <strong>Abstract:</strong> We consider an online planning algorithm for partially observable Markov decision processes (POMDPs), called Anytime Error Minimization Search 2 (AEMS2). Despite the considerable success it has enjoyed in robotics and other problems, no quantitative analysis exists of the relationship between its near-optimality and the computation invested. Exploiting ideas from fully-observable MDP planning, we provide here such an analysis, in which the relationship is modulated via a measure of problem complexity called near-optimality exponent. We illustrate the exponent for some interesting POMDP structures, and examine the role of the informative heuristics used by AEMS2 in the guarantees. In the second part of the paper, we introduce a domestic assistance problem in which a robot monitors partially observable switches and turns them off if needed. AEMS2 successfully solves this task in real experiments, and also works better than several state of the art planners in simulation comparisons.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt6_02">14:50-15:05, Paper ThBT6.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0147.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('147'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Time-Optimal Coordination of Mobile Robots Along Specified Paths</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195278" title="Click to go to the Author Index">Altche, Florent</a></td><td class="r">MINES ParisTech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191257" title="Click to go to the Author Index">Qian, Xiangjun</a></td><td class="r">MINES ParisTech - PSL Res. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191259" title="Click to go to the Author Index">de La Fortelle, Arnaud</a></td><td class="r">MINES ParisTech - PSL Res. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab147" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0147.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Intelligent_Transportation_Systems" title="Click to go to the Keyword Index">Intelligent Transportation Systems</a></span><br>
                           <strong>Abstract:</strong> In this paper, we address the problem of time-optimal coordination of mobile robots under kinodynamic constraints along specified paths. We propose a novel approach based on time discretization that leads to a mixed-integer linear programming (MILP) formulation. This problem can be solved using general-purpose MILP solvers in a reasonable time, resulting in a resolution-optimal solution. Moreover, unlike previous work found in the literature, our formulation allows an exact linear modeling (up to the discretization resolution) of second-order dynamic constraints. Extensive simulations are performed to demonstrate the effectiveness of our approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt6_03">15:05-15:20, Paper ThBT6.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0261.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('261'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Online Planning for Energy-Efficient and Disturbance-Aware UAV Operations</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133879" title="Click to go to the Author Index">Bezzo, Nicola</a></td><td class="r">Univ. of Virginia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148231" title="Click to go to the Author Index">Mohta, Kartik</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133897" title="Click to go to the Author Index">Nowzari, Cameron</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169096" title="Click to go to the Author Index">Lee, Insup</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104342" title="Click to go to the Author Index">Kumar, Vijay</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102357" title="Click to go to the Author Index">Pappas, George J.</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab261" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0261.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Autonomous_Agents" title="Click to go to the Keyword Index">Autonomous Agents</a></span><br>
                           <strong>Abstract:</strong> In this paper we consider an online planning problem for unmanned aerial vehicle (UAV) operations. Specifically, a UAV has the task of reaching a goal from a set of possible goals while minimizing the amount of energy required. Due to unforeseen disturbances, it is possible that initially attractive goals might end up being very expensive during the execution. Thus, two main problems are investigated here: i) how to predict and plan the motion of the UAV at run time to minimize its energy consumption and ii) when to schedule next replanning time to avoid unnecessary periodic re-evaluation executions. Our approach considers a nonlinear model of the system for which a model predictive controller is used to determine the desired control inputs for each possible goal. These control inputs are then used to estimate the energy required to reach the different goals. Finally, a self-triggered scheduling policy determines how long to wait before replanning the goal to aim for. The proposed framework is validated through simulations and experiments in which a quadrotor must choose and reach some goal while being subject to external disturbances.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt6_04">15:20-15:35, Paper ThBT6.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0861.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('861'); return false" title="Click to show or hide the keywords and abstract">Decision Making in a UAV-Based Delivery System with Impatient Customers</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187431" title="Click to go to the Author Index">Grippa, Pasquale</a></td><td class="r">Univ. of Klagenfurt</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab861" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> This article introduces a framework to compute decision making policies (mission planning) for a UAV-based delivery system serving impatient customers. Customers arrive on a finite number of locations L separated by arbitrary but fixed distances and eventually leave if not served. Policies seek to minimize the average net cost (maximize the average net revenue), i.e. loss from customers’ abandonment deprived of the revenue from successful services. We introduce a novel model for the stochastic and dynamic pickup and delivery problem based on semi-Markov decision processes, and show the dependence of the optimal average net cost on the minimum distance between locations &#948;. Furthermore, we propose a feature-based state aggregation method to overcome the curse of dimensionality due to the exact modeling. The selection of relevant features is based on their correlation with the optimal performance. We show that the distance to the nearest pickup location dominates on other features for almost all &#948;. Based on this observation, we introduce the policy nearest neighbor or none, a policy with computational complexity O(L<sup>3</sup>) in many cases of interest. We show that this policy performs considerably better that the nearest neighbor (greedy) policy, and reaches the optimum for some &#948;.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt6_05">15:35-15:50, Paper ThBT6.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1714.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1714'); return false" title="Click to show or hide the keywords and abstract">Sequential Quadratic Programming for Task Plan Optimization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160714" title="Click to go to the Author Index">Hadfield-Menell, Dylan</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180746" title="Click to go to the Author Index">Lin, Christopher</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169238" title="Click to go to the Author Index">Chitnis, Rohan</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169058" title="Click to go to the Author Index">Russell, Stuart Jonathan</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107568" title="Click to go to the Author Index">Abbeel, Pieter</a></td><td class="r">UC Berkeley</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1714" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Mobile_Manipulation" title="Click to go to the Keyword Index">Mobile Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> We consider the problem of refining an abstract task plan into a motion trajectory. Task and motion planning is a hard problem that is essential to long-horizon mobile manipulation problems. Many approaches divide the problem into two steps: a search for a task plan and task plan refinement to find a feasible trajectory. We apply sequential quadratic programming to jointly optimize over the parameters in a task plan (e.g., trajectories, grasps, put down locations). We provide two modifications that make our formulation more suitable to task and motion planning. We show how to use movement primitives to reuse previous solutions (and so save optimization effort) without trapping the algorithm in a poor basin of attraction. We also derive an early convergence criterion that lets us quickly detect unsatisfiable constraints so we can re-initialize their variables. We present experiments in a navigation amongst movable objects domain show substantial improvement in cost over a backtracking refinement algorithm.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt7"><b>ThBT7</b></a></td>
               <td class="r">#107</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt7" title="Click to go to the Program at a Glance"><b>Human-Robot Interaction 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#106623" title="Click to go to the Author Index">Vaughan, Richard</a></td><td class="r">Simon Fraser Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#102949" title="Click to go to the Author Index">De Luca, Alessandro</a></td><td class="r">Sapienza Univ. of Rome</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt7_01">14:35-14:50, Paper ThBT7.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0462.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('462'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Robot Reading Human Gaze: Why Eye Tracking Is Better Than Head Tracking for Human-Robot Collaboration</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#143414" title="Click to go to the Author Index">Palinko, Oskar</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148808" title="Click to go to the Author Index">Rea, Francesco</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107990" title="Click to go to the Author Index">Sandini, Giulio</a></td><td class="r">Italian Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108900" title="Click to go to the Author Index">Sciutti, Alessandra</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab462" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0462.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Interaction" title="Click to go to the Keyword Index">Humanoid Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Detection_and_Tracking" title="Click to go to the Keyword Index">Human Detection and Tracking</a></span><br>
                           <strong>Abstract:</strong> Robots are at the position to become our everyday companions in the near future. Still, many hurdles need to be cleared to achieve this goal. One of them is the fact that robots are still not able to perceive some important communication cues naturally used by humans, e.g. gaze. In the recent past, eye gaze in robot perception was substituted by its proxy, head orientation. Such an approach is still adopted in many applications today. In this paper we introduce performance improvements to an eye tracking system we previously developed and use it to explore if this approximation is appropriate. More precisely, we compare the impact of the use of eye- or head-based gaze estimation in a human robot interaction experiment with the iCub robot and naïve subjects. We find that the possibility to exploit the richer information carried by eye gaze has a significant impact on the interaction. As a result, our eye tracking system allows for a more efficient human-robot collaboration than a comparable head tracking approach, according to both quantitative measures and subjective evaluation by the human participants.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt7_02">14:50-15:05, Paper ThBT7.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0682.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('682'); return false" title="Click to show or hide the keywords and abstract">Social Activity Recognition Based on Probabilistic Merging of Skeleton Features with Proximity Priors from RGB-D Data</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182956" title="Click to go to the Author Index">Coppola, Claudio</a></td><td class="r">Univ. of Lincoln</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#127606" title="Click to go to the Author Index">Faria, Diego</a></td><td class="r">Univ. of Coimbra</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103575" title="Click to go to the Author Index">Nunes, Urbano</a></td><td class="r">Inst. De Sistemas E Robotica</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101540" title="Click to go to the Author Index">Bellotto, Nicola</a></td><td class="r">Univ. of Lincoln</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab682" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a></span><br>
                           <strong>Abstract:</strong> Social activity based on body motion is a key feature for non-verbal and physical behavior defined as function for communicative signal and social interaction between individuals. Social activity recognition is important to study human-human communication and also human-robot interaction. Based on that, this research has threefold goals: (1) recognition of social behavior (e.g. human-human interaction) using a probabilistic approach that merges spatio-temporal features from individual bodies and social features from the relationship between two individuals; (2) learn priors based on physical proximity between individuals during an interaction using proxemics theory to feed a probabilistic ensemble of activity classifiers; and (3) provide a public dataset with RGB-D data of social daily activities including risk situations useful to test approaches for assisted living, since this type of dataset is still missing. Results show that using the proposed approach designed to merge features with different semantics and proximity priors improves the classification performance in terms of precision, recall and accuracy when compared with other approaches that employ alternative strategies.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt7_03">15:05-15:20, Paper ThBT7.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1167.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1167'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Localizing External Contact Using Proprioceptive Sensors: The Contact Particle Filter</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196437" title="Click to go to the Author Index">Manuelli, Lucas</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105841" title="Click to go to the Author Index">Tedrake, Russ</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1167" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1167.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> In order for robots to interact safely and intelligently with their environment they must be able to reliably estimate and localize external contacts. This paper introduces CPF, the Contact Particle Filter, which is a general algorithm for detecting and localizing external contacts on rigid body robots without the need for external sensing. CPF finds external contact points that best explain the observed external joint torque, and returns sensible estimates even when the external torque measurement is corrupted with noise. We demonstrate the capability of the CPF to track multiple external contacts on a simulated Atlas robot, and compare our work to existing approaches.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt7_04">15:20-15:35, Paper ThBT7.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1551.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1551'); return false" title="Click to show or hide the keywords and abstract">Using Nonverbal Signals to Request Help During Human-Robot Collaboration</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179518" title="Click to go to the Author Index">Cha, Elizabeth</a></td><td class="r">Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106165" title="Click to go to the Author Index">Mataric, Maja</a></td><td class="r">Univ. of Southern California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1551" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperating_Robots" title="Click to go to the Keyword Index">Cooperating Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Telerobotics" title="Click to go to the Keyword Index">Telerobotics</a></span><br>
                           <strong>Abstract:</strong> Non-humanoid robots are becoming increasingly utilized for collaborative tasks that rely on each collaborator’s ability to effectively convey their mental state while accurately estimating and interpreting their partner’s knowledge, intent, and actions. During these tasks, it may be beneficial or even necessary for the human collaborator to assist the robot. Consequently, we explore the use of nonverbal signals to request help during a collaborative task. We focus on light and sound as they are commonly used communication channels across many domains. This paper analyzes the effectiveness of three nonverbal help signals that vary in urgency. Our results show that these signals significantly influence the human collaborator’s and their perception of the collaboration.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt7_05">15:35-15:50, Paper ThBT7.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1641.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1641'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Optimal Robot Selection by Gaze Direction in Multi-Human Multi-Robot Interaction</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195914" title="Click to go to the Author Index">Zhang, Lingkang</a></td><td class="r">Simon Fraser Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106623" title="Click to go to the Author Index">Vaughan, Richard</a></td><td class="r">Simon Fraser Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1641" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1641.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a></span><br>
                           <strong>Abstract:</strong> This paper presents a computer vision based system for interaction between multiple humans and multiple robots. Each human can ``select'' (obtain the undivided attention of) a robot by simply looking directly at it. This extends previous work whereby a single human can select one or more robots from a population. Each robot optimally assigns human identities to tracked faces in its camera view using a local Hungarian algorithm. The gaze-direction and location of the faces are estimated via vision, and a score for each robot-face pair is assigned. Then the system finds the global optimal allocation of robot-to-human selections using a centralized Hungarian algorithm. A useful feature of this method is that robots can be selected by people they cannot see. This is the first demonstration of optimal many-to-many robot-selection HRI.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt8"><b>ThBT8</b></a></td>
               <td class="r">#108</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt8" title="Click to go to the Program at a Glance"><b>Multi-Robot Systems 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#103169" title="Click to go to the Author Index">Robuffo Giordano, Paolo</a></td><td class="r">Centre National De La Recherche Scientifique (CNRS)</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#107110" title="Click to go to the Author Index">Frazzoli, Emilio</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt8_01">14:35-14:50, Paper ThBT8.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0412.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('412'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Active Decentralized Scale Estimation for Bearing-Based Localization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155077" title="Click to go to the Author Index">Spica, Riccardo</a></td><td class="r">Centre National De La Recherche Scientifique (CNRS)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103169" title="Click to go to the Author Index">Robuffo Giordano, Paolo</a></td><td class="r">Centre National De La Recherche Scientifique (CNRS)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab412" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0412.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a novel decentralized active perception strategy that maximizes the convergence rate in estimating the (unmeasurable) formation scale in the context of bearing-based formation localization for robots evolving in R<sup>3</sup> x S<sup>1</sup>. The proposed algorithm does not assume presence of a global reference frame and only requires <i>bearing-rigidity</i> of the formation (for the localization problem to admit a unique solution), and presence of (at least) one pair of robots in mutual visibility. Two different scenarios are considered in which the active scale estimation problem is treated either as a primary task or as a secondary objective with respect to the constraint of attaining a desired bearing formation. The theoretical results are validated by realistic simulations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt8_02">14:50-15:05, Paper ThBT8.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0470.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('470'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Cooperative Aerial Tele-Manipulation with Haptic Feedback</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#175749" title="Click to go to the Author Index">Mohammadi, Mostafa</a></td><td class="r">Univ. of Siena</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104988" title="Click to go to the Author Index">Franchi, Antonio</a></td><td class="r">LAAS-CNRS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162464" title="Click to go to the Author Index">Barcelli, Davide</a></td><td class="r">Univ. of Siena</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105260" title="Click to go to the Author Index">Prattichizzo, Domenico</a></td><td class="r">Univ. of Siena</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab470" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0470.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a bilateral tele-operation scheme for cooperative aerial manipulation in which a human operator drives a team of Vertical Take-Off and Landing (VTOL) aerial vehicles, that grasped an object beforehand, and receives a force feedback depending on the states of the system. For application scenarios in which dexterous manipulation by each robot is not necessary, we propose using a rigid tool attached to the vehicle through a passive spherical joint, equipped with a simple adhesive mechanism at the tool-tip that can stick to the grasped object. Having more than two robots, we use the extra degrees of freedom to find the optimal force allocation in term of minimum power and forces smoothness. The human operator commands a desired trajectory for the robot team through a haptic interface to a pose controller, and the output of the pose controller along with system constraints, e.g., VTOL limited forces and contact maintenance, defines the feasible set of forces. Then, an on-line optimization allocates forces by minimizing a cost function of forces and their variation. Finally, propeller thrusts are computed by a dedicated attitude and thrust controller in a decentralized fashion. Human/Hardware in the loop simulation study shows efficiency of the proposed scheme, and the importance of haptic feedback to achieve a better performance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt8_03">15:05-15:20, Paper ThBT8.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0651.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('651'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Rigidity-Based Decentralized Bearing Formation Controller for Groups of Quadrotor UAVs</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191166" title="Click to go to the Author Index">Schiano, Fabrizio</a></td><td class="r">Univ. of Rennes 1 - INRIA Rennes Bretagne Atlantique</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104988" title="Click to go to the Author Index">Franchi, Antonio</a></td><td class="r">LAAS-CNRS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177275" title="Click to go to the Author Index">Zelazo, Daniel</a></td><td class="r">Tech. - Israel Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103169" title="Click to go to the Author Index">Robuffo Giordano, Paolo</a></td><td class="r">Centre National De La Recherche Scientifique (CNRS)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab651" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0651.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> This paper considers the problem of controlling a formation of quadrotor UAVs equipped with onboard cameras and able to measure relative bearings in their local body frames w.r.t. neighboring UAVs. The control goal is twofold: (i) steering the agent group towards a formation defined in terms of desired bearings, and (ii) actuating the group motions in the `null-space' of the current bearing formation. The proposed control strategy strongly relies on an extension of the rigidity theory to the case of <i>directed</i> bearing frameworks in R<sup>3</sup> x S<sup>1</sup>. This extension allows to devise a <i>decentralized</i> bearing controller which, unlike most of the present literature, does not need presence of a common reference frame or of reciprocal bearing measurements for the agents. Simulation and experimental results are then presented for illustrating and validating the approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt8_04">15:20-15:35, Paper ThBT8.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0769.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('769'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Merging Appearance-Based Spatial Knowledge in Multirobot Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#125573" title="Click to go to the Author Index">Karaoguz, Hakan</a></td><td class="r">Bogazici Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107206" title="Click to go to the Author Index">Bozma, H. Isil</a></td><td class="r">Bogazici Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab769" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0769.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Learning" title="Click to go to the Keyword Index">Visual Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> This paper considers the merging of appearance-based spatial knowledge among robots having compatible visual sensing. Each robot is assumed to retain its knowledge in its individual long-term spatial memory where i) the place knowledge and their spatial relations are retained in an organized manner in place and map memories respectively; and ii) a ‘place’ refers to a spatial region as designated by a collection of associated appearances. In the proposed approach, each robot communicates with another robot, receives its memory and then merges the received knowledge with its own. The novelty of the merging process is that it is done in two stages: merging of place knowledge followed by the merging of map knowledge. As each robot’s place memory is processed as a whole or in portions, the merging process scales easily with respect to the amount and overlap of the appearance data. Furthermore, the merging can be done in decentralized manner. Our experimental results with a team of three robots demonstrate that the resulting merged knowledge enables the robots to reason about learned places.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt8_05">15:35-15:50, Paper ThBT8.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1026.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1026'); return false" title="Click to show or hide the keywords and abstract">Provably Safe and Deadlock-Free Execution of Multi-Robot Plans under Delaying Disturbances</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165316" title="Click to go to the Author Index">&#268;áp, Michal</a></td><td class="r">CTU in Prague</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196389" title="Click to go to the Author Index">Gregoire, Jean</a></td><td class="r">MIT</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107110" title="Click to go to the Author Index">Frazzoli, Emilio</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1026" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Planning__Scheduling_and_Coordination" title="Click to go to the Keyword Index">Planning, Scheduling and Coordination</a></span><br>
                           <strong>Abstract:</strong> One of the standing challenges in multi-robot systems is the ability to reliably coordinate motions of multiple robots in environments where the robots are subject to disturbances. We consider disturbances that force the robot to temporarily stop and delay its advancement along its planned trajectory which can be used to model, e.g., passing-by humans for whom the robots have to yield. Although reactive collision-avoidance methods are often used in this context, they may lead to deadlocks between robots. We design a multi-robot control strategy for executing coordinated trajectories computed by a multi-robot trajectory planner and give a proof that the strategy is safe and deadlock-free even when robots are subject to delaying disturbances. Our simulations show that the proposed strategy scales significantly better with the intensity of disturbances than the naive liveness-preserving approach. The empirical results further confirm that the proposed approach is more reliable and also more efficient than state-of-the-art reactive techniques.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt9"><b>ThBT9</b></a></td>
               <td class="r">#204~205</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt9" title="Click to go to the Program at a Glance"><b>Micro/Nano Robots</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#123306" title="Click to go to the Author Index">Tombari, Federico</a></td><td class="r">Univ. of Bologna</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#147274" title="Click to go to the Author Index">Abelmann, Leon</a></td><td class="r">Univ. of Twente</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt9_01">14:35-14:50, Paper ThBT9.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0178.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('178'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Influence of the Magnetic Field on the Two-Dimensional Control of Magnetospirillum Gryphiswaldense Strain MSR-1</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#175725" title="Click to go to the Author Index">Hassan, Heba</a></td><td class="r">German Univ. in Cairo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159459" title="Click to go to the Author Index">Pichel, Marc Philippe</a></td><td class="r">Twente Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191856" title="Click to go to the Author Index">Hageman, Tijmen</a></td><td class="r">Korean Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147274" title="Click to go to the Author Index">Abelmann, Leon</a></td><td class="r">Univ. of Twente</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#153284" title="Click to go to the Author Index">Khalil, Islam S.M.</a></td><td class="r">German Univ. in Cairo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab178" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0178.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a></span><br>
                           <strong>Abstract:</strong> Magnetotactic bacteria have the potential to controllably reach deep-seated regions of the body via vessels and achieve targeted drug delivery. In this application, motion of the magnetotactic bacteria is influenced by the strength of the external magnetic field. Here, we investigate the swimming characteristics of magnetotactic bacteria (Magnetospirillum gryphiswaldense strain MSR-1) under the influence of uniform and adaptive magnetic fields inside microfluidic chip with depth of 5 µm. This depth enables tracking of single bacterium and comparison of uniform and adaptive magnetic field on the positioning accuracy. We find that under the influence of magnetic field reversal with approximately twice the field strength, the diameter of the U-turn trajectories taken by the magnetotactic bacteria is decreased by 63%. In addition, the adaptive magnetic field decreases the size of region-of convergence of the controlled bacteria within the vicinity of the reference position by 65.5%, compared to control using uniform magnetic field. The comparisons between motion control using uniform and adaptive magnetic fields are done on the same culture of magnetotactic bacteria and using the same cell in each motion control trial.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt9_02">14:50-15:05, Paper ThBT9.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0953.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('953'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Development of a Microhand Using Direct Laser Writing for Indirect Optical Manipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137237" title="Click to go to the Author Index">Avci, Ebubekir</a></td><td class="r">Massey Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117925" title="Click to go to the Author Index">Yang, Guang-Zhong</a></td><td class="r">Imperial Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab953" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0953.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Mechanism_Design" title="Click to go to the Keyword Index">Mechanism Design</a>, <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose manipulation ability extension of the optical tweezers by developing microhands, which are to use as end-effectors of the laser beam. First, three different 3D micro-scale handles are designed, then manufactured by the two-photon polymerization method with nano-scale resolution of 100 nm. Second, printed microhands are manipulated by multi-spot laser beam which traps and manipulates numerous objects simultaneously. Third, where direct trapping of the target object is not possible due to target objects’ features such as size, shape, material, index of refraction, etc., indirect manipulation of the target microobjects is achieved by using the microhands as an extension of optical tweezers. Finally, three different microhand designs are compared in terms of speed and success rate. Furthermore, suitability of different shapes of microhandles against common usage of spherical shape is discussed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt9_03">15:05-15:20, Paper ThBT9.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1011.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1011'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Magnetically-Guided In-Situ Microrobot Fabrication</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192298" title="Click to go to the Author Index">Li, Zhe</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192410" title="Click to go to the Author Index">Youssefi, Omid</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117587" title="Click to go to the Author Index">Diller, Eric D.</a></td><td class="r">Univ. of Toronto</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1011" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1011.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a></span><br>
                           <strong>Abstract:</strong> Mobile microrobots are typically fabricated in a multi-step microfabrication process and then transported into an enclosed workspace for operation. This paper presents a new, 3D printing inspired method for in-situ fabrication of mobile magnetic microrobots with complex topology from a polymer filament on demand directly inside an enclosed operational environment. Through the use of a tip magnet on the filament, the target shape is formed by magnetic guidance from external electromagnetic coils which wirelessly project fields into the workspace as the filament is fed through a hot needle which is inserted into the workspace. A bending model and a shape planner are developed for predicting and controlling the fabrication process. Magnetically-active millimeter-scale robotic devices of different shapes and sizes are fabricated using polylactic acid (PLA) filament with diameter as small as 50 micrometers. As a demonstration of the in-situ formation of a functional microrobotic device, a force-sensing microrobot with integrated sensing spring is fabricated inside an enclosed space, and then is used to measure the manipulation force during a pushing experiment by optical deformation measurement. We thus show the utility of the fabrication method for creating complex microrobot shapes remotely in enclosed environments for advanced microrobotic applications, with the potential for scaled down applications in healthcare and microfluidics.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt9_04">15:20-15:35, Paper ThBT9.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1168.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1168'); return false" title="Click to show or hide the keywords and abstract">Closed-Loop Selective Manipulation of Multiple Microparticles by Controlling the Transient Regime of Marangoni Flows</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195372" title="Click to go to the Author Index">Muñoz, Elvin Mark</a></td><td class="r">Univ. De Ingenieria Y Tecnologia - UTEC</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196559" title="Click to go to the Author Index">Quispe, Johan Edilberto</a></td><td class="r">Univ. De Ingenieria Y Tecnologia - UTEC</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165681" title="Click to go to the Author Index">Vela, Emir Augusto</a></td><td class="r">Univ. De Ingeniería Y Tecnología</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1168" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a></span><br>
                           <strong>Abstract:</strong> In this paper, a closed-loop strategy for controlling the transient regime of Marangoni flows and thus to selectively manipulate and separate micro-particles is reported. Marangoni flows were generated by an infrared laser as a heat source. Simulations of the transient regime of Marangoni flows were performed with COMSOL Multiphysics to analyze the temperature field and velocity profile. The convection cell dynamic growth was controlled with the laser beam exposure time. Then, selected particles, glass beads ranging from 150 up to 212 microns, were dragged by small convection flows without reaching undesired particles. The closed-loop control improved the manipulation speed and precision in comparison to manual manipulation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt9_05">15:35-15:50, Paper ThBT9.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1265.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1265'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Unexpected Beads Alignment in a Microfluidic Channel</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113239" title="Click to go to the Author Index">Tsai, Chia-Hung Dylan</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196638" title="Click to go to the Author Index">Phan, Manh Hao</a></td><td class="r">Osaka Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132199" title="Click to go to the Author Index">Mizoue, Kouji</a></td><td class="r">MIZOUE PROJECT JAPAN Corp</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100119" title="Click to go to the Author Index">Kaneko, Makoto</a></td><td class="r">Osaka Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1265" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1265.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biological_Applications_of_Micro_Robots" title="Click to go to the Keyword Index">Biological Applications of Micro Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Smart_Actuators" title="Click to go to the Keyword Index">Smart Actuators</a></span><br>
                           <strong>Abstract:</strong> A surprising phenomenon is observed in a microfluidic channel where suspending microbeads are spontaneously aligned into lines. Microbeads are randomly distributed in the channel at a relatively high velocity, but start to align into lines at a relatively low velocity. The alignment has been repeated with and without obstacles in the channel. The phenomenon is interpreted as an unintended acoustic wave being around the experimental environment, and the wave resulted in a standing wave which moves the microbeads towards the nodes of the standing wave. By using a frequency analyzer, it is found that a pulse-width-modulation controller in the system generated high-frequency signals, which is the most possible wave source for the alignment. The experimental results are presented, and characteristics of acoustic wave are analyzed. The phenomenon could contribute to microfluidic applications for achieving acoustic alignment without complex fabrication of interdigital transducers.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thbt10"><b>ThBT10</b></a></td>
               <td class="r">#206~208</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thbt10" title="Click to go to the Program at a Glance"><b>Bipedal Control</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101611" title="Click to go to the Author Index">Hutchinson, Seth</a></td><td class="r">Univ. of Illinois</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#106951" title="Click to go to the Author Index">Zhang, Jianwei</a></td><td class="r">Univ. of Hamburg</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt10_01">14:35-14:50, Paper ThBT10.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0229.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('229'); return false" title="Click to show or hide the keywords and abstract">Bipedal Walking Pattern Generation Based on an Extrapolated Center of Mass</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109394" title="Click to go to the Author Index">Park, Sangsin</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102941" title="Click to go to the Author Index">Oh, Jun Ho</a></td><td class="r">Korea Advanced Inst. of Sci. and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab229" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> For a biped robot to keep walking, basic walking patterns are needed. One method to generate these patterns is to use an extrapolated center of mass (XcoM) concept and constant zero-moment point (ZMP) patterns. However, center of mass (CoM) patterns generated from such a method have discontinuous ZMP and CoM accelerations. For solving this problem, we propose a method in which continuous ZMP patterns can be simply generated from constant ones. In addition, experimental results of forward walking are presented. The results demonstrate that this pattern generation method can give a starting point for walking robots.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt10_02">14:50-15:05, Paper ThBT10.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0855.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('855'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Simple 2D Straight-Leg Passive Dynamic Walking Model without Foot-Scuffing Problem</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195881" title="Click to go to the Author Index">Li, Qingdu</a></td><td class="r">Chongqing Univ. of Posts and Telecommunications</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195888" title="Click to go to the Author Index">Liu, Guodong</a></td><td class="r">Chongqing Univ. of Posts and Telecommunications</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195883" title="Click to go to the Author Index">Tang, Jun</a></td><td class="r">Chongqing Univ. of Posts and Telecommunications</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106951" title="Click to go to the Author Index">Zhang, Jianwei</a></td><td class="r">Univ. of Hamburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab855" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0855.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> This paper presents a simple 2D passive dynamic walking model with straight legs based on a novel hip joint, called T-joint. The model directly solves the common foot-scuffing problem in straight-legged walkers without introducing any new degree of freedom or additional motion phase, which is unavoidable in kneed robots. The mathematic model of the new walker is a 4D hybrid dynamical system, which can be reduced to a 3D Poincare map. A stable period-1 walking gait is found by searching the map with a proposed algorithm. Numerical studies show that the model performs well for disturbances on initial conditions and also on a large slope. The stable walking gait is verified by a virtual prototype in ADAMS. This study has been successfully used to make an efficient walking robot called Xingzhe, which has set a new world record for the longest distance after 134km non-stoping walking.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt10_03">15:05-15:20, Paper ThBT10.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1205.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1205'); return false" title="Click to show or hide the keywords and abstract">Optimal Double Support Zero Moment Point Trajectories for Bipedal Locomotion</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107358" title="Click to go to the Author Index">Lanari, Leonardo</a></td><td class="r">Sapienza Univ. Di Roma</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101611" title="Click to go to the Author Index">Hutchinson, Seth</a></td><td class="r">Univ. of Illinois</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1205" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> In this paper, we address the problem of planning optimal zero moment point (ZMP) trajectories for the double support phase in bipedal gaits that alternate between single and double support. This is achieved by allowing pre- and post-actuation during the single support phases. Thus, we solve two coupled problems: exact tracking of a given desired ZMP trajectory in the pre- and post-phases (single support), and determination of the desired ZMP during the transition phase (double support). Both are solved while minimizing the overall control energy. We also provide a formal method to assess how the choice of desired ZMP trajectory during the single support phases impacts the overall energy expended during the footstep cycle. Although the obtained solution may not be physically feasible in general, it represents a benchmark to which alternative feasible solutions may be compared. Our approach generalizes previous results that consider only constant output in the pre- and post-phases, e.g., allowing pre- and post-phase output from a family of polynomial splines. We evaluate the approach via simulations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thbt10_04">15:20-15:35, Paper ThBT10.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1378.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1378'); return false" title="Click to show or hide the keywords and abstract">A Planar Stable Walking Model Based on Ankle Actuation and the Virtual Pendulum Concept</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156191" title="Click to go to the Author Index">Lee, Jongwoo</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110832" title="Click to go to the Author Index">Oh, Yonghwan</a></td><td class="r">Korea Inst. of Science & Tech. (KIST)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1378" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a novel planar biped model which achieves asymptotically stable walking, based on ankle actuation and the virtual pendulum concept. Simple models for walking have provided useful insights in understanding fundamental principles of human locomotion as well as developing controllers for biped robots. Existing simplest walking models include a point mass with either rigid legs or compliant legs. Both models are able to describe different gaits such as walking and running, but are not able to address posture stabilization, which is another important issue in bipedalism. Recently, the virtual pendulum (VP) concept was proposed as an intuitive posture stabilization strategy and successfully demonstrated on the compliant leg scheme. However, the model does not address inherent peripheral mechanics of walking, i.e., ankle actuation and collisional energy loss from foot-ground interaction. The model proposed in this paper consists of a rigid trunk, rigid legs and ankle actuation. The energy dissipation due to collision and compensation by ankle actuation play an essential role for asymptotically stable walking, while the trunk posture is stabilized based on the VP concept. Nonlinear dynamic simulation verifies that the model constructs a stable limit cycle with a small angular oscillation of trunk.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thspt12"><b>ThSpT12</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thspt12" title="Click to go to the Program at a Glance"><b>Special Forum 3: Medical Robotics</b></a></td>
               <td class="r">Special Forum</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#106263" title="Click to go to the Author Index">Yi, Byung-Ju</a></td><td class="r">Hanyang Univ</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="tht31"><b>ThT31</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#tht31" title="Click to go to the Program at a Glance"><b>Micro Robot/Robot Intelligence</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#147375" title="Click to go to the Author Index">Antonelli, Marco</a></td><td class="r">Hong Kong Univ. of Science and Tech</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#155126" title="Click to go to the Author Index">Lelevé, Arnaud</a></td><td class="r">INSA De Lyon (Inst. National Des Sciences Appliquees), Univ. De Lyon</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_01">16:10-16:11, Paper ThT31.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0390.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('390'); return false" title="Click to show or hide the keywords and abstract">3D Haptic Rendering of Tissues for Epidural Needle Insertion Using an Electro-Pneumatic 7 Degrees of Freedom Device</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195752" title="Click to go to the Author Index">Alès, Pierre-Jean</a></td><td class="r">Univ. of Verona , Italy</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181851" title="Click to go to the Author Index">Herzig, Nicolas</a></td><td class="r">Ampere UMR CNRS 5005 - INSA Lyon - Univ. De Lyon</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155126" title="Click to go to the Author Index">Lelevé, Arnaud</a></td><td class="r">INSA De Lyon (Inst. National Des Sciences Appliquees), Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102430" title="Click to go to the Author Index">Moreau, Richard</a></td><td class="r">INSA-Lyon</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195754" title="Click to go to the Author Index">Bauer, Christian</a></td><td class="r">Department of Anesthesia and Intensive Care, Hopital De La Croix</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab390" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Virtual_Reality_and_Interfaces" title="Click to go to the Keyword Index">Virtual Reality and Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a></span><br>
                           <strong>Abstract:</strong> Epidural anaesthesia is a medical gesture commonly performed by an anaesthesiologist. However, it remains one of the most difficult gestures to master for medical students. Given the lack of sufficiently realistic training devices available for future physicians, we propose a new haptic simulator which reproduces the haptic sensations felt by anaesthesiologists when performing this kind of operation. The originality of this simulator is the coupling of a Geomagic Touch device with a pneumatic cylinder to reproduce the &quot;Loss of Resistance&quot; phenomenon which helps the physician to control the needle depth. In this paper, we introduce the parametric 3D model of the region of interest and the control laws used jointly. Even though this device could not reproduce the right level of forces required in this type of anaesthesia, an anaesthesiologist involved in the project gave positive feedback about its haptic tissue rendering.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_02">16:11-16:12, Paper ThT31.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0394.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('394'); return false" title="Click to show or hide the keywords and abstract">Exploitation of SEM Charging Effects for Monitoring Robotic Assembly Tasks</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137190" title="Click to go to the Author Index">Bartenwerfer, Malte</a></td><td class="r">Carl Von Ossietzky Univ. of Oldenburg</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107730" title="Click to go to the Author Index">Fatikow, Sergej</a></td><td class="r">Univ. of Oldenburg</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab394" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a></span><br>
                           <strong>Abstract:</strong> Robotic handling inside the SEM is well known, but mostly a teleoperated task, but automation of in-situ handling would be highly advantageous and could enable serious production and assembly in the SEM. However, reliable techniques who facilitate an automation are still lacking. Especially the positioning along the optical axis of the SEM remains as a major challenge. In this paper, an universal approach addressing this particular issue is proposed, allowing to assist and improve handling and assembly task. The approach exploits typical charging effects in the SEM and derives information about the positions of objects and end-effectors as well as about assembly statuses. Assembly accuracies better than 100 nm are achieved and controlled approaching speeds of 10 &#956;m/s.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_03">16:12-16:13, Paper ThT31.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0606.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('606'); return false" title="Click to show or hide the keywords and abstract">A Novel Strategy for Smooth Force-Position Switching Control of Micropositioning Piezoelectric Actuators</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182124" title="Click to go to the Author Index">Fallahinia, Navid</a></td><td class="r">Amirkabir Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105532" title="Click to go to the Author Index">Zareinejad, Mohammad</a></td><td class="r">Amirkabir Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132258" title="Click to go to the Author Index">Talebi, Ali</a></td><td class="r">AmirKabir Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137174" title="Click to go to the Author Index">Baghestan, Keivan</a></td><td class="r">Amirkabir Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#136684" title="Click to go to the Author Index">Ghafarirad, Hamed</a></td><td class="r">Amirkabir Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab606" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> Control of the exerted force on objects as well as the position of the actuator during a cell characterization operation has an essential role in achieving an efficient performance. In such operations, any undesired applied force could degrade the efficiency or make damages to the object. A challenging problem associated with application to cell characterization using a piezoelectric actuator is to design a suitable force-position switching control law and also to deal with nonlinear hysteretic behavior of such actuators. The main concern in this operation is to provide a smooth switching transition between position and force control modes. A modified PrandtlIshlinskii (PI) operator and its inverse are utilized for both identification and real time compensation of the hysteresis nonlinear behavior. By proposing an appropriate force-position switching control approach, the smooth transition between these two modes is guaranteed. The stability of each controller as well as the switching system is demonstrated analytically. Experimental results depict that the proposed approach achieves precise force-position control within each modes and also the switching remains smooth.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_04">16:13-16:14, Paper ThT31.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0624.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('624'); return false" title="Click to show or hide the keywords and abstract">A Design of Phase-Closed-Loop Nanomachining Control Based Ultrasonic-Vibration-Assisted AFM</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183798" title="Click to go to the Author Index">Shi, Jialin</a></td><td class="r">Shenyang Inst. of Automation, Chinese Acad. of Sciences</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110692" title="Click to go to the Author Index">Liu, Lianqing</a></td><td class="r">Shenyang Inst. of Automation</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183799" title="Click to go to the Author Index">Yu, Peng</a></td><td class="r">Shenyang Inst. of Automation, Chinese Acad. of Sciences</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131466" title="Click to go to the Author Index">Cong, Yang</a></td><td class="r">Chinese Acad. of Science, China</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab624" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a></span><br>
                           <strong>Abstract:</strong> This paper proposed a phase-closed-loop nanomachining control method to realize the directly control of machining depth based on ultrasonic vibration-assisted AFM. By using applied force to control the machining depth, conventional AFM machining approaches unable to machining a nanostructure with specified machined depth. With the proposed method, the vibration phase of micro-cantilever has a specific relationship with machining depth. Therefore, the nano-grooves with desired depth can be machined by using phase value as feedback of PID control. In this paper, the theoretical analysis and simulation are carried out, and the experiments of phase-closed-loop control method are conducted. The experimental results verify the primary feasibility of the proposed method. The present method also demonstrates the potential on the fabrication of three-dimension nanostructures and nanoelectronic device.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_05">16:14-16:15, Paper ThT31.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0697.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('697'); return false" title="Click to show or hide the keywords and abstract">Unsupervised Learning of Depth During Coordinated Head/Eye Movements</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147375" title="Click to go to the Author Index">Antonelli, Marco</a></td><td class="r">Hong Kong Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#120295" title="Click to go to the Author Index">Rucci, Michele</a></td><td class="r">Boston Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149347" title="Click to go to the Author Index">Shi, Bertram Emil</a></td><td class="r">Hong Kong Univ. of Science and Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab697" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Neurorobotics" title="Click to go to the Keyword Index">Neurorobotics</a></span><br>
                           <strong>Abstract:</strong> Autonomous robots and humans need to create a coherent 3D representation of their peripersonal space in order to interact with nearby objects. Recent studies in visual neuroscience suggest that the small coordinated head/eye movements that humans continually perform during fixation provides useful depth information. In this work, we mimic such a behavior on a humanoid robot and propose a computational model that extracts depth information without requiring the kinematic model of the robot. First, we show that, during fixational head/eye movements, proprioceptive cues and optic flow lie on a low dimensional subspace that is a function of the depth of the target. Then, we use the generative adaptive subspace self-organizing map (GASSOM) to learn these depth-dependent subspaces. The depth of the target is eventually decoded using a winner-take-all strategy. The proposed model is validated on a simulated model of the iCub robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_06">16:15-16:16, Paper ThT31.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0712.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('712'); return false" title="Click to show or hide the keywords and abstract">AFM Measurement of the Mechanical Properties of Single Adherent Cells Based on Vibration</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#181809" title="Click to go to the Author Index">Zhang, Chuang</a></td><td class="r">Shenyang Inst. of Automation Chinese Acad. of Sciences</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183798" title="Click to go to the Author Index">Shi, Jialin</a></td><td class="r">Shenyang Inst. of Automation, Chinese Acad. of Sciences</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170243" title="Click to go to the Author Index">Wang, Wenxue</a></td><td class="r">Shenyang Inst. of Automation, CAS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100087" title="Click to go to the Author Index">Xi, Ning</a></td><td class="r">Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#108031" title="Click to go to the Author Index">Wang, Yuechao</a></td><td class="r">Shenyang Inst. of Automation</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110692" title="Click to go to the Author Index">Liu, Lianqing</a></td><td class="r">Shenyang Inst. of Automation</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab712" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biological_Applications_of_Micro_Robots" title="Click to go to the Keyword Index">Biological Applications of Micro Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a></span><br>
                           <strong>Abstract:</strong> Cellular mechanical properties as the main physical performance characteristics have been actively studied in the past years for the study of cytobiology and the development of medicine. In this study, by combining Hertz model, a novel strategy is proposed to simultaneously measure the cellular mechanical properties including cellular mass, elasticity and viscidity, based on the principle of forced vibration stimulated by simple harmonic force, with piezoelectric transducer (PZT) as vibrator and Atomic Force Microscope (AFM) as detector. The corresponding theoretical model was derived and the simulation was realized based on the proposed model. The experiments of indentations and vibrations with myoblasts and myotubes were implemented to calculate the three mechanical parameters of cells according to the proposed strategy. The results validated the proposed approach. This work would be useful for the development of cytology, medicine, previously diagnose, specific therapy and so on.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_07">16:16-16:17, Paper ThT31.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0814.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('814'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Three-Dimensional Visual Tracking and Pose Estimation in Scanning Electron Microscopes</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168389" title="Click to go to the Author Index">Cui, Le</a></td><td class="r">Bosch (China) Investment Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101938" title="Click to go to the Author Index">Marchand, Eric</a></td><td class="r">Univ. De Rennes 1, IRISA, INRIA Rennes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100627" title="Click to go to the Author Index">Haliyo, Dogan Sinan</a></td><td class="r">Univ. Pierre Et Marie Curie - Paris 6 - CNRS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100629" title="Click to go to the Author Index">Régnier, Stéphane</a></td><td class="r">Univ. Pierre Et Marie Curie</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab814" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0814.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> Visual tracking and estimation of the 3D pose of a micro/nano-object is a key issue in the development of automated manipulation tasks using a visual feedback. The 3D pose of the micro object is estimated based on a template matching algorithm. Nevertheless, a key challenge for visual tracking in a scanning electron microscope (SEM) is the difficulty to observe the motion along the depth direction. In this paper, we propose a template-based hybrid visual tracking scheme that uses luminance information to estimate the object displacement on x-y plane and uses defocus information to estimate object depth.	This approach is experimentally validated on 4 DoF-motion of a sample in a SEM.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_08">16:17-16:18, Paper ThT31.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0956.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('956'); return false" title="Click to show or hide the keywords and abstract">Model Validation of Discretized Spatial Closed Elastica</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103775" title="Click to go to the Author Index">Mochiyama, Hiromi</a></td><td class="r">Univ. of Tsukuba</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab956" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a></span><br>
                           <strong>Abstract:</strong> A closed elastica, which is an elastic rod whose both ends are fixed to prescribed two places, can be found in various situations in robotics.&#12288;In this paper, we investigate validity of the discretized spatial model of a closed elastica. The discretized closed elastica model can be regarded as a series of rigid bodies connected with passive elastic joints physically, and represented by a set of nonlinear equations derived by discretizing differential equations with boundary conditions as well as Euler equations expressing local minimum elastic energy. The validity of the considered model was studied by comparing the measured shape and the calculated shape from the model. Experimental results using a laser position sensor for shape measurement show that good correspondence between measured and calculated shapes, which supports the validity of the considered model. The constrained force and torque at the tip of an elastica, which can be obtained simultaneously associated with shape calculation, are also verified from measurement by a 6-axes force/torque sensor.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_09">16:18-16:19, Paper ThT31.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1076.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1076'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Stiffness Rendering on Soft Tangible Devices Controlled through Inverse FEM Simulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180254" title="Click to go to the Author Index">Largilliere, Frederick</a></td><td class="r">Univ. of Lille</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180262" title="Click to go to the Author Index">Coevoet, Eulalie</a></td><td class="r">INRIA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180230" title="Click to go to the Author Index">Sanz Lopez, Mario</a></td><td class="r">INRIA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162339" title="Click to go to the Author Index">Grisoni, Laurent</a></td><td class="r">Univ. of Lille</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115421" title="Click to go to the Author Index">Duriez, Christian</a></td><td class="r">INRIA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1076" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1076.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a></span><br>
                           <strong>Abstract:</strong> Haptic rendering of soft bodies is essential in medical simulations of procedures such as surgery or palpation. The most commonly used approach is to recreate the sense of touch using a specific design and control of a robotic arm. In this paper, we propose a new approach, based on soft-robotics technology. We create a tangible deformable device that allows users to &quot;touch&quot; soft tissues and perceive mechanical material properties, in a realistic manner. The device is able to dynamically provide user touch with different stiffness perceptions, thanks to actuators placed at the boundaries. We introduce a control algorithm, based on inverse Finite Element Analysis, which controls the actuators in order to recreate a desired stiffness that corresponds to the contact with soft tissues in the virtual environment. The approach uses antagonistic actuation principle to create a wide range of stiffness. We validate our algorithm and demonstrate the method using prototypes based on simple mechanisms.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_10">16:19-16:20, Paper ThT31.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1093.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1093'); return false" title="Click to show or hide the keywords and abstract">Sensor Substitution for Video-Based Action Recognition</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192513" title="Click to go to the Author Index">Rupprecht, Christian</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147137" title="Click to go to the Author Index">Lea, Colin</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123306" title="Click to go to the Author Index">Tombari, Federico</a></td><td class="r">Univ. of Bologna</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107647" title="Click to go to the Author Index">Navab, Nassir</a></td><td class="r">TU Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104128" title="Click to go to the Author Index">Hager, Gregory</a></td><td class="r">Johns Hopkins Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1093" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a></span><br>
                           <strong>Abstract:</strong> There are many applications where domain-specific sensing, such as accelerometers, kinematics, or force sensing, provide unique and important information for control or for analysis of motion. However, it is not always the case that these sensors can be deployed or accessed beyond laboratory environments. For example, it is possible to instrument humans or robots to measure motion in the laboratory in ways that it is not possible to replicate in the wild. An alternative, which we explore in this paper, is to address situations where accurate sensing is available while training an algorithm, but for which only video is available for deployment. We present two examples of this sensory substitution methodology. The first variation trains a convolutional neural network to regress a real-valued signal -- robot end-effector pose -- from video. The second example regresses binary signals detecting when specific objects are in motion. We evaluate these on the JIGSAWS dataset for robotic surgery training assessment and the 50 Salads dataset for modeling complex structured cooking tasks. We evaluate the trained models for video-based action recognition and show that the trained models provide information that is comparable to the sensory signals they replace.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_11">16:20-16:21, Paper ThT31.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1106.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1106'); return false" title="Click to show or hide the keywords and abstract">Learning Where to Search Using Visual Attention</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192010" title="Click to go to the Author Index">Kloss, Alina</a></td><td class="r">Max-Planck-Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137014" title="Click to go to the Author Index">Kappler, Daniel</a></td><td class="r">Max-Planck Inst. for Intelligent Systems</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202508" title="Click to go to the Author Index">Lensch, Hendrik Peter Asmus</a></td><td class="r">Univ. of Tuebingen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115578" title="Click to go to the Author Index">Butz, Martin Volker</a></td><td class="r">Univ. of Tuebingen</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102004" title="Click to go to the Author Index">Schaal, Stefan</a></td><td class="r">MPI Intelligent Systems & Univ. of Southern California</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116883" title="Click to go to the Author Index">Bohg, Jeannette</a></td><td class="r">Max-Planck Inst. for Intelligent Systems</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1106" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Perception_for_Grasping_and_Manipulation" title="Click to go to the Keyword Index">Perception for Grasping and Manipulation</a></span><br>
                           <strong>Abstract:</strong>  One of the central tasks for a household robot is searching for specific objects. It does not only require localizing the target object but also identifying promising search locations in the scene if the target is not immediately visible. As computation time and hardware resources are usually limited in robotics, it is desirable to avoid expensive visual processing steps that are exhaustively applied over the entire image. The human visual system can quickly select those image locations that have to be processed in detail for a given task. This allows us to cope with huge amounts of information and to efficiently deploy the limited capacities of our visual system. In this paper, we therefore propose to use human fixation data to train a top-down saliency model that predicts relevant image locations when searching for specific objects. We show that the learned model can successfully prune bounding box proposals without rejecting the ground truth object locations. In this aspect, the proposed model outperforms a model that is trained only on the ground truth segmentations of the target object instead of fixation data.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_12">16:21-16:22, Paper ThT31.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1126.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1126'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>An Energy Based Approach for Passive Dual-User Haptic Training Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179568" title="Click to go to the Author Index">Liu, Fei</a></td><td class="r">INSA De Lyon</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155126" title="Click to go to the Author Index">Lelevé, Arnaud</a></td><td class="r">INSA De Lyon (Inst. National Des Sciences Appliquees), Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179916" title="Click to go to the Author Index">Eberard, Damien</a></td><td class="r">INSA De Lyon (Inst. National Des Sciences Appliquees)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102432" title="Click to go to the Author Index">Redarce, Tanneguy</a></td><td class="r">INSA De Lyon (Inst. National Des Sciences Appliquees)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1126" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1126.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Robots_and_Systems" title="Click to go to the Keyword Index">Medical Robots and Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a></span><br>
                           <strong>Abstract:</strong> This paper introduces a new controller for dual-user training systems, designed by way of an energy based approach. Dual-user training systems are useful for supervised hands-on training when a trainer shows the right gestures to a trainee and where the forces to apply on the tools are difficult to dose. An energy shared control (ESC) based architecture is proposed, based on an intrinsically passive authority sharing mechanism which is enhanced to provide a full force feedback to both users. As this enhancement may violate the natural passivity of the system, a passivity controller is introduced. A task based comparative study with two other dual-user schemes (Complementary Linear Combination (CLC) and Masters Correspondence with Environment Transfer (MECT) from [1] is conducted, which reveals analogous performances. Real-time experiments demonstrate good tracking performances.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_13">16:22-16:23, Paper ThT31.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1257.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1257'); return false" title="Click to show or hide the keywords and abstract">Sensing the Motion of Bellows through Changes in Mutual Inductance</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171563" title="Click to go to the Author Index">Felt, Wyatt</a></td><td class="r">Univ. of Michigan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196589" title="Click to go to the Author Index">Suen, Michelle</a></td><td class="r">Univ. of Michigan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#128007" title="Click to go to the Author Index">Remy, C. David</a></td><td class="r">Univ. of Michigan</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1257" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Hydraulic_Pneumatic_Actuators" title="Click to go to the Keyword Index">Hydraulic/Pneumatic Actuators</a>, <a href="IROS16_KeywordIndexMedia.html#Smart_Actuators" title="Click to go to the Keyword Index">Smart Actuators</a></span><br>
                           <strong>Abstract:</strong> Bellows-like actuators are popular in soft robotic systems. Sensing the movement of these actuators with traditional sensors is challenging. This work proposes and tests a sensing system based on the changing mutual inductance of wire coils on bellows. A method for modeling the changes in mutual inductance between coils of tightly-packed wires is introduced. Changes in mutual inductance are measured through the self-inductance of a circuit made up of the coils in series. The self-inductance of the circuit measures the bellows bend-angle. The experiments show an approximately quadratic relationship between the bend angle and the measured inductance. From a bend angle of 121 degrees to -67 degrees the inductance of the circuit increases by 19%. The bias-inducing effects of shear strain, torsional strain, non-uniform bending, and nearby metal are also explored.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_14">16:23-16:24, Paper ThT31.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1338.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1338'); return false" title="Click to show or hide the keywords and abstract">Communication-Efficient Motion Coordination and Data Fusion in Information Gathering Teams</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137099" title="Click to go to the Author Index">Kassir, Abdallah</a></td><td class="r">Notre Dame Univ. - Louaize</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104600" title="Click to go to the Author Index">Fitch, Robert</a></td><td class="r">The Univ. of Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101702" title="Click to go to the Author Index">Sukkarieh, Salah</a></td><td class="r">Univ. of Sydney</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1338" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Communication_aware_Sensor_and_Motion_Planning" title="Click to go to the Keyword Index">Communication-aware Sensor and Motion Planning</a></span><br>
                           <strong>Abstract:</strong> Multi-robot information gathering teams typically require communication for data fusion and cooperative decision making. However, when communication takes place over wireless networks, stringent bandwidth limits apply. These limits raise the need for efficient utilisation of available communication resources in a manner that balances information gathering utility with communication costs or limits. In our previous work, we introduced the dynamic information flow (DIF) problem as a general formulation of this trade-off. We introduced two variants of the problem addressing the issue of communication efficiency for data fusion only. In this paper, we extend one of the variants to address communication efficiency for both data fusion and cooperative decision making in a synergistic manner. We present a solution to this new variant that integrates a multi-cast routing algorithm with information structure optimisation. This solution allows teams that involve high-data-rate sensors and tight coordination to respect bandwidth limits. Through several simulations we verify that our solution significantly reduces bandwidth usage of such teams while maintaining information gathering performance.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_15">16:24-16:25, Paper ThT31.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1347.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1347'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>On-Chip Automation of Sequential Flow Switching with Serially Connectable Fluidic Monostable Multivibrator</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180542" title="Click to go to the Author Index">Kang, Junsu</a></td><td class="r">Postech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196687" title="Click to go to the Author Index">Lee, Donghyeon</a></td><td class="r">Pohang Univ. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180536" title="Click to go to the Author Index">Heo, Young Jin</a></td><td class="r">POSTECH</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100095" title="Click to go to the Author Index">Chung, Wan Kyun</a></td><td class="r">POSTECH</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1347" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1347.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biological_Applications_of_Micro_Robots" title="Click to go to the Keyword Index">Biological Applications of Micro Robots</a></span><br>
                           <strong>Abstract:</strong> We propose a fluidic monostable multivibrator (fMMV) circuit, which is a new flow-switching mechanism in microfluidic chips. Flow control using parallel fMMV circuits does not require an external controller; this is a distinct advantage over various conventional micro-flow control methods. The fMMV circuit mainly consists of an inverter and an RC circuit. Each of the parts uses a microchannel as a resistor, a membrane chamber as a capacitor and a membrane valve as a transistor. The inverter acts as a trigger which opens the membrane valve and the RC circuit delays the closing of the valve, so that flow switching can occur over a time interval. A serial fMMV circuit can switch flows in multiple channels and regulate flowrates with pre-defined durations. By modifying the resistances in fMMV circuits, the flow rates and duration of each phase could be adjusted. For a proof of concept demonstration, we performed experiments using 3 parallel fMMV and 4 parallel fMMV circuit systems and these experiments show the applicability of fMMV circuit to various biochemical processes.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_16">16:25-16:26, Paper ThT31.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1352.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1352'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Keyframe-Based Online Object Learning and Detection</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150665" title="Click to go to the Author Index">Lee, Sehyung</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117882" title="Click to go to the Author Index">Lim, Jongwoo</a></td><td class="r">Hanyang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102631" title="Click to go to the Author Index">Suh, Il Hong</a></td><td class="r">Hanyang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1352" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1352.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a keyframe-based online object learning and detection method. To manage appearance changes of target objects, the proposed method incrementally updates an object database using detection results. One of the major problems in updating the appearance model is that the object model can gradually be degraded by accumulated errors and biased to specific views. To solve this problem, our object model is updated according to the selected keyframes, which not only help memorize important views of target objects, but also prevent the holistic appearance model from overfitting. The database is represented as a graph of the registered images, and the importance of the database images is measured by analyzing the constructed graph. Then, the redundant or less important images are discarded from the database. As a result, the database is efficiently maintained while new views of the objects are gradually added. The experimental results demonstrate that the proposed algorithm efficiently maintains the object database and improves the detection performance compared to previous incremental object learning and detection algorithms.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_17">16:26-16:27, Paper ThT31.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1376.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1376'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Development of a Magnetic Nanoparticles Guidance System for Interleaved Actuation and MPI-Based Monitoring</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193070" title="Click to go to the Author Index">Zhang, Xingming</a></td><td class="r">School of Mechanical Engineering Gyeongsang National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193071" title="Click to go to the Author Index">Lê, Tu&#7845;n Anh</a></td><td class="r">School of Mechanical Engineering Gyeongsang National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106386" title="Click to go to the Author Index">Yoon, Jungwon</a></td><td class="r">Gyeongsang National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1376" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1376.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a></span><br>
                           <strong>Abstract:</strong> Targeted drug delivery by using magnetic nanoparticles (MNPs) is an efficient technique to deliver drug molecules towards specific tissues in a human body. The MNPs’ 1D guidance system is a combined electromagnetic actuation (EMA) and monitoring system, which can provide an accurate control scheme with nanoparticle’s localization for more precise targeting of the drug delivery. The localization of the MNPs is done by magnetic particle imaging (MPI) with low amplitude excitation field. In this paper, we have developed a novel coil topology for 1D MNPs feedback control, by alternate supply of different currents to coils set in time sequence, the coil set alternates functions between MPI and EMA. Motion of MNPs is controlled by a gradient of the magnetic field in EMA period, the distribution of MNPs is reconstructed in MPI period and provides feedback to the EMA. The guidance system will provide navigation and tracking interleaved for targeted drug delivery of MNPs in compact and efficient ways. The 1D MNPs guidance system has 2Hz of EMA and MPI hybrid frequency, allowing a position control of MNPs with 90nm diameter.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_18">16:27-16:28, Paper ThT31.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1444.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1444'); return false" title="Click to show or hide the keywords and abstract">Nanorobot Enabled in Situ Sensing Molecular Interactions for Drug Discovery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190621" title="Click to go to the Author Index">Yang, Yongliang</a></td><td class="r">Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100087" title="Click to go to the Author Index">Xi, Ning</a></td><td class="r">Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146453" title="Click to go to the Author Index">Sun, Zhiyong</a></td><td class="r">Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#173783" title="Click to go to the Author Index">Basson, Marc</a></td><td class="r">Department of Surgery, Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192491" title="Click to go to the Author Index">Zeng, Bixi</a></td><td class="r">Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#139303" title="Click to go to the Author Index">Song, Bo</a></td><td class="r">Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166462" title="Click to go to the Author Index">Chen, Liangliang</a></td><td class="r">Michigan State Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192498" title="Click to go to the Author Index">Zhou, Zhanxin</a></td><td class="r">Michigan State Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1444" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Cellular_and_Modular_Robots" title="Click to go to the Keyword Index">Cellular and Modular Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a></span><br>
                           <strong>Abstract:</strong> Nanorobot has the potential to automate the manipulation and observation processes at molecular scale. Current drug discovery process is labor and cost intensive.	Thus, a strong demand exists to automate this process.	Here, we developed an Atomic Force Microscopy (AFM) based nanorobot for in situ sensing molecular interactions for drug discovery. The AFM tip and sample substrate are functionalized by the molecules of interest. Via measuring the interactive binding forces between these two molecules using the AFM based nanorobot, we are able to test the effectiveness of drug candidates on attenuating or enhancing the molecular interactions involved in cell signaling pathways. To measure the single molecular interactions precisely, we developed a new substrate coating method. The new method functionalizes the substrate much more evenly compared with the previous method. We further optimized settings during measuring the interactive binding force, such as coating with bovine serum albumin (BSA) and the level of indentation of AFM tip onto the substrate. With these developments, this nanorobot measures single molecular interactions automated. We further used this nanorobot to test a small peptide, which was designed to attenuate the interactive binding force between focal adhesion kinase (FAK) and protein kinase B (AKT), two molecules involved in cell adhesion.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_19">16:28-16:29, Paper ThT31.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1470.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1470'); return false" title="Click to show or hide the keywords and abstract">A Hardware-In-The-Loop Simulator for Safety Training in Robotic Surgery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195566" title="Click to go to the Author Index">Li, Xiao</a></td><td class="r">Univ. of Illinois at Urbana-Champaign</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196668" title="Click to go to the Author Index">Alemzadeh, Homa</a></td><td class="r">Univ. of Illinois at Urbana-Champaign</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196671" title="Click to go to the Author Index">Chen, Daniel</a></td><td class="r">Univ. of Illinois at Urbana-Champaign</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196674" title="Click to go to the Author Index">Kalbarczyk, Zbigniew</a></td><td class="r">Univ. of Illinois at Urbana-Champaign</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196675" title="Click to go to the Author Index">Iyer, Ravishankar</a></td><td class="r">Univ. of Illinois at Urbana-Champaign</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196676" title="Click to go to the Author Index">Kesavadas, Thenkurussi</a></td><td class="r">Univ. of Illinois at Urbana-Champaign</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1470" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Safety" title="Click to go to the Keyword Index">Robot Safety</a>, <a href="IROS16_KeywordIndexMedia.html#Haptics_and_Haptic_Interfaces" title="Click to go to the Keyword Index">Haptics and Haptic Interfaces</a></span><br>
                           <strong>Abstract:</strong> This paper presents a simulation-based safety training simulator for robot assisted surgery. While adverse events occur rarely during training, they could be fatal to the patients if they happen during real surgical procedures and are not handled properly by the surgical team. In this work we propose a hardware-in-the-loop robotic surgery simulator with high fidelity of the robot motion in a simulated environment, which is capable of reproducing adverse events during surgery. The proposed simulator is built upon the Raven-II open source surgical robot, integrated with a simulated surgeon console and a safety hazard injection engine, which automatically injects faults into modules of the robot control software. We simulate representative safety hazards seen in the adverse events, related to da Vinci robot, reported to the FDA MAUDE database. A novel haptic feedback strategy is provided to the operator when the underlying dynamics differ from the real robot states.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_20">16:29-16:30, Paper ThT31.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1520.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1520'); return false" title="Click to show or hide the keywords and abstract">Voltage/frequency Rate Dependent Modeling for Nano-Robotic Systems Based on Piezoelectric Stick-Slip Actuators</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184877" title="Click to go to the Author Index">Boudaoud, Mokrane</a></td><td class="r">Univ. Pierre Et Marie Curie</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196330" title="Click to go to the Author Index">Liang, Shuai</a></td><td class="r">Pierre and Marie Curie Univ. the Inst. for Intelligent</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184880" title="Click to go to the Author Index">Lu, Tianming</a></td><td class="r">Univ. Pierre Et Marie Curie</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#202413" title="Click to go to the Author Index">Oubellil, Raouia</a></td><td class="r">GIPSA Lab</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100629" title="Click to go to the Author Index">Régnier, Stéphane</a></td><td class="r">Univ. Pierre Et Marie Curie</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1520" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#New_Actuators" title="Click to go to the Keyword Index">New Actuators</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> In order to define trajectory-tracking strategies for nano-robotic systems using piezoelectric stick-slip actuators, the dynamics of the elementary actuator must be studied and well modeled. The modeling of this class of actuators is complex because several nonlinear parameters are involved. In this paper, we propose a systematic modeling methodology of piezoelectric stick-slip actuators for nano-robotic systems control. The main idea is the proposition of an augmented voltage/frequency rate dependent modeling of the friction force based on a multi-state elasto-plastic formulation. Experimental and simulation results demonstrate the efficiency of the model in the time and the frequency domains. As a case of study, the proposed model is used to define a control strategy in order to detect collisions when the nano-robotic system is operating inside a Scanning Electron Microscope (SEM). This application demonstrates the need of a voltage/frequency rate dependent modeling.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_21">16:30-16:31, Paper ThT31.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1541.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1541'); return false" title="Click to show or hide the keywords and abstract">Encoding Human Actions with a Frequency Domain Approach</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196813" title="Click to go to the Author Index">Shah, Dharmil</a></td><td class="r">Tech. Univ. of Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134969" title="Click to go to the Author Index">Falco, Pietro</a></td><td class="r">Tech. Univ. of Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154562" title="Click to go to the Author Index">Saveriano, Matteo</a></td><td class="r">Tech. Univ. of Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104647" title="Click to go to the Author Index">Lee, Dongheui</a></td><td class="r">Tech. Univ. of Munich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1541" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Gesture__Posture__Social_Spaces_and_Facial_Expressions" title="Click to go to the Keyword Index">Gesture, Posture, Social Spaces and Facial Expressions</a>, <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a></span><br>
                           <strong>Abstract:</strong> In this work, we propose a Frequency-based Action Descriptor (FADE) to represent human actions. In robotics, with the development of Programming by Demonstration (PbD) methods, representing and recognizing large sets of actions has become crucial to build autonomous systems that learn from humans. The FADE descriptor leverages Fast Fourier Transform (FFT) for action representation and is combined with the Manhattan distance for measuring similarities between actions. It is characterized by a low time and space complexity and is particularly suitable for classification of human actions. For clustering problems, we propose a modified version of FADE, called Uncompressed-FADE (U-FADE), which performs well in combination with Spectral Clustering algorithms at the price of a reduced compression. We compare FADE with action descriptors based on Singular Value Decomposition (SVD) and Hidden Markov Models (HMM) on the entire HDM05 motion capture database. Despite the high dimensionality of the problem, we obtained on the entire database a promising recognition rate of 78% combining FADE with a simple 1-NN classification algorithm. Furthermore, we achieved a rate of 98% on a small action set and 88% on a medium action set.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_22">16:31-16:32, Paper ThT31.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1576.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1576'); return false" title="Click to show or hide the keywords and abstract">Affordance-Based Active Belief: Recognition Using Visual and Manual Actions</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#118732" title="Click to go to the Author Index">Ruiken, Dirk</a></td><td class="r">Univ. of Massachusetts</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180394" title="Click to go to the Author Index">Wong, Jay Ming</a></td><td class="r">Univ. of Massachusetts Amherst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167964" title="Click to go to the Author Index">Liu, Tiffany Q.</a></td><td class="r">Univ. of Massachusetts Amherst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180396" title="Click to go to the Author Index">Hebert, Mitchell</a></td><td class="r">Univ. of Massachusetts Amherst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167958" title="Click to go to the Author Index">Takahashi, Takeshi</a></td><td class="r">Univ. of Massachusetts, Amherst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#166223" title="Click to go to the Author Index">Lanighan, Michael</a></td><td class="r">Univ. of Massachusetts Amherst</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101349" title="Click to go to the Author Index">Grupen, Rod</a></td><td class="r">Univ. of Massachusetts</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1576" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Recognition" title="Click to go to the Keyword Index">Recognition</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> This paper presents an active, model-based recognition system. It applies information theoretic measures in a belief-driven planning framework to recognize objects using the history of visual and manual interactions and to select the most informative actions. A generalization of the aspect graph is used to construct forward models of objects that account for visual transitions. We use populations of these models to define the belief state of the recognition problem. This paper focuses on the impact of the belief-space and object model representations on recognition efficiency and performance. A benchmarking system is introduced to execute controlled experiments in a challenging mobile manipulation domain. It offers a large population of objects that remain ambiguous from single sensor geometry or from visual or manual actions alone. Results are presented for recognition performance on this dataset using locomotive, pushing, and lifting controllers as the basis for active information gathering on single objects. An information theoretic approach that is greedy over the expected information gain is used to select informative actions, and its performance is compared to a sequence of random actions.	
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht31_23">16:32-16:33, Paper ThT31.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1600.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1600'); return false" title="Click to show or hide the keywords and abstract">Automated Pick-Up of Carbon Nanotubes Inside a Scanning Electron Microscope</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195621" title="Click to go to the Author Index">Guo, Yana</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132932" title="Click to go to the Author Index">Shi, Qing</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#147873" title="Click to go to the Author Index">Yang, Zhan</a></td><td class="r">Soochow Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149167" title="Click to go to the Author Index">Wang, Huaping</a></td><td class="r">Beijig Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184162" title="Click to go to the Author Index">Yu, Ning</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101086" title="Click to go to the Author Index">Lining, Sun</a></td><td class="r">Harbin Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100171" title="Click to go to the Author Index">Huang, Qiang</a></td><td class="r">Beijing Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101162" title="Click to go to the Author Index">Fukuda, Toshio</a></td><td class="r">Meijo Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1600" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Manipulation_and_Compliant_Assembly" title="Click to go to the Keyword Index">Manipulation and Compliant Assembly</a>, <a href="IROS16_KeywordIndexMedia.html#Formal_Methods_in_Robotics_and_Automation" title="Click to go to the Keyword Index">Formal Methods in Robotics and Automation</a></span><br>
                           <strong>Abstract:</strong> It is of great importance to pick up a single carbon nanotube (CNT) from a bulk of CNTs for nanodevice fabrication. In this study, we have proposed a nanorobotic ma-nipulation system allowing automated pick-up of CNTs based on visual feedback. We utilize histogram normalization for au-tomatic binarization, and it achieves to clearly distinguish CNTs from substrate and other impurities under different image brightness. Furthermore, we develop the gradient orientation inversion (GOI) algorithm to recognize CNT tip and atomic force microscopy (AFM) cantilever. Taking full advantages of the geometrical characteristics of CNT and AFM cantilever, GOI is proved to be quite robust. We have designed segment detection method (SDM) to successfully separate the AFM cantilever and CNT, whereas the contact detection be-tween them is achieved by analyzing the straightness var-iation. Preliminary experimental results imply that our method shows high promise in realistic fabrication of nanodevices.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="tht32"><b>ThT32</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#tht32" title="Click to go to the Program at a Glance"><b>Robot Control and Planning</b></a></td>
               <td class="r">Teaser Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104857" title="Click to go to the Author Index">Dolan, John M.</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#172127" title="Click to go to the Author Index">De Stefano, Marco</a></td><td class="r">DLR - German Aerospace Center</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_01">16:10-16:11, Paper ThT32.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0024.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('24'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Reactive Stepping Algorithm Based on Preview Controller with Observer for Biped Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#149525" title="Click to go to the Author Index">Urbann, Oliver</a></td><td class="r">TU Dortmund Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170807" title="Click to go to the Author Index">Hofmann, Matthias</a></td><td class="r">Robotics Res. Inst. TU Dortmund Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab24" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0024.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> Reactive stepping is an important utility to regain balance when bipedal walking motions are disturbed. This paper sheds light on the reasons for humanoid robots to fall down. It presents a method to calculate modifications of predefined foot placements with the objective to minimize deviations of the Zero Moment Point from a reference without interrupting the walk. The calculation is in closed-form, and is embedded into a well-evaluated preview controller with observer based on the 3D Linear Inverted Pendulum Mode (3D-LIPM). Experiments in simulation and on a physical robot prove the benefit of the proposed system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_02">16:11-16:12, Paper ThT32.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0214.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('214'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Continuous-Time Trajectory Optimization for Online UAV Replanning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151594" title="Click to go to the Author Index">Oleynikova, Helen</a></td><td class="r">ETH Zürich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168414" title="Click to go to the Author Index">Burri, Michael</a></td><td class="r">ETH Zuerich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159722" title="Click to go to the Author Index">Taylor, Zachary Jeremy</a></td><td class="r">Univ. of Sydney, Australian Centre for Field Robotics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101699" title="Click to go to the Author Index">Nieto, Juan</a></td><td class="r">ETH Zürich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100088" title="Click to go to the Author Index">Siegwart, Roland</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132521" title="Click to go to the Author Index">Galceran, Enric</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab214" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0214.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> Multirotor unmanned aerial vehicles (UAVs) are rapidly gaining popularity for many applications. However, safe operation in partially unknown, unstructured environments remains an open question. In this paper, we present a continuous-time trajectory optimization method for real-time collision avoidance on UAVs. We then propose a system where this motion planning method is used as a local replanner, and runs at a high rate to continuously recompute safe trajectories as the multicopter gains information about its environment. We validate our approach by comparing against existing methods and demonstrate the complete system avoiding obstacles on a multicopter platform.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_03">16:12-16:13, Paper ThT32.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0255.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('255'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Planning and Control of Biped Robots with Upper Body</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#130873" title="Click to go to the Author Index">Luo, Xiang</a></td><td class="r">Southeast Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113157" title="Click to go to the Author Index">Xia, Dan</a></td><td class="r">Southeast Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115174" title="Click to go to the Author Index">Zhu, Chi</a></td><td class="r">Maebashi Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab255" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0255.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> the principle and control method of torso orientation in dynamic biped walking is addressed. First, the role of torso motion in walking performance, especially at the landing moment, is investigated by using a simplified model. Second, a control strategy of torso orientation is proposed, including the algorithms in the push-off and the single support phases (SSP). Furthermore, the module of torso control is integrated into the control method of dynamic biped walking, which was proposed in our previous research. The paper ends with the simulation of a humanoid robot with 21 internal degrees of freedom (DOF), and shows the feasibility of the proposed method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_04">16:13-16:14, Paper ThT32.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0310.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('310'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Distributed Deformable Configuration Control for Multi-Robot Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117489" title="Click to go to the Author Index">Lee, Seoung Kyou</a></td><td class="r">The Univ. of Texas Health Science Center at Houston</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107307" title="Click to go to the Author Index">McLurkin, James</a></td><td class="r">Rice Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177092" title="Click to go to the Author Index">Shin, Dongsuk</a></td><td class="r">The Univ. of Texas Health Medical School at Houston</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177073" title="Click to go to the Author Index">Jang, Taeho</a></td><td class="r">Univ. of Texas Health Science Center at Houston</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177099" title="Click to go to the Author Index">Kim, Daniel</a></td><td class="r">The Univ. of Texas Health Medical School at Houston</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab310" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0310.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Networks" title="Click to go to the Keyword Index">Sensor Networks</a></span><br>
                           <strong>Abstract:</strong>  In this paper, we present deformable configuration control — a fully distributed algorithm that allows multiple robots to deform their configuration to avoid various shapes of obstacles while maintaining connectivity. Robots contacted with an obstacle first estimate the width of an obstacle by sharing bumped status of individual robots, and choose an appropriate obstacle avoidance scenarios between obstacle detouring and bouncing off a wall. Second, for both scenarios, robots switch their motion model to a parent following motion to avoid the obstacle. Finally, robots keep sensing the maximum tree angle to estimate whether they are completely escaped from the obstacle, and return to flock formation motion model. We provide theoretical analysis about maintaining connectivity while robots are avoiding an obstacle. Simulation results show a group of 36 robots successfully avoid three different kinds of obstacles including 1) a small bar, 2) a narrow corridor, and 3) a large wall while maintaining connectivity.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_05">16:14-16:15, Paper ThT32.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0342.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('342'); return false" title="Click to show or hide the keywords and abstract">Learning Cooperative Primitives with Physical Human-Robot Interaction for a Human-Powered Lower Exoskeleton</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183121" title="Click to go to the Author Index">Huang, Rui</a></td><td class="r">Univ. of Electronic Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159479" title="Click to go to the Author Index">Cheng, Hong</a></td><td class="r">Univ. of Electronic Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117756" title="Click to go to the Author Index">Guo, Hongliang</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#120883" title="Click to go to the Author Index">Lin, Xichuan</a></td><td class="r">Univ. of Electronic Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183135" title="Click to go to the Author Index">Chen, Qiming</a></td><td class="r">Univ. of Electronic Science and Tech. of China</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134089" title="Click to go to the Author Index">Sun, Fuchun</a></td><td class="r">Tsinghua Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab342" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Human-powered lower exoskeletons have gained considerable interests from both academia and industry over the past few decades, and thus have seen increasing applications in areas of human locomotion assistance and strength augmentation. One of the most important aspects in those applications is to achieve robust control of lower exoskeletons, which, in the first place, requires the proactive modeling of human movement trajectories through physical Human-Robot Interaction (pHRI). As a powerful representation tool for motion trajectories, Dynamic Movement Primitive (DMPs) has been used extensively to model human movement trajectories. However, canonical DMPs only offers a general offline representation of human movement trajectory and neglects the real-time interaction term, therefore it cannot be directly applied to lower exoskeletons which need to model human motion trajectories online since different pilots have different trajectories and even one pilot might change his/her intended trajectory during walking. This paper presents a novel Coupled Cooperative Primitives (CCPs) scheme, which models the motion trajectories online. Besides maintaining canonical motion primitives, we also model the interaction term between the pilot and exoskeletons through impedance models and apply a reinforcement learning method based on Policy Improvement and Path Integrals (PI^2) to learn the parameters online. Experimental results on both a single degree-of-freedom (DOF) platform and a HUman-powered Augmentation Lower Exoskeleton (HUALEX) system demonstrate the advantages of our proposed CCP scheme.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_06">16:15-16:16, Paper ThT32.6</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0345.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('345'); return false" title="Click to show or hide the keywords and abstract">Trajectory Tracking Control of an Omnidirectional Mobile Robot with Friction Compensation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157863" title="Click to go to the Author Index">Ren, Chao</a></td><td class="r">Tianjin Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100170" title="Click to go to the Author Index">Ma, Shugen</a></td><td class="r">Tianjin Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab345" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> This paper presents and discusses the trajectory tracking control design with friction compensation for a three wheeled omnidirectional mobile robot. Firstly, a dynamic model without considering the friction forces is derived. Part of the control effort is used to compensate the friction effects, which is estimated by an extended state observer without using a friction model. Then traditional resolved acceleration control is applied to the robot, based on the derived dynamic model. In addition, stability analysis of the controller and observer is presented. Experimental results show that the proposed control design is efficient in compensating the friction effects and in improving the tracking control performances.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_07">16:16-16:17, Paper ThT32.7</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0391.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('391'); return false" title="Click to show or hide the keywords and abstract">Robust Impedance Control with Applications to a Series-Elastic Actuated System</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#152432" title="Click to go to the Author Index">Haninger, Kevin</a></td><td class="r">UC Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168425" title="Click to go to the Author Index">Lu, Junkai</a></td><td class="r">Univ. of California, Berkeley</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100071" title="Click to go to the Author Index">Tomizuka, Masayoshi</a></td><td class="r">Univ. of California</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab391" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a>, <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Impedance control offers a theoretical basis for safe interaction between a robot and the environment, but model uncertainty, disturbances and actuation dynamics can compromise the accuracy of the rendered impedance in implementation. If both the interactive force and motion are directly sensed, the relationship between them can be robustly regulated to present the desired impedance dynamics. In this paper, a Disturbance Observer based controller architecture is presented which offers performance robustness for impedance control. Conditions for stability and passivity are developed, then this controller is analyzed on a series-elastic actuated system. The effect of actuation dynamics on both performance and stability is analyzed, then experimental results are presented.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_08">16:17-16:18, Paper ThT32.8</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0474.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('474'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Robust Dynamic Walking Using Online Foot Step Optimization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132354" title="Click to go to the Author Index">Feng, Siyuan</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155949" title="Click to go to the Author Index">Xinjilefu, X</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101843" title="Click to go to the Author Index">Atkeson, Christopher</a></td><td class="r">CMU</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150747" title="Click to go to the Author Index">Kim, Joohyung</a></td><td class="r">Disney Res</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab474" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0474.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> To enable robust dynamic walking on the Atlas robot, we extend our previous work by adding a receding- horizon component. The new controller consists of three hierarchies: a center of mass (CoM) trajectory planner that follows a sequence of desired foot steps, a receding-horizon controller that optimizes the next foot placement to minimize future CoM tracking errors, and an inverse dynamics based full body controller that generates instantaneous joint commands to track these motions while obeying physical constraints. An approximate value function is generated by the CoM planner, and is used to guide the foot placement and inverse dynamics optimizations. The proposed controller is implemented and tested on the Atlas robot. It is capable of walking with strong external perturbations such as recovering from large pushes and traversing unstructured terrain.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_09">16:18-16:19, Paper ThT32.9</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0709.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('709'); return false" title="Click to show or hide the keywords and abstract">Dynamic Surface Control-Based Stabilization of an N^th Chained Systems with Application to a Car-Like Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196137" title="Click to go to the Author Index">Tchenderli-Braham, Smain Azzeddine</a></td><td class="r">Centre for Development of Advanced Tech. (CDTA)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab709" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a></span><br>
                           <strong>Abstract:</strong> This work aims to design a Dynamic Surface Controller (DSC) in order to stabilize the n^th order chained systems able to express several kinds of nonholonomic, nonlinear and underactuated systems as unicycle, car-like, be-steerable car, car with trailer, etc. These latter are difficult to handle because of the complexity of their kinematic model. We purpose the use of the DSC in order to avoid the explosion of terms yielded by the backstepping algorithm and leading to compute the high order derivatives of variables. From the Lyapunov stability analysis, we prove that the designed controls render the closed loop system ultimately Uniformly Bounded (UUB). The applicability and the effectiveness of the control method are shown through simulation results when applying the control method on a car-like robot expressed by a fourth order chained system.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_10">16:19-16:20, Paper ThT32.10</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0765.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('765'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Disturbance Compensation and Step Optimization for Push Recovery</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188443" title="Click to go to the Author Index">Griffin, Robert J.</a></td><td class="r">Virginia Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#136444" title="Click to go to the Author Index">Leonessa, Alexander</a></td><td class="r">Virginia Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123799" title="Click to go to the Author Index">Asbeck, Alan</a></td><td class="r">Virginia Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab765" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0765.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a></span><br>
                           <strong>Abstract:</strong> To operate in human environments, robots must be able to withstand external disturbances. Small disturbances can be stabilized through momentum regulation, but larger ones require steps to prevent falling. This work presents two new techniques for disturbance rejection. The first is an extension of divergent component of motion (DCM) and capture point tracking controllers that augments a PI feedback control law with a disturbance observer. This is used to estimate transient disturbances through momentum-rate-of-change error. For larger disturbances, we present a novel optimization-based framework based on the DCM dynamics that uses a quadratic program to compute the desired ground reaction forces and recovery step location. Using optimization gives a flexibility that enables planning angular momentum-rate-of-change trajectories to help reduce recovery step length. We then illustrate the effectiveness of these methods with hardware and simulation experiments on the compliant THOR humanoid.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_11">16:20-16:21, Paper ThT32.11</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0787.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('787'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Analytical Investigation of the Stabilizing Function of the Musculoskeletal System Using Lyapunov Stability Criteria and Its Robotic Applications</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#174549" title="Click to go to the Author Index">Chang, Handdeut</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162888" title="Click to go to the Author Index">Kim, Sangjoon J.</a></td><td class="r">KAIST</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115549" title="Click to go to the Author Index">Kim, Jung</a></td><td class="r">KAIST</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab787" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0787.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Variable_Stiffness_Actuator_Design_and_Control" title="Click to go to the Keyword Index">Variable Stiffness Actuator Design and Control</a></span><br>
                           <strong>Abstract:</strong> The stabilization of the man-made dynamic systems has been achieved by sensor based state feedback control algorithms which require high computational bandwidth and high stiffness structures. However, many biological systems achieved similar or superior stable behavior with low speed signal transmission via nervous systems, which is easy to introduce unstable performance in the view of control engineering. In order to explain this phenomenon, the concept of selfstabilization has been recently proposed and investigated widely. Self-stabilization is defined as the ability to restore its original state after a disturbance without any feedback control. We analytically investigated the stabilizing function of a musculoskeletal system using the Lyapunov stability theory. Based on this investigation, in this study, we propose a design method to realize the self-stabilizing function of a musculoskeletal system, and experimentally verify that the self-stabilizing function can be physically realized and explained by the proposed Lyapunov function.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_12">16:21-16:22, Paper ThT32.12</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0863.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('863'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Mixed-Integer Programming for Automatic Walking Step Duration</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196327" title="Click to go to the Author Index">Maximo, Marcos Ricardo Omena de Albuquerque</a></td><td class="r">Aeronautics Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142190" title="Click to go to the Author Index">Ribeiro, Carlos Henrique Costa</a></td><td class="r">Tech. Inst. of Aeronautics</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196342" title="Click to go to the Author Index">Afonso, Rubens</a></td><td class="r">Aeronautics Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab863" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0863.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a></span><br>
                           <strong>Abstract:</strong> This paper presents a mixed-integer model predictive controller for walking. In the proposed scheme, mixed-integer quadratic programs (MIQP) are solved online to simultaneously decide center of mass jerks, footsteps positions and steps durations while respecting actuation, geometry, and contact constraints. Simulation results show that this MIQP scheme is able to keep balance while a fixed step duration controller fails in situations where the robot faces very strong disturbances.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_13">16:22-16:23, Paper ThT32.13</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0881.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('881'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Stabilization of a Compliant Humanoid Robot Using Only Inertial Measurement Units with a Viscoelastic Reaction Mass Pendulum Model</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172449" title="Click to go to the Author Index">Mifsud, Alexis</a></td><td class="r">LAAS-CNRS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#122563" title="Click to go to the Author Index">Benallegue, Mehdi</a></td><td class="r">Laas / Cnrs</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101933" title="Click to go to the Author Index">Lamiraux, Florent</a></td><td class="r">CNRS</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab881" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0881.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Underactuated_Robots" title="Click to go to the Keyword Index">Underactuated Robots</a></span><br>
                           <strong>Abstract:</strong> To guarantee its balance, a humanoid robot has to respect some contact force constraints. Therefore, traditional controllers generate motions complying with these constraints, but they usually consider the robot as stiff and the joint position perfectly known. However, several robots contain compliant parts in their structure. This flexibility modifies the forces at contacts and endangers balance. However, most solutions to stabilize the robot rely on force sensors. But several humanoid robots aren’t equipped with these sensors. This paper has two aims. The first one is to develop a compliance stabilizer using the center of mass position and upper-body orientation through a viscoelastic reaction mass pendulum model. The second objective is to show the performances of such a stabilizer when relying only on an IMU-based state observer. Experimental results on HRP-2 robot show that the stabilization successfully rejects perturbations with high gains using only these IMU signals. Moreover, the actuation of the upper-body orientation provides redundancy, robustness and finally improved performances to the stabilizer.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_14">16:23-16:24, Paper ThT32.14</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0898.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('898'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Using Language Models to Generate Whole-Body Multi-Contact Motions</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#176929" title="Click to go to the Author Index">Mandery, Christian</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114026" title="Click to go to the Author Index">Borras Sol, Julia</a></td><td class="r">Karlsruhe Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179577" title="Click to go to the Author Index">Jöchner, Mirjam</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102922" title="Click to go to the Author Index">Asfour, Tamim</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab898" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0898.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a></span><br>
                           <strong>Abstract:</strong> We present a novel approach for generating sequences of whole-body poses with multi-contacts for humanoid robots, which is inspired by techniques from natural language processing. To this end, we propose a probabilistic n-gram language model learned from observation of human locomotion tasks. Human motion data is automatically segmented according to detected contacts of the body with the environment to provide support, that is, support poses, which are further subdivided with regard to whole-body configuration. These poses are subsequently used to train a language model, whose words are the poses, and whose sentences represent sequences of poses. Then, we propose a planning algorithm that, given the constraints imposed by a task, finds the sequence of transitions with the highest probability according to our language model. We have applied our approach to 140 motion capture recordings of locomotion tasks that involve using one or both hands for support. The evaluation demonstrates that our approach is able to generate complex sets of pose transitions, and shows promising results regarding its application to more complex tasks.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_15">16:24-16:25, Paper ThT32.15</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0913.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('913'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>An Optimized Passivity-Based Method for Simulating Satellite Dynamics on a Position Controlled Robot in Presence of Latencies</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172127" title="Click to go to the Author Index">De Stefano, Marco</a></td><td class="r">DLR - German Aerospace Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111257" title="Click to go to the Author Index">Artigas, Jordi</a></td><td class="r">DLR - German Aerospace Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110186" title="Click to go to the Author Index">Secchi, Cristian</a></td><td class="r">Univ. of Modena & Reggio Emilia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab913" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0913.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a>, <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a></span><br>
                           <strong>Abstract:</strong> This paper introduces a performance oriented method for simulating stable free floating satellite dynamics on a position controlled robot. Intrinsic latencies found in robot controllers, i.e. between input and output data, are known to produce stability issues and performance degradation. These issues are even more apparent during contact phases, where impact dynamics play a major role. The approach presented in this paper guarantees stability through passivity and preserves the performance through the use of an optimal damping. The energy produced by delays found in the closed loop system is monitored and dissipated when necessary. In order to implement the dynamics accurately, the necessary damping is formulated as an optimization problem. Thus, over-dissipation can be avoided and the system becomes less conservative. Performance and effectiveness of the method are shown in simulation and verified experimentally on a position controlled seven degrees of freedom Light Weight Robot equipped with a force-torque sensor at the end-effector.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_16">16:25-16:26, Paper ThT32.16</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1045.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1045'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Preliminary Experiments with a Unified Controller for a Powered Knee-Ankle Prosthetic Leg across Walking Speeds</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180619" title="Click to go to the Author Index">Quintero, David</a></td><td class="r">Univ. of Texas at Dallas</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179050" title="Click to go to the Author Index">Villarreal, Dario J.</a></td><td class="r">Univ. of Texas at Dallas</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#127261" title="Click to go to the Author Index">Gregg, Robert D.</a></td><td class="r">Univ. of Texas at Dallas</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1045" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1045.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Centered_Robotics" title="Click to go to the Keyword Index">Human Centered Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a></span><br>
                           <strong>Abstract:</strong> This paper presents the experimental validation of a novel control strategy that unifies the entire gait cycle of a powered knee-ankle prosthetic leg without the need to switch between controllers for different periods of gait. Current control methods divide the gait cycle into several sequential periods each with independent controllers, resulting in many patient-specific control parameters and switching rules that must be tuned for a specific walking speed. The single controller presented is speed-invariant with a minimal number of control parameters to be tuned. A single, periodic virtual constraint is derived that exactly characterizes the desired actuated joint motion as a function of a mechanical phase variable across walking cycles. A single sensor was used to compute a phase variable related to the residual thigh angle’s phase plane, which was recently shown to robustly represent the phase of non-steady human gait. This phase variable allows the prosthesis to synchronize naturally with the human user for intuitive, biomimetic behavior. A custom powered knee-ankle prosthesis was designed and built to implement the control strategy and validate its performance. A human subject experiment was conducted across multiple walking speeds (1 to 3 miles/hour) in a continuous sequence with the single phase-based controller, demonstrating its adaptability to the user’s intended speed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_17">16:26-16:27, Paper ThT32.17</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1108.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1108'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Low Complex Sensor-Based Shared Control for Power Wheelchair Navigation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196460" title="Click to go to the Author Index">Devigne, Louise</a></td><td class="r">IRISA UMR CNRS 6074 - INRIA - INSA Rennes - Rehabilitation Cente</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171960" title="Click to go to the Author Index">K. Narayanan, Vishnu</a></td><td class="r">Inria Rennes, INSA Rennes</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160354" title="Click to go to the Author Index">Pasteau, François</a></td><td class="r">INSA Rennes / IRISA Lagadic Team / IETR</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#154230" title="Click to go to the Author Index">Babel, Marie</a></td><td class="r">IRISA UMR CNRS 6074 - INRIA - INSA Rennes</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1108" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1108.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Collision_Detection_and_Avoidance" title="Click to go to the Keyword Index">Collision Detection and Avoidance</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a></span><br>
                           <strong>Abstract:</strong> Motor or visual impairments may prevent a user from steering a wheelchair effectively in indoor environments. In such cases, joystick jerks arising from uncontrolled motions may lead to collisions with obstacles. We here propose a perceptive shared control system that progressively corrects the trajectory as a user manually drives the wheelchair, by means of a sensor-based shared control law capable of smoothly avoiding obstacles. This control law is based on a low complex optimization framework validated through simulations and extensive clinical trials. The provided model uses distance information. Therefore, for low-cost considerations, we use ultrasonic sensors to measure the distances around the wheelchair. The solution therefore provides an efficient assistive tool that does not alter the quality of experience perceived by the user, while ensuring his security in hazardous situations.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_18">16:27-16:28, Paper ThT32.18</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1114.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1114'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Coordination of Monopedal SLIP Models towards Quadrupedal Running</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164483" title="Click to go to the Author Index">Shahbazi Aghbelagh, Mohammad</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#118853" title="Click to go to the Author Index">Lopes, Gabriel</a></td><td class="r">Delft Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1114" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1114.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a></span><br>
                           <strong>Abstract:</strong> This paper presents a coordination controller for the Dual-SLIP model, a novel template for quadrupedal steady and transitional running. The model consists of a pair of “physically-unconnected” Spring-Loaded Inverted Pendulums (SLIPs), each representing a part of the body of a quadruped (see Figure 1). For this model, we propose a spatio-temporal coordination controller that describes the evolution of coordination parameters by simple difference equations. A “time-aware” deadbeat low-level controller is also proposed to realizing the generated control specifications in each SLIP individually. Evaluation of the proposed coordination controller for the Dual-SLIP model in simulation shows that even with remarkably off-phase initial conditions and ground height variation disturbances, quadrupedal bounding, pronking and different transitions between them can be realized.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_19">16:28-16:29, Paper ThT32.19</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1150.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1150'); return false" title="Click to show or hide the keywords and abstract">Identification of Fully Physical Consistent Inertial Parameters Using Optimization on Manifolds</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167320" title="Click to go to the Author Index">Traversaro, Silvio</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165859" title="Click to go to the Author Index">Brossette, Stanislas</a></td><td class="r">Cnrs-Um2 Lirmm, Cnrs-Aist Jrl Umi3218/crt</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113780" title="Click to go to the Author Index">Escande, Adrien</a></td><td class="r">Cnrs-Aist Jrl Umi3218/rl</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111052" title="Click to go to the Author Index">Nori, Francesco</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1150" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Calibration_and_Identification" title="Click to go to the Keyword Index">Calibration and Identification</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> This paper presents a new condition, the fully physical consistency for a set of inertial parameters to determine if they can be generated by a physical rigid body. The proposed condition ensure both the positive definiteness and the triangular inequality of 3D inertia matrices as opposed to existing techniques in which the triangular inequality constraint is ignored. This paper presents also a new parametrization that naturally ensures that the inertial parameters are fully physical consistency. The proposed parametrization is exploited to reformulate the inertial identification problem as a manifold optimization problem, that ensures that the identified parameters can always be generated by a physical body. The proposed optimization problem has been validated with a set of experiments on the iCub humanoid robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_20">16:29-16:30, Paper ThT32.20</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1186.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1186'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Heel and Toe Lifting Walk Controller for Resource Constrained Humanoid Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133360" title="Click to go to the Author Index">Yi, Seung-Joon</a></td><td class="r">Naver Labs</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106613" title="Click to go to the Author Index">Lee, Daniel D.</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1186" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1186.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a></span><br>
                           <strong>Abstract:</strong> Common design principles for low cost humanoid robots include a low center of mass height and a large support area for increased static stability. However, such principles limit the bipedal mobility of the robot due to the kinematic constraints involved. In this paper, we present an efficient locomotion controller that utilizes automatically calculated heel and toe lift motions to overcome the kinematic constraints. This helps with uneven terrain traversal by providing additional support, and also enables a dynamic heel-strike toe-off gait with a large stride length. We demonstrate the controller in physically realistic simulations, and on the THOR-RD full-sized humanoid robot and DARwIn-OP miniature humanoid robot.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_21">16:30-16:31, Paper ThT32.21</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1208.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1208'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Smooth Trajectory Generation on SE(3) for a Free Flying Space Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170414" title="Click to go to the Author Index">Watterson, Michael</a></td><td class="r">Univ. of Pennsylvania</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106900" title="Click to go to the Author Index">Smith, Trey</a></td><td class="r">NASA Ames Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104342" title="Click to go to the Author Index">Kumar, Vijay</a></td><td class="r">Univ. of Pennsylvania</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1208" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1208.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Space_Robotics_and_Automation" title="Click to go to the Keyword Index">Space Robotics and Automation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a></span><br>
                           <strong>Abstract:</strong> We propose a new optimal trajectory generation technique on SE(3) which avoids known obstacles. We harness differential geometry and Lie algebraic techniques to formulate a cost functional which considers the geometric structure of this space and makes physical sense. We propose an approximation technique to generate trajectories on the subgroup SO(3) and use Positive Semidefinite Programming (PSD) to approximate an NP-Hard problem with one which is tractable to compute. From this trajectory on the subgroup, the trajectory generation on the other dimensions of the group becomes a Quadratic Program (QP). For obstacle avoidance, we use a computational geometric technique to decompose the environment into convex regions to confine the trajectory. We generalize a method from cubes to polyhedrons to expand these regions to better condition the QP. We leverage control techniques on SE(3) and dexterous grasping literature to control our unique platform and compare our method to similar methods for calculate optimal trajectories on SO(3) and SE(3), in the absence of obstacles. In addition, we show generated simulated SE(3) trajectories avoiding obstacles within a non-convex environment.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_22">16:31-16:32, Paper ThT32.22</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1274.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1274'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Humanoid Manipulation Planning Using Backward-Forward Search</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169748" title="Click to go to the Author Index">Grey, Michael</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183173" title="Click to go to the Author Index">Garrett, Caelan</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#132937" title="Click to go to the Author Index">Liu, Karen</a></td><td class="r">Georgia Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134049" title="Click to go to the Author Index">Ames, Aaron</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114706" title="Click to go to the Author Index">Thomaz, Andrea Lockerd</a></td><td class="r">Univ. of Texas at Austin</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1274" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1274.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Task_Planning" title="Click to go to the Keyword Index">Task Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> This paper explores combining task and manipulation planning for humanoid robots. Existing methods tend to either take prohibitively long to compute for humanoids or artificially limit the physical capabilities of the humanoid platform by restricting the robot's actions to predetermined trajectories. We present a hybrid planning system which is able to scale well for complex tasks without relying on predetermined robot actions. Our system utilizes the hybrid backward-forward planning algorithm for high-level task planning combined with humanoid primitives for standing and walking motion planning. These primitives are designed to be efficiently computable during planning, despite the large amount of complexity present in humanoid robots, while still informing the task planner of the geometric constraints present in the problem. Our experiments apply our method to simulated pick-and-place problems with additional gate constraints impacting navigation using the DRC-HUBO1 robot. Our system is able to solve puzzle-like problems on a humanoid within a matter of minutes.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_23">16:32-16:33, Paper ThT32.23</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1329.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1329'); return false" title="Click to show or hide the keywords and abstract">Automated Motion-Based Tactical Maneuver Discovery, Reasoning and Trajectory Planning for Autonomous Driving</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179309" title="Click to go to the Author Index">Gu, Tianyu</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104857" title="Click to go to the Author Index">Dolan, John M.</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188687" title="Click to go to the Author Index">Lee, Jin-Woo</a></td><td class="r">General Motors R&D</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1329" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#AI_Reasoning_Methods" title="Click to go to the Keyword Index">AI Reasoning Methods</a>, <a href="IROS16_KeywordIndexMedia.html#Behaviour_Based_Systems" title="Click to go to the Keyword Index">Behaviour-Based Systems</a></span><br>
                           <strong>Abstract:</strong> In a hierarchical planning system for autonomous driving vehicles, it is a common practice to separate two distinct planning modules: the higher-level behavior planner and the lower-level motion planner. A closer analysis of the behavior planners reveals that they typically handle the following three tactical aspects of urban autonomous driving: rule-based, route-based and motion-based. While the first two aspects are suitable to be handled at the higher level, motion-based tactical reasoning is intrinsically linked to motion planning. We propose a planning framework that automatically discovers different motion-level tactical maneuver patterns, and fuses pattern reasoning and sampling-based trajectory planning. The results demonstrate enhanced planning feasibility, coherency and scalability.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_24">16:33-16:34, Paper ThT32.24</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1406.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1406'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Coordinate Change Dynamic Movement Primitives - a Leader-Follower Approach</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196378" title="Click to go to the Author Index">Zhou, You</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123063" title="Click to go to the Author Index">Do, Martin</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102922" title="Click to go to the Author Index">Asfour, Tamim</a></td><td class="r">Karlsruhe Inst. of Tech. (KIT)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1406" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1406.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_Interaction" title="Click to go to the Keyword Index">Humanoid Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Learning_from_Demonstration" title="Click to go to the Keyword Index">Learning from Demonstration</a></span><br>
                           <strong>Abstract:</strong> Dynamic movement primitives prove to be a useful and effective way to represent a movement of a given agent. However, the original DMP formulation does not take the interaction among multiple agents into the consideration. Thus, many researchers focus on the development of a coupling term for the underlying dynamical system and its associated learning strategies. The result is highly dependent on the quality of the learning methods. In this paper, we present a new way to formulate and realize interactive movement primitive in a leader-follower configuration, where the relationship between the follower and the leader is explicitly represented via the new formulation. This formulation does not only simplify the learning process, but it also meets the requirements of several applications. We separately tested our new formulation in the context of the handover task and the wiping task. The results demonstrate the flexibility and simplicity of the new formulation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="tht32_25">16:34-16:35, Paper ThT32.25</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1442.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1442'); return false" title="Click to show or hide the keywords and abstract">Dynamically Feasible and Safe Shape Transitions for Teams of Aerial Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196265" title="Click to go to the Author Index">Desai, Arjav</a></td><td class="r">Robotics Inst. Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180657" title="Click to go to the Author Index">Cappo, Ellen</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111260" title="Click to go to the Author Index">Michael, Nathan</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1442" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Nonholonomic_Motion_Planning" title="Click to go to the Keyword Index">Nonholonomic Motion Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a></span><br>
                           <strong>Abstract:</strong> We consider the problem of generating dynamically feasible and safe plans for teams of aerial robots (quadrotors) while holding a fixed relative formation as well as transitioning between a sequence of formations. We extend the existing assignment and planning approaches for quadrotor teams to find minimal-time trajectories to enable team tran-sition between non-rest initial and ending states while ensuring dynamic feasibility with respect to predefined kinematic,dynamic, and collision constraints. This work also presents a method for safe splitting and merging of robot formations according to input specification. The proposed methodology is capable of generating dynamically feasible and safe plans for teams of quadrotors in real time. We validate the performance of the proposed approach through various trials and scenarios conducted in simulation.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thci1"><b>ThCI1</b></a></td>
               <td class="r">#111</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thci1" title="Click to go to the Program at a Glance"><b>Interactive Session: Micro Robot/Robot Intelligence</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#147375" title="Click to go to the Author Index">Antonelli, Marco</a></td><td class="r">Hong Kong Univ. of Science and Tech</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#155126" title="Click to go to the Author Index">Lelevé, Arnaud</a></td><td class="r">INSA De Lyon (Inst. National Des Sciences Appliquees), Univ. De Lyon</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thci2"><b>ThCI2</b></a></td>
               <td class="r">#112</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thci2" title="Click to go to the Program at a Glance"><b>Interactive Session: Robot Control and Planning</b></a></td>
               <td class="r">Interactive Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104857" title="Click to go to the Author Index">Dolan, John M.</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#172127" title="Click to go to the Author Index">De Stefano, Marco</a></td><td class="r">DLR - German Aerospace Center</td></tr>
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct1"><b>ThCT1</b></a></td>
               <td class="r">#101</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct1" title="Click to go to the Program at a Glance"><b>Soft Robots</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#193060" title="Click to go to the Author Index">Lessard, Steven</a></td><td class="r">Univ. of California, Santa Cruz</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#100766" title="Click to go to the Author Index">Suzumori, Koichi</a></td><td class="r">Tokyo Inst. of Tech</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct1_01">16:40-16:55, Paper ThCT1.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0344.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('344'); return false" title="Click to show or hide the keywords and abstract">Discrete Cosserat Approach for Soft Robot Dynamics: A New Piece-Wise Constant Strain Model with Torsion and Shears</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150250" title="Click to go to the Author Index">Renda, Federico</a></td><td class="r">Khalifa Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183900" title="Click to go to the Author Index">Cacucciolo, Vito</a></td><td class="r">Scuola Superiore Sant'Anna</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101631" title="Click to go to the Author Index">Dias, Jorge</a></td><td class="r">Univ. of Coimbra</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179559" title="Click to go to the Author Index">Seneviratne, Lakmal</a></td><td class="r">L. D. Seneviratne Is with Kings Coll. London, UK, and Robotics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab344" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> Modeling and control of soft robots is an up-to-date and exciting area of research which has been tackled with complementary approaches so far. In this paper, we modify the existing continuum Cosserat approach optimizing it for soft robot arms which can be discretized in a finite number of sections and degrees of freedom. The resulting new piece-wise constant strain model extends the existing piece-wise constant curvature model by allowing torsion and shears strains which are fundamental to cope with out-of-the-plane external forces as appearing for example during ground locomotion. A first experimental comparison has been also conducted using one fluidic actuated leg of the soft crawler FASTT.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct1_02">16:55-17:10, Paper ThCT1.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0551.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('551'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Proposal of Flexible Robotic Arm with Thin McKibben Actuators Mimicking Octopus Arm Structure</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195890" title="Click to go to the Author Index">Doi, Toshiyuki</a></td><td class="r">Okayama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103313" title="Click to go to the Author Index">Wakimoto, Shuichi</a></td><td class="r">Okayama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100766" title="Click to go to the Author Index">Suzumori, Koichi</a></td><td class="r">Tokyo Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195891" title="Click to go to the Author Index">Mori, Kazuya</a></td><td class="r">Okayama Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab551" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0551.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Hydraulic_Pneumatic_Actuators" title="Click to go to the Keyword Index">Hydraulic/Pneumatic Actuators</a></span><br>
                           <strong>Abstract:</strong> An octopus arm has no rigid structure, it is mostly composed of muscles aligned in various directions and the nerves. The muscles are roughly aligned in three directions, and by driving the muscles selectively, the octopus arm can perform multiple functions such as the contracting, bending, torsion and stiffness alteration. This study aims at the development of a new flexible robotic arm using thin McKibben actuators mimicking the muscle structure of an octopus arm. The McKibben actuator is a well-known pneumatic artificial muscle, and we have developed extremely thin McKibben actuators by using a braiding machine. In this paper, configuration of the flexible arm is proposed. The developed mechanism consists of thirty two thin McKibben actuators arranged in three directions, axial, radial and oblique, imitating the muscle structure of an actual octopus arm. The fundamental motion of the flexible arm is investigated experimentally. The proposed mechanism performs bending, contracting, torsion movements and stiffness alteration like an octopus arm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct1_03">17:10-17:25, Paper ThCT1.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0629.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('629'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Kinematic Modeling and Observer Based Control of Soft Robot Using Real-Time Finite Element Method</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195998" title="Click to go to the Author Index">Zhang, Zhongkai</a></td><td class="r">INRIA, Univ. of Lille, France</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162379" title="Click to go to the Author Index">Dequidt, Jeremie</a></td><td class="r">Lab. D'informatique Fondamentale De Lille</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187159" title="Click to go to the Author Index">Kruszewski, Alexandre</a></td><td class="r">Ec. Centrale De Lille</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180254" title="Click to go to the Author Index">Largilliere, Frederick</a></td><td class="r">Univ. of Lille</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115421" title="Click to go to the Author Index">Duriez, Christian</a></td><td class="r">INRIA</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab629" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0629.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a></span><br>
                           <strong>Abstract:</strong> This paper aims at providing a novel approach to modeling and controlling soft robots. Based on real-time Finite Element Method (FEM), we obtain a globally defined discretetime kinematic model in the workspace of soft robots. From the kinematic equations, we deduce the soft-robot Jacobian matrix and discuss the conditions to avoid singular configurations. Then, we propose a novel observer based control methodology where the observer is built by Finite Element Model in this paper to deal with the control problem of soft robots. A closed-loop controller for position control of soft robot is designed based on the discrete-time model with feedback signal being extracted by means of visual servoing. Finally, experimental results on a parallel soft robot show the efficiency and performance of our proposed controller.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct1_04">17:25-17:40, Paper ThCT1.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1301.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1301'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Bio-Inspired Tensegrity Manipulator with Multi-DOF, Structurally Compliant Joints</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193060" title="Click to go to the Author Index">Lessard, Steven</a></td><td class="r">Univ. of California, Santa Cruz</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195420" title="Click to go to the Author Index">Castro, Dennis</a></td><td class="r">Univ. of California Santa Cruz</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195406" title="Click to go to the Author Index">Asper, William</a></td><td class="r">Univ. of California Santa Cruz</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196005" title="Click to go to the Author Index">Chopra, Shaurya Deep</a></td><td class="r">Univ. of California, Santa Cruz</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195405" title="Click to go to the Author Index">Baltaxe-Admony, Leya Breanna</a></td><td class="r">Univ. of California Santa Cruz</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#193055" title="Click to go to the Author Index">Teodorescu, Mircea</a></td><td class="r">UCSC</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#137052" title="Click to go to the Author Index">SunSpiral, Vytas</a></td><td class="r">SGT Inc. / NASA Ames Res. Center</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172287" title="Click to go to the Author Index">Agogino, Adrian</a></td><td class="r">UC Santa Cruz, NASA Ames Res. Center</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1301" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1301.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Flexible_Arms" title="Click to go to the Keyword Index">Flexible Arms</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a></span><br>
                           <strong>Abstract:</strong> Most traditional robotic mechanisms feature inelastic joints that are unable to robustly handle large deformations and off-axis moments. As a result, the applied loads are transferred rigidly throughout the entire structure. The disadvantage of this approach is that the exerted leverage is magnified at each subsequent joint possibly damaging the mechanism. In this paper, we present two lightweight, elastic, bio-inspired tensegrity robotic arms adapted from prior static models which mitigate this danger while improving their mechanism's functionality. Our solutions feature modular tensegrity structures that function similarly to the human elbow and the human shoulder when connected. Like their biological counterparts, the proposed robotic joints are flexible and comply with unanticipated forces. Both proposed structures have multiple passive degrees of freedom and four active degrees of freedom (two from the shoulder and two from the elbow). The structural advantages demonstrated by the joints in these manipulators illustrate a solution to the fundamental issue of elegantly handling off-axis compliance. Additionally, this initial experiment illustrates that moving tensegrity arms must be designed with large reachable and dexterous workspaces in mind, a change from prior tensegrity arms which were only static. These initial experiments should be viewed as an exploration into the design space of active tensegrity structures, particularly those inspired by biological joints and limbs.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct2"><b>ThCT2</b></a></td>
               <td class="r">#102</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct2" title="Click to go to the Program at a Glance"><b>Visual Servoing 2</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#150329" title="Click to go to the Author Index">Yang, Liangjing</a></td><td class="r">Singapore Univ. of Tech. and Design</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#101721" title="Click to go to the Author Index">Hashimoto, Koichi</a></td><td class="r">Tohoku Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct2_01">16:40-16:55, Paper ThCT2.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1452.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1452'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Adaptive 3D Pose Computation of Suturing Needle Using Constraints from Static Monocular Image Feedback</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191020" title="Click to go to the Author Index">Zhong, Fangxun</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#123555" title="Click to go to the Author Index">Navarro-Alarcon, David</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#176856" title="Click to go to the Author Index">Wang, Zerui</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100055" title="Click to go to the Author Index">Liu, Yunhui</a></td><td class="r">Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191268" title="Click to go to the Author Index">Zhang, Tianxue</a></td><td class="r">THE CHINESE Univ. OF HONGKONG</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146858" title="Click to go to the Author Index">Yip, Hiu Man</a></td><td class="r">The Chinese Univ. of Hong Kong</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103003" title="Click to go to the Author Index">Wang, Hesheng</a></td><td class="r">Shanghai Jiao Tong Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1452" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1452.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Vision" title="Click to go to the Keyword Index">Robot Vision</a>, <a href="IROS16_KeywordIndexMedia.html#Surgical_Robotics" title="Click to go to the Keyword Index">Surgical Robotics</a></span><br>
                           <strong>Abstract:</strong> In this paper, we address the problem of the image-based 3D pose computation of a semi-circle suturing needle using monocular image feedback for laparoscopy. We propose a constrained two-degree-of-freedom (2-DOF) geometry-based modelling method to parametrise the needle's 6-DOF pose, including depth information. The modelling solely relies on the simultaneous observation of the needle's apparent tip and junction. No external markers are needed for extra constraints. An adaptive controller combining gradient descent and vector-flow method is introduced to iteratively guide the needle's initial guessing pose to its real pose by minimizing image-based position errors. Experiments have been conducted using both numerical simulations and simulated laparoscopic scenarios to evaluate the performance of the algorithm.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct2_02">16:55-17:10, Paper ThCT2.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1484.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1484'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Towards Automatic Robot Assisted Microscopy: An Uncalibrated Approach for Robotic Vision Guided Micromanipulation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#150329" title="Click to go to the Author Index">Yang, Liangjing</a></td><td class="r">Singapore Univ. of Tech. and Design</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114283" title="Click to go to the Author Index">Youcef-Toumi, Kamal</a></td><td class="r">Massachusetts Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102871" title="Click to go to the Author Index">Tan, U-Xuan</a></td><td class="r">Singapore Univ. of Tech. and Design</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1484" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1484.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Micromanipulation during live microscopic imaging relies heavily on good manual controls, dexterity, and hand-eye coordination. However, unassisted manual operations in these procedures greatly limit the speed, repeatability, and ease of operation. This is especially challenging in the case of microinjection where the insertion path needs to be in precise alignment with the imaging plane to avoid damage to cells. In this paper, we proposed an assistive robotic system that facilitates micromanipulation under microscopy. This comes in the form of intelligent robotic vision and guided manipulation. Using user-selected patch similarity, the system registers target templates and provides online coordinated depth compensation that ensures in-plane microinjection without the need for any prior calibration. This vision-based auto-registration approach readily integrates to any existing microscope system uncalibrated. It can also work as a standalone imaging solution with any general digital microscope camera. Experiments show that the similarity-score based depth compensation performed better than the uncompensated method. The method was shown to self-recover from an unfocused position. By robotizing conventional microscopy and micromanipulation procedures, we hope to address traditional latent needs and open up new possibilities in the ways experimental biology is performed.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct2_03">17:10-17:25, Paper ThCT2.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1505.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1505'); return false" title="Click to show or hide the keywords and abstract">Distance Metrics and Algorithms for Task Space Path Optimization</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#173337" title="Click to go to the Author Index">Holladay, Rachel</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105832" title="Click to go to the Author Index">Srinivasa, Siddhartha</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1505" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> We propose a method for generating a configuration space path that closely follows a desired task space path despite the presence of obstacles. We formalize closeness via two path metrics based on the discrete Hausdorff and Frechet distances. Armed with these metrics, we can cast our problem as a trajectory optimization problem. We also present two techniques to assist our optimizer in the case of local minima by further constraining the trajectory Finally, we leverage shape matching analysis, the Procrustes metric, to compare with respect to only their shape.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct2_04">17:25-17:40, Paper ThCT2.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1639.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1639'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Optimal Visual Servoing for Differentially Flat Underactuated Systems</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#186172" title="Click to go to the Author Index">Sheckells, Matthew</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180665" title="Click to go to the Author Index">Garimella, Gowtham</a></td><td class="r">Johns Hopkins Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124270" title="Click to go to the Author Index">Kobilarov, Marin</a></td><td class="r">Johns Hopkins Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1639" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1639.VI.mpeg" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Navigation" title="Click to go to the Keyword Index">Visual Navigation</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> This work introduces a hybrid visual servoing technique for differentially flat, underactuated systems that is well suited for aggressive dynamics. Standard Position-Based Visual Servoing (PBVS) and Image-Based Visual Servoing (IBVS) approaches for underactuated systems, such as quadrotors, oftentimes do not explicitly ensure that the relevant image features stay in the camera's field of view, especially while the system is performing agile maneuvers. We present a control technique that is designed to mitigate this issue and that results in increased robustness. Given a goal image, we first solve a constrained Perspective-n-Point (PnP) problem to find an equilibrium pose which aligns the camera with the goal. We then formulate the task of navigating to the goal pose as an optimal control problem, where a cost over the resulting image feature tracks along the trajectory is minimized which implicitly keeps features in the field of view over the course of the trajectory. The optimization is performed over a polynomial parametrization of the flat outputs of the system to decrease the dimensionality of the optimization. Simulations and physical experiments are performed with a quadrotor system to benchmark the algorithm's performance against a typical PBVS approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct2_05">17:40-17:55, Paper ThCT2.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1642.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1642'); return false" title="Click to show or hide the keywords and abstract">Model-Based Virtual Visual Servoing with Point Cloud Data</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196060" title="Click to go to the Author Index">Kingkan, Cherdsak</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196076" title="Click to go to the Author Index">Ito, Shogo</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111354" title="Click to go to the Author Index">Arai, Shogo</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159258" title="Click to go to the Author Index">Nammoto, Takashi</a></td><td class="r">Tohoku Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101721" title="Click to go to the Author Index">Hashimoto, Koichi</a></td><td class="r">Tohoku Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1642" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Visual_Servoing" title="Click to go to the Keyword Index">Visual Servoing</a>, <a href="IROS16_KeywordIndexMedia.html#Industrial_Robots" title="Click to go to the Keyword Index">Industrial Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Visual_Tracking" title="Click to go to the Keyword Index">Visual Tracking</a></span><br>
                           <strong>Abstract:</strong> In this paper, we address an issue on non-existence of a CAD model of an object in a model-based virtual visual servoing system. The approach for reconstructing a 3D model with fewer faces from point cloud data is presented. Because of a number of faces on the model surface, this reconstructed model required less rendering time than a CAD model, consequently, high speed and high accuracy model-based visual servoing can be achieved. We present the experimental results to demonstrate the effectiveness in terms of rendering time, convergence speed, and tracking speed measurements. The comparison of performances of a model-based visual servoing using different models, i.e.- CAD, Coarse mesh, Fine mesh, and Propose models, is also presented.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct3"><b>ThCT3</b></a></td>
               <td class="r">#103</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct3" title="Click to go to the Program at a Glance"><b>Force and Tactile Sensing</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102549" title="Click to go to the Author Index">Hirai, Shinichi</a></td><td class="r">Ritsumeikan Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#106608" title="Click to go to the Author Index">Choi, Youngjin</a></td><td class="r">Hanyang Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct3_01">16:40-16:55, Paper ThCT3.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0223.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('223'); return false" title="Click to show or hide the keywords and abstract">A Soft Three Axis Force Sensor Useful for Robot Grippers</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#162694" title="Click to go to the Author Index">Chathuranga, Damith Suresh</a></td><td class="r">Ritsumeikan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#121997" title="Click to go to the Author Index">Wang, Zhongkui</a></td><td class="r">Ritsumeikan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105797" title="Click to go to the Author Index">Noh, Yohan</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140137" title="Click to go to the Author Index">Nanayakkara, Thrishantha</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102549" title="Click to go to the Author Index">Hirai, Shinichi</a></td><td class="r">Ritsumeikan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab223" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Grasping" title="Click to go to the Keyword Index">Grasping</a></span><br>
                           <strong>Abstract:</strong> A novel three axis force sensor, based on magnetic flux measurements, was used in the fingers of a gripper. The force sensor uses three Hall Effect sensors orthogonally placed at the base of a hemisphere made of silicon rubber. A neodymium permanent magnet was inside the hemisphere. When a force was applied to the perimeter of hemisphere, it compresses the hemisphere displacing the magnet. This displacement causes change in the magnetic field around the Hall-effect sensors. By analysing these changes, we calculate the force in three directions using a lookup table. This sensor can be used in robot grippers to manipulate objects dexterously with tactile feedback. The cheap construction, robustness	and reliability are few advantages of this sensor for it to be used in the industrial applications. The sensor design, simulation and its characterization are presented in this work. Furhtermore, as an application, a peg in a hole experiment is carriedout to present the ability of the sensors to be used in robot grippers for manipulation tasks.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct3_02">16:55-17:10, Paper ThCT3.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1134.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1134'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Designing a Virtual Whole Body Tactile Sensor Suit for a Simulated Humanoid Robot Using Inverse Dynamics</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159449" title="Click to go to the Author Index">Faraji, Salman</a></td><td class="r">EPFL</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105018" title="Click to go to the Author Index">Ijspeert, Auke</a></td><td class="r">EPFL</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1134" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1134.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Human_Robot_Interaction" title="Click to go to the Keyword Index">Human-Robot Interaction</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a novel architecture to estimate external forces applied to a compliantly controlled balancing robot in simulations. We use similar dynamics equations used in the controller to find mismatches in the available sensory data and associate them to an unknown external force. Then by decomposing Jacobians, we search over the surface of all body links in the robot to find the force application point. By approximating link geometries with ellipsoids, we can derive analytic solutions to solve the search problem very fast in real time. The proposed approach is tested on a complex humanoid robot in simulations where it outperforms static estimators over fast dynamic motions. We foresee a lot of applications for this method especially in human-robot interactions where it can serve as a whole body virtual suit of tactile sensors. It can also be very useful in identifying the inertial properties of objects being manipulated or mounted on the robot like a backpack.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct3_03">17:10-17:25, Paper ThCT3.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1384.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1384'); return false" title="Click to show or hide the keywords and abstract">A Soft Microfabricated Capacitive Sensor for High Dynamic Range Strain Sensing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183736" title="Click to go to the Author Index">Shin, Hee-Sup</a></td><td class="r">Univ. of Maryland</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196488" title="Click to go to the Author Index">Charalambides, Alexi</a></td><td class="r">Univ. of Maryland</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133353" title="Click to go to the Author Index">Penskiy, Ivan</a></td><td class="r">Univ. of Maryland, Coll. Park</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103249" title="Click to go to the Author Index">Bergbreiter, Sarah</a></td><td class="r">Univ. of Maryland, Coll. Park</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1384" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Soft_bodied_Robots" title="Click to go to the Keyword Index">Soft-bodied Robots</a></span><br>
                           <strong>Abstract:</strong> This work demonstrates an all-elastomer MEMS capacitive strain sensor with high dynamic range (5000:1), and features an inexpensive molding microfabrication process. The sensor is comprised of conductive elastometric comb capacitors embedded in a dielectric. Two different sensor designs, lateral combs (LC) and transverse combs (TC), were developed to evaluate sensor sensitivity as a function of load orientation. Both sensors have combs with a gap of 30 µm, length of 4 mm, and depth of 65 µm. A linear elastic analytical model was developed to predict change in capacitance as a function of strain, and experimental results show a reasonable agreement with the theoretical predictions. The observed strain responses have high linearity and dynamic range, and negligible hysteresis. The strain resolution of the LC and TC sensors is 100 µstrain and 500 µstrain, respectively, tested up to 50% strain.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct3_04">17:25-17:40, Paper ThCT3.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1554.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1554'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Distinguishing Sliding from Slipping During Object Pushing</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140374" title="Click to go to the Author Index">Meier, Martin</a></td><td class="r">Bielefeld Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#127686" title="Click to go to the Author Index">Walck, Guillaume</a></td><td class="r">Bielefeld Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103006" title="Click to go to the Author Index">Haschke, Robert</a></td><td class="r">Bielefeld Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103487" title="Click to go to the Author Index">Ritter, Helge Joachim</a></td><td class="r">Bielefeld Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1554" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1554.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Tactile_Sensing" title="Click to go to the Keyword Index">Tactile Sensing</a>, <a href="IROS16_KeywordIndexMedia.html#Dexterous_Manipulation" title="Click to go to the Keyword Index">Dexterous Manipulation</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Learning" title="Click to go to the Keyword Index">Robot Learning</a></span><br>
                           <strong>Abstract:</strong> The advent of advanced tactile sensing technology triggered the development of methods to employ them for grasp evaluation, online slip detection, and tactile servoing. In contrast to recent approaches to slip detection, distinguishing slip from non-slip conditions, we consider the more difficult task of distinguishing different types of slippage. Particularly we consider an object pushing task, where forces can only be applied from the top. In that case, the robot needs to notice when the object successfully moves vs. when the object gets stuck while the finger slips over its surface. As an example, consider the task of pushing around a piece of paper. <p>We propose and evaluate three different convolutional network architectures and proof the applicability of the method for online classification in a robot pushing task.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct3_05">17:40-17:55, Paper ThCT3.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1561.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1561'); return false" title="Click to show or hide the keywords and abstract">Detection of Multi-Biosignal Using a Quartz Crystal Resonator Based Wide Range Load Sensor with Compact Frequency Counter</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169277" title="Click to go to the Author Index">Murozaki, Yuichi</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113673" title="Click to go to the Author Index">Sakuma, Shinya</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100111" title="Click to go to the Author Index">Arai, Fumihito</a></td><td class="r">Nagoya Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1561" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Force_and_Tactile_Sensing" title="Click to go to the Keyword Index">Force and Tactile Sensing</a></span><br>
                           <strong>Abstract:</strong> Monitoring of biosignals plays important roles in health management in daily life. Especially, the sensing method of biosignals, which does not require special efforts such as restraining people or wearing the sensors to measure them, is really important to maintain monitoring activities of people. We call such methods what a sensing way should be for monitoring of biosignals as casual sensing methods. Previously, we have developed highly sensitive and wide-measurement-range load sensors based on measuring frequency shift of quartz crystal resonator (QCR) as the sensing principal. We have integrated the load sensor into a chair, and measure the load when people just sit on it. Since the load sensor has wide measurement range of 10^5 order, multi-biosignal; heartbeat, respiration, and body motion under the weight-loaded environment can be measured from load information. Thus, people can casually monitor the biosignals by sitting on the chair. However, the previous sensing system required us to measure the freqency shift of one-Hz order in tens-MHz of the resonant frequency of a QCR. In this case, the sensing system requires a expensive frequency counter, and it is not suitable for daily use situation such as in-home sensing. In this paper, we presents the detection of multi-biosignal method using a newly developed load sensing system which utilizes the developed frequency counter unit. In order to measure the freqency shift of one-Hz order in tens-MHz of the resonant frequency, we use a differential method of signal for two QCRs with an electrical signal-mixing circuit. By using the method, we can reduce the required measurement range for frequency from tens-MHz to tens-kHz. The load sensing performances were evaluated, and the results showed that the sensitivity and withstand load were 2.9 [mN] and 300 [N], respectively. Finally, we demonstrated the measurement of multi-biosignal by using constructed system, and succeeded in detecting respiration, heartbeat, and body motion.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct4"><b>ThCT4</b></a></td>
               <td class="r">#104</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct4" title="Click to go to the Program at a Glance"><b>Mobile Robots</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101240" title="Click to go to the Author Index">Hasegawa, Yasuhisa</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#141359" title="Click to go to the Author Index">Indelman, Vadim</a></td><td class="r">Tech. - Israel Inst. of Tech</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct4_01">16:40-16:55, Paper ThCT4.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0392.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('392'); return false" title="Click to show or hide the keywords and abstract">Multi-Robot Decentralized Belief Space Planning in Unknown Environments Via Efficient Re-Evaluation of Impacted Paths</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190869" title="Click to go to the Author Index">Regev, Tal</a></td><td class="r">Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#141359" title="Click to go to the Author Index">Indelman, Vadim</a></td><td class="r">Tech. - Israel Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab392" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a>, <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#SLAM" title="Click to go to the Keyword Index">SLAM</a></span><br>
                           <strong>Abstract:</strong> In this paper we develop a new approach for decentralized multi-robot belief space planning in high- dimensional state spaces while operating in unknown environments. State of the art approaches often address related problems within a sampling based motion planning paradigm, where robots generate candidate paths and are to choose the best paths according to a given objective function. As exhaustive evaluation of all candidate path combinations from different robots is computationally intractable, a commonly used (sub-optimal) framework is for each robot, at each time epoch, to evaluate its own candidate paths while only considering the best paths announced by other robots. Yet, even this approach can become computationally expensive, especially for high-dimensional state spaces and for numerous candidate paths that need to be evaluated. In particular, upon an update in the announced path from one of the robots, state of the art approaches re-evaluate belief evolution for all candidate paths and do so from scratch. In this work we develop a framework to identify and efficiently update only those paths that are actually impacted as a result of an update in the announced path. Our approach is based on appropriately propagating belief evolution along impacted paths while employing insights from factor graph and incremental smoothing for efficient inference that is required for evaluating the utility of each impacted path. We demonstrate our approach in a synthetic simulation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct4_02">16:55-17:10, Paper ThCT4.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0414.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('414'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>The Role of Morphological Computation of the Goat Hoof in Slip Reduction</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195768" title="Click to go to the Author Index">Abad Guaman, Sara Adela</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168757" title="Click to go to the Author Index">Sornkarn, Nantachai</a></td><td class="r">King's Coll. London</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#140137" title="Click to go to the Author Index">Nanayakkara, Thrishantha</a></td><td class="r">King's Coll. London</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab414" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0414.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> The remarkable ability of goats to maintain stability during climbing cliffs or trees provides a valuable opportunity to understand some of the secrets of stable legged locomotion on unstructured terrains. This paper, for the first time, presents analytical and experimental explanations as to how the morphological computation at the goat hoof makes a significant contribution to slip reduction on both smooth and rough surfaces. We conducted experiments using a laboratory made hoof with adjustable degrees of freedom and compared its dynamic behavior against a rounded foot. We recorded forces and position of the hoof to analyze the effect of its shape and the individual contributions from 3-joints in the hoof on the work required to slip. Our results show that the work required to make the hoof slip is three times higher than that required for the rounded foot. This proves that the hoof is a more stable design. Additionally, the variables in the transient state are affected not only by the number and type of joints but also by the interaction with the environment. These findings promote the development of new types of feet for robots for all terrain conditions with greater stability and less control complexity.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct4_03">17:10-17:25, Paper ThCT4.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0549.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('549'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>A Robust Adaptive Control of Mecanum Wheel Mobile Robot: Simulation and Experimental Validation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195938" title="Click to go to the Author Index">Alakshendra, Veer</a></td><td class="r">Visvesvarya National Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#184722" title="Click to go to the Author Index">Chiddarwar, Shital</a></td><td class="r">Visvesvaraya National Inst. of Tech. Nagpur</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab549" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0549.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> Omnidirectional mobile robots with four Mecanum wheels are used in various homes, military, nuclear power plant, industrial, hospital and space applications. A lot of research has been done using three universal wheels but trajectory control for four Mecanum wheeled mobile robot (FMWMR) in presence of uncertainties still needs attention. Thus, to obtain smooth motion of mobile robots, with chattering free control input, in presence of uncertainties and external force disturbances, a robust and adaptive control is necessary. In view of these aspects, this paper extends the use of adaptive sliding mode controller for trajectory tracking of FMWMR. The effectiveness of proposed controller is verified using two case problems. Simulation results are presented for the verification of proposed controller for FMWMR. Further, experiments are conducted using position and orientation sensor to show the performance of the controller in real world environment. Simulation and experimental results revealed that FMWMR is capable of tracking any type of trajectories.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct4_04">17:25-17:40, Paper ThCT4.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0708.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('708'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Quasi-Passive Dynamic Autonomous Control to Enhance Horizontal and Turning Gait Speed Control</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155380" title="Click to go to the Author Index">Kobayashi, Taisuke</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103474" title="Click to go to the Author Index">Sekiyama, Kosuke</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101240" title="Click to go to the Author Index">Hasegawa, Yasuhisa</a></td><td class="r">Nagoya Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114338" title="Click to go to the Author Index">Aoyama, Tadayoshi</a></td><td class="r">Hiroshima Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101162" title="Click to go to the Author Index">Fukuda, Toshio</a></td><td class="r">Meijo Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab708" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0708.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Interaction" title="Click to go to the Keyword Index">Humanoid Interaction</a></span><br>
                           <strong>Abstract:</strong> This paper proposes a quasi-passive dynamic autonomous control (Q-PDAC) for a three-dimensional (3-D) bipedal gait of humanoid robots from start points to goal points. The major approach for 3-D traveling is currently footstep planning by a constantly stable gait with an emphasis on its accurate and secure traveling. However, energy would potentially be wasted when the robot accurately travels according to the planned footsteps. In contrast, a limit-cycle-based gait possesses the good efficiency by a gait speed control, although the accurate and secure traveling is difficult for it. Its gait speed control is unfortunately not enough to freely travel on 3-D spaces: shortages of a turning speed control, trackability of horizontal speed, and stability of the bipedal gait. Hence, the Q-PDAC supplies three proper angular momenta by hip and ankle joints to achieve the turning motion and enhance the trackability of horizontal motion. Three angular momenta are simply designed consistent in the PDAC dynamics, and achieved the sufficient gait speed control for 3-D traveling. As a result, the robot can efficiently travel from the start point to the goal point while following a leader point not to collide with walls.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct4_05">17:40-17:55, Paper ThCT4.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1095.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1095'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Micro Aerial Projector - Stabilizing Projected Images of an Airborne Robotics Projection Platform</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#191667" title="Click to go to the Author Index">Isop, Werner Alexander</a></td><td class="r">Tech. Univ. Graz</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#164664" title="Click to go to the Author Index">Pestana Puerta, Jesus</a></td><td class="r">Univ. Pol. De Madrid</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#192624" title="Click to go to the Author Index">Ermacora, Gabriele</a></td><td class="r">Pol. Di Torino</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#109260" title="Click to go to the Author Index">Fraundorfer, Friedrich</a></td><td class="r">Graz Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#115242" title="Click to go to the Author Index">Schmalstieg, Dieter</a></td><td class="r">TU-Graz</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1095" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1095.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Robot_Companions_and_Social_Human_Robot_Interaction" title="Click to go to the Keyword Index">Robot Companions and Social Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> A mobile flying projector is hard to build due to the limited size and payload capability of a micro aerial vehicle. Few flying projector designs have been studied in recent research. However, to date, no practical solution has been presented. We propose a versatile laser projection system enabling in-flight projection with feedforward correction for stabilization of projected images. We present a quantitative evaluation of the accuracy of the projection stabilization in two autonomous flight experiments. While this approach is our first step towards a flying projector, we foresee interesting applications, such as providing on-site instructions in various human machine interaction scenarios.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct5"><b>ThCT5</b></a></td>
               <td class="r">#105</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct5" title="Click to go to the Program at a Glance"><b>UAV-Control</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#110966" title="Click to go to the Author Index">Carloni, Raffaella</a></td><td class="r">Univ. of Twente</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#103663" title="Click to go to the Author Index">Kim, H. Jin</a></td><td class="r">Seoul National Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct5_01">16:40-16:55, Paper ThCT5.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0231.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('231'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Gust Disturbance Alleviation with Incremental Nonlinear Dynamic Inversion</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183399" title="Click to go to the Author Index">Smeur, Ewoud</a></td><td class="r">TU Delft</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131959" title="Click to go to the Author Index">de Croon, Guido</a></td><td class="r">TU Delft / ESA</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187837" title="Click to go to the Author Index">Chu, Qi Ping</a></td><td class="r">Delft Univ. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab231" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0231.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Control_Architectures_and_Programming" title="Click to go to the Keyword Index">Control Architectures and Programming</a></span><br>
                           <strong>Abstract:</strong> Micro Aerial Vehicles (MAVs) are limited in their operation outdoors near obstacles by their ability to withstand wind gusts. Currently widespread position control methods such as Proportional Integral Derivative control do not perform well under the influence of gusts. Incremental Nonlinear Dynamic Inversion (INDI) is a sensor-based control technique that can control nonlinear systems subject to disturbances. This method was developed for the attitude control of MAVs, but in this paper we generalize this method to the outer loop control of MAVs under gust loads. Significant improvements over a traditional Proportional Integral Derivative (PID) controller are demonstrated in an experiment where the drone flies in and out of a fan's wake. The control method does not rely on frequent position updates, so it is ready to be applied outside with standard GPS modules.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct5_02">16:55-17:10, Paper ThCT5.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1084.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1084'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Robust Control of UAVs Using the Parameter Space Approach</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196429" title="Click to go to the Author Index">Abdelmoeti, Samer</a></td><td class="r">Univ. of Twente</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110966" title="Click to go to the Author Index">Carloni, Raffaella</a></td><td class="r">Univ. of Twente</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1084" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1084.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> In this paper a robust PID controller for quadrotor unmanned aerial vehicles is proposed that uses the parameter space approach. Stability and robustness analyses are carried out in the controller parameter space to determine a set of stable controller gains that guarantee also robustness against system parameter uncertainties. Additionally, the trade-off between robustness and performance is included in the control gain choice. Experimental results validate the proposed approach, where the robust behavior of a quadrotor is shown for step response and path following.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct5_03">17:10-17:25, Paper ThCT5.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1184.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1184'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Wind Field Estimation and Identification Having Shear Wind and Discrete Gusts Features with a Small UAS</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196580" title="Click to go to the Author Index">Rodriguez Salazar, Leopoldo</a></td><td class="r">Univ. De Sevilla</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#133413" title="Click to go to the Author Index">Cobano, Jose A.</a></td><td class="r">Univ. of Seville</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104455" title="Click to go to the Author Index">Ollero, Anibal</a></td><td class="r">Univ. of Seville</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1184" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1184.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Marine_Robotics" title="Click to go to the Keyword Index">Marine Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> This paper presents a new method for estimation and identification of shear wind and discrete gusts of a previously unknown wind field by using an Unmanned Aircraft System (UAS). Wind estimation and identification is key in energy-efficient trajectory planning and dynamic soaring applications. The research proposes an approach for mapping a complete wind field from the collected data. Therefore, the generated map also describes areas where UAS has not passed through. The proposed method consists of the next steps: 1) the wind vector is estimated in each UAS position; 2) wind data are fitted into a Weibull probability density function and meeting the Prandtl’s power law relationship; 3) scale factor of the Weibull distribution and the power law coefficient are computed; 4) wind feature detection such as shear layer and gusts is performed from the relation wind magnitude vs. altitude obtained; and finally 5), data could be extrapolated to generate the complete wind field. Novel aspects and advantages include the optimization of the scale factor from the estimated wind data by using a genetic algorithm, the identification of wind features separately, and the possibility to apply the method online. Real data of flight have been used to validate the method and many simulations and studies have been performed to test and analyze the proposed method in different scenarios.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct5_04">17:25-17:40, Paper ThCT5.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1207.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1207'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Autonomous Flight and Vision-Based Target Tracking for a Flapping-Wing MAV</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196090" title="Click to go to the Author Index">Ryu, Seungwan</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196561" title="Click to go to the Author Index">Kwon, Ukjin</a></td><td class="r">Seoul National Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#103663" title="Click to go to the Author Index">Kim, H. Jin</a></td><td class="r">Seoul National Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1207" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1207.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Biomimetics" title="Click to go to the Keyword Index">Biomimetics</a>, <a href="IROS16_KeywordIndexMedia.html#Micro_Nano_Robots" title="Click to go to the Keyword Index">Micro/Nano Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a></span><br>
                           <strong>Abstract:</strong> In this paper, we design an autonomous flight controller for height regulation and bang-bang control for directional control of a light-weight flapping-wing micro air vehicle (FWMAV) with limited payload. We also present autonomous vision-based target tracking for a FWMAV equipped with a low-cost and light-weight first person view (FPV) camera. We construct a ground station, integrated with control and vision algorithms, which performs the image processing and the computation of control inputs based on the acquired state variables from motion capture system. In addition, we employ a vision algorithm for a low-quality camera to detect a static target with the discussions on the techniques to improve the reliability of visual detection. Experimental results show satisfactory flight performance, achieving the height regulation and directional control, and autonomous vision-based target tracking.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct5_05">17:40-17:55, Paper ThCT5.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1372.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1372'); return false" title="Click to show or hide the keywords and abstract">Unscented External Force and Torque Estimation for Quadrotors</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#180367" title="Click to go to the Author Index">McKinnon, Christopher</a></td><td class="r">Univ. of Toronto</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#124265" title="Click to go to the Author Index">Schoellig, Angela P.</a></td><td class="r">Univ. of Toronto</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1372" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Unmanned_Aerial_Systems" title="Click to go to the Keyword Index">Unmanned Aerial Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Sensor_Fusion" title="Click to go to the Keyword Index">Sensor Fusion</a></span><br>
                           <strong>Abstract:</strong> In this paper, we describe an algorithm, based on the well-known Unscented Quaternion Estimator, to estimate external forces and torques acting on a quadrotor. This formulation uses a non-linear model for the quadrotor dynamics, naturally incorporates process and measurement noise, requires only a few parameters to be tuned manually, and uses singularity-free unit quaternions to represent attitude. We demonstrate in simulation that the proposed algorithm can outperform existing methods. We then highlight how our approach can be used to generate force and torque profiles from experimental data, and how this information can later be used for controller design. Finally, we show how the resulting controllers enable a quadrotor stay in the wind field of a moving fan.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct6"><b>ThCT6</b></a></td>
               <td class="r">#106</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct6" title="Click to go to the Program at a Glance"><b>Wearable Robots</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#114076" title="Click to go to the Author Index">Lim, Bokman</a></td><td class="r">Samsung Advanced Inst. of Tech</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#159277" title="Click to go to the Author Index">Jang, Junwon</a></td><td class="r">Samsung Electronics Co., Ltd</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct6_01">16:40-16:55, Paper ThCT6.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0114.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('114'); return false" title="Click to show or hide the keywords and abstract">Assistance Strategy for Stair Ascent with a Robotic Hip Exoskeleton</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159277" title="Click to go to the Author Index">Jang, Junwon</a></td><td class="r">Samsung Electronics Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179626" title="Click to go to the Author Index">Kim, Kyungrock</a></td><td class="r">Samsung Advanced Inst. of Tech. (SAIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111383" title="Click to go to the Author Index">Lee, Jusuk</a></td><td class="r">Samsung Electronics Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114076" title="Click to go to the Author Index">Lim, Bokman</a></td><td class="r">Samsung Advanced Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111493" title="Click to go to the Author Index">Shim, Youngbo</a></td><td class="r">Samsung Electronics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab114" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a></span><br>
                           <strong>Abstract:</strong> In this paper, we propose a novel assistance strategy for stair ascent walking using our robotic hip exoskeleton. Our strategy exploits foot contact event estimated by an inertial measurement unit (IMU) and can detect user intention as well as reflect user preference. In our strategy, a gait cycle is divided into 4 phases and the transitions between the phases are based on events that are unavoidable and can be detected reliably using the sensors available for our exoskeleton. The proposed strategy presents criteria for the initiation and termination of assistance by recognizing user intention, as well as methods to adjust the timing and the amount of assistance corresponding to user preference. When each step starts, the duration of assistance is determined and the torque profile for the whole step is planned ahead. We demonstrate the validity of the proposed strategy for stair ascent and examine its effects on hip joint angle trajectory through experimental results.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct6_02">16:55-17:10, Paper ThCT6.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0138.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('138'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Simulating Gait Assistance of a Hip Exoskeleton: Feasibility Studies for Ankle Muscle Weaknesses</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#114076" title="Click to go to the Author Index">Lim, Bokman</a></td><td class="r">Samsung Advanced Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#146457" title="Click to go to the Author Index">Hyung, SeungYong</a></td><td class="r">Samsung Electronics Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179626" title="Click to go to the Author Index">Kim, Kyungrock</a></td><td class="r">Samsung Advanced Inst. of Tech. (SAIT)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111383" title="Click to go to the Author Index">Lee, Jusuk</a></td><td class="r">Samsung Electronics Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159277" title="Click to go to the Author Index">Jang, Junwon</a></td><td class="r">Samsung Electronics Co., Ltd</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#111493" title="Click to go to the Author Index">Shim, Youngbo</a></td><td class="r">Samsung Electronics</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab138" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0138.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Animation_and_Simulation" title="Click to go to the Keyword Index">Animation and Simulation</a>, <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a></span><br>
                           <strong>Abstract:</strong> This paper presents a simulation framework for pathological gait assistance with a hip exoskeleton. Previously we had developed an event-driven controller for gait assistance [1]. We now simulate (or optimize) the gait assistance in ankle pathologies (e.g., weak dorsiflexion or plantarflexion). It is done by 1) utilizing the neuromuscular walking model, 2) parameterizing assistive torques for swing and stance legs, and 3) performing dynamic optimizations that takes into account the human-robot interactive dynamics. We evaluate the energy expenditures and walking parameters for the different gait types. Results show that each gait type should have a different assistance strategy comparing with the assistance of normal gait. Although we need further studies about the pathologies, our simulation model is feasible to design the gait assistance for the ankle muscle weaknesses.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct6_03">17:10-17:25, Paper ThCT6.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0669.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('669'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Position Control Using Adaptive Backlash Compensation for Bowden Cable Transmission in Soft Wearable Exoskeleton</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185400" title="Click to go to the Author Index">Dinh, Binh Khanh</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#174344" title="Click to go to the Author Index">Cappello, Leonardo</a></td><td class="r">Istituto Italiano Di Tecnologia</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187609" title="Click to go to the Author Index">Xiloyannis, Michele</a></td><td class="r">Nanyang Tech. Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#120006" title="Click to go to the Author Index">Masia, Lorenzo</a></td><td class="r">Nanyang Tech. Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab669" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0669.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Tendon_Wire_Mechanisms" title="Click to go to the Keyword Index">Tendon/Wire Mechanisms</a>, <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a></span><br>
                           <strong>Abstract:</strong> In recent years, bowden-cable transmissions have been developed and utilized widely in many robotic applications due to advantages in durability, lightweight, safety, and flexibility. Especially, over the last decade, a substantial number of soft wearable exoskeletons using bowden cables for motion transmission have been designed for human assistance, empowerment and rehabilitation. The major advantage of soft assistive devices driven by bowden-cable transmissions is to allow decentralizing the actuation stages proximally such that their mass has the least effect on the end-effector. Besides the advantage, the main drawback of the bowden cable-driven system comes from the presence of nonlinearities such as friction and backlash hysteresis that affects their control accuracy. Hence, in this paper, we introduce a mathematical model for backlash hysteresis and propose a solution based on the nonlinear adaptive control to compensate for the backlash effect. The backlash hysteresis model and control scheme are validated first on a custom-designed test bench and then applied to control a soft exoskeleton in a preliminary human trial.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct6_04">17:25-17:40, Paper ThCT6.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0838.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('838'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Intuitive Prosthetic Control Using Upper Limb Inter-Joint Coordinations and IMU-Based Shoulder Angles Measurement: A Pilot Study</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#194423" title="Click to go to the Author Index">Merad, Manelle</a></td><td class="r">Inst. Des Systèmes Intelligents Et De Robotique - Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#201884" title="Click to go to the Author Index">De Montalivet, Etienne</a></td><td class="r">Univ. Pierre Et Marie Curie</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179992" title="Click to go to the Author Index">Roby-Brami, Agnès</a></td><td class="r">Univ. Pierre Et Marie Curie, Paris 6</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106021" title="Click to go to the Author Index">Jarrassé, Nathanael</a></td><td class="r">UMR7222, Centre National De La Recherche Scientifique (CNRS)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab838" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0838.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Medical_Systems__Healthcare__and_Assisted_Living" title="Click to go to the Keyword Index">Medical Systems, Healthcare, and Assisted Living</a>, <a href="IROS16_KeywordIndexMedia.html#Physical_Human_Robot_Interaction" title="Click to go to the Keyword Index">Physical Human-Robot Interaction</a></span><br>
                           <strong>Abstract:</strong> Commercialized upper limb prostheses do not match the expectations of amputated people, especially transhumeral amputees. Most of them report a lack of functionality, mostly explained by a counter-intuitive control strategy. This paper presents the first implementation of an automatic prosthesis control approach based on natural coordinations between upper limb joints and IMU-based humeral orientation measurement. Two healthy individuals were able to use the prosthetic forearm attached to their upper arm to point at targets in a 3D workspace with a reasonable error. The results demonstrate the potential applications of automatizing the motion of some joints along the upper limb, in the same way as human upper limbs are controlled.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct6_05">17:40-17:55, Paper ThCT6.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1023.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1023'); return false" title="Click to show or hide the keywords and abstract">Acceleration-Based Transparency Control Framework for Wearable Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#131860" title="Click to go to the Author Index">Boaventura, Thiago</a></td><td class="r">ETH Zurich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107589" title="Click to go to the Author Index">Buchli, Jonas</a></td><td class="r">ETH Zurich</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1023" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Wearable_Robots" title="Click to go to the Keyword Index">Wearable Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Compliance_and_Impedance_Control" title="Click to go to the Keyword Index">Compliance and Impedance Control</a>, <a href="IROS16_KeywordIndexMedia.html#Rehabilitation_Robotics" title="Click to go to the Keyword Index">Rehabilitation Robotics</a></span><br>
                           <strong>Abstract:</strong> To render a wearable robot imperceptible to a user is a very challenging control task. The constant and intrinsic interaction between robot and human, and person-dependent behaviours are the main difficulties when designing such cooperative control. In this contribution we introduce and discuss a novel and promising transparency control framework. The foundation of the framework is to measure the acceleration of the human limbs and to exploit this measurement to generate feedforward control commands by using a rigid body model of the robot. The framework includes also an acceleration feedback controller and a state estimator to enhance the overall performance. We present a simplified stability analysis with different feedback controllers and preliminary experimental data that demonstrate the potential of the proposed method in reducing interaction forces and mimicking human motions.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct7"><b>ThCT7</b></a></td>
               <td class="r">#107</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct7" title="Click to go to the Program at a Glance"><b>Robot Control and Planning</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#116631" title="Click to go to the Author Index">Lee, Wee Sun</a></td><td class="r">National Univ. of Singapore</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#142145" title="Click to go to the Author Index">Wang, Yuquan</a></td><td class="r">Royal Inst. of Tech. (KTH)</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct7_01">16:40-16:55, Paper ThCT7.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0316.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('316'); return false" title="Click to show or hide the keywords and abstract">Reactive Task-Oriented Redundancy Resolution Using Constraint-Based Programming</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#142145" title="Click to go to the Author Index">Wang, Yuquan</a></td><td class="r">Royal Inst. of Tech. (KTH)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116198" title="Click to go to the Author Index">Wang, Lihui</a></td><td class="r">KTH Royal Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab316" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Reactive_and_Sensor_Based_Planning" title="Click to go to the Keyword Index">Reactive and Sensor-Based Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Manufacturing_and_Automation" title="Click to go to the Keyword Index">Manufacturing and Automation</a></span><br>
                           <strong>Abstract:</strong> Constraint based programming provides a versatile framework for combining several different constraints into a single robot control scheme. We take advantage of the redundancy of a robot manipulator to improve the execution of a reactive tracking task, in terms of a task-dependent measure which is a weighted sum of velocity transmissions along the current directions of motion.<p>With inspiration from recent work, we provide analytical gradients and computable weights of the task-dependent measure, which enable us to include it in a reactive constraint based programming framework, without relying on inexact numerical approximations and manually tuning weights. <p>The proposed approach is illustrated in a set of simulations, comparing the performance with a standard constraint based programming method.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct7_02">16:55-17:10, Paper ThCT7.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0406.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('406'); return false" title="Click to show or hide the keywords and abstract">Contact-Based Language for Robotic Manipulation Planning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195510" title="Click to go to the Author Index">Shah, Anuj</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#118853" title="Click to go to the Author Index">Lopes, Gabriel</a></td><td class="r">Delft Univ. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179397" title="Click to go to the Author Index">Najafi, Esmaeil</a></td><td class="r">Delft Univ. of Tech. Univ. of Tehran</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab406" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperative_Manipulators" title="Click to go to the Keyword Index">Cooperative Manipulators</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Planning_for_Manipulators" title="Click to go to the Keyword Index">Motion Planning for Manipulators</a></span><br>
                           <strong>Abstract:</strong> This paper proposes a new approach to robotic manipulation planning based on the contact between a set of objects, robots and surfaces. We consider making or breaking contact as the most abstract, yet representative element of a manipulation task. Using this paradigm, a robotic manipulation planner has been developed. Given an environment with robots and objects, a manipulation graph is generated by a set of rules and the available geometrical information. Next, the object manipulation planning is formulated as a graph search problem. Paths on this graph divide a complex manipulation task into sub-tasks, followed by low-level path planning and controller assignment for each sub-task. By sequentially executing these controllers in a hybrid fashion, one achieves the overall manipulation task.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct7_03">17:10-17:25, Paper ThCT7.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0489.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('489'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Act to See and See to Act: POMDP Planning for Objects Search in Clutter</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195707" title="Click to go to the Author Index">Li, Jue Kun</a></td><td class="r">National Univ. of Singapore</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101988" title="Click to go to the Author Index">Hsu, David</a></td><td class="r">National Univ. of Singapore</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116631" title="Click to go to the Author Index">Lee, Wee Sun</a></td><td class="r">National Univ. of Singapore</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab489" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0489.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Manipulation_Planning_and_Control" title="Click to go to the Keyword Index">Manipulation Planning and Control</a>, <a href="IROS16_KeywordIndexMedia.html#Integrated_Task_and_Motion_Planning" title="Click to go to the Keyword Index">Integrated Task and Motion Planning</a></span><br>
                           <strong>Abstract:</strong> We study the problem of objects search in clutter. In cluttered environments, partial occlusion among objects prevents vision systems from correctly recognizing objects. Hence, the agent needs to move objects around to gather information, which helps reduce uncertainty in perception. At the same time, the agent needs to minimize the efforts of moving objects to reduce the time required to complete the task. We model the problem as a Partially Observable Markov Decision Process (POMDP), formulating it as a problem of optimal decision making under uncertainty. By exploiting spatial constraints, we are able to adapt online POMDP planners to handle objects search problems with large state space and action space. Experiments show that the POMDP solution outperforms greedy approaches, especially in cases where multi-step manipulation is required.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct7_04">17:25-17:40, Paper ThCT7.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1019.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1019'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Multi-Contact Planning and Control for a Torque-Controlled Humanoid Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156101" title="Click to go to the Author Index">Werner, Alexander</a></td><td class="r">German Aerospace Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#165965" title="Click to go to the Author Index">Henze, Bernd</a></td><td class="r">German Aerospace Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196427" title="Click to go to the Author Index">Rodriguez, Diego A.</a></td><td class="r">German Aerospace Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196431" title="Click to go to the Author Index">Gabaret, Jonathan</a></td><td class="r">German Aerospace Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#167355" title="Click to go to the Author Index">Porges, Oliver</a></td><td class="r">German Aerospace Center (DLR)</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104075" title="Click to go to the Author Index">Roa, Maximo A.</a></td><td class="r">German Aerospace Center, DLR</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1019" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1019.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_Navigation" title="Click to go to the Keyword Index">Humanoid Navigation</a></span><br>
                           <strong>Abstract:</strong> Humanoid robots that need to traverse constrained and uncertain environments require a suitable combination of perception, planning and control. This paper presents an integrated pipeline that allows the robot to autonomously acquire visual information, define step locations, compute feasible multi-contact stances using hands and feet, and generate a motion plan to reach the desired goal even going through different contact states. The execution of the desired path is guaranteed through a passivity-based multi-contact controller. The approach is evaluated in simulations and experiments in different scenarios using the humanoid robot TORO.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct7_05">17:40-17:55, Paper ThCT7.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1514.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1514'); return false" title="Click to show or hide the keywords and abstract">Motion Planning Using Hierarchical Aggregation of Workspace Obstacles</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#187435" title="Click to go to the Author Index">Ghosh, Mukulika</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106343" title="Click to go to the Author Index">Thomas, Shawna</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105498" title="Click to go to the Author Index">Morales, Marco</a></td><td class="r">Inst. Tecnológico Autónomo De México</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106418" title="Click to go to the Author Index">Rodriguez, Samuel</a></td><td class="r">Texas A&M Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102662" title="Click to go to the Author Index">Amato, Nancy</a></td><td class="r">Texas A&M Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1514" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a></span><br>
                           <strong>Abstract:</strong> Sampling-based motion planning is the state-of-the-art technique for solving challenging motion planning problems in a wide variety of domains. While generally successful, their performance suffers from increasing problem complexity. In many cases, the full problem complexity is not needed for the entire solution. We present a hierarchical aggregation framework that groups and models sets of obstacles based on the currently needed level of detail. The hierarchy enables sampling to be performed using the simplest and most conservative representation of the environment possible in that region. Our results show that this scheme improves planner performance irrespective of the underlying sampling method and input problem. In many cases, improvement is significant, with running times often less than 60% of the original planning time.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct8"><b>ThCT8</b></a></td>
               <td class="r">#108</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct8" title="Click to go to the Program at a Glance"><b>Multi-Robot Systems 3</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104313" title="Click to go to the Author Index">O'Kane, Jason</a></td><td class="r">Univ. of South Carolina</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#117857" title="Click to go to the Author Index">Sycara, Katia</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct8_01">16:40-16:55, Paper ThCT8.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0092.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('92'); return false" title="Click to show or hide the keywords and abstract">Managing Environment Models in Multi-Robot Teams</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190040" title="Click to go to the Author Index">Koch, Pierrick</a></td><td class="r">LAAS-CNRS</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101697" title="Click to go to the Author Index">Lacroix, Simon</a></td><td class="r">LAAS/CNRS</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab92" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a>, <a href="IROS16_KeywordIndexMedia.html#Field_Robots" title="Click to go to the Keyword Index">Field Robots</a></span><br>
                           <strong>Abstract:</strong> Environment models are the primary matter to autonomous decisions for mobile robots, and also to cooperation within teams of robots that operate in the same environment. The decisions to take within a robot or a robot team relate to motions, perceptions and communications: various types of environment models are therefore required to evaluate and plan these actions. While the literature abounds with approaches to environment modeling using data perceived by the robots, very few work tackle the problem of {em managing} such models within a team of robots. Managing environment models implies first defining the proper data structures and associated mechanisms that allow both their efficient update and use by the decisional processes that require them, and second ensuring the models consistency as the robots evolve. This article presents the definition of ``AtLaas'', a framework dedicated to the managing of environment models within a robot team. It establishes the principles that govern the framework design, and proposes efficient data structures to store and manage data and models within the team. The relevance of the framework is illustrated throughout some examples.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct8_02">16:55-17:10, Paper ThCT8.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0246.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('246'); return false" title="Click to show or hide the keywords and abstract">Checkout My Map: Version Control for Fleetwide Visual Localisation</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#179163" title="Click to go to the Author Index">Gadd, Matthew</a></td><td class="r">Univ. of Oxford</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#105828" title="Click to go to the Author Index">Newman, Paul</a></td><td class="r">Oxford Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab246" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperating_Robots" title="Click to go to the Keyword Index">Cooperating Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Localization" title="Click to go to the Keyword Index">Localization</a></span><br>
                           <strong>Abstract:</strong> This paper is about underpinning long-term operations of fleets of vehicles using visual localisation. In particular it examines ways in which vehicles, considered as independent agents, can share, update and leverage each others' visual experiences in a mutually beneficial way. We draw on our previous work in Experience-based Navigation (EBN) [1], in which a visual map supporting multiple representations of the same place is built, yielding real-time localisation capability for a solitary vehicle. We now consider how any number of such agents might operate in concert via data sharing policies that are germane to the shared task of lifelong localisation. We rapidly construct considerable maps by the conjoining of work distributed to asynchronous processes, and share expertise amongst the team by the selective dispensing of mission-specific map contents. We demonstrate and evaluate our system against 100km of data collected in North Oxford over a period of a month featuring diverse deviation in appearance due to atmospheric, lighting, and structural dynamics. We show that our framework is capable of creating maps in a fraction of the time required by single-agent EBN, with no significant loss in localisation robustness, and is able to furnish robots on real-world forays with maps which require much less storage.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct8_03">17:10-17:25, Paper ThCT8.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0789.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('789'); return false" title="Click to show or hide the keywords and abstract">Forming Repeating Patterns of Mobile Robots: A Provably Correct Decentralized Algorithm</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#151483" title="Click to go to the Author Index">Song, Yang</a></td><td class="r">Univ. of South Carolina</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#104313" title="Click to go to the Author Index">O'Kane, Jason</a></td><td class="r">Univ. of South Carolina</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab789" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Networked_Robots" title="Click to go to the Keyword Index">Networked Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Path_Planning_for_Multiple_Mobile_Robots_or_Agents" title="Click to go to the Keyword Index">Path Planning for Multiple Mobile Robots or Agents</a></span><br>
                           <strong>Abstract:</strong> We describe a new decentralized algorithm for multi-robot systems to form arbitrary repeated lattice patterns. Prior work showed how to represent a desired pattern using a directed graph in which each edge is labeled with a rigid body transformation, and proposed an algorithm that accepts this graph as input and computes destinations for each robot using only local information. In this paper, we improve upon that result by describing a new algorithm, substantially different both in message passing procedure and in movement strategy, to resolve several limitations of the existing algorithm. We prove that, by executing this algorithm, the robots will form the desired lattice pattern in a bounded amount of time. We further show that, if the robots’ communication graph is connected at the start of the algorithm, it will remain connected throughout the algorithm’s execution. Using a simulation, we demonstrate that this algorithm works correctly for systems with dozens of autonomous robots to form various lattice patterns. Moreover, the experiments show a significant improvement in solution quality for our new algorithm compared to the previous approach.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct8_04">17:25-17:40, Paper ThCT8.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1027.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1027'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Robot Self-Assembly As Adaptive Growth Process: Collective Selection of Seed Position and Self-Organizing Tree-Structures</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#196426" title="Click to go to the Author Index">Divband Soorati, Mohammad</a></td><td class="r">Univ. of Paderborn</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117790" title="Click to go to the Author Index">Hamann, Heiko</a></td><td class="r">Univ. of Paderborn</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1027" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1027.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Self_Organised_Robot_Systems" title="Click to go to the Keyword Index">Self-Organised Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Swarm_Robotics" title="Click to go to the Keyword Index">Swarm Robotics</a>, <a href="IROS16_KeywordIndexMedia.html#Biologically_Inspired_Robots" title="Click to go to the Keyword Index">Biologically-Inspired Robots</a></span><br>
                           <strong>Abstract:</strong> Autonomous self-assembly allows to create structures and scaffolds on demand and automatically. The desired structure may be predetermined or alternatively it is the result of an artificial growth process that adapts to environmental features and to the intermediate structure itself. In a self-organizing and decentralized control approach the robots interact only locally and form the structure collectively. Designing a complete approach that allows the robot group to collectively decide on where to start the self-assembly, that adapts at runtime to environmental conditions, and that guarantees the structural stability is challenging and does not yet exist. We present an approach to self-assembly inspired by diffusion-limited aggregation that generates an adaptive structure reacting to environmental conditions in an artificial growth process. During a preparatory stage the robots collectively decide where to start the self-assembly also depending on environmental conditions. In the actual self-assembly stage, the robots create tree-like structures that grow towards light. We report the results of robot self-assembly experiments with 50 Kilobots. Our results demonstrate how an adaptive growth process can be implemented in robots. We briefly describe our future work of how to extend the approach to a 3-d growth process and how robot self-assembly as an open-ended adaptive growth process opens up a multiplicity of future opportunities.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct8_05">17:40-17:55, Paper ThCT8.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1710.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1710'); return false" title="Click to show or hide the keywords and abstract">Distributed Knowledge Leader Selection for Multi-Robot Environmental Sampling under Bandwidth Constraints</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185040" title="Click to go to the Author Index">Luo, Wenhao</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185041" title="Click to go to the Author Index">Khatib, Shehzaman Salim</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#169585" title="Click to go to the Author Index">Nagavalli, Sasanka</a></td><td class="r">Carnegie Mellon Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#107599" title="Click to go to the Author Index">Chakraborty, Nilanjan</a></td><td class="r">Stony Brook Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117857" title="Click to go to the Author Index">Sycara, Katia</a></td><td class="r">Carnegie Mellon Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1710" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Multi_Robot_Systems" title="Click to go to the Keyword Index">Multi-Robot Systems</a>, <a href="IROS16_KeywordIndexMedia.html#Distributed_Robot_Systems" title="Click to go to the Keyword Index">Distributed Robot Systems</a></span><br>
                           <strong>Abstract:</strong> In many multi-robot applications such as target search, environmental monitoring and reconnaissance, the multi-robot system operates semi-autonomously, but under the supervision of a remote human who monitors task progress. In these applications, each robot collects a large amount of task-specific data that must be sent to the human periodically to keep the human aware of task progress. It is often the case that the human-robot communication links are extremely bandwidth constrained and/or have significantly higher latency than inter-robot communication links, so it is impossible for all robots to send their task-specific data together. Thus, only a subset of robots, which we call the knowledge leaders, can send their data at a time. In this paper, we study the knowledge leader selection problem, where the goal is to select a subset of robots with a given cardinality that transmits the most informative task-specific data for the human. We prove that the knowledge leader selection is a submodular function maximization problem under explicit conditions and present a novel distributed submodular optimization algorithm that has the same approximation guarantees as the centralized greedy algorithm. The effectiveness of our approach is demonstrated using numerical simulations.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct9"><b>ThCT9</b></a></td>
               <td class="r">#204~205</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct9" title="Click to go to the Program at a Glance"><b>Climbing Robots</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#101936" title="Click to go to the Author Index">Hashimoto, Kenji</a></td><td class="r">Waseda Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#106490" title="Click to go to the Author Index">Liu, Dikai</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct9_01">16:40-16:55, Paper ThCT9.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0059.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('59'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Design of Wall-Climbing Robot Using Electrically Activated Rotational-Flow Adsorption Unit</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195127" title="Click to go to the Author Index">Zhou, Qiang</a></td><td class="r">Zhejiang Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#170594" title="Click to go to the Author Index">Li, Xin</a></td><td class="r">Zhejiang Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab59" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0059.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Climbing_Robots" title="Click to go to the Keyword Index">Climbing Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Wheeled_Robots" title="Click to go to the Keyword Index">Wheeled Robots</a></span><br>
                           <strong>Abstract:</strong> Traditional climbing robots that use vacuum suckers have some technical problems, e.g., inability to climb coarse walls, frictional resistance and abrasion of suckers, and poor obstacle-surmounting ability. In this study, a new negative pressure adsorption mechanism is applied to the design of a climbing robot. This mechanism generates and maintains negative pressure and adsorption force by using the air’s rotational inertia effect; therefore, the structure incorporating this mechanism is called the electrically activated rotational-flow adsorption unit. The most important characteristic of the adsorption unit is that it can function without being in contact with the wall, which fundamentally solves these technical problems associated with traditional climbing robots. In this study, we designed a square-shaped rotational-flow adsorption unit to improve the robot’s load ability (18% increase in the adsorption force) and designed a soft skirt structure to improve the robot’s obstacle-surmounting ability. Finally, we fabricated a prototype of the climbing robot and tested it on a actual wall (extremely coarse wall, wall containing a large groove). The test results show that our prototype robot can move stably on extremely coarse walls and can pass over large grooves easily.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct9_02">16:55-17:10, Paper ThCT9.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0570.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('570'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Design of Spring-Suspended Suction Cup Based on the Air Inflow Change with Inside Negative Pressure</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159837" title="Click to go to the Author Index">Matsuno, Takahiro</a></td><td class="r">Ritsumeikan</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101808" title="Click to go to the Author Index">Ma, Shugen</a></td><td class="r">Ritsumeikan Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab570" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0570.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Climbing_Robots" title="Click to go to the Keyword Index">Climbing Robots</a></span><br>
                           <strong>Abstract:</strong> The safety of working on walls has been improved by several adsorption mechanisms most of which sustain the absorption by pumps or other actuators. This research proposes an alternative method (a spring-suspended suction cup with a buckled plate spring) that can be attached for long durations without any vacuum pumping system. The negative pressure of the spring suspended suction cup is analyzed and the buckled plate spring is appraised by the energy efficiency and force over long adsorption times of the suction cup. The adhesion time of the suction cup is calculated and compared with that of the volume-fixed suction cup. Under high air inflow conditions, the spring-suspended suction cup adhered to the test surface for longer than the fixed-volume cup. The advantages of the spring-suspended suction cup were verified in experiments on a developed prototype.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct9_03">17:10-17:25, Paper ThCT9.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0608.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('608'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Exploring in 3D with a Climbing Robot: Selecting the Next Best Base Position on Arbitrarily-Oriented Surfaces</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156380" title="Click to go to the Author Index">Quin, Phillip</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#113516" title="Click to go to the Author Index">Paul, Gavin</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110174" title="Click to go to the Author Index">Alempijevic, Alen</a></td><td class="r">Univ. of Tech. Sydney</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106490" title="Click to go to the Author Index">Liu, Dikai</a></td><td class="r">Univ. of Tech. Sydney</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab608" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0608.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Climbing_Robots" title="Click to go to the Keyword Index">Climbing Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Path_Planning" title="Click to go to the Keyword Index">Motion and Path Planning</a>, <a href="IROS16_KeywordIndexMedia.html#Mapping" title="Click to go to the Keyword Index">Mapping</a></span><br>
                           <strong>Abstract:</strong> This paper presents an approach for selecting the next best base position for a climbing robot so as to observe the highest information gain about the environment. The robot is capable of adhering to and moving along and transitioning to surfaces with arbitrary orientations. This approach samples known surfaces, and takes into account the robot kinematics, to generate a graph of valid attachment points from which the robot can either move to other positions or make observations of the environment. The information value of nodes in this graph are estimated and a variant of A* is used to traverse the graph and discover the most worthwhile node that is reachable by the robot. This approach is demonstrated in simulation and shown to allow a 7 degree-of-freedom inchworm-inspired climbing robot to move to positions in the environment from which new information can be gathered about the environment.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct9_04">17:25-17:40, Paper ThCT9.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0678.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('678'); return false" title="Click to show or hide the keywords and abstract">Guide Rail Design for a Passive Suction Cup Based Wall-Climbing Robot</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#155350" title="Click to go to the Author Index">Ge, Dingxin</a></td><td class="r">Ritsumeikan Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#157863" title="Click to go to the Author Index">Ren, Chao</a></td><td class="r">Tianjin Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#100170" title="Click to go to the Author Index">Ma, Shugen</a></td><td class="r">Tianjin Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#159837" title="Click to go to the Author Index">Matsuno, Takahiro</a></td><td class="r">Ritsumeikan</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab678" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Climbing_Robots" title="Click to go to the Keyword Index">Climbing Robots</a></span><br>
                           <strong>Abstract:</strong> This paper designs a guide rail for a wall-climbing robot based on passive suction cups. The designed guide rail can guarantee stable climbing of a wall-climbing robot. Firstly, to design the parameters of the guide rail, properties of the utilized passive suction cup are experimentally studied. Then a guide rail is designed to distribute the forces of the attached suction cups. It guarantees that the front attached suction cup of the robot obtains a large enough reaction force from the attached surface. Experimental results show that the robot prototype with the designed guide rail is able to stably climb a surface without falling off, since the front suction cup of the robot prototype can be completely attached to the climbing surface.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct9_05">17:40-17:55, Paper ThCT9.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1330.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1330'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Trajectory Generation for Ladder Climbing Motion with Separated Path and Time Planning</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190069" title="Click to go to the Author Index">Sun, Xiao</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#101936" title="Click to go to the Author Index">Hashimoto, Kenji</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#172112" title="Click to go to the Author Index">Hamamoto, Shinya</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190334" title="Click to go to the Author Index">Koizumi, Ayanori</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190335" title="Click to go to the Author Index">Matsuzawa, Takashi</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#190336" title="Click to go to the Author Index">Teramachi, Tomotaka</a></td><td class="r">Waseda Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#102287" title="Click to go to the Author Index">Takanishi, Atsuo</a></td><td class="r">Waseda Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1330" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1330.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Climbing_Robots" title="Click to go to the Keyword Index">Climbing Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> This paper introduces a motion planning method to generate ladder climbing motion for a four-limbed robot. This method contains the following points: (1) independent planning of path and time in 3 dimensional space for trajectory planning; (2) path length minimization according to given midpoints. In trajectory planning, arc-length parameterization is used to separate path planning and time planning so that they can be done independently. After path is planned, time planning along the planned path can be given freely to meet our requirement, such as speed and acceleration adjustment for the protection of motors, optimization for dynamics analysis, dynamic obstacle avoidance and so on. Results from simulations and experiments authenticate the validity of our motion generation method.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thct10"><b>ThCT10</b></a></td>
               <td class="r">#206~208</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thct10" title="Click to go to the Program at a Glance"><b>Humanoid Locomotion</b></a></td>
               <td class="r">Regular session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#116765" title="Click to go to the Author Index">Tsuji, Toshiaki</a></td><td class="r">Saitama Univ</td></tr>
<tr><td>Co-Chair: <a href="IROS16_AuthorIndexMedia.html#134049" title="Click to go to the Author Index">Ames, Aaron</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct10_01">16:40-16:55, Paper ThCT10.1</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0306.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('306'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Real-Time Predictive Kinematic Evaluation and Optimization for Biped Robots</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#168508" title="Click to go to the Author Index">Hildebrandt, Arne-Christoph</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#195197" title="Click to go to the Author Index">Demmeler, Manuel</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158348" title="Click to go to the Author Index">Wittmann, Robert</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#171543" title="Click to go to the Author Index">Wahrmann, Daniel</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#182527" title="Click to go to the Author Index">Sygulla, Felix</a></td><td class="r">Tech. Univ. of Munich</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183873" title="Click to go to the Author Index">Rixen, Daniel</a></td><td class="r">Tech. Univ. München</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116678" title="Click to go to the Author Index">Buschmann, Thomas</a></td><td class="r">Google, Inc</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab306" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0306.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> Collision-free walking in cluttered environments is still an open issue for humanoids. Most current approaches use heuristics with large safety margins to plan the robot’s motion. That way, the chance of collisions can be greatly reduced but the robot movements are artificially limited. In this context, we extend our framework for motion generation and whole- body collision-avoidance by an on-line predictive kinematic parameter evaluation and optimization: we propose to evaluate the parameter set describing the walking pattern by integrating the full kinematic model of the robot. Initial parameter sets, which are kinematically infeasible due to kinematic limits or collisions, can be identified and adapted before the motion is executed. Starting with a feasible solution, the parameter set is optimized using a gradient method. Since the method is applied before each step, while the robot is executing the previous step, it is very reactive to changes in the environment or in the user input. The optimization method is not limited to a specific walking pattern representation, but it is applicable to different representations. We want to emphasize its suitability for real- time control. The optimization can be stopped if it exceeds a predetermined time budget. In that case, an executable but suboptimal result is used. The method is presented with simulation results obtained with our multi-body simulation. We have also validated the real-time performance in experiments with our humanoid Lola.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct10_02">16:55-17:10, Paper ThCT10.2</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0351.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('351'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Tricycle Manipulation Strategy for Humanoid Robot Based on Active and Passive Manipulators Control</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#177784" title="Click to go to the Author Index">Kimura, Kohei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#117479" title="Click to go to the Author Index">Nozawa, Shunichi</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#135552" title="Click to go to the Author Index">Kakiuchi, Yohei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106350" title="Click to go to the Author Index">Okada, Kei</a></td><td class="r">The Univ. of Tokyo</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#106348" title="Click to go to the Author Index">Inaba, Masayuki</a></td><td class="r">The Univ. of Tokyo</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab351" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/0351.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_Robots" title="Click to go to the Keyword Index">Humanoid Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_Control" title="Click to go to the Keyword Index">Motion Control</a>, <a href="IROS16_KeywordIndexMedia.html#Cooperative_Manipulators" title="Click to go to the Keyword Index">Cooperative Manipulators</a></span><br>
                           <strong>Abstract:</strong> Humanoid robot has the potential to manipulate wide range of tools in daily life. Arms and legs of humanoid robot contribute this ability. Above all, manipulation tasks for vehicles which are the same size as a life-sized humanoid or larger size than it require the operational motion by both arms and legs of humanoid robot. In addition to the arms and legs cooperative motion control, it is also important for humanoid robot to stabilize self posture during driving vehicle. In this research, we focus on the arms-legs-integrated manipulation task for tricycle controlled by humanoid robot. We propose dual manipulators control law that is defined as active manipulator which works movable objects such as handle and crank, and passive manipulator which follows the movement of this objects. We discuss the self stabilizing strategy for humanoid robot by both active manipulating legs as well as manipulation strategy for objects. Furthermore, this paper contributes the strategy of recognition and planning for outside obstacle situations and configures the tricycle manipulation system. Applying this proposed system, we show the experimental result for tricycle manipulation by life-sized humanoid robot HRP2-JSK on obstacle-mixed situation.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct10_03">17:10-17:25, Paper ThCT10.3</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/0792.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('792'); return false" title="Click to show or hide the keywords and abstract">A Novel Performance Measure for Biped Robots against Bounded Persistent Disturbances</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#156191" title="Click to go to the Author Index">Lee, Jongwoo</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#188358" title="Click to go to the Author Index">Kim, Jung Hoon</a></td><td class="r">Korea Inst. of Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#110832" title="Click to go to the Author Index">Oh, Yonghwan</a></td><td class="r">Korea Inst. of Science & Tech. (KIST)</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab792" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Legged_Robots" title="Click to go to the Keyword Index">Legged Robots</a>, <a href="IROS16_KeywordIndexMedia.html#Dynamics" title="Click to go to the Keyword Index">Dynamics</a></span><br>
                           <strong>Abstract:</strong> Despite successful demonstrations of outdoor walking by a few biped robots, performance measure for such robots has not been formally defined yet. The performance measure should be adequately defined by which one can evaluate how well the robot keeps from falling in the presence of disturbance. If such performance measure is suitably determined, designing a sort of optimal controller for stable outside walking would be possible. This paper firstly suggests to adopt the l_infty-induced norm defined on the linearized Poincar`e map as a novel performance measure for biped robots, in the presence of bounded persistent disturbance. In order to validate the measure, a nonlinear dynamic simulation is conducted by extending an existing simple model to walk on rough terrain, of which height variance is bounded by some maximum value. The measure exploited for the model is compared with the numerical result obtained from nonlinear dynamic simulation. Finally, an example of application of this measure is provided, which successfully predicts whether the system could overcome upcoming terrain roughness.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct10_04">17:25-17:40, Paper ThCT10.4</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1242.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1242'); return false" title="Click to show or hide the keywords and abstract">Force Control of a Jumping Musculoskeletal Robot with Pneumatic Artificial Muscles</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#183247" title="Click to go to the Author Index">Kaneko, Takeshi</a></td><td class="r">Saitama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#185441" title="Click to go to the Author Index">Sekiya, Masashi</a></td><td class="r">Saitama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116620" title="Click to go to the Author Index">Ogata, Kunihiro</a></td><td class="r">National Inst. of Advanced Industrial Science and Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#158571" title="Click to go to the Author Index">Sakaino, Sho</a></td><td class="r">Saitama Univ</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#116765" title="Click to go to the Author Index">Tsuji, Toshiaki</a></td><td class="r">Saitama Univ</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1242" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           
                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Force_Control" title="Click to go to the Keyword Index">Force Control</a>, <a href="IROS16_KeywordIndexMedia.html#Variable_Stiffness_Actuator_Design_and_Control" title="Click to go to the Keyword Index">Variable Stiffness Actuator Design and Control</a></span><br>
                           <strong>Abstract:</strong> This paper introduces a method of force control for a jumping biped robot to correctly control the ground reaction force during continuous jumping. Assuming dynamic motion such as jumping and running, the attitude of the robot depends on the dynamics in response to the ground reaction force. Therefore, controlling the ground reaction force is necessary for stabilizing the robot's motion. However, control of the ground reaction force involves a fundamental problem: feedback control does not work properly against the impact force owing to limitations in the control bandwidth. This study introduces a method for stiffness ellipse control of three antagonist pairs of six pneumatic artificial muscles. When the tip of the robot makes contact with the ground, an external force is induced in the direction of lower stiffness. By utilizing this property of the stiffness ellipse, it is possible to control the ground reaction force by feedforward control, which is not dependent on the control bandwidth. Based on this idea, impact force control at landing and jumping force control at takeoff were proposed to correctly control the ground reaction force during the continuous jumping. The results of several experiments convince us that the relationship between the ground reaction force and the stiffness ellipse is almost linear, and that the ground reaction force can be controlled with high reproducibility by adjusting the stiffness ellipse.
                        </div>
                     </td>
                  </tr>
               
<tr style="line-height: 0.2em"><td colspan="2">&nbsp;</td></tr>
<tr class="pHdr"><td valign="bottom"><a name="thct10_05">17:40-17:55, Paper ThCT10.5</a></td><td class="r">&nbsp;</td></tr>
<tr><td colspan="2"><span class="pTtl"><a href="./files/1583.pdf" title="Click to open the pdf file"><img src="images/pdf.png" height="12" border="0" alt=""></></a><a href="" onclick="viewAbstract('1583'); return false" title="Click to show or hide the keywords and abstract"><img src="images/att.png" style="border: 0; margin: 0px 4px 0px 0px" alt=""></>Efficient HZD Gait Generation for Three-Dimensional Underactuated Humanoid Running</a></span></td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160906" title="Click to go to the Author Index">Ma, Wenlong</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#160744" title="Click to go to the Author Index">Hereid, Ayonga</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#148199" title="Click to go to the Author Index">Hubicki, Christian</a></td><td class="r">Georgia Inst. of Tech</td></tr>
<tr><td><a href="IROS16_AuthorIndexMedia.html#134049" title="Click to go to the Author Index">Ames, Aaron</a></td><td class="r">Georgia Inst. of Tech</td></tr>

                  <tr>
                     <td colspan="2" style="padding: 0px">
                        <div id="Ab1583" style="padding-top: 10px; padding-left: 4px; padding-right: 4px; display: none">
                           <strong>Attachments:</strong> <span style=""><a href="./files/1583.VI.mp4" title="Click to open">Video Attachment</a></span><br>

                           <span style="line-height: 2em"><strong>Keywords:</strong> <a href="IROS16_KeywordIndexMedia.html#Humanoid_and_Bipedal_Locomotion" title="Click to go to the Keyword Index">Humanoid and Bipedal Locomotion</a>, <a href="IROS16_KeywordIndexMedia.html#Optimal_Control" title="Click to go to the Keyword Index">Optimal Control</a>, <a href="IROS16_KeywordIndexMedia.html#Motion_and_Trajectory_Generation" title="Click to go to the Keyword Index">Motion and Trajectory Generation</a></span><br>
                           <strong>Abstract:</strong> Dynamic humanoid locomotion is a challenging control problem, and running is especially difficult to achieve, given the underactuation inherent to aerial domains. Previous work developed a gait-generating optimization framework for dynamic locomotion in the context of hybrid zero dynamics, producing stable 3D walking on the humanoid hardware platform DURUS. Here, we demonstrate that this optimization method also extends to stable 3D running. Gaits generated from the optimization, which optimizes the dynamics of all 23 degrees of freedom to maximize energy economy, results in stable running in a DURUS simulation model. Notably, the presented running is underactuated in all domains, due to DURUS' spring-legged design. Further, we generated 25 different running gaits, over a range of speeds (1.5-3.0 m/s), to demonstrate the reliability of solving the large-scale nonlinear program. We report statistical performance of the optimization in successfully generating stable running (average computation time: 323 seconds) in an effort to establish a benchmark for large-scale gait generation. We inspected this array of gaits across speeds, noting recognizable trends in optimized strategies from prior studies on lower-order models, (e.g. both increased step frequency and step length with speed), along with the first reported cost-of-transport curve for a 3D humanoid running model. We consider this result an important step toward humanoid running on the DURUS hardware platform.
                        </div>
                     </td>
                  </tr>
               
</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thwt12"><b>ThWT12</b></a></td>
               <td class="r">Grand Ballroom</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thwt12" title="Click to go to the Program at a Glance"><b>Competition Winner Talk</b></a></td>
               <td class="r">Session</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#104237" title="Click to go to the Author Index">Moon, Hyungpil</a></td><td class="r">Sungkyunkwan Univ</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thf1t11"><b>ThF1T11</b></a></td>
               <td class="r">#301</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thf1t11" title="Click to go to the Program at a Glance"><b>Government Forum</b></a></td>
               <td class="r">Forum</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#105736" title="Click to go to the Author Index">Kang, Sungchul</a></td><td class="r">Korea Inst. of Science & Tech</td></tr>

</table><table class="trk">

             <tr><td colspan="2">&nbsp;</td></tr>
              <tr class="sHdr">
               <td><a name="thf2t13"><b>ThF2T13</b></a></td>
               <td class="r">#203</td>
              </tr>
             
             <tr class="sHdr">
               <td nowrap><a href="IROS16_ProgramAtAGlanceMedia.html#thf2t13" title="Click to go to the Program at a Glance"><b>Autonomous Technologies and Their Societal Impact Forum</b></a></td>
               <td class="r">Forum</td>
             </tr>
            
<tr><td>Chair: <a href="IROS16_AuthorIndexMedia.html#102514" title="Click to go to the Author Index">Madhavan, Raj</a></td><td class="r">Amrita Univ</td></tr>

</table>
</div>

<p>&nbsp;<br>&nbsp;</p><p>&nbsp;<br>&nbsp;</p>


</div>

</body>

</html>
