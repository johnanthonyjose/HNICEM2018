<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>IROS16</title>
<link href="style.css" rel="stylesheet" type="text/css" media="screen" />
</head>

<body leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">
<div class="c" id="TheTop"></div>
<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h2>Workshops and Tutorials</h2>
</td></tr>
</table>

<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Challenges in Robot Competitions
</h3>
<a href="https://sites.google.com/site/challengesinrc/home" target=_new>
https://sites.google.com/site/challengesinrc/home
</a>
<p align="justify">
Full Day Workshop MoFT1                        
<br>
Mon, Oct 10, 08:30-18:00, Grand Ballroom
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Tomomasa Sato (New Energy and Industrial Technology Development Organization), Bruno Siciliano (Univ. of Naples Federico II), Henrik I. Christensen (Georgia Institute of Technology), Minoru Asada (Osaka University), Elena Messina (U.S. National Institute of Standards & Technology), Hiroyuki Okada (Tamagawa University), Kazuhito Yokoi (AIST), Satoshi Tadokoro (Tohoku University)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Robot competitions/challenges aim to create an opportunity to bring together the most advanced robot technologies globally and to challenge the human limits.
</p><p align="justify">
By solving actual problems in the society, the robot competitions/challenges deepen people’s understanding of robots and induce positive discussions that would lead to concrete uses and applications of robots. In this workshop, we introduce several robot competitions/challenges all around the world such as euRathlon, EuRoC, RoCKIn, DRC, RoboCup, ARGOS, etc. and exchange information of these events for future organizers of robot competitions/challenges.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Bruno Siciliano (Univ. of Naples Federico II), Alan Winfield (Univ. of the West of England, Bristol), Pedro U. Lima (Univ. of the West of England, Bristol), Itsuki Noda (National Institute of Advanced Industrial Science and Technology), Grill Prat (Toyota Motors), Curtis Carson (Airbus), Roland Siegwart (ETH Zurich)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>

<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Human-Robot Collaboration: Towards Co-Adaptive Learning through Semi-Autonomy and Shared Control
</h3>
<a href="http://www.ausy.tu-darmstadt.de/Workshops/IROS2016" target=_new>
http://www.ausy.tu-darmstadt.de/Workshops/IROS2016
</a>
<p align="justify">
Full Day Workshop MoFT2                              
<br>
Mon, Oct 10, 08:30-18:00, Room 111
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Luka Peternel (HRI2, ADVR, IIT), Guilherme Maeda (IAS, TU Darmstadt), Leonel Rozo (IIT), Serena Ivaldi (INRIA Nancy Grand-Est), Claudia Pérez D'Arpino (MIT), Julie A. Shah (MIT), Jan Babic (JSI), Tamim Asfour (KIT), Erhan Oztop (Ozyegin University), Jan Peters (TU Darmstadt)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
One of the major goals in robotics is to make robots operate in unstructured environments under unpredictable conditions. Of great interest is the ability of robots to collaborate with human counterparts in various complex tasks and share tools in either industrial or daily-life settings. Such robots can address the unprecedented growth of the elderly population by acting as caregivers, or as body-part enhancement devices (i.e. prostheses and exoskeletons). Successful human-robot collaboration usually involves unforeseen interactions and requires a high degree of safety, mutual adaptation and shared control between the acting agents.
</p><p align="justify">
The concept of mutual adaptation requires new forms of high-level reasoning and control to enable optimal interaction and collaboration. Addressing conditions that arise when human-robot joint actions are initially inadequate, such as skill gap between collaborating agents, mutual improvement, and different speed of individual improvement can be extremely challenging. While the human partner in human-robot collaboration is usually considered an expert, her/his behaviour may change over time as a result of self-improvement, gradual improvement of the robot or mutual improvement due to the novelty of task. Therefore, human adaptation and improvement during the collaboration cannot be neglected and the robot should adapt to the varying human behaviour. In the opposite scenario, the human can be inexperienced and the robot proficient in the given task. Here, the robot should adapt its behaviour to accommodate for slower or easier execution in the initial stages to help the human to improve.
</p><p align="justify">
Methods to assess the competence of each member are essential to decide when to switch roles in collaborative tasks. New algorithms area also needed to adapt joint human-robot skills according to individual preferences and to transfer such skills to different scenarios and users. In addition, new methods are required to dynamically incorporate human decisions and instructions while interactively enriching the current repertoire of collaborative skills of semi-autonomous robot. Another challenge regards the use of multiple feedback information and multiple motor commands. When the robot learns from the human and/or adapts to his/her behaviour in an online manner during the execution of a collaborative task, differences in behaviour between both agents can produce undesirable or even unsafe conditions. This aspect is especially relevant when the controlled task and/or tools are shared between the human and the robot. To resolve this issue, a share control framework is necessary to arbitrate and blend their roles, actions/intentions and cues from different modalities.
</p><p align="justify">
The goal of the workshop is to (1) bring together top experts in human-robot collaboration and robot learning fields, (2) discuss the state-of-art in the field of shared control in human-in-the-loop robot learning and (3) lay down promising future research directions for co-adaptation in human-robot collaboration.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Heni Ben Amor (Arizona State University), Sylvain Calinon (Idiap Research Institute), Anca Dragon (Univ. of California, Berkeley), Abderrahmane Kheddar  (CNRS), Ross Knepper (Cornell University), Dongheui Lee (TU Munich), Manuel Lopes (Inria Bordeaux), Yukie Nagai (Osaka University), Fumihide Tanaka (Univ. of Tsukuba)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>



<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Microrobots for Next Generation Biomedical Applications
</h3>
<a href="https://mrc.dgist.ac.kr:448/index.php?mid=page_aPNS21" target=_new>
https://mrc.dgist.ac.kr:448/index.php?mid=page_aPNS21
</a>
<p align="justify">
Full Day Workshop MoFT3                              
<br>
Mon, Oct 10, 08:30-18:00, Room 112
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Hongsoo Choi (Daegu Gyeongbuk Institute of Science & Technology), Brad Nelson (ETH Zurich), Li Zhang (The Chinese University of Hong Kong)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Micro-/nanorobots have attracted substantial efforts from academic, industrial, and biomedical communities with multidisciplinary research interests. In recent years, rapid growth has been made in the field of remotely actuated micro-/nanorobotic systems because of the significant development in micro-/nanofabrication technology and magentic control system. In addition, many high-impact biomedical applications are being developed by next generation microrobots. Micro-/nanorobotic systems are expected to provide promising revolutionary advances in medicine, biology, environment, and others because of many unique functionalities of micro-/nanorobots. The goal of this workshop on “Microrobots for next generation biomedical applications“ is to bring together world-leading scholars with multidisciplinary interests into a forum, to show the state-of-the-art research and advances in fabrication, control, material, medical imaging of remotely actuated micro-/nanorobotic systems, by presenting cutting edge technologies and addressing challenges in the biomedical applications of micro-/nanorobotic systems. The audience will realize various limitations, requirements, and future research directions. This workshop would be rewarding for academic, industrial, and biomedical communities to know and discuss about recent research results, new challenges and promising future applications. Therefore, this one day workshop on “Microrobots for next generation biomedical applications“ would be a great event to collect and demonstrate some of the latest progress of this emerging but fast growing field, and to stimulate future R&D on micro-/nanorobotics.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Hongsoo Choi  (DGIST), Brad Nelson (ETH Zurich), Li Zhang (The Chinese University of Hong Kong), Sylvain Martel ( POLYTECHNIQUE MONTREAL), Fumihito Arai (Nagoya University), Antoine Ferreira (INSA Centre Val de Loire), David Cappelleri (Purdue University), Minjun Kim (Drexel University), Hong-Bo Sun (Jilin University), Jungwon Yoon (Gyeongsang National University), Qiang He (Harbin Institute of Technology), Jaesung Hong (DGIST), ByungJu Yi (Hanyang University), Gunhee Jang (Hanyang University)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>

<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Shared Autonomy
</h3>
<a href="https://aiweb.techfak.uni-bielefeld.de/iros2016_workshop_shared_autonomy/" target=_new>
https://aiweb.techfak.uni-bielefeld.de/iros2016_workshop_shared_autonomy/
</a>
<p align="justify">
Full Day Workshop MoFT4                              
<br>
Mon, Oct 10, 08:30-18:00, Room 101
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Britta Wrede (Bielefeld University), Wolfram Burgard (Univ. of Freiburg), Helge Ritter (Bielefeld University), Sven Wachsmuth (Bielefeld University)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
With robots entering our every day lives the question of how to share autonomy in joint actions comes into the focus of robotics research. Shared autonomy arises, if two autonomous agents interact to coordinate their capabilities. This coordination can occur with regard to different aspects, such as cooperative task scheduling to minimize interference, temporal alignment to create synergies from behavior synchronization, or task partitioning to gain from complementary capabilities. Moreover, such coordination benefits if the two agents have knowledge about their mutual capabilities, resource constraints or internal states, such as beliefs, interests, intentions or even moods - if one of the agent is a human or a robot capable of social behavior. Some of this knowledge may be given, but some may be obtainable only through learning or interactive shared actions during which new information and insights arise. Therefore, Shared Autonomy opens the wider scope of understanding task-directed optimization at the autonomy level of each agent in its coupling with a spectrum of interaction-related constraints and value functions that arise when the autonomous agents have rich representations that include the representation of their self in its interaction with a partner, jointly embedded in a shared context. This entails a range of consequences for further research: 
<ol>
<li>How can we achieve a stronger focus on the perception of user intention and user state and their integration with the robot's world perception, intentions and state? By better recognizing the user's (local) intentions the robot can provide local support for achieving joint goals. This entails both, physical as well as communicative intentions and thus requires a broader model of the user that unifies task and communication models in a coherent way.
<li>Further, how can we achieve a relaxation of the constraints on robot autonomy? By allowing for less than optimal plan solutions and executions by the robot new space for emergent collaborative behavior is opened up that may exceed the robot's world model. However, if this criterion is relaxed a new optimization criterion is needed. How can this be achieved?
<li>Related to this, how can we achieve learning capabilities that extend the robot's active world model? In other words, the robot should be able to take advantage of emerging joint goal-directed behavior by enlarging its world model. How can we achieve to break this research barrier?
</ul>
With this workshop we want to bring together robotics researchers with different perspectives in order to discuss and challenge existing concepts of shared autonomy and, stimulated by above considerations, provide a platform for the formulation of new ideas and proposals to overcome existing limitations. We see this as an important topic for robotic research in the future and expect continued workshops on this topic to build a platform where future research directions and strategies will be discussed.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Rachid Alami (LAAS Toulouse), Aude Billard (EPFL Lausanne), Henrik Christensen (Georgia Tech), Marc Hanheide (Univ. of Lincoln), Giorgio Metta (IIT Genova), Adriana Tapus (ENSTA Paris Tech), Manuel Lopez (CNRS Bordeaux), Katharina Muelling (CMU Pittsburgh), Siddhartha Srinivasa (CMU Pittsburgh), Minoru Asada (Asada Laboratory)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Safety-Related Sensing for Collaborative Applications
</h3>
<a href="http://home.deib.polimi.it/zanchettin/IROS2016/" target=_new>
http://home.deib.polimi.it/zanchettin/IROS2016/
</a>
<p align="justify">
Full Day Workshop MoFT5                              
<br>
Mon, Oct 10, 08:30-18:00, Room 102
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Hao Ding (ABB Corporate Research Germany), Fabrizo Flacco (CNRS), Mikael Hedelind (ABB Corporate Research), Andrea Zanchettin (DEIB)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
During the past decade, the interest in safe human-robot collaboration (HRC) for applications in industrial production has developed, from a niche research topic to a broad effort encompassing activities, from basic research to application profiles, and from standardization to biomechanics and ergonomics. The driving force behind the entire effort is the vision that practically relevant industrial scenarios will include both human workers with their specific expertise and robotic production assistants with their characteristic strengths, combining forces to empower a production facility with superior productivity and flexibility. In this scenario, the sensing and perception of the human operator is crucial. From the one hand, this need pushed companies on the development of new sensing technologies. From the other hand, researches studied how to use conventional sensors for perceiving the information needed to ensure safety. A review of such developments, and a friendly exchange of ideas and point of views between academy and industries, is the main target of the proposed workshop. Previous workshops on ICRA or IROS had the focus on sensing, but none of them was tailored for safety-related sensing, which has the potential for industrial applications.
</p><p align="justify">
This workshop is the focus of the proposed workshop, where we would like to exchange ideas on:
<ul>
<li>Safety sensing requirements for collaborative application;
<li>State-of-the-art safety sensing technology, covering scientific research, prototypes and existing products.
</ul>
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Alwin Hoffmann (Universtaet Augsburg), Bjoern Matthias (ABB Corporate Research), Nicola Pedrocchi (Institute of Industrial Technologies and Automation), Jeremy A. Marvel (NIST), Otto Goernemann (Sick), Sami Haddadin (Institute of Automatic Control), Thomas Pilz (Pilz), Jag-bok Song (Intelligent Robotics Lab.), Roberta N. Shea (Rockwell Automation)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Integrating Multiple Knowledge Representation and Reasoning Techniques in Robotics (MIRROR-16)
</h3>
<a href="http://aass.oru.se/Agora/MIRROR-2016/" target=_new>
http://aass.oru.se/Agora/MIRROR-2016/
</a>
<p align="justify">
Full Day Workshop MoFT6                              
<br>
Mon, Oct 10, 08:30-18:00, Room 103
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Vaishak Belle (KU Leuven), Christian Dornhege (Univ. of Freiburg), Fredrik Heintz (Linköping University), Joachim Hertzberg (Univ. of Ösnabruck), George Konidaris (Duke University), Benjamin Kuipers (Univ. of Michigan), Lars Kunze (Univ. of Birmingham), Uwe Köckemann  (Örebro University), Fabien Lagriffoul (Örebro University), Morteza Lahijanian (Rice University), Gerhard Lakemeyer (RWTH Aachen University), Shella Mcllraith (Univ. of Toronto), Andrea Orlandini (ISTC CNR), Jennifer Renoux (Örebro University), Alessandro Saffiotti (Örebro University), Hao Zhang (Colorado School of Mines)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The ability of a robotic system to reason about its surroundings, its goals, and its actions, is paramount to developing robots that act autonomously and appropriately. However, the common goal of AI and Robotics researchers to realize intelligent robot systems has not yet led to fully AI-driven robots, in spite of great attainments in both research areas. One of the major hindrances is the lack of attention to integrated reasoning. This is the problem of jointly reasoning about heterogeneous and inter-dependent aspects of the world, expressed in different forms and at different levels of abstraction. The focus of this workshop is on the general techniques, the applications, the scopes, and the challenges that lie behind the integration of several reasoning systems. 
</p><p align="justify">
This workshop will stimulate the development of much needed methodologies and tools for addressing the integrated reasoning problem in a systematic way. Such methodologies and tools are necessary to avoid two important and well-known issues in Robotics. First, systems composed of different modules implementing specialized algorithms which are integrated in an ad-hoc manner are more difficult to replicate. Second, the underlying integration techniques, often a big part of realization, cannot be used to build other integrated reasoning systems. These significantly hinder advancement in the field of intelligent robotics. This workshop is instrumental in bringing these problems to light. It will provide a venue for Robotics and AI researchers to exchange the lessons learned from different special cases of integrated reasoning. This will foster interest in general methods that address different applications, robot systems, and requirements.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Marc Hanheide (Univ. of Lincoln), Esra Erdem (Sabanci University), Andrew Tinka (Amazon Robotics), Volker Krüger (Aalborg University), Andrzej Pronobis ( Univ. of Washington)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Evaluation and Benchmarking of Underactuated and Soft Robotic Hands
</h3>
<a href="http://benchsofthands_ws_iros16.diism.unisi.it/" target=_new>
http://benchsofthands_ws_iros16.diism.unisi.it/
</a>
<p align="justify">
Full Day Workshop MoFT7                              
<br>
Mon, Oct 10, 08:30-18:00, Room 104
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Maximo Roa (German Aerospace Center), Domenico Prattichizzo (Univ. of Siena), Monica Malvezzi (Univ. of Siena), Maria Pozzi (Univ. of Siena)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The aim of this workshop is to help in the growing need of mathematical tools and shared standards in the emergent field of soft manipulation. In particular, it will tackle the problem of finding innovative ways to evaluate grasps with underactuated and soft robotic hands. The development of such devices is a cutting-edge research topic that requires an interdisciplinary approach. In this context, having a common benchmarking framework for assessing the quality of compliant and underactuated manipulation systems could foster fruitful scientific collaborations, drive the design of new robotic hands and facilitate the grasp execution process with existing hands.
</p><p align="justify">
Benchmarking robotic hands is particularly problematic due to the complexity of these mechanisms and the wide range of tasks they are expected to accomplish. They can be evaluated based on their physical characteristics (weight, number of DOFs, power consumption, etc.) and on their functional performance. The problem of computing the quality of grasps performed by underactuated and compliant hands has been rarely addressed in the literature. Classical quality indexes are mainly thought for precision grasps with fully actuated hands, and either compute the optimal location of contact points on the object, or the optimal hand configuration. These concepts, however, may not be relevant when dealing with underactuated and compliant hands that adapt to the objects’ shape and are likely to perform power grasps, for which the quality evaluation based on traditional approaches has high computational costs. In addition, approximating the real contact points/areas becomes difficult when dealing with soft continuous robotic hands like the RBO Hand 2.
</p><p align="justify">
More recently, the use of object databases or grasp taxonomies has tried to cover the need for standardized benchmarking tasks. This workshop will not only open a debate on the application of these methods to underactuated and soft hands, but will also address how and to what extent human grasping can be used as a reference for this type of hands. The introduction of soft hands that exploit environmental constraints to perform manipulation and grasping tasks opens also new and interesting scenarios for learning from human strategies and adapting them for robotic manipulation. Also, the use of underactuation, although limiting the ability for in-hand manipulation, still offers a manipulation workspace that can be effectively exploited for different applications.
</p><p align="justify">
This workshop will bring together researchers with different backgrounds to exchange ideas on the topics outlined above, with inspiring talks to sparkle discussions among the assistants, contributions of posters and demos to illustrate the latest achievements in the field both from the hardware and software perspective, and with a round table and continuous debate to try to converge towards new ideas that can guide the design, planning, and control of soft manipulation.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Oliver Brock (Technische Universität Berlin), Antonio Bicchi (Univ.of Pisa), Aaron Dollar (Yale University), Ravi Balasubramanian (Oregon State University), Sven Behnke (Univ. of Bonn), Domenico Prattichizzo (Univ. of Siena), Nancy Pollard (Carnegie Mellon University), Maximo A. Roa (Institut für Robotik und Mechatronik), Joseph A. Falco (NIST)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Artistically Skilled Robots
</h3>
<a href="http://www.idiap.ch/workshop/iros2016/" target=_new>
http://www.idiap.ch/workshop/iros2016/
</a>
<p align="justify">
Full Day Workshop MoFT8                              
<br>
Mon, Oct 10, 08:30-18:00, Room 105
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Frederic Fol Leymarie (Goldsmiths), Sylvain Calinon (Idap Research Institute), Daniel Berio (Goldsmiths)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The goal of the workshop is to discuss the state of the art and the future of artistic applications in robotics. This is a maturing, but still novel area of R&D in robotics, which involves modeling and understanding a complex and multifaceted human behaviour that includes: (i) perceptual abilities, (ii) generative abilities, (iii) creativity, (iv) reflective abilities, (v) pedagogical abilities, and (vi) social skills. The workshop will concentrate on developments in robotic systems that can have the capacity to understand artistic styles through practice, to simulate the human art creation process, to produce artworks with a given style, and further explore and develop novel styles, alone or in collaboration with other robots or humans. The proposed theme also involves to jointly deepen our understanding of human creativity, while advancing robotic systems capable of producing and evaluating distinctive artistic styles, and having the capacity to interact with the world through embodied creative actions.
</p><p align="justify">
In Personal Robotics R&D, one of the key challenges is to develop robotic platforms that can provide multiple adaptable skills and that can exist and interact with humans in a useful, educational and playful manner. This requires going beyond performative-only applications of robots, and developing robotic systems that are able to naturally interact with humans and that are responsive to human activities and sensibilities. The robotic embodiment of the creative processes involved in art production, observation and appreciation, is a crucial step in this direction.
</p><p align="justify">
The workshop will for example discuss (but is not limited to) visual art practice, including sketching, drawing, painting, calligraphy, sculpting and novel forms of digital fabrication (e.g. ceramics, additive manufacturing). Arts provide a testbed for the embodiment of complex skills in robots, such as natural skilled motions, gestures and complex interactions with the environment and humans. In order to tackle the broadness of this topic, we propose a highly interdisciplinary set of speakers with expertise at the crossroad of Robot Control, Movement Science, A.I./Machine Learning, Cognitive Science, Computer Graphics, the Visual Arts, Psychology and Neuroscience. We expect contributions submitted to the workshop to be similarly multidisciplinary, and thus broaden the general interest of this workshop and spark inspiration and topics for discussion between the participants. Finally, we also plan to have a follow-up publication in the form of a book or a special issue.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Kendra Byrne (Google), Louis-Philippe Demers (NTU), Kathrin Dörfler (Cramazio Kohler Research), Damith Herath (Human Centred Technology Research Centre), Katsushi Ikeuchi (Microsoft Research Asia), Seichiro Katsura (Keio University), Heather Knight (Carnegie Mellon University), Michel Taix (LAAS-CNRS), Katsuyoshi Tsujita (Osaka Institute of Technology)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>



<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Virtual Neurorobotics in the Human Brain Project
</h3>
<a href="http://www.fzi.de/en/research/projekt-details/human-brain-project/iros-2016-neurorobotics-workshop/" target=_new>
http://www.fzi.de/en/research/projekt-details/human-brain-project/iros-2016-neurorobotics-workshop/
</a>
<p align="justify">
Full Day Workshop MoFT9                              
<br>
Mon, Oct 10, 08:30-18:00, Room 106
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Stefan Ulbrich (FZI Research Center for Information Technology), Rüdiger Dillmann (Karlsruhe Institute of Technology), Cecilia Laschi (Scuola Superiore Sant’Anna), Egidio Falotico (Scuola Superiore Sant’Anna)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
IROS 2016 Tutorial 
“Virtual Neurorobotics in the Human Brain Project”
</p><p align="justify">
Neurorobotics is quite a young discipline that applies insights from research in computational neuroscience and medicine to robotics. The benefits from this interdisciplinary approach are two-fold. On the one hand, robotics provides embodiments that can be used to develop principles for and evaluate functional neural circuits or even models of whole brains. On the other hand, robotics research will also greatly benefit from neuroscience with respect to creating adaptive and robust control and perception principles. One of the problems researchers in this field are facing is the limited access to hardware (e.g., robots or novel neuromorphic technologies) which often come at high expenses or limited availability. 
</p><p align="justify">
To deal with this problem, the Neurorobotics Platform (NRP) in the subproject Neurorobotics of the Human Brain Project has been developed and released to the public earlier this year. It provides access to state-of-the-art tools such as robot and brain simulators, designers for creating experiments, environments, and brain and robot models. Researchers can define and run closed-loop experiments entirely in a web-based application, which runs on many devices, without the need for neither local installations nor administration expertise. Running centralized on high-performance clusters, it also transparently grants its users access to computing resources that are not commonly available. While the NRP mainly targets neurorobotics, is also interesting for roboticists that look for an easy-to-setup virtual experimentation setup. 
</p><p align="justify">
The objective of this tutorial session is to present this technology, inviting for a constructive discussion about virtual neurorobotics, and also to address further topics with respect to neurorobotics. The tutorial session is divided into invited talks about related topics (virtual neurorobotics, neuromorphic hardware and computational neuroscience and robotics) and a hands-on session in which participants are guided through a tutorial showing the capabilities of the Neurorobotics Platform. 
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
F. Röhrbein (Technische Universität München), Guilio Sandini (Italian Institute of Technology), Ansgar Büschges (Univ. of Cologne), Yoshihiko Nakamura (Univ. of Tokyo), Heinrich Bülthoff ( Max Planck), Chris Eliasmith (Univ. of Waterloo)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>

<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Dexterity Acquisition in Object Manipulation
</h3>
<a href="http://zkks.w3.kanazawa-u.ac.jp/IROS2016WS/" target=_new>
http://zkks.w3.kanazawa-u.ac.jp/IROS2016WS/
</a>
<p align="justify">
Full Day Workshop MoFT10                             
<br>
Mon, Oct 10, 08:30-18:00, Room 107
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Tetsuyou Watanabe (Kanazawa University), Kensuke Harada (Osaka University), Mitsunori Tada (National Institute of Advanced Industrial Science and Technology), 
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The aim of this workshop is to understand how human acquires dexterity in object manipulation, discuss the possibility of its application in robotic systems, and to draw key strategies for dealing with robotic dexterous manipulation in next generation. 
</p><p align="justify">The level of dexterous manipulation by robots is currently far from that of human being. What can improve the ability of robots? One hint might be to understand the approaches of human being in dexterity acquisition. 
</p><p align="justify">Software viewpoints: Robotic surgical systems are now popular for minimally invasive surgeries. In order to operate the robot, surgeons have to learn complex procedures. The methodology for facilitating the learning process and investigation of human behavior in the learning process could provide an insight for constructing learning based dexterous manipulation by robots. Prosthetic hand and arm are controlled by amputee people via neural signals such as EMG or EEG. The object manipulation has to be done by the limited number of control inputs. The control strategies for prosthetic hand could be a candidate of new control schema for robotic manipulation. The hypothesis of muscle synergy, which is considered to be a key for dexterity in human, also could provide valuable insights on robotic manipulation.
</p><p align="justify">Hardware viewpoints: The structure of human finger and hand play an important role for dexterous manipulation. It was acquired in the process of evolution. The key structures for dexterity are also valid for key structure of robotic hand design.
</p><p align="justify">Software viewpoints can provide new planning strategy or new control schema, while hardware viewpoints can provide new design of robotic hands (and arms). By elevating a relationship between the both viewpoints, this workshop will accelerate to generate next challenge topics in dexterous manipulation by robots.
</p><p align="justify">This workshop will make an opportunity of close interaction between researchers in different fields, in order to make a trigger for next object manipulation challenge.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Jumpei Arata (Kyushu University), Allison M. Okamura (Stanford University), Zhe Xu (Yale University), Koh Hosoda (Osaka University), Kazuhiko Seki (National Institute of Neuroscience), Ryuta Ozawa (Ritsumeikan University), Kenji Tahara (Kyushu University), Mitsunori Tada (Human Informatics Research Institution), Kensuke Harada (Osaka University), Alberto Rodriguez (Massachusetts Institute of Technology), Tetsuyou Watanabe (Kanazawa University)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>



<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Perspectives on Analysis and Design of Human-Centered Robotics
</h3>
<a href="https://people.eecs.berkeley.edu/~dsadigh/IROS16_Workshop/" target=_new>
https://people.eecs.berkeley.edu/~dsadigh/IROS16_Workshop/
</a>
<p align="justify">
Full Day Workshop MoFT11                             
<br>
Mon, Oct 10, 08:30-18:00, Room 108
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Dorsa Sadigh (UC Berkeley), Katherine Driggs-Campbell (UC Berkeley), Jaime Fisac (UC Berkeley), Robert Matthew (UC Berkeley)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
It is an exciting and pivotal moment in the history of robotics. As the gap between theoretical research and fully-fledged technology continues to close, important advances from mechanical design to decision algorithms are enabling robots to reliably carry out more complex tasks than ever before, unlocking an enormous potential for new applications. Once confined to the manufacturing floor, robots are quickly entering the public space at multiple levels: drones, surgical robots and self-driving cars are becoming tangible technologies impacting the human experience. Most of these new opportunities will require robotic systems to closely interact with human beings in their natural environments, which challenges the robotics community to look beyond its research, and in the midst of increasingly powerful statistical methods, the time is finally ripe for robotics to deal with the elephant in the room: us. Of course, efforts are already underway. Yet, even as ongoing research in the young field of human-robot-interaction contributes a variety of valuable insights, it is not always clear how to translate these insights into general principles that can then be applied to robotic planning, verification, and control. On one hand, the knowledge gained from cognitive and behavioral studies needs to be condensed into actionable predictive models that can naturally integrate into existing frameworks to inform the design and operation of robotic systems. At the same time, the frameworks themselves will need to adapt in order to better accommodate and build on these models. This leaves questions such as which human models are appropriate, and how to formalize interactions between humans and robots. For example, when investigating a human-robot system, the choice of human model can dramatically change the conclusions that can be drawn from the composed system. Simple models(templates) often allow for faster computation while sacrificing the nuances of reality. More complex models (anchors) are better equipped to take these into account and can be used in a variety of circumstances, however can require intense computation. The purpose of this workshop is to bring together researchers in industry and academia from different areas of robotics to hear their perspective on human-centered systems. In principle, there are models and design techniques being developed for intelligent systems within each subfield (e.g. exoskeletons, autonomous vehicles, etc.) in isolation. By looking at different perspectives on robotics in society, we can not only find common ground and apply these techniques to different human-robot systems, but also answer some of the remaining concerns in developing intelligent interactive systems: Choosing a human model as well as a model of interaction and level of abstraction that facilitate smooth integration of humans into robotic systems. Exploiting the structure in these models to make better sense of the increasingly abundant data, and inform data collection. Merging data-driven and model-based techniques for the design of provably correct systems. 
</p><p align="justify">Channeling the combined predictive power of models and data into flexible planning and control algorithms will ultimately be crucial to provide desirable robot behavior, with performance and correctness guarantees, in the human space. This workshop will provide a combined view of some of the key existing technical methods for tackling parts of this problem and promote a multidisciplinary discussion to consolidate 
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Shankar Sastry (Univ. of California), Ruzena Bajcsy (Univ. of California), Aaron Ames (Georgia Institute of Technology), Oussama Khatib (Stanford University), Daniel Koditschek (Univ. of Pennsylvania),  Antonio Bicchi (Univ. of Pisa), Ken Goldberg (UC Berkeley), Julie Shah (Computer Science and Artificial Intelligence Laboratory), Anca Dragan (UC Berkeley), Gregory Hager (John Hopkins University), Cenk Cavusoglu (Case Western Reserve University), 
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
RoboCup Tutorial: Multi-Robot Autonomy in Robot Soccer as an Adversarial Domain
</h3>
<a href="http://www.ieee-ras.org/robocup/activities/187-technical-committees/robocup/787-tutorial-at-iros-2016" target=_new>
http://www.ieee-ras.org/robocup/activities/187-technical-committees/robocup/787-tutorial-at-iros-2016
</a>
<p align="justify">
Half Day Workshop Morning MoH1T12               
<br>
Mon, Oct 10, 08:30-12:30, Room 204~205
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Minoru Asada (Osaka University), Manuela M. Veloso (Carnegie Mellon University), Daniele Nardi (Univ. of La Sapienza), Daniel D. Lee (Univ. of Pennsylvania)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
In this tutorial, we will introduce robot soccer as a problem involving planning for the coordination among multiple robots in response to an opponent team. We will focus on presenting a variety of techniques used in robot soccer, including (i) multi-robot strategies that respond to the score of the game in a finite horizon game, (ii) role assignment through predefined and negotiated agreements; (iii) distributed state sharing and decision making; (iv) decentralized sparse interaction planning under uncertainty; and playbook generation, learning, and adaptation. The tutorial will be illustrated with RoboCup games of the different soccer leagues, namely simulation, small-size, middle-size, standard platform, and humanoids. 
</p>
<!-- <p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Robot Modularity
</h3>
<a href="https://clawar.org/event/workshop-iros16-modularity/" target=_new>
https://clawar.org/event/workshop-iros16-modularity/
</a>
<p align="justify">
Half Day Workshop Morning MoH1T13               
<br>
Mon, Oct 10, 08:30-12:30, Room 206~208
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Hong Seong Park (Kangwon National University), Gurvinder S. Virk (University of Gävle), Shuping Yang (Beijing Research Institute of Automation for Machinery Institute), S.C. Kang (KIST)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Robot researchers have been active for many years to develop innovative methods for robot modularity to help stop the “re-invention of the wheel” scenarios where robot designers have to start from scratch to realize a specific robot system application. Robot industry has seen the value of robot modularity for many years and many companies have made significant in-house modular conceptual approaches which has resulted in many customers benefitting from the novel products commercialized. Much of the work was originally done for hardware components but software modularity has also become important in the robotics domain and software platforms such as ROS, RT-middleware, and OPRoS have appeared. These software platforms are now being implemented in commercial robots.
</p><p align="justify">It is well known that robot modularity provides a flexible design approach where robot modules (hardware and software) have the potential to be easily inter-connected (both physically and functionally) with other modules to develop application specific robot solutions quickly and cost effectively.
</p><p align="justify">The adoption of modularity in the IT sector has been impressive but the take-up in the robot industry has been limited and further efforts are needed. The reasons for the slow take up may be the fragmented approaches developed and the fact that robot modularity requires a very flexible and balanced approach to allow reusability of software and hardware modules to have widespread appeal to the wide ranges of different robot domains.
</p><p align="justify">In view of these concerns ISO created a new work group, namely ISO TC299/ WG6-Modularity for service robots so that open robot modular approaches could be developed using the normal consensus approaches adopted in developing ISO standards. WG6 started its work in 2014 and general principles on modularity are being formulated bearing in mind a number of issues; the issues include connectivity, interoperability, safety, security, system Integration, composability, platform independence, openness, and module granularity.
</p><p align="justify">The aim of the workshop is to bring together researchers and industrialists to have an open discussion with experts, developers, and researchers to share recent R&D results, challenges, and future research trends in realizing the needed technology so that we are able to meet the global demands for flexibility of robots and robotic systems. So we organize oral/poster/lightning talk sessions to encourage the participation of young researchers and promote discussion between the speakers and the audience.
</p>
<!-- <p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Robotics for the Elderlies: Involving Science, End Users, and Public Bodies
</h3>
<a href="http://echord.eu/iros-2016/" target=_new>
http://echord.eu/iros-2016/
</a>
<p align="justify">
Half Day Workshop Morning MoH1T14                    
<br>
Mon, Oct 10, 08:30-12:30, Room 301
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Francesco Maurelli (Technische Universitat Munchen), Maureen Neitz (Univ.of Washington), Franziska Kirstein (University of Southern Denmark, Odense), Ana Maria Puig Pey Claveria (Institut de Robòtica), Alberto Sanfeliu (Institut de Robòtica)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
A child born today can expect to live more than 30 years longer than one born in 1900. This positive trend leads towards an ageing society, in 2012 over 800 million people were aged 60 and over and their number is expected to more than double until the year 2050. In this context health services for the elderly are becoming increasingly important for society, opening a vast field for robotics applications. An example for such an application is the robotized Comprehensive Geriatric Assessment (CGA), a clinical management strategy, used around the world, assessing the capabilities of the elderly patients and providing valuable data for the medical staff to prepare an appropriate care plan. There are several attempts worldwide, in cooperation with relevant public bodies and hospitals, to make the CGA (semi-)autonomous, though many challenges still remain open.
Our workshop “Robotics for the elderlies: involving science, end users, and public bodies” at the 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2016) aims to be a forum for discussion of various approaches in the field of robotics for the elderly, involving all the stakeholders, ranging from scientists to end users and to public bodies.
The workshop also comprises a poster spotlight and poster session, to allow active participation of researchers, including students, in the field of assistive robotics, in order to broaden the information available on the current research worldwide. We kindly invite researchers to submit posters addressing one ore more of the following topics:
<ul>
<li>Geriatric assessment through robotics
<li>Robotic companions
<li>Robotic monitoring systems
<li>Vision or other sensor-based algorithms for patient assessment
<li>Human-Robot interaction (especially in the case of elderly people)
<li>Acceptability of robotics solutions
<li>Robotic mobility aids
<li>Roboethics
<li>Cooperation with public institutions to introduce robotics technology
</ul>
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Alois Knoll (University of Tokyo), Paolo Dario (The BioRobotics Institute), Filippo Cavallo (The BioRobotics Institute), Elizabeth Anne Broadbent (The University of Auckland), Jonathan Kelly (University of Toronto)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Teaching Robotics through Cloud Simulations
</h3>
<a href="http://www.theconstructsim.com/teaching-robotics-with-cloud-simulations/" target=_new>
http://www.theconstructsim.com/teaching-robotics-with-cloud-simulations/
</a>
<p align="justify">
Half Day Workshop Morning MoH2T15               
<br>
Mon, Oct 10, 08:30-12:30, Room 203
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Ricardo Tellez (The Construct), E. Cervera (The Construct)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
How to concentrate on teaching robotics
</p><p align="justify">All teachers and students suffer two main problems when teaching/learning robotics:
<ul>
<li>First, there are not enough robots for all the students, and the existing robots are usually very simple.
<li>Second, it is a nightmare to have each student with their computer ready for the robotics class, either because the operating system is not the proper one, the version of ROS is not the correct one, or there are many problems installing the required version of Gazebo.
</ul>
</p><p align="justify">We will teach a solution that removes all those barriers, because uses systems already prepared in the cloud. The environment used by each student will be exactly the same as the teacher’s, hence the teacher can be sure that his exercises will work for the students.
</p><p align="justify">This will allow the teacher to concentrate on the teaching instead of solving problems of versions, configurations or installations, at the same time that allows the student to learn complex concepts by using many different (simulated) robots that otherwise would never had access to.
</p><p align="justify">We will be using the tool The Construct that provides different types of simulators for robotics through a web browser.
</p><p align="justify">We will provide a complete course we have developed that teaches the basics of robotics, simulations and ROS by means of robot simulations in the cloud. This course will be freely available for all teachers and students.
</p><p align="justify">
<b>Speakers</b>
</p><!-- <p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
See, Touch and Hear: 2nd Workshop on Multimodal Sensor-based Robot Control for HRI and Soft Manipulation
</h3>
<a href="www.lirmm.fr/IROS15_2nd_wk_Visio-haptic_control" target=_new>
www.lirmm.fr/IROS15_2nd_wk_Visio-haptic_control
</a>
<p align="justify">
Half Day Workshop Afternoon MoH2T12              
<br>
Mon, Oct 10, 14:00-18:00, Room 204~205
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Andrea Cherubini (Université de Montpellier), David Navarro-Alarcon (CUHK T Stone Robotics Institute), Robert Haschke (Univ. of Bielefeld), Youcef Mezouar (SIGMA'Clermont), Juan Antonio Corrales (Blaise Pascal University)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The recent development of bio-inspired sensors (which are nowadays affordable and lightweight) has spurred their use on robots, particularly on anthropomorphic ones (e.g., humanoids and dexterous hands). Such sensors include e.g. RGB-D cameras, microphones, tactile skins, joint torque sensors, and capacitive proximity sensors. Since these sensors generally measure different physical phenomena, it is preferable to use them directly in the low-level servo controller rather than to apply multi-sensory fusion, or to design complex state machines. We believe that adaptive sensor-based methods directly linking perception to action can provide better solutions in unpredictable scenarios, than traditional planning and model-based techniques, which require a priori models of the environment. This idea, originally proposed in the hybrid position-force control paradigm, when extended to feedback from multiple sensors, brings new challenges to the controller design; e.g. related to the sensors characteristics (synchronization, hybrid control, task compatibility, etc.) or to the task representation. This multimodal approach represents at best our cognitive processes (which directly link perception and action), and is fundamental in many innovative robotic applications, such as human-robot interaction, soft material manipulation, and whole-body control. Human-robot interaction for collaborative tasks often relies on force/tactile feedback, to transmit the user intention to the robot. However, the robot should also be capable of recognizing the intention, when there is no direct contact with the human. Possible solutions come from audio and/or visual data, which should then be combined with haptics to obtain the best result. These approaches are particularly useful in whole-body control of humanoid robots, since their actuators and sensors are generally bio-inspired, to facilitate interaction with the human. The automatic manipulation of soft materials (e.g., in the food industry) represents a second important case study. The natural evolution of recent works on vision-based servoing of soft objects is the integration of haptics and force feedback. Whole-body control is a third field of research that would greatly profit from the discussed methods. In fact, multiple tasks (manipulation, self collision avoidance, etc.) can be simultaneously realized by exploiting the diverse sensing capabilities of the robot body. We propose a half-day workshop to enhance active collaboration and discuss formal methods for sensor-based control. The purpose of the workshop is to bring together researchers with common interests in the area of multimodal control, based on a variety of sensed signals, including vision (2D and 3D), touch (haptics), audio, position, force, proximity (from capacitive measurements) etc. The invited speakers will share their experience and will give an insight into the evolution and current status of multimodal control. The workshop will also be opened to paper submission, and the final schedule will be adapted depending on the quantity and quality of the submissions. We will organize a poster session of the submitted papers, to ease interaction and discussion between participants.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Alois Knoll (University of Tokyo), Paolo Dario (The BioRobotics Institute), Filippo Cavallo (The BioRobotics Institute), Elizabeth Anne Broadbent (The University of Auckland), Jonathan Kelly (University of Toronto)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Workshop on Bio-inspired Social Robot Learning in Home Scenarios
</h3>
<a href="https://www2.informatik.uni-hamburg.de/wtm/SocialRobotsWorkshop2016/index.php" target=_new>
https://www2.informatik.uni-hamburg.de/wtm/SocialRobotsWorkshop2016/index.php
</a>
<p align="justify">
Half Day Workshop Afternoon MoH2T13  
<br>
Mon, Oct 10, 14:00-18:00, Room 206~208
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Francisco Cruz (Univ. of Hamburg), Jimmy Baraglia (Osaka university), Stefan Wermtern (Knowledge Technology Institute), Yukie Nagai (Osaka University)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
There has been considerable progress in robotics in the last years allowing robots to successfully contribute to our society. We can find them from industrial environments, where they are nowadays established, to domestic places, where their presence is steadily rising. The workshop intends to explore the following question: “How well prepared are learning robots to be social actors in daily-life home environments in the near future”. 
</p><p align="justify">
The workshop is therefore not only an opportunity to address this focuses on the latest scientific contributions on bio-inspired learning social robotics, but also links this with a clear focus to push the presence of robots in people’s daily-life environment. Thus, one main goal of the workshop is offering a common space for roboticists from different fields of expertise to contribute beyond the current state-of-the-art of learning methods in robotics specially applied to home scenarios and recent developments in assistive robots. 
</p><p align="justify">Roboticists are aware of the big challenges that involve working with service and assistive robots in home environments to develop real robot domestic applications. For instance, the RoboCup initiative founded a specific league “RoboCup@Home league” to aim the development of highly interactive intelligent robots to perform tasks in new and complex environments while being able to anticipate and resolve conflictual situations that may lead to mistakes or incomplete performance. Such complex learning tasks in home environments can include among others learning to: 
<ul>
<li>Provide help in home services.
<li>Wipe/tidy up a table, floor, or room.
<li>Cook a meal.
<li>Be of assistance for elderly people.
<li>Be a conversational companion. 
</ul>
</p><p align="justify">Each of these domestic activities have been mostly investigated and developed as more simple restricted tasks in controlled environments. However, the learning and further development of real complex tasks in actual dynamic scenarios is still an open issue in robotics. Intelligent robots operating around us should be able to know where it is located itself, detect people, learn and recognize faces, learn new objects, understand action-object opportunities, and furthermore they should learn to behave cooperatively in domestic scenarios. 
</p><p align="justify">In order to accomplish these complex domestic tasks successfully, robots and roboticists have to deal with many challenges such as perception, pattern recognition, navigation, and object manipulation, all of that in varying environmental conditions. Such challenges can only be addressed if the robot constantly acquires and learns new skills, either autonomously or from parent-like trainers. The special issue principally targets bio-inspired developmental learning approaches and psychologically motivated learning approaches for domestic environments. These learning approaches are inspired by how humans develop knowledge through interactions with their environment. 
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Angelo Cangelosi (Centre for Robotics and Neural Systems), Jun Tani (Cognitive Neuro-Robotics Laboratory), Emre Ugur (Bogazici University), Giulio Sandini (Italian Institute of Technology (IIT)), Yukie Nagai (Emergent Robotics Laboratory), Stefan Wermter (Knowledge Technology Institute)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Twisted String Actuation: State of the Art, Challenges and New Applications
</h3>
<a href="http://www-lar.deis.unibo.it/people/gpalli/TwistedString_Workshop/" target=_new>
http://www-lar.deis.unibo.it/people/gpalli/TwistedString_Workshop/
</a>
<p align="justify">
Half Day Workshop Afternoon MoH2T14                  
<br>
Mon, Oct 10, 14:00-18:00, Room 301
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Igor Gaponov (Korea University of Technology and Education), Gianluca Palli (Univ. of Bologna), Chris May (Saarland University), Jee-Hwan Ryu (Korea University of Technology and Education)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
A twisted string actuator (TSA) is a light, compliant and cheap mechanical actuator, where a string connected to an electric motor acts as a gear. When a load is attached to the string on the other end, the rotation imposed on the string by the motor will reduce the length of the string, thus causing the translational motion of the load due to the generated pulling force. Advantages of TSAs include low weight and price, quiet operation, intrinsic compliance and flexibility. Because of these benefits, TSAs are finding increased applications in various areas of engineering, which include medical robotics and orthoses, exoskeletons and wearable devices, high-accuracy positioning stages and mechanisms, variable stiffness joints and actuators, space robotics, and many others.
</p><p align="justify">The main target of this workshop is to present the current state of the art and the future trends in modeling, control and applications in the area of twisted string-based actuators and transmission mechanisms. The workshop also aims to instigate knowledge sharing inside the engineering and research communities and to outline main future directions and issues of the novel mechanisms.
</p><p align="justify">This event will bring together researchers working on twisted string actuation, engineers from industry and scientists with experience in the areas of mechanism design and compliant and flexible actuators. One of the principle outcomes of the workshop is to assist in making novel twisted string-based devices and technologies more suitable for various applications in industry and daily life. The workshop also aims at strengthening collaboration between research groups working in this field around the world, at attracting interest from the engineering community towards the emerging transmission technology of twisted string actuation, and hopefully this event will bring with it new and exciting collaboration and funding opportunities.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Kyung-Soo Kim (KAIST), Gunter Niemeyer (Disney Research), Moshe Shoham (Israel Institute of Technology), Takahiro Inoue (okayama Prefectural University), Igor Gaponov (Korea University of Technology and Education), Gianluca Palli (Univ. Of Bologna), Ivan Godler (Twist Drive Technologies, Inc.), Thomas Low (SRI International)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>

<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Personal Robot Interaction
</h3>
<a href="http://rccnc.ustc.edu.cn/iros2016/IROS2016-Workshop-Personal-Robot-Interaction.html" target=_new>
http://rccnc.ustc.edu.cn/iros2016/IROS2016-Workshop-Personal-Robot-Interaction.html
</a>
<p align="justify">
Full Day Workshop FrFT1                          
<br>
Fri, Oct 14, 08:30-18:00, Grand Ballroom
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Yimin Zhang (Intel Labs China), Jiqiang Song (Intel Labs China), Xiaoping Chen (School of Computer Science and Technology)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Personal Robots has emerged as a highlight for both research community and industry. These robots are expected to interact with their human masters at home, bring added value, or even be respected and loved by their human masters. These expectations pose serious challenges for the personal robot to interact with human intelligently. The interactions could span from “Information oriented interactions,” “task oriented interactions,” to “interactions with emotion, ”and even “social interactions.” In practical environment these robots have to function independently or collaborate with their human masters to accomplish tasks of various kinds, including “being personal assistant,” “child education,” “elder caring,” etc. From certain perspective these personal robots are acting not only as a “server” or “device” but more as a reliable “companion”. Many questions arise and wait to be answered before this vision becomes reality. Below are a few examples: What are the special needs for personal robots serving personal users comparing to other kind of robots? What kind of human like behavior are important for personal robots, e.g. social interaction skills? How to mimic human like behavior in interacting with personal users? How to achieve emotion interaction? And what are the limitations of state-of-the-art technology and what different ways should we take? How to build trust and respect while interacting with personal users like human does? Is it because of the service skills provided by personal robots? Or something else, like social skills? Should the services be personalized? And what are possible ways to achieve that? Can long term interaction help personal robots to better serve personal users? And how we can enable that? All these questions pose serious challenges to researchers in many areas, including perception and cognition capabilities, multi-modality Human-Robot Interaction, personalization of robot service, innovation applications, user experience, and sensors/computing platforms. On one hand, technologies, such as visual perception, in AI field are moving forward quickly. On the other hand, these AI technologies are still far away from making robots function as human beings do in many aspects. Thus, technologies and systems have to be carefully designed to leverage these advanced technologies while being practical. This workshop aims to provide an opportunity for researchers and experts to discuss and debate on different topics within this challenging research field. Leading researchers from both academia and related industry will update attendees with the latest technical advancements. More importantly this workshop intends to share industrial viewpoints from practical application perspective. Furthermore, carefully selected innovative poster papers and practical demos (from both academia and industry) will be available to show latest results and inspire more research work in this direction. We believe this workshop will have significant societal impact on the near future research of personal robots. 
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Jianwei Zhang (Univ.of Hamburg), Jianbo Shi (GRASP Lab), Xiaoping Chen (USTC), Il Hong Suh (Hanyang University), Takayuki Kanda (Intelligent Robotics and Communication Labatories), Jiqiang Song (Intel Labs China), Yimin Zhang (Intel Labs China)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Vision-based High Speed Autonomous Navigation of UAVs
</h3>
<a href="http://www.seas.upenn.edu/~loiannog/workshopIROS2016uav/" target=_new>
http://www.seas.upenn.edu/~loiannog/workshopIROS2016uav/
</a>
<p align="justify">
Full Day Workshop FrFT2                                 
<br>
Fri, Oct 14, 08:30-18:00, Room 111
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Guiseppe Loianno (Univ. of Pennsylvania), Davide Scaramuzza (Univ. of Zurich), Vijay Kumar (Univ. of Pennsylvania), Shaojie Shen (HKUST), Gary McGrath (Qualcomn Research), Sebastian Scherer (CMU), Justin Thomas (University of Pennsylvania), Friedrich Fraundorfer (TU Graz), Juan Nieto (ETH Zurich), Michael Watterson (Univ. of Pennsylvania), Nathan Michael (CMU), Zachary Taylor (ETH Zurich), Martin Saska (CTU)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Autonomous micro helicopters are starting to play a major role in tasks like search and rescue, environment monitoring, security surveillance, transportation and inspection. However, for such operations, two main challenges arise. The use GPS based navigation is not sufficient. Fully autonomous operation in cities or other dense environments requires micro helicopters to fly at low altitudes, where GPS signals are often shadowed or indoors and generally. In addition, the previous listed tasks are executed at low speed, compromising the execution of critical missions, which have to be typically accomplished in a limited amount of time. Thus, a number of perception and control challenges have still to be solved. This workshop will focus on the systems' challenges for small-scale and high speed navigation of aerial vehicles, where the size, weight and payload constraints only allow light-weight sensors like cameras, and the operating conditions of high speeds (20 m/s) require perception, state estimation, environment reconstruction, obstacle avoidance and planning algorithms over longer ranges and shorter time scales. This workshop will focus not only on the scientific foundations, but also the algorithmic and software design challenges, which arise in the settings of small-scale, high speed navigation in three-dimensional environments. The workshop will feature, in addition to contributed and invited talks, real-time demos provided both from academia and industry actively working in this field.
</p><!-- <p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>



<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
The Mechatronics behind Force/Torque Controlled Robot Actuation: Secrets & Challenges
</h3>
<a href="https://iros2016torquecontrolledactuation.wordpress.com/" target=_new>
https://iros2016torquecontrolledactuation.wordpress.com/
</a>
<p align="justify">
Full Day Workshop FrFT3                                 
<br>
Fri, Oct 14, 08:30-18:00, Room 112
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Jörn Malzahn (Istituto Italiano di Tecnologia), Sangbae Kim(Massachusetts Institute of Technology), Nicholas Paine (Human Centered Robotics Lab), Nikolaos Tsagarakis Iistituto Italiano di Tecnologia)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The next generation of industrial robots is envisioned to share workspaces with humans and physically interact with human collaborators in the dynamic environments of highly customized small batch sized production. Moreover, there exists the vision of robotic assistants and assistive robotic devices that help us in our everyday life and ensure individual mobility along with a high standard of living including autonomy in high ages. The demographic change in today’s industrial societies and the associated social and economic challenges turn this vision into a true need of action.
</p><p align="justify">A key enabler for this new generation of robots and assistive robotic devices is the broad availability of robust and affordable force/torque enabled robotic actuators, which pave the way for the advanced control concepts required to:
solve dexterous manipulation of arbitrary or possibly delicate objects with a priori unknown shapes, weights, friction and stiffness properties;
allow whole body robotic locomotion or robotic system assisted human locomotion in unstructured, dynamic and possibly cluttered environments as well as stairs and ladders while exploiting multiple contacts;
realize intuitive, safe and dependable physical interaction of robots and assistive robotic devices with untrained human users.
</p><p align="justify">The workshop seeks to help speeding up the development force/torque enabled robotic actuators within the community and contribute to the realization of the aforementioned visions of robot assistants and assistive devices in industrial and household environments by: bringing together researchers, who develop force/torque sensing technologies and force/torque enabled actuators for robots; inviting speakers from academia and industry that display the state of the art as well as open challenges and open demands to the robotics community; providing a platform for establishing and fostering collaborations towards the solution of these challenges; attracting experts to share experiences (success stories but also failures!) and publish best practices, evaluations and performance comparisons of designs, solutions, concepts and algorithms; providing a discussion forum for industry and academia on the necessary steps for mutual knowledge transfer that improves the availability of force/torque enabled robotic actuators.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Alin Albu-Schäffer (DLR Institute of Robotics and Mechatronics), Marco Hutter (Robotic Systems Lab), Hiroshi Kaminaga (Nakamura and Takano Laboratory), Kyoungchul Kong (Robotic Systems Control Laboratory), Joshua Mehling (NASA Johnson Space Center), Ludovic Righetti (Movement Generation and Control Group), Claudio Semini (Dynamic Legged Systems Lab), Nicholas Paine (Apptronik Inc.), Arne Wahrburg (ABB Research Center Germany)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Closed-loop Grasping and Manipulation: Challenges and Progress
</h3>
<a href="http://www.h2020romans.eu/#!closed-loop-grasping-and-manipulation/i4u03" target=_new>
http://www.h2020romans.eu/#!closed-loop-grasping-and-manipulation/i4u03
</a>
<p align="justify">
Full Day Workshop FrFT4                                 
<br>
Fri, Oct 14, 08:30-18:00, Room 101
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Yasemin Bekiroglu (Univ. of Birmingham), Miao Li (EPFL), Florian Pokorny (KTH), Robert Krug (Univ. of Orebro), Aude Billard (EPFL)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Despite decades of research, robust autonomous robotic grasping and manipulation at a level approaching human skills remains an elusive goal. One reason is the difficulty in dealing with the inevitable uncertainties and unforeseen situations encountered in dynamic and unstructured application environments. Unknown information required to plan grasps such as object shape and pose needs to be extracted from the environment through sensors. However, sensory measurements are noisy and associated with a degree of uncertainty. Furthermore, object parameters relevant to grasp planning, such as friction and mass,  may not be accurately estimated. In real-world settings, these issues can lead to grasp failures with serious consequences.
Additionally, physical interaction during object manipulation in many scenarios (e.g., daily life, industrial settings), can go well beyond grasping for picking and placing. Examples of these tasks include opening a door, screwing a light bulb, using a tool and writing. They may require actions such as caging, pushing, sliding, etc. Task accomplishment depends not only on the contact interactions between object and the manipulator/hand/finger, but also in particular on the exploitation of the environments. Recent studies to achieve such tasks are scattered across many different topics: passive mechanical adaptation through compliant hand design, caging, pushing, extrinsic dexterity, exploiting environmental constraints and dynamic grasp adaptation, etc. Despite these efforts, there is still no generic, principled approach to encode varying task constraints at the same time in order to deal properly with the various uncertain circumstances during interaction. Skills to reason about the task requirements, to ground these in the sensory information, to devise reactive behaviors in order to respond compliantly to uncertainties, to choose and execute optimal actions are crucial for reliable physical interactions such as object manipulation. In order to tame the complexity, most of these issues have been studied in isolation and most object manipulation systems are still open loop. This greatly limits the applicability of such approaches in real-world settings.
This workshop focuses on task representation of object manipulation to enable multi-contact manipulation planning and reactive behaviors that can eventually close the loop between planning and control and lead to robust manipulation that can deal with uncertainty. The aim is to connect researchers from different backgrounds such as planning, control, learning, design and perception in order to set the basis and define core open problems for object manipulation. Furthermore, we want to discuss advantages, limitations, challenges and progress of different approaches pertaining to the workshop topic.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Kenji Tahara (Kyushu University), Kensuke Harada (AIST), Alberto Rodriguez (MIT), Todor Stoyanov (Orebro University), Anca Dragan (UC Berkeley), Maximo Roa (DLR), Daniel Kappler (Max-Plank Institute for Intelligent Systems), Tetsuyou Watanabe (Kanazawa University), Robert Platt (Northeastern University), Oliver Brock (TU-Berlin), Tamim Asfour (Karlsruhe Institute of Technology), Serena Ivaldi (INRIA), Yu Sun (Univ. of South Florida)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>

<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
State Estimation and Terrain Perception for All Terrain Mobile Robots
</h3>
<a href="http://www.asl.ethz.ch/publications-and-sources/workshops/iros-2016-state-estimation-and-terrain-perception.html" target=_new>
http://www.asl.ethz.ch/publications-and-sources/workshops/iros-2016-state-estimation-and-terrain-perception.html
</a>
<p align="justify">
Full Day Workshop FrFT5                                 
<br>
Fri, Oct 14, 08:30-18:00, Room 102
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Micheal Bloesch (ETH Zurich), Peter Frankhauser (ETH Zurich), Ronald Siegwart (ETH Zurich), David Johnson (The University of Sydney), Salah Sukkarieh (The University of Sydney), Phillppe Martinet (Ecole Centrale de Nantes)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Enabling mobile robots to move in unknown environments requires them to have an understanding of the surrounding and their location within. This is especially important for unmanned ground vehicles (UGVs) such as legged robots, tracked and wheeled vehicles. These systems rely on the interaction with the terrain for traction, while avoiding collision, slippage, and instabilities. Therefore, an accurate terrain representation together with a reliable pose estimation is crucial for the successful deployment of these robots. The main objective of this workshop is to bring together people from the fields of state estimation and terrain perception for UGVs to exchange ideas and foster collaboration.
</p><p align="justify">Since in real world robotic applications both state estimation and terrain perception are tightly interweaved problems, they have to be addressed conjointly. In comparison to previous similar workshops, the proposed workshop pays special attention on the challenges resulting from combining methods from both state estimation and terrain perception. The discussed topics will include the processing of exteroceptive sensor data (vision, RGB-D, LiDAR, Time-of-Flight), the representation and interpretation of environments, and the consistent formulation of state estimation algorithms. During the discussions we will also address the practical problems related to the integration on real robots where uncertain, corrupted and missing data have to be handled.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
M. Camurri, C. Semini (Dynamic Legged Systems Lab), A. Elfes (Autonomous Systems), P. Fankhauser (Autonomous Systems Lab), M. Bloesch (Autonomous Systems Lab), R. Siegwart (Autonomous Systems Lab), C. Mericli (National Robotics Engineering Consortium), M. Laverne (National Robotics Engineering Consortium), A. Kelly (National Robotics Engineering Consortium), K. Yoshida (The Space Robotics Lab), T. Barfoot (Autunomous Space Robotics Laboratory), D. Belter (Institute of Control and information Engineering), P. Skrzpczynski (Institute of Control and information Engineering), S. Leutenegger (Dyson Robotics Lap), S. Behnke (Autonomous Intelligent Systems)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Assistance and Service Robotics in a Human Environment
</h3>
<a href="http://www.asl.ethz.ch/publications-and-sources/workshops/iros-2016-state-estimation-and-terrain-perception.html" target=_new>
http://www.asl.ethz.ch/publications-and-sources/workshops/iros-2016-state-estimation-and-terrain-perception.html
</a>
<p align="justify">
Full Day Workshop FrFT6                                 
<br>
Fri, Oct 14, 08:30-18:00, Room 103
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Samer MOHAMMED (LISSI-UPEC), Yacine AMIRAT (LISSI-UPEC), David DANEY (INRIA Sophia Antipolis), Abdelghani CHIBANI (LISSI-UPEC), Anne SPALANZANI (LISSI-UPEC), Anne SPALANZANI (INRIA Rhone-Alpes), Ren LUO (NTU University)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
This workshop will focus on assistance and service robotics in a human environment in different contexts of human life. This major research issue will affect our lives in the near future. The integral assistance systems are robotic modules and technological aids in general for personal assistance, such as robots, mobile bases, electric wheelchairs, soft robot manipulator arm. They can support frail people with special needs in their living environment. Assistive and Service Robotics covers a broad spectrum of research topics ranging from intelligent robots acting as a servant, secretary, or companion, to intelligent robotic systems, such as, autonomous wheelchairs, ambient intelligent systems and smart spaces. Some international industrials already think that smart houses or smart buildings (with sensors, actuators and computer capabilities) can be already considered as “static robots”. According to this vision, adding a mobile robot inside the house or the building could endow the whole system with “mobility capabilities”. This workshop will focus on the assistance in terms of mobility, social interaction, as well as everyday chores that are particularly relevant to the elderly. Topics related to social interaction, smart homes, mobility assistance, healthcare and wellbeing would be covered. Fundamental and technological research, in particular, the one related to autonomous indoor vehicles, sensor and actuators networks, wearable and ubiquitous technologies, and human-robot interaction, will be addressed. This workshop is the fifth edition of a series of workshop organized in this field at IROS 2012, IROS 2013, IROS 2014 and IROS 2015.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Wolfram Brgard (Albert-Ludwigs-Universitat Freiburg), Norihiro Hagita (ATR Intelligent Robotics and Communication Laboratories), Francesco Nori (Instituto Italiano di Tecnologia), Jong-Hwan Kim (KAIST), Kyoungchul Kong (Sogang University), Fancois Michaud (Universite de Sherbrooke), Ryad Chellali (Nanjing Tech University), Rachid Alami (LAAS-CNRS), Gentiane Venture (Tokyo University of Agriculture and Technology), Myunghee Kim (Carnegie Mellon University)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Joint Workshop on Wearable Robotics and Assistive Devices
</h3>
<a href="https://cumulus.ijs.si/iros2016wsportal/" target=_new>
https://cumulus.ijs.si/iros2016wsportal/
</a>
<p align="justify">
Full Day Workshop FrFT7                                 
<br>
Fri, Oct 14, 08:30-18:00, Room 104
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Tadej Petric (Univ. of Maribo), Jan Babic (Jozef Stefan Institute), Katja Mombaur (Universität Heidelberg), Myunghee Kim (Carnegie Mellon University), Steven H. Collins (Carnegie Mellon University), Nicola Vitiello (The BioRobotics Institute), Samer Mohammed (LiSSi), Juan Camilo Moreno (Max Plank Institute of Molecular Plant Physiology), Conor James Walsh (Harvard Biodesign Lab), Domenico Prattichizzo (Univ. of Siena)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The population aged 60 and over is expected to rise considerably in the coming years. The rise in life expectancy combined with falling birth rates, will accelerate the ageing of this population. Facing this problem or reducing its effect would have a great societal impact by improving the quality of life and regaining people independence. On the other hand, robotic applications have rapidly expanded from classical industrial applications with repetitive tasks to applications with close human-robot interaction. Particularly, wearable robotics has gained an increasing attention in the last decades and it is expected to have a great impact on the development of assisting robotic devices. Given the application scope of exoskeletons and their tight physical interaction with the human body, consideration of human physiology is crucial for all aspects of exoskeleton research and development. Nevertheless, there are many cases when such devices are designed, built and/or controlled in a way that either underestimates or even neglects the physiological and biomechanical parameters pertinent to the human body. In addition, the emergence of novel wearable technologies with considerable reduction in size, cost and energy consumption, are becoming a privileged solution to provide assistive services to humans. Despite of the significant technological and scientific advancements achieved in the field of wearable powered robotic technologies, we have not yet witnessed the success of a fully-wearable powered assistive robotic device, e.g. a robotic suit, which is easy to wear and intuitive to cooperate with.
</p><p align="justify">In this framework, the purpose of this workshop is to gather PhD students and researchers from different fields related to wearable robotics and assistive devices, to lively discuss the current trends, the major advances, the new research directions and future challenges in the field of wearable robots and its common edge with human physiology. Moreover, real demos and poster sessions will provide an opportunity for all participants to interact and exchange their experience together.
</p><!-- <p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Frontiers of Endoluminal Robotic Surgery
</h3>
<a href="http://sssa.bioroboticsinstitute.it/workshops/FERS2016" target=_new>
http://sssa.bioroboticsinstitute.it/workshops/FERS2016
</a>
<p align="justify">
Full Day Workshop FrFT8                                 
<br>
Fri, Oct 14, 08:30-18:00, Room 105
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Gastone Ciuti (Scuola Superiore Sant’Anna), Pietro Valdastri (Univ. of Leeds), Shuxin Wang (Tianjin University), Paolo Dario (Scuola Superiore Sant’Anna)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The objective of this workshop is to advance knowledge in the field of endoluminal robotic surgery, by presenting innovative tethered and untethered mechatronic instruments and surgical robots, capsule-based devices and other diagnostic and therapeutic platforms, ranging from the meso- to nano-scale. 
</p><p align="justify">A wide range of open challenges about endoluminal robots will be addressed in the proposed workshop, entitled “Frontiers of Endoluminal Robotics Surgery”. Ranging from active navigation mechanisms to sensing and therapeutic modules, the presentations will cover key aspects of innovative robotic devices for endoluminal procedures approaching issues, such as: i) capsules and novel flexible endoscopic/endocavity devices, ii) robotic navigation for active endoscopic probes and robots, iii) smart mechanisms for actuation and therapy delivery, iv) sensing and therapeutic modules and also iv) micro- and nano-scale devices.
</p><p align="justify">We will call for posters and the best contribution will be selected by the workshop attendees during the organized event; the winner will be announced by the end of the workshop. Contributions can be theoretical or experimental studies concerning the mentioned areas. Submission are open to any kind of endoluminal/endocavity robotic platform and device for advanced diagnosis and targeted therapy. Engineering designs, modelling and developments, also supported by experimentations in bench, ex-vivo and in-vivo conditions, will be presented. 
</p><p align="justify">The current and future challenges will be discussed in a panel discussion with all invited speakers and the workshop attendees.  In particular, to represent the current research trends, we will design a combination of invited talks: invited speakers will include experts with both engineering and medical backgrounds. Smart solutions for industrial endoscopic applications will be also considered in the proposed workshop.
</p><!-- <p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Workshop on Machine Learning Methods for High-Level Cognitive Capabilities in Robotics
</h3>
<a href="http://mlhlcr2016.tanichu.com/" target=_new>
http://mlhlcr2016.tanichu.com/
</a>
<p align="justify">
Full Day Workshop FrFT9                                 
<br>
Fri, Oct 14, 08:30-18:00, Room 106
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Takayuki Nagai (The University of Electro-Communications), Tetsuya Ogata (Waseda University), Emre Ugur (Bogazici University), Yiannis Demiris (Imperial College London), Tadahiro Taniguchi (Ritsumeikan University)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
The objective of this workshop is to advance knowledge in the field of endoluminal robotic surgery, by presenting innovative tethered and untethered mechatronic instruments and surgical robots, capsule-based devices and other diagnostic and therapeutic platforms, ranging from the meso- to nano-scale. 
</p><p align="justify">A wide range of open challenges about endoluminal robots will be addressed in the proposed workshop, entitled “Frontiers of Endoluminal Robotics Surgery”. Ranging from active navigation mechanisms to sensing and therapeutic modules, the presentations will cover key aspects of innovative robotic devices for endoluminal procedures approaching issues, such as: i) capsules and novel flexible endoscopic/endocavity devices, ii) robotic navigation for active endoscopic probes and robots, iii) smart mechanisms for actuation and therapy delivery, iv) sensing and therapeutic modules and also iv) micro- and nano-scale devices.
</p><p align="justify">We will call for posters and the best contribution will be selected by the workshop attendees during the organized event; the winner will be announced by the end of the workshop. Contributions can be theoretical or experimental studies concerning the mentioned areas. Submission are open to any kind of endoluminal/endocavity robotic platform and device for advanced diagnosis and targeted therapy. Engineering designs, modelling and developments, also supported by experimentations in bench, ex-vivo and in-vivo conditions, will be presented. 
</p><p align="justify">The current and future challenges will be discussed in a panel discussion with all invited speakers and the workshop attendees.  In particular, to represent the current research trends, we will design a combination of invited talks: invited speakers will include experts with both engineering and medical backgrounds. Smart solutions for industrial endoscopic applications will be also considered in the proposed workshop.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Jun Tani (KAIST), Justus Piater (University of Innsbruck), Xavier Hinaut (INRIA), Kuniaki Noda (Nissan North America), Tadahiro Taniguchi (Ritsumeikan University), Komei Sugiura (NICT)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Towards a Unified Workflow for Multi¬contact Motion on Legged Robots: Challenges in Planning, Optimization and Control
</h3>
<a href="http://homepages.laas.fr/nmansard/entracte/index.php?n=Publication.WorkshopIROS2016" target=_new>
http://homepages.laas.fr/nmansard/entracte/index.php?n=Publication.WorkshopIROS2016
</a>
<p align="justify">
Full Day Workshop FrFT10                                
<br>
Fri, Oct 14, 08:30-18:00, Room 107
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Steve Tonneau (LAAS), Timothy Bretl (Univ. of Illinois), Nicolas Mansard (LAAS), Igor Mordatch (Univ. of California)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Early contributions on multi contact locomotion for legged robots have underlined the complexity of planning, then controlling robot motions in cluttered environments. In both the robotics and computer-graphics community, a large variety of approaches have been recently proposed to tackle the problem, thus often targeting one specific aspect: 1) the planning of a feasible path for the robot; 2) the optimization of its trajectory; or 3) the feedback control of the robot during the execution of a dynamic motion. Integrating these different aspects is not only an engineering issue. It raises scientific questions in terms of robustness of the algorithms and performance requirements. The objective of this workshop is to gather people working in these fields and propose a debate on the combination of these various aspects into a functional workflow for robot motions in cluttered environments. Renowned speakers from the robotics and computer graphics field will present their work, and recommend the reading of selected papers prior the conference. This will provide the audience with the ability to prepare their venue and ask relevant questions that will be analyzed by student groups and discussed during dedicated debate sessions.
</p><!-- <p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Tenth International Cognitive Robotics Workshop
</h3>
<a href="http://www.cse.unsw.edu.au/~cogrob/2016/" target=_new>
http://www.cse.unsw.edu.au/~cogrob/2016/
</a>
<p align="justify">
Full Day Workshop FrFT11                                
<br>
Fri, Oct 14, 08:30-18:00, Room 108
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Mario Gianni (Sapienza University of Rome), David Rajaratnam (Univ. of New South Wales), Rachid Alami (LAAS), Vaishak Belle (Univ. of Toronto), Mehmet Dogar (Univ. of Leeds), Christian Dornhege (Univ. of Freiburg), Esra Erdam (Sabanci University), Alexander Ferrein (FH Aachen University of Applied Sciences), Fredrik Heintz (Linkoping University), Bernhard Hengst (Univ. of New South Wales), Piyush Khandelwal (Univ. of Texas), George Konidaris (Duke), Venkatraman Narayanan (Carnegie Mellon University), Daniele Nardi (Univ. of Rome “La Spaienza”), Maurice Pagnucco (Univ. of New South Wales), Volkan Patoglu (Sabanci University), Ron Petrick (Heriot-Watt University), Ken Satoh (National Institute of Informatcis and Sokendai), Stefan Schiffer (RWTH Aachen University), Michael Thielscher (Univ. of New South Wales), Fangkai Yang (Univ. of Texas at Austin), Shiqi Zhang (Univ. of Texas at Austin)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Research in robotics has traditionally emphasized low-level sensing and control tasks including sensory processing, path planning, and manipulator design and control. In contrast, research in cognitive robotics is concerned with endowing robots and software agents with higher level cognitive functions that enable them to reason, act and perceive in changing, incompletely known, and unpredictable environments. Such robots must, for example, be able to reason about goals, actions, when to perceive and what to look for, the cognitive states of other agents, time, collaborative task execution, etc. In short, cognitive robotics is concerned with integrating reasoning, perception and action with a uniform theoretical and implementation framework. 
The use of both software robots (softbots) and robotic artifacts in everyday life is on the upswing and we are seeing increasingly more examples of their use in society with commercial products around the corner and some already on the market. As interaction with humans increases, so does the demand for sophisticated robotic capabilities associated with deliberation and high-level cognitive functions. Combining results from traditional robotics disciplines with those from AI and cognitive science has and will continue to be central to research in cognitive robotics. 
This workshop aims to bring together researchers involved in all aspects of the theory and implementation of cognitive robots, to discuss current work and future directions. The workshop is concerned with foundational research questions on cognitive robotics, as well as robotic system design and robotic applications that utilize AI methods. 
</p><!-- <p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Folding in Robotics
</h3>
<a href="http://idealab.asu.edu/foldable_robotics/" target=_new>
http://idealab.asu.edu/foldable_robotics/
</a>
<p align="justify">
Full Day Workshop FrFT12                           
<br>
Fri, Oct 14, 08:30-18:00, Room 204~205
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Samuel Felton (Harvard University), Daniel Aukes (Arizona State University), Onur Ozcan (Bilkent University), Michael Tolley (UC San Diego), 
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Folding has a long history in art, mathematics, and biology. Now, researchers are taking lessons from these diverse fields and applying them to the next generation of robots. Already, folding has enabled inexpensive fabrication, transformable mechanisms, automated assembly techniques, and computational design tools. 'Folding in Robotics' is a hybrid workshop/tutorial in which the many aspects of robotic folding will be discussed and demonstrated. 
</p><p align="justify">
In the morning, researchers will explore, through presentations and discussion, the latest results and existing challenges in:
<ul>
<li>Materials and fabrication techniques
<li>Computational design tools
<li>Kinematic and mechanism design
-Robotic systems design
<li>Educational, artistic, and research applications
</ul>
In the afternoon, participants will experience the capabilities of folded robotics first-hand. By harnessing the inexpensive and rapid nature of folded fabrication, we will demonstrate how to build hinges and linkage systems, fabricate complex laminates, and design with computational tools. The tutorial will culminate with each participant building their own mechanism using paper and plastic
</p><!-- <p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
SPEAKERS
</i>
</p> -->
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Developing Advanced Robotics Applications with MATLAB and Simulink
</h3>
<a href="www.mathworks.com/iros2016" target=_new>
www.mathworks.com/iros2016
</a>
<p align="justify">
Half Day Workshop Morning FrH1T13                   
<br>
Fri, Oct 14, 08:30-12:30, Room 206~208
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Harshita Bhurat (MathWorks)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Historically, robotic engineers and scientists have faced several challenges to accelerate and streamline the design, prototyping, and verification of robotics systems. Robotic design requires modeling and analysis of different components; a process that includes understanding of the equations of motion and modeling complex electro-mechanical systems. Designers also require rapid prototyping capability of algorithms for path planning, path following, map representation, collision avoidance and localization depending on the mechanical structure of the robot. This workshop discusses how Model-Based Design aligns with the development of advanced robotics applications. It introduces basic design principles and the state-of-the-art prototyping techniques using MATLAB and Simulink to model, simulate, test and verify funcitonality on ROS-enabled robots and dynamics simulators. We will show different ways of deployment using automatic ROS node generation and testing on real low-cost hardware such as Arduino, Raspberry Pi and Beaglebone board.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
MathWorks Application Engineers, Robotics, Development Team and Technical Marketing Team
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>

<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Human Movement Understanding and Robotics
</h3>
<a href="http://typo.iwr.uni-heidelberg.de/groups/orb/conferences-workshops/iros2016-hmur/" target=_new>
http://typo.iwr.uni-heidelberg.de/groups/orb/conferences-workshops/iros2016-hmur/
</a>
<p align="justify">
Half Day Workshop Morning FrH1T15                 
<br>
Fri, Oct 14, 08:30-12:30, Room 203
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Emel Demircan (Human Performance and Robotics Laboratory), Manish Sreeenivasa (Optimization in Robotics and Biomechanics)
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
Robotics research has drawn much inspiration from humans as a system: in the design of the anthropomorphic aspects of manipulators, sensors, and actuators, the way it coordinates the motion of its body, and the higher level strategies of its realization of complex tasks and in interacting with the external environment. In recent years, robotics computational strategies have been seen to contribute significantly to the analysis of human motion and manipulation skills. The analyses have led to the advancements in the field of robotics, such as by allowing human¬ inspired capabilities in robots and simulated systems as well as the nature inspired techniques of robot learning through observation. Furthermore, they also allowed the deeper understanding of human body and its motion generation strategies. This half¬-day workshop on Human Movement Understanding and Robotics aims to gather, present, and discuss the state of the art of algorithms for modeling, analysis, control, and simulation of human movement and human¬-robot interaction that has experienced a major research interest within the robotics community. It covers aspects commonly associated with the technical committees on human movement understanding, biorobotics, whole¬ body control, and model¬-based optimization within the Robotics and Automation Society (RAS), including bioinspiration, biomimetics, haptics, as well as topics from biomechanics; including real¬time motion tracking, identification, and analysis, with applications in assistive robotics, sports medicine, rehabilitation, and orthopaedics. The main motivation and objectives of the workshop are as follows: 
<ol>
<li>The strategies of human motion control and synthesis and its use in: the analysis of optimized human motion generation, such as in sports and other tasks requiring precise motion and manipulation of human body dynamics; 
<li>The strategies of human motion reconstruction on engineered anthropomorphic systems, such as the humanoid, mobile manipulators, and simulated systems; 
<li>Human motion generation and task learning, which includes but not limited to: the strategies of generalization of learnt tasks to the learning of new tasks, resolution of human motor redundancy, human strategies in the handling of constraints; 
<li>Understanding human brain for motor control and rehabilitation; and 
<li>Understanding human locomotion and manipulation skills applicable in humanoid motion control. 
</ol>
This intersection of fields of study has been a rich ground for cross-¬fertilisation, where we see many members of our research community contributing significantly to both the fundamental techniques as well as the development of applications in this area. This half¬-day workshop is intended to highlight the latest work in this intersection and to strengthen the efforts to bridge the gap between robotics and biomechanics research. 
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Gerald Brantner (Stanford University), Jean-Paul Laumond (LAAS-CNRS), Matthew Howar (King’s College London), Ko Ayusawa (AIST), Jaeheung Park (Seoul National University), Emel Demircan (California State University), Manish Screenivasa (Univ. of Heidelberg)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<table border="0" cellspacing="0" cellpadding="0" width="85%" nowrap style="margin: auto">
<tr><td>
<h3>
Intelligent Instruments and Software for Future Medical Workspaces
</h3>
<a href="http://robotics.hanyang.ac.kr/main/main.php" target=_new>
http://robotics.hanyang.ac.kr/main/main.php
</a>
<p align="justify">
Half Day Workshop Afternoon FrH2T14                     
<br>
Fri, Oct 14, 13:30-18:00, Room 301
</p><p align="justify">
<b>Organizers</b>
</p><p align="justify">
<i>
Byung-Ju Yi (Hanyang University), Jae-sung Hong (DGIST) 
</i>
</p><p align="justify">
<b>Abstract</b>
</p><p align="justify">
For decades, a great deal of efforts to develop surgical robots have been conducted all over the world. However, only a few models have appeared in the market. Constant question to ourselves is what was the problem? This workshop aims at discussion on future direction of surgical robot technology. Such topics include design of improved end-effectors, full haptic and tactile feedback, surgical global positioning systems (GPS), modular design for rapid setup and breakdown, and reduced size and markedly reduced cost of surgical robots. Experts who performed successful collaboration among company, university, and research laboratory are also invited to speak how to translate technology from laboratory to medical workspace. Speakers consist of prestigious members of Asian Society on Computer Aided Surgery (ASCAS) and International Society of Computer Aided Surgery (ISCAS). This workshop will be held in conjunction with ACCAS (Asian Society on Computer Aided Surgery) 2016, which will be held during October 14-15, 2016. Thus, majority of ACCAS participants will join and entertain this workshop activity.
</p><p align="justify">
<b>Speakers</b>
</p><p align="justify">
<i>
Pierre Jannin (University of Rennes), Takeyoshi Dohi (University of Tokyo), Makoto Hashizume (Kyushu University), Guang-Zhong Yang (Imperial College London), Danail Stoyanov (University College London), Young Soo Kim (Hanyang University), Sungchul Kang (KIST)
</i>
</p>
</td></tr>
<tr><td>
<br style="line-height:150%;">
<a href="#top">RETURN TO THE TOP</a>
<br style="line-height:150%;">
<hr>
</td></tr>
</table>
<br><br>


<br><p align="justify"><br><p align="justify"><br><p align="justify"><br><p align="justify">

</body>
</html>


